[
    {
        "op_name": "sin",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2048; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 2, 16, 4), \"float32\"), compute: T.Buffer((16, 2, 16, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2048):\n            compute_1 = T.Buffer((2048,), data=compute.data)\n            data_1 = T.Buffer((2048,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            16,
            2,
            16,
            4
        ],
        "input_shape": "[[16, 2, 16, 4]]",
        "output_shape": "[[16, 2, 16, 4]]"
    },
    {
        "op_name": "adaptive_pool_max",
        "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 2040; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n      adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < (((((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) % 8) == 0) ? ((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) >> 3) : (((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) >> 3) + 1)) - (((ax0_ax1_fused_ax2_fused & 7) * 5) >> 3)); ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 2; ++rv1) {\n          adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)] = max(adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)], data[((((((ax0_ax1_fused_ax2_fused >> 3) * 80) + ((((ax0_ax1_fused_ax2_fused & 7) * 5) >> 3) * 16)) + (rv0 * 16)) + (ax3 * 2)) + rv1)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < ((((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) % 8) == 0) ? (((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) >> 3) : ((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) >> 3) + 1)) - ((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < 2; ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))], data[((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) >> 4) * 80) + (((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) >> 3) * 16)) + (rv0 * 16)) + ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 2)) + rv1)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 17, 5, 16), \"float32\"), adaptive_pool_max: T.Buffer((15, 17, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(2040):\n            for ax3 in range(8):\n                adaptive_pool_max_1 = T.Buffer((16320,), data=adaptive_pool_max.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused * 8 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(T.Let(T.Let(T.Let(T.Select(cse_var_3 % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 // 8, where={cse_var_1: cse_var_3 // 8}), where={cse_var_3: cse_var_2 + 5}), where={cse_var_2: ax0_ax1_fused_ax2_fused % 8 * 5}), 2):\n                    cse_var_2 = T.int32()\n                    cse_var_3 = T.int32()\n                    cse_var_1 = T.int32()\n                    cse_var_4: T.int32 = ax0_ax1_fused_ax2_fused * 8 + ax3\n                    data_1 = T.Buffer((20400,), data=data.data)\n                    adaptive_pool_max_1[cse_var_4] = T.max(adaptive_pool_max_1[cse_var_4], data_1[ax0_ax1_fused_ax2_fused // 8 * 80 + ax0_ax1_fused_ax2_fused % 8 * 5 // 8 * 16 + rv0 * 16 + ax3 * 2 + rv1])",
        "op_args": [
            15,
            17,
            5,
            16
        ],
        "input_shape": "[[15, 17, 5, 16]]",
        "output_shape": "[[15, 17, 8, 8]]"
    },
    {
        "op_name": "abs",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 48; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3 = 0; i3 < 12; ++i3) {\n        compute[(((i0_i1_fused * 48) + (i2 * 12)) + i3)] = fabsf(data[(((i0_i1_fused * 48) + (i2 * 12)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 3, 4, 12), \"float32\"), compute: T.Buffer((16, 3, 4, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(48):\n            for i2, i3 in T.grid(4, 12):\n                cse_var_1: T.int32 = i0_i1_fused * 48 + i2 * 12 + i3\n                compute_1 = T.Buffer((2304,), data=compute.data)\n                data_1 = T.Buffer((2304,), data=data.data)\n                compute_1[cse_var_1] = T.fabs(data_1[cse_var_1])",
        "op_args": [
            16,
            3,
            4,
            12
        ],
        "input_shape": "[[16, 3, 4, 12]]",
        "output_shape": "[[16, 3, 4, 12]]"
    },
    {
        "op_name": "cos",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3094; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = cosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = __cosf(data[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 13, 7), \"float32\"), compute: T.Buffer((17, 2, 13, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3094):\n            compute_1 = T.Buffer((3094,), data=compute.data)\n            data_1 = T.Buffer((3094,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cos(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            17,
            2,
            13,
            7
        ],
        "input_shape": "[[17, 2, 13, 7]]",
        "output_shape": "[[17, 2, 13, 7]]"
    },
    {
        "op_name": "atan",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1428; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 9; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 9) + i3_s)] = atanf(data[((i0_i1_fused_i2_fused * 9) + i3_s)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 12, 7, 9), \"float32\"), compute: T.Buffer((17, 12, 7, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1428):\n            for i3_s in range(9):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 9 + i3_s\n                compute_1 = T.Buffer((12852,), data=compute.data)\n                data_1 = T.Buffer((12852,), data=data.data)\n                compute_1[cse_var_1] = T.atan(data_1[cse_var_1])",
        "op_args": [
            17,
            12,
            7,
            9
        ],
        "input_shape": "[[17, 12, 7, 9]]",
        "output_shape": "[[17, 12, 7, 9]]"
    },
    {
        "op_name": "add",
        "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 20; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 9; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n          T_add[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)] = (data[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)] + data_1[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 10, 9, 18), \"float32\"), data_1: T.Buffer((20, 10, 9, 18), \"float32\"), T_add: T.Buffer((20, 10, 9, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(20):\n            for ax1, ax2, ax3 in T.grid(10, 9, 18):\n                cse_var_1: T.int32 = ax0 * 1620 + ax1 * 162 + ax2 * 18 + ax3\n                T_add_1 = T.Buffer((32400,), data=T_add.data)\n                data_2 = T.Buffer((32400,), data=data.data)\n                data_3 = T.Buffer((32400,), data=data_1.data)\n                T_add_1[cse_var_1] = data_2[cse_var_1] + data_3[cse_var_1]",
        "op_args": [
            20,
            10,
            9,
            18
        ],
        "input_shape": "[[20, 10, 9, 18], [20, 10, 9, 18]]",
        "output_shape": "[[20, 10, 9, 18]]"
    },
    {
        "op_name": "adaptive_pool_avg",
        "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 195; ++ax0_ax1_fused) {\n    float adaptive_pool_sum[8];\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n        adaptive_pool_sum[ax3] = 0.000000e+00f;\n        for (int32_t rv0 = 0; rv0 < ((((ax2 + 1) % 8) == 0) ? ((ax2 + 1) >> 3) : (((ax2 + 1) >> 3) + 1)); ++rv0) {\n          for (int32_t rv1 = 0; rv1 < ((((((ax3 * 2) + 2) % 8) == 0) ? ((ax3 + 1) >> 2) : (((ax3 + 1) >> 2) + 1)) - (ax3 >> 2)); ++rv1) {\n            adaptive_pool_sum[ax3] = (adaptive_pool_sum[ax3] + data[((((ax0_ax1_fused * 2) + (rv0 * 2)) + (ax3 >> 2)) + rv1)]);\n          }\n        }\n      }\n      for (int32_t ax3_1 = 0; ax3_1 < 8; ++ax3_1) {\n        adaptive_pool_avg[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3_1)] = (adaptive_pool_sum[ax3_1] / (((float)((((ax2 + 1) % 8) == 0) ? ((ax2 + 1) >> 3) : (((ax2 + 1) >> 3) + 1))) * ((float)((((((ax3_1 * 2) + 2) % 8) == 0) ? ((ax3_1 + 1) >> 2) : (((ax3_1 + 1) >> 2) + 1)) - (ax3_1 >> 2)))));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] / (((float)(((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) % 8) == 0) ? (((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) >> 3) : ((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) >> 3) + 1))) * ((float)(((((((((int)threadIdx.x) & 7) * 2) + 2) % 8) == 0) ? (((((int)threadIdx.x) & 7) + 1) >> 2) : ((((((int)threadIdx.x) & 7) + 1) >> 2) + 1)) - ((((int)threadIdx.x) & 7) >> 2)))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < (((((((((int)blockIdx.x) & 1) * 4) + (((int)threadIdx.x) >> 3)) + 1) % 8) == 0) ? ((((((int)threadIdx.x) + 8) >> 5) + (((int)blockIdx.x) & 1)) >> 1) : (((((((int)threadIdx.x) + 8) >> 5) + (((int)blockIdx.x) & 1)) >> 1) + 1)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((int)threadIdx.x) & 7) * 2) + 2) % 8) == 0) ? (((((int)threadIdx.x) & 7) + 1) >> 2) : ((((((int)threadIdx.x) & 7) + 1) >> 2) + 1)) - ((((int)threadIdx.x) & 7) >> 2)); ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data[(((((((int)blockIdx.x) >> 1) * 2) + (rv0 * 2)) + ((((int)threadIdx.x) & 7) >> 2)) + rv1)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 13, 1, 2), \"float32\"), adaptive_pool_avg: T.Buffer((15, 13, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(195):\n            adaptive_pool_sum = T.allocate([8], \"float32\", \"global\")\n            for ax2 in range(8):\n                adaptive_pool_sum_1 = T.Buffer((8,), data=adaptive_pool_sum, align=32)\n                for ax3 in range(8):\n                    adaptive_pool_sum_1[ax3] = T.float32(0)\n                    for rv0, rv1 in T.grid(T.Let(T.Select((ax2 + 1) % 8 == 0, cse_var_1, cse_var_1 + 1), where={cse_var_1: (ax2 + 1) // 8}), T.Let(T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_2, cse_var_2 + 1) - ax3 // 4, where={cse_var_2: (ax3 + 1) // 4})):\n                        cse_var_1 = T.int32()\n                        cse_var_2 = T.int32()\n                        data_1 = T.Buffer((390,), data=data.data)\n                        adaptive_pool_sum_1[ax3] = adaptive_pool_sum_1[ax3] + data_1[ax0_ax1_fused * 2 + rv0 * 2 + ax3 // 4 + rv1]\n                for ax3 in range(8):\n                    cse_var_5: T.int32 = ax2 + 1\n                    cse_var_4: T.int32 = cse_var_5 // 8\n                    cse_var_3: T.int32 = (ax3 + 1) // 4\n                    adaptive_pool_avg_1 = T.Buffer((12480,), data=adaptive_pool_avg.data)\n                    adaptive_pool_avg_1[ax0_ax1_fused * 64 + ax2 * 8 + ax3] = adaptive_pool_sum_1[ax3] / (T.Cast(\"float32\", T.Select(cse_var_5 % 8 == 0, cse_var_4, cse_var_4 + 1)) * T.Cast(\"float32\", T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_3, cse_var_3 + 1) - ax3 // 4))",
        "op_args": [
            15,
            13,
            1,
            2
        ],
        "input_shape": "[[15, 13, 1, 2]]",
        "output_shape": "[[15, 13, 8, 8]]"
    },
    {
        "op_name": "sum",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[27];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 2210; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 27; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 27) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 0.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 1865; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 16) + (((int)threadIdx.x) >> 1)) < 29835) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 15, 18, 17), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([27], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((27,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(27):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(2210, 27):\n            data_1 = T.Buffer((59670,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 27 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(27):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]",
        "op_args": [
            13,
            15,
            18,
            17
        ],
        "input_shape": "[[13, 15, 18, 17]]",
        "output_shape": "[[]]"
    },
    {
        "op_name": "fast_softmax",
        "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 260; ++i0_i1_fused) {\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      T_softmax_maxelem[0] = -3.402823e+38f;\n      for (int32_t k = 0; k < 15; ++k) {\n        T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[(((i0_i1_fused * 45) + (i2 * 15)) + k)]);\n      }\n      T_softmax_expsum[0] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 15; ++k_1) {\n          int32_t v_ = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0])));\n      }\n      for (int32_t i3_s = 0; i3_s < 15; ++i3_s) {\n          int32_t v__1 = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_norm[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0])) / T_softmax_expsum[0]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 195) {\n    T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 15; ++k) {\n    if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 195) {\n        int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(52) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)])) / T_softmax_expsum[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) < 195) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 15; ++k) {\n    if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) < 195) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 960) + (((int)threadIdx.x) * 15)) + k)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 20, 3, 15), \"float32\"), T_softmax_norm: T.Buffer((13, 20, 3, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(260):\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i2 in range(3):\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((11700,), data=data.data)\n                for k in range(15):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0_i1_fused * 45 + i2 * 15 + k])\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(15):\n                    cse_var_1: T.int32 = i0_i1_fused * 45 + i2 * 15 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[0])\n                for i3_s in range(15):\n                    cse_var_2: T.int32 = i0_i1_fused * 45 + i2 * 15 + i3_s\n                    T_softmax_norm_1 = T.Buffer((11700,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_2] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[0]) / T_softmax_expsum_1[0]",
        "op_args": [
            13,
            20,
            3,
            15
        ],
        "input_shape": "[[13, 20, 3, 15]]",
        "output_shape": "[[13, 20, 3, 15]]"
    },
    {
        "op_name": "acos",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1496; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = acosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(17) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 17, 1, 11), \"float32\"), compute: T.Buffer((8, 17, 1, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1496):\n            compute_1 = T.Buffer((1496,), data=compute.data)\n            data_1 = T.Buffer((1496,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.acos(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            8,
            17,
            1,
            11
        ],
        "input_shape": "[[8, 17, 1, 11]]",
        "output_shape": "[[8, 17, 1, 11]]"
    },
    {
        "op_name": "asin",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 9; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 7; ++i3_s) {\n          compute[((((i0 * 847) + (i1 * 77)) + (i2 * 7)) + i3_s)] = asinf(data[((((i0 * 847) + (i1 * 77)) + (i2 * 7)) + i3_s)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 7623) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 11, 11, 7), \"float32\"), compute: T.Buffer((9, 11, 11, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(9):\n            for i1, i2, i3_s in T.grid(11, 11, 7):\n                cse_var_1: T.int32 = i0 * 847 + i1 * 77 + i2 * 7 + i3_s\n                compute_1 = T.Buffer((7623,), data=compute.data)\n                data_1 = T.Buffer((7623,), data=data.data)\n                compute_1[cse_var_1] = T.asin(data_1[cse_var_1])",
        "op_args": [
            9,
            11,
            11,
            7
        ],
        "input_shape": "[[9, 11, 11, 7]]",
        "output_shape": "[[9, 11, 11, 7]]"
    },
    {
        "op_name": "batch_to_space_nd",
        "c_code": "void default_function_kernel(float* T_strided_slice, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 3; ++ax0) {\n    float T_transpose[3040];\n    float T_reshape[80];\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n        for (int32_t ax1_1 = 0; ax1_1 < 2; ++ax1_1) {\n          for (int32_t ax4 = 0; ax4 < 2; ++ax4) {\n            for (int32_t ax5 = 0; ax5 < 20; ++ax5) {\n              T_reshape[(((ax1_1 * 40) + (ax4 * 20)) + ax5)] = data[((((((ax2 * 4560) + (ax1_1 * 2280)) + (ax0 * 760)) + (ax1 * 40)) + (ax4 * 20)) + ax5)];\n            }\n          }\n        }\n        for (int32_t ax3 = 0; ax3 < 2; ++ax3) {\n          for (int32_t ax4_1 = 0; ax4_1 < 2; ++ax4_1) {\n            for (int32_t ax5_1 = 0; ax5_1 < 20; ++ax5_1) {\n              T_transpose[(((((ax1 * 160) + (ax2 * 80)) + (ax3 * 40)) + (ax4_1 * 20)) + ax5_1)] = T_reshape[(((ax4_1 * 40) + (ax3 * 20)) + ax5_1)];\n            }\n          }\n        }\n      }\n    }\n    for (int32_t ax1_2 = 0; ax1_2 < 38; ++ax1_2) {\n      for (int32_t ax2_1 = 0; ax2_1 < 4; ++ax2_1) {\n        for (int32_t ax3_1 = 0; ax3_1 < 20; ++ax3_1) {\n          T_strided_slice[((((ax0 * 3040) + (ax1_2 * 80)) + (ax2_1 * 20)) + ax3_1)] = T_transpose[(((ax1_2 * 80) + (ax2_1 * 20)) + ax3_1)];\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ data) {\n  T_strided_slice[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) % 20) / 10) * 4560) + (((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 10) / 5) * 2280)) + ((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) / 20) * 40)) + (((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) % 10) / 5) * 20)) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 20))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 19, 2, 20), \"float32\"), T_strided_slice: T.Buffer((3, 38, 4, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(3):\n            T_transpose = T.allocate([3040], \"float32\", \"global\")\n            T_reshape = T.allocate([80], \"float32\", \"global\")\n            for ax1, ax2 in T.grid(19, 2):\n                T_reshape_1 = T.Buffer((80,), data=T_reshape)\n                for ax1_1, ax4, ax5 in T.grid(2, 2, 20):\n                    cse_var_1: T.int32 = ax4 * 20\n                    data_1 = T.Buffer((11400,), data=data.data)\n                    T_reshape_1[ax1_1 * 40 + cse_var_1 + ax5] = data_1[ax2 * 4560 + ax1_1 * 2280 + ax0 * 760 + ax1 * 40 + cse_var_1 + ax5]\n                for ax3, ax4, ax5 in T.grid(2, 2, 20):\n                    T_transpose_1 = T.Buffer((3040,), data=T_transpose)\n                    T_transpose_1[ax1 * 160 + ax2 * 80 + ax3 * 40 + ax4 * 20 + ax5] = T_reshape_1[ax4 * 40 + ax3 * 20 + ax5]\n            for ax1, ax2, ax3 in T.grid(38, 4, 20):\n                cse_var_3: T.int32 = ax1 * 80\n                cse_var_2: T.int32 = ax2 * 20\n                T_strided_slice_1 = T.Buffer((9120,), data=T_strided_slice.data)\n                T_transpose_1 = T.Buffer((3040,), data=T_transpose)\n                T_strided_slice_1[ax0 * 3040 + cse_var_3 + cse_var_2 + ax3] = T_transpose_1[cse_var_3 + cse_var_2 + ax3]",
        "op_args": [
            15,
            19,
            2,
            20
        ],
        "input_shape": "[[15, 19, 2, 20]]",
        "output_shape": "[[3, 38, 4, 20]]"
    },
    {
        "op_name": "global_pool_max",
        "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 22; ++ax0_ax1_fused) {\n    adaptive_pool_max[ax0_ax1_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 4; ++rv0) {\n      adaptive_pool_max[ax0_ax1_fused] = max(adaptive_pool_max[ax0_ax1_fused], data[((ax0_ax1_fused * 4) + rv0)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(22) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 4; ++rv0) {\n    adaptive_pool_max[((int)threadIdx.x)] = max(adaptive_pool_max[((int)threadIdx.x)], data[((((int)threadIdx.x) * 4) + rv0)]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 2, 4, 1), \"float32\"), adaptive_pool_max: T.Buffer((11, 2, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(22):\n            adaptive_pool_max_1 = T.Buffer((22,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0 in range(4):\n                data_1 = T.Buffer((88,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused], data_1[ax0_ax1_fused * 4 + rv0])",
        "op_args": [
            11,
            2,
            4,
            1
        ],
        "input_shape": "[[11, 2, 4, 1]]",
        "output_shape": "[[11, 2, 1, 1]]"
    },
    {
        "op_name": "asinh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 240; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 19; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 19) + i3)] = asinhf(data[((i0_i1_fused_i2_fused * 19) + i3)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 4, 15, 19), \"float32\"), compute: T.Buffer((4, 4, 15, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(240):\n            for i3 in range(19):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 19 + i3\n                compute_1 = T.Buffer((4560,), data=compute.data)\n                data_1 = T.Buffer((4560,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])",
        "op_args": [
            4,
            4,
            15,
            19
        ],
        "input_shape": "[[4, 4, 15, 19]]",
        "output_shape": "[[4, 4, 15, 19]]"
    },
    {
        "op_name": "global_pool_avg",
        "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 5; ++ax0) {\n    float adaptive_pool_sum[1];\n    for (int32_t ax1 = 0; ax1 < 8; ++ax1) {\n      adaptive_pool_sum[0] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < 15; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 15; ++rv1) {\n          adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[((((ax0 * 1800) + (ax1 * 225)) + (rv0 * 15)) + rv1)]);\n        }\n      }\n      adaptive_pool_avg[((ax0 * 8) + ax1)] = (adaptive_pool_sum[0] * 4.444444e-03f);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] * 4.444444e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 15; ++rv0) {\n    for (int rv1 = 0; rv1 < 15; ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 4500) + (((int)threadIdx.x) * 225)) + (rv0 * 15)) + rv1)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 8, 15, 15), \"float32\"), adaptive_pool_avg: T.Buffer((5, 8, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(5):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            for ax1 in range(8):\n                adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n                adaptive_pool_sum_1[0] = T.float32(0)\n                for rv0, rv1 in T.grid(15, 15):\n                    data_1 = T.Buffer((9000,), data=data.data)\n                    adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0 * 1800 + ax1 * 225 + rv0 * 15 + rv1]\n                adaptive_pool_avg_1 = T.Buffer((40,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 8 + ax1] = adaptive_pool_sum_1[0] * T.float32(0.0044444444444444444)",
        "op_args": [
            5,
            8,
            15,
            15
        ],
        "input_shape": "[[5, 8, 15, 15]]",
        "output_shape": "[[5, 8, 1, 1]]"
    },
    {
        "op_name": "atanh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 11; ++i3) {\n          compute[((((i0 * 297) + (i1 * 33)) + (i2 * 11)) + i3)] = atanhf(data[((((i0 * 297) + (i1 * 33)) + (i2 * 11)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(33) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 33) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 33) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 9, 3, 11), \"float32\"), compute: T.Buffer((18, 9, 3, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(18):\n            for i1, i2, i3 in T.grid(9, 3, 11):\n                cse_var_1: T.int32 = i0 * 297 + i1 * 33 + i2 * 11 + i3\n                compute_1 = T.Buffer((5346,), data=compute.data)\n                data_1 = T.Buffer((5346,), data=data.data)\n                compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])",
        "op_args": [
            18,
            9,
            3,
            11
        ],
        "input_shape": "[[18, 9, 3, 11]]",
        "output_shape": "[[18, 9, 3, 11]]"
    },
    {
        "op_name": "dilate",
        "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2464; ++i0_i1_fused_i2_fused_i3_fused) {\n    DilatedInput[i0_i1_fused_i2_fused_i3_fused] = data[i0_i1_fused_i2_fused_i3_fused];\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 11, 16, 7), \"float32\"), DilatedInput: T.Buffer((2, 11, 16, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2464):\n            DilatedInput_1 = T.Buffer((2464,), data=DilatedInput.data)\n            data_1 = T.Buffer((2464,), data=data.data)\n            DilatedInput_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused]",
        "op_args": [
            2,
            11,
            16,
            7
        ],
        "input_shape": "[[2, 11, 16, 7]]",
        "output_shape": "[[2, 11, 16, 7]]"
    },
    {
        "op_name": "ceil",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 88; ++i0_i1_fused) {\n    for (int32_t i3 = 0; i3 < 17; ++i3) {\n      compute[((i0_i1_fused * 17) + i3)] = ceilf(data[((i0_i1_fused * 17) + i3)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 187) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 11, 1, 17), \"float32\"), compute: T.Buffer((8, 11, 1, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(88):\n            for i3 in range(17):\n                cse_var_1: T.int32 = i0_i1_fused * 17 + i3\n                compute_1 = T.Buffer((1496,), data=compute.data)\n                data_1 = T.Buffer((1496,), data=data.data)\n                compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])",
        "op_args": [
            8,
            11,
            1,
            17
        ],
        "input_shape": "[[8, 11, 1, 17]]",
        "output_shape": "[[8, 11, 1, 17]]"
    },
    {
        "op_name": "flatten",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 17; ++i) {\n    for (int32_t j = 0; j < 270; ++j) {\n      compute[((i * 270) + j)] = data[((i * 270) + j)];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 3, 9, 10), \"float32\"), compute: T.Buffer((17, 270), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(17):\n            for j in range(270):\n                cse_var_1: T.int32 = i * 270 + j\n                compute_1 = T.Buffer((4590,), data=compute.data)\n                data_1 = T.Buffer((4590,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1]",
        "op_args": [
            17,
            3,
            9,
            10
        ],
        "input_shape": "[[17, 3, 9, 10]]",
        "output_shape": "[[17, 270]]"
    },
    {
        "op_name": "erf",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 312; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = erff(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 6, 1, 4), \"float32\"), compute: T.Buffer((13, 6, 1, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(312):\n            compute_1 = T.Buffer((312,), data=compute.data)\n            data_1 = T.Buffer((312,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.erf(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            13,
            6,
            1,
            4
        ],
        "input_shape": "[[13, 6, 1, 4]]",
        "output_shape": "[[13, 6, 1, 4]]"
    },
    {
        "op_name": "fifo_buffer",
        "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 255; ++i_j_fused) {\n    for (int32_t k = 0; k < 7; ++k) {\n      for (int32_t l = 0; l < 18; ++l) {\n        new_buffer[(((i_j_fused * 126) + (k * 18)) + l)] = data[(((i_j_fused * 126) + (k * 18)) + l)];\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 17, 7, 18), \"float32\"), buffer: T.Buffer((15, 17, 7, 18), \"float32\"), new_buffer: T.Buffer((15, 17, 7, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(255):\n            for k, l in T.grid(7, 18):\n                cse_var_1: T.int32 = i_j_fused * 126 + k * 18 + l\n                new_buffer_1 = T.Buffer((32130,), data=new_buffer.data)\n                data_1 = T.Buffer((32130,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]",
        "op_args": [
            15,
            17,
            7,
            18
        ],
        "input_shape": "[[15, 17, 7, 18], [15, 17, 7, 18]]",
        "output_shape": "[[15, 17, 7, 18]]"
    },
    {
        "op_name": "exp",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 19; ++i1) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3 = 0; i3 < 10; ++i3) {\n        compute[(((i1 * 40) + (i2 * 10)) + i3)] = expf(data[(((i1 * 40) + (i2 * 10)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 19, 4, 10), \"float32\"), compute: T.Buffer((1, 19, 4, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(19, 4, 10):\n            cse_var_1: T.int32 = i1 * 40 + i2 * 10 + i3\n            compute_1 = T.Buffer((760,), data=compute.data)\n            data_1 = T.Buffer((760,), data=data.data)\n            compute_1[cse_var_1] = T.exp(data_1[cse_var_1])",
        "op_args": [
            1,
            19,
            4,
            10
        ],
        "input_shape": "[[1, 19, 4, 10]]",
        "output_shape": "[[1, 19, 4, 10]]"
    },
    {
        "op_name": "fast_erf",
        "c_code": "void default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 648; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 6; ++ax3) {\n      T_fast_erf[((ax0_ax1_fused_ax2_fused * 6) + ax3)] = ((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_fast_erf, float* __restrict__ data) {\n  T_fast_erf[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 12, 6, 6), \"float32\"), T_fast_erf: T.Buffer((9, 12, 6, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(648):\n            for ax3 in range(6):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 6 + ax3\n                T_fast_erf_1 = T.Buffer((3888,), data=T_fast_erf.data)\n                data_1 = T.Buffer((3888,), data=data.data)\n                T_fast_erf_1[cse_var_1] = T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-2.7261423674040941e-10) + T.float32(2.7706814620387377e-08)) + T.float32(-2.101023937939317e-06)) + T.float32(-5.6925062381196767e-05)) + T.float32(-0.00073499063728377223)) + T.float32(-0.0029545999132096767)) + T.float32(-0.016096033155918121)) / (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-1.4566071513399947e-05) + T.float32(-0.00021337404905352741)) + T.float32(-0.001682827016338706)) + T.float32(-0.0073733292520046234)) + T.float32(-0.014264739118516445))",
        "op_args": [
            9,
            12,
            6,
            6
        ],
        "input_shape": "[[9, 12, 6, 6]]",
        "output_shape": "[[9, 12, 6, 6]]"
    },
    {
        "op_name": "depth_to_space",
        "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 504; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 6; ++i3) {\n      depth_to_space[((i0_i1_fused_i2_fused * 6) + i3)] = data[((((((i0_i1_fused_i2_fused / 36) * 270) + (((i0_i1_fused_i2_fused % 36) % 2) * 108)) + ((i3 % 2) * 54)) + (((i0_i1_fused_i2_fused % 36) / 2) * 3)) + (i3 / 2))];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) >> 2) * 270) + (((((((int)blockIdx.x) & 3) * 9) + (((int)threadIdx.x) / 6)) % 2) * 108)) + (((((int)threadIdx.x) % 6) % 2) * 54)) + (((((((int)blockIdx.x) & 3) * 9) + (((int)threadIdx.x) / 6)) / 2) * 3)) + ((((int)threadIdx.x) % 6) / 2))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 5, 18, 3), \"float32\"), depth_to_space: T.Buffer((14, 1, 36, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(504):\n            for i3 in range(6):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused % 36\n                depth_to_space_1 = T.Buffer((3024,), data=depth_to_space.data)\n                data_1 = T.Buffer((3780,), data=data.data)\n                depth_to_space_1[i0_i1_fused_i2_fused * 6 + i3] = data_1[i0_i1_fused_i2_fused // 36 * 270 + T.truncmod(cse_var_1, 2) * 108 + T.truncmod(i3, 2) * 54 + T.Div(cse_var_1, 2) * 3 + T.Div(i3, 2)]",
        "op_args": [
            14,
            5,
            18,
            3
        ],
        "input_shape": "[[14, 5, 18, 3]]",
        "output_shape": "[[14, 1, 36, 6]]"
    },
    {
        "op_name": "fast_exp",
        "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 15; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n            int32_t v_ = ((int32_t)(floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_fast_exp[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 19, 2, 16), \"float32\"), T_fast_exp: T.Buffer((15, 19, 2, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(15):\n            for ax1, ax2, ax3 in T.grid(19, 2, 16):\n                cse_var_1: T.int32 = ax0 * 608 + ax1 * 32 + ax2 * 16 + ax3\n                T_fast_exp_1 = T.Buffer((9120,), data=T_fast_exp.data)\n                data_1 = T.Buffer((9120,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])",
        "op_args": [
            15,
            19,
            2,
            16
        ],
        "input_shape": "[[15, 19, 2, 16]]",
        "output_shape": "[[15, 19, 2, 16]]"
    },
    {
        "op_name": "fast_tanh",
        "c_code": "void default_function_kernel(float* T_fast_tanh, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 252; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 12; ++ax3) {\n        T_fast_tanh[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)] = ((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_fast_tanh, float* __restrict__ data) {\n  T_fast_tanh[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 14, 2, 12), \"float32\"), T_fast_tanh: T.Buffer((18, 14, 2, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(252):\n            for ax2, ax3 in T.grid(2, 12):\n                cse_var_1: T.int32 = ax0_ax1_fused * 24 + ax2 * 12 + ax3\n                T_fast_tanh_1 = T.Buffer((6048,), data=T_fast_tanh.data)\n                data_1 = T.Buffer((6048,), data=data.data)\n                T_fast_tanh_1[cse_var_1] = T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(-2.76076847742355e-16) + T.float32(2.0001879048247699e-13)) + T.float32(-8.60467152213735e-11)) + T.float32(5.1222970903711401e-08)) + T.float32(1.4857223571797901e-05)) + T.float32(0.00063726192887543596)) + T.float32(0.0048935245589178597)) / (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(1.1982583946670199e-06) + T.float32(0.000118534705686654)) + T.float32(0.0022684346324390002)) + T.float32(0.0048935251855438504))",
        "op_args": [
            18,
            14,
            2,
            12
        ],
        "input_shape": "[[18, 14, 2, 12]]",
        "output_shape": "[[18, 14, 2, 12]]"
    },
    {
        "op_name": "flip",
        "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 8; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 13; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 4; ++ax3) {\n        T_reverse_sequence[(((ax0_ax1_fused * 52) + (ax2 * 4)) + ax3)] = data[((((((ax0_ax1_fused & 1) * 52) + (ax2 * 4)) + ax3) + 312) - ((ax0_ax1_fused >> 1) * 104))];\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(13) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) & 7) * 13) + ((int)threadIdx.x)) + 312) - ((((int)blockIdx.x) >> 3) * 104))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 2, 13, 4), \"float32\"), T_reverse_sequence: T.Buffer((4, 2, 13, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(8):\n            for ax2, ax3 in T.grid(13, 4):\n                cse_var_1: T.int32 = ax2 * 4\n                T_reverse_sequence_1 = T.Buffer((416,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((416,), data=data.data)\n                T_reverse_sequence_1[ax0_ax1_fused * 52 + cse_var_1 + ax3] = data_1[ax0_ax1_fused % 2 * 52 + cse_var_1 + ax3 + 312 - ax0_ax1_fused // 2 * 104]",
        "op_args": [
            4,
            2,
            13,
            4
        ],
        "input_shape": "[[4, 2, 13, 4]]",
        "output_shape": "[[4, 2, 13, 4]]"
    },
    {
        "op_name": "floor",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 594; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 10; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 10) + i3)] = floorf(data[((i0_i1_fused_i2_fused * 10) + i3)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(15) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 18, 11, 10), \"float32\"), compute: T.Buffer((3, 18, 11, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(594):\n            for i3 in range(10):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 10 + i3\n                compute_1 = T.Buffer((5940,), data=compute.data)\n                data_1 = T.Buffer((5940,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])",
        "op_args": [
            3,
            18,
            11,
            10
        ],
        "input_shape": "[[3, 18, 11, 10]]",
        "output_shape": "[[3, 18, 11, 10]]"
    },
    {
        "op_name": "isnan",
        "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 112; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 19; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 5; ++i3_s) {\n        compute[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)] = ((int8_t)(data[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)] != data[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)]));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 665) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 8, 19, 5), \"float32\"), compute: T.Buffer((14, 8, 19, 5), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(112):\n            for i2, i3_s in T.grid(19, 5):\n                cse_var_1: T.int32 = i0_i1_fused * 95 + i2 * 5 + i3_s\n                compute_1 = T.Buffer((10640,), \"int8\", data=compute.data)\n                data_1 = T.Buffer((10640,), data=data.data)\n                compute_1[cse_var_1] = T.Cast(\"int8\", T.isnan(data_1[cse_var_1]))",
        "op_args": [
            14,
            8,
            19,
            5
        ],
        "input_shape": "[[14, 8, 19, 5]]",
        "output_shape": "[[14, 8, 19, 5]]"
    },
    {
        "op_name": "log",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 3; ++i0) {\n    for (int32_t i1 = 0; i1 < 18; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 1836) + (i1 * 102)) + (i2 * 17)) + i3)] = logf(data[((((i0 * 1836) + (i1 * 102)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(51) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = __logf(data[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 18, 6, 17), \"float32\"), compute: T.Buffer((3, 18, 6, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(3):\n            for i1, i2, i3 in T.grid(18, 6, 17):\n                cse_var_1: T.int32 = i0 * 1836 + i1 * 102 + i2 * 17 + i3\n                compute_1 = T.Buffer((5508,), data=compute.data)\n                data_1 = T.Buffer((5508,), data=data.data)\n                compute_1[cse_var_1] = T.log(data_1[cse_var_1])",
        "op_args": [
            3,
            18,
            6,
            17
        ],
        "input_shape": "[[3, 18, 6, 17]]",
        "output_shape": "[[3, 18, 6, 17]]"
    },
    {
        "op_name": "log10",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 42; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      for (int32_t i3 = 0; i3 < 6; ++i3) {\n        compute[(((i0_i1_fused * 18) + (i2 * 6)) + i3)] = log10f(data[(((i0_i1_fused * 18) + (i2 * 6)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 6, 3, 6), \"float32\"), compute: T.Buffer((7, 6, 3, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(42):\n            for i2, i3 in T.grid(3, 6):\n                cse_var_1: T.int32 = i0_i1_fused * 18 + i2 * 6 + i3\n                compute_1 = T.Buffer((756,), data=compute.data)\n                data_1 = T.Buffer((756,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])",
        "op_args": [
            7,
            6,
            3,
            6
        ],
        "input_shape": "[[7, 6, 3, 6]]",
        "output_shape": "[[7, 6, 3, 6]]"
    },
    {
        "op_name": "log2",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i3 = 0; i3 < 13; ++i3) {\n        compute[(((i0 * 104) + (i1 * 13)) + i3)] = log2f(data[(((i0 * 104) + (i1 * 13)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 143) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 8, 1, 13), \"float32\"), compute: T.Buffer((11, 8, 1, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i3 in T.grid(8, 13):\n                cse_var_1: T.int32 = i0 * 104 + i1 * 13 + i3\n                compute_1 = T.Buffer((1144,), data=compute.data)\n                data_1 = T.Buffer((1144,), data=data.data)\n                compute_1[cse_var_1] = T.log2(data_1[cse_var_1])",
        "op_args": [
            11,
            8,
            1,
            13
        ],
        "input_shape": "[[11, 8, 1, 13]]",
        "output_shape": "[[11, 8, 1, 13]]"
    },
    {
        "op_name": "max",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[22];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 22; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 330; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 22; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 22) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 22; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 12; ++k0) {\n    for (int k1 = 0; k1 < 5; ++k1) {\n      for (int k2 = 0; k2 < 11; ++k2) {\n        for (int k3 = 0; k3 < 11; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 605) + (k1 * 121)) + (k2 * 11)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 5, 11, 11), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([22], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((22,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(22):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(330, 22):\n            data_1 = T.Buffer((7260,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 22 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(22):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])",
        "op_args": [
            12,
            5,
            11,
            11
        ],
        "input_shape": "[[12, 5, 11, 11]]",
        "output_shape": "[[]]"
    },
    {
        "op_name": "min",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[14];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 14; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 144; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 14; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 14) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 14; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 3.402823e+38f;\n  for (int k0 = 0; k0 < 6; ++k0) {\n    for (int k1 = 0; k1 < 3; ++k1) {\n      for (int k2 = 0; k2 < 16; ++k2) {\n        for (int k3 = 0; k3 < 7; ++k3) {\n          data_red[0] = min(data_red[0], data[((((k0 * 336) + (k1 * 112)) + (k2 * 7)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 3, 16, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([14], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((14,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(14):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(144, 14):\n            data_1 = T.Buffer((2016,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 14 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(14):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])",
        "op_args": [
            6,
            3,
            16,
            7
        ],
        "input_shape": "[[6, 3, 16, 7]]",
        "output_shape": "[[]]"
    },
    {
        "op_name": "leaky_relu",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2592; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused]) ? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * 5.000000e-01f));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] * 5.000000e-01f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 12, 18, 4), \"float32\"), compute: T.Buffer((3, 12, 18, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2592):\n            compute_1 = T.Buffer((2592,), data=compute.data)\n            data_1 = T.Buffer((2592,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.if_then_else(T.float32(0) < data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused] * T.float32(0.5))",
        "op_args": [
            3,
            12,
            18,
            4
        ],
        "input_shape": "[[3, 12, 18, 4]]",
        "output_shape": "[[3, 12, 18, 4]]"
    },
    {
        "op_name": "log_softmax",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  float T_softmax_maxelem[495];\n  float compute_1[1];\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        T_softmax_maxelem[(((i0 * 33) + (i1 * 3)) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 4; ++k) {\n          T_softmax_maxelem[(((i0 * 33) + (i1 * 3)) + i2)] = max(T_softmax_maxelem[(((i0 * 33) + (i1 * 3)) + i2)], data[((((i0 * 132) + (i1 * 12)) + (i2 * 4)) + k)]);\n        }\n      }\n    }\n  }\n  for (int32_t i0_outer_outer_inner = 0; i0_outer_outer_inner < 5; ++i0_outer_outer_inner) {\n    for (int32_t i3_outer_outer_inner = 0; i3_outer_outer_inner < 4; ++i3_outer_outer_inner) {\n      for (int32_t i0_outer_inner = 0; i0_outer_inner < 3; ++i0_outer_inner) {\n        for (int32_t i1_outer_inner = 0; i1_outer_inner < 11; ++i1_outer_inner) {\n          for (int32_t i2_outer_inner = 0; i2_outer_inner < 3; ++i2_outer_inner) {\n            compute_1[0] = 0.000000e+00f;\n            for (int32_t k_1 = 0; k_1 < 4; ++k_1) {\n              compute_1[0] = (compute_1[0] + expf((data[(((((i0_outer_outer_inner * 396) + (i0_outer_inner * 132)) + (i1_outer_inner * 12)) + (i2_outer_inner * 4)) + k_1)] - T_softmax_maxelem[((((i0_outer_outer_inner * 99) + (i0_outer_inner * 33)) + (i1_outer_inner * 3)) + i2_outer_inner)])));\n            }\n            compute[(((((i0_outer_outer_inner * 396) + (i0_outer_inner * 132)) + (i1_outer_inner * 12)) + (i2_outer_inner * 4)) + i3_outer_outer_inner)] = ((data[(((((i0_outer_outer_inner * 396) + (i0_outer_inner * 132)) + (i1_outer_inner * 12)) + (i2_outer_inner * 4)) + i3_outer_outer_inner)] - T_softmax_maxelem[((((i0_outer_outer_inner * 99) + (i0_outer_inner * 33)) + (i1_outer_inner * 3)) + i2_outer_inner)]) - logf(compute_1[0]));\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) < 495) {\n    compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 4; ++k) {\n    if (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) < 495) {\n      compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 495) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2))]) - __logf(compute_1[((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2))]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 495) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 4; ++k) {\n    if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 495) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) * 4)) + k)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 11, 3, 4), \"float32\"), compute: T.Buffer((15, 11, 3, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_softmax_maxelem = T.allocate([495], \"float32\", \"global\")\n        compute_1 = T.allocate([1], \"float32\", \"global\")\n        T_softmax_maxelem_1 = T.Buffer((495,), data=T_softmax_maxelem)\n        data_1 = T.Buffer((1980,), data=data.data)\n        for i0, i1, i2 in T.grid(15, 11, 3):\n            T_softmax_maxelem_1[i0 * 33 + i1 * 3 + i2] = T.float32(-3.4028234663852886e+38)\n            for k in range(4):\n                cse_var_1: T.int32 = i0 * 33 + i1 * 3 + i2\n                T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 132 + i1 * 12 + i2 * 4 + k])\n        for i0_outer_outer_inner, i3_outer_outer_inner, i0_outer_inner, i1_outer_inner, i2_outer_inner in T.grid(5, 4, 3, 11, 3):\n            cse_var_2: T.int32 = i0_outer_outer_inner * 396 + i0_outer_inner * 132 + i1_outer_inner * 12 + i2_outer_inner * 4 + i3_outer_outer_inner\n            compute_2 = T.Buffer((1,), data=compute_1, align=4)\n            compute_2[0] = T.float32(0)\n            for k in range(4):\n                compute_2[0] = compute_2[0] + T.exp(data_1[i0_outer_outer_inner * 396 + i0_outer_inner * 132 + i1_outer_inner * 12 + i2_outer_inner * 4 + k] - T_softmax_maxelem_1[i0_outer_outer_inner * 99 + i0_outer_inner * 33 + i1_outer_inner * 3 + i2_outer_inner])\n            compute_3 = T.Buffer((1980,), data=compute.data)\n            compute_3[cse_var_2] = data_1[cse_var_2] - T_softmax_maxelem_1[i0_outer_outer_inner * 99 + i0_outer_inner * 33 + i1_outer_inner * 3 + i2_outer_inner] - T.log(compute_2[0])",
        "op_args": [
            15,
            11,
            3,
            4
        ],
        "input_shape": "[[15, 11, 3, 4]]",
        "output_shape": "[[15, 11, 3, 4]]"
    },
    {
        "op_name": "negative",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 10; ++i3) {\n          compute[((((i0 * 540) + (i1 * 60)) + (i2 * 10)) + i3)] = (data[((((i0 * 540) + (i1 * 60)) + (i2 * 10)) + i3)] * -1.000000e+00f);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * -1.000000e+00f);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 9, 6, 10), \"float32\"), compute: T.Buffer((4, 9, 6, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(9, 6, 10):\n                cse_var_1: T.int32 = i0 * 540 + i1 * 60 + i2 * 10 + i3\n                compute_1 = T.Buffer((2160,), data=compute.data)\n                data_1 = T.Buffer((2160,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)",
        "op_args": [
            4,
            9,
            6,
            10
        ],
        "input_shape": "[[4, 9, 6, 10]]",
        "output_shape": "[[4, 9, 6, 10]]"
    },
    {
        "op_name": "lrn",
        "c_code": "void default_function_kernel(float* T_divide, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 1560; ++ax0_ax1_fused_ax2_fused) {\n    float tensor[1];\n    for (int32_t ax3 = 0; ax3 < 9; ++ax3) {\n      tensor[0] = 0.000000e+00f;\n      tensor[0] = (tensor[0] + (data[((ax0_ax1_fused_ax2_fused * 9) + ax3)] * data[((ax0_ax1_fused_ax2_fused * 9) + ax3)]));\n      T_divide[((ax0_ax1_fused_ax2_fused * 9) + ax3)] = (data[((ax0_ax1_fused_ax2_fused * 9) + ax3)] / powf((2.000000e+00f + (1.000000e-04f * tensor[0])), 7.500000e-01f));\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel_1(float* __restrict__ T_divide, float* __restrict__ data, float* __restrict__ tensor) {\n  T_divide[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] / powf((2.000000e+00f + (1.000000e-04f * tensor[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))])), 7.500000e-01f));\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ tensor) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 1755) {\n    tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 1755) {\n    tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + (data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 10, 13, 9), \"float32\"), T_divide: T.Buffer((12, 10, 13, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(1560):\n            tensor = T.allocate([1], \"float32\", \"global\")\n            for ax3 in range(9):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 9 + ax3\n                tensor_1 = T.Buffer((1,), data=tensor, align=4)\n                tensor_1[0] = T.float32(0)\n                data_1 = T.Buffer((14040,), data=data.data)\n                tensor_1[0] = tensor_1[0] + data_1[cse_var_1] * data_1[cse_var_1]\n                T_divide_1 = T.Buffer((14040,), data=T_divide.data)\n                T_divide_1[cse_var_1] = data_1[cse_var_1] / T.pow(T.float32(2) + T.float32(9.9999997473787516e-05) * tensor_1[0], T.float32(0.75))",
        "op_args": [
            12,
            10,
            13,
            9
        ],
        "input_shape": "[[12, 10, 13, 9]]",
        "output_shape": "[[12, 10, 13, 9]]"
    },
    {
        "op_name": "prod",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[21];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 21; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 300; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 21; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 21) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 21; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 15; ++k0) {\n    for (int k1 = 0; k1 < 20; ++k1) {\n      for (int k2 = 0; k2 < 3; ++k2) {\n        for (int k3 = 0; k3 < 7; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 420) + (k1 * 21)) + (k2 * 7)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 20, 3, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([21], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((21,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(21):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(300, 21):\n            data_1 = T.Buffer((6300,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 21 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(21):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]",
        "op_args": [
            15,
            20,
            3,
            7
        ],
        "input_shape": "[[15, 20, 3, 7]]",
        "output_shape": "[[]]"
    },
    {
        "op_name": "mirror_pad",
        "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 5; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      MirrorPadInput[((i0 * 9) + i1)] = data[((((3 <= i0) ? (4 - i0) : ((i0 < 1) ? (0 - i0) : (i0 - 1))) * 6) + ((i1 == 8) ? (13 - i1) : ((i1 < 2) ? (1 - i1) : (i1 - 2))))];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(11) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) < 45) {\n    MirrorPadInput[((((int)blockIdx.x) * 11) + ((int)threadIdx.x))] = data[((((27 <= ((((int)blockIdx.x) * 11) + ((int)threadIdx.x))) ? (4 - (((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) / 9)) : ((((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) < 9) ? 0 : ((((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) / 9) - 1))) * 6) + (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9) == 8) ? (13 - (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9)) : (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9) < 2) ? (1 - (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9)) : ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9) - 2))))];\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 6), \"float32\"), MirrorPadInput: T.Buffer((5, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(5):\n            for i1 in range(9):\n                MirrorPadInput_1 = T.Buffer((45,), data=MirrorPadInput.data)\n                data_1 = T.Buffer((12,), data=data.data)\n                MirrorPadInput_1[i0 * 9 + i1] = data_1[T.if_then_else(3 <= i0, 4 - i0, T.if_then_else(i0 < 1, 0 - i0, i0 - 1)) * 6 + T.if_then_else(i1 == 8, 13 - i1, T.if_then_else(i1 < 2, 1 - i1, i1 - 2))]",
        "op_args": [
            14,
            16,
            2,
            6
        ],
        "input_shape": "[[2, 6]]",
        "output_shape": "[[5, 9]]"
    },
    {
        "op_name": "round",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    for (int32_t i2 = 0; i2 < 2; ++i2) {\n      for (int32_t i3 = 0; i3 < 11; ++i3) {\n        compute[(((i0 * 22) + (i2 * 11)) + i3)] = roundf(data[(((i0 * 22) + (i2 * 11)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(3) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) < 374) {\n    compute[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))] = roundf(data[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 1, 2, 11), \"float32\"), compute: T.Buffer((17, 1, 2, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(17):\n            for i2, i3 in T.grid(2, 11):\n                cse_var_1: T.int32 = i0 * 22 + i2 * 11 + i3\n                compute_1 = T.Buffer((374,), data=compute.data)\n                data_1 = T.Buffer((374,), data=data.data)\n                compute_1[cse_var_1] = T.round(data_1[cse_var_1])",
        "op_args": [
            17,
            1,
            2,
            11
        ],
        "input_shape": "[[17, 1, 2, 11]]",
        "output_shape": "[[17, 1, 2, 11]]"
    },
    {
        "op_name": "pool1d",
        "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 19; ++ax0) {\n    float pad_temp[13];\n    for (int32_t ax2_s = 0; ax2_s < 13; ++ax2_s) {\n      pad_temp[ax2_s] = (((1 <= ax2_s) && (ax2_s < 12)) ? data[(((ax0 * 11) + ax2_s) - 1)] : -3.402823e+38f);\n    }\n    for (int32_t ax2 = 0; ax2 < 6; ++ax2) {\n      pool_max[((ax0 * 6) + ax2)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n        pool_max[((ax0 * 6) + ax2)] = max(pool_max[((ax0 * 6) + ax2)], pad_temp[((ax2 * 2) + rv0)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  if (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 114) {\n    pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    if (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 114) {\n      pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))], (((1 <= ((((((int)blockIdx.x) + ((int)threadIdx.x)) % 6) * 2) + rv0)) && (((rv0 >> 1) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 6)) < 6)) ? data[(((((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) / 6) * 11) + (((((int)blockIdx.x) + ((int)threadIdx.x)) % 6) * 2)) + rv0) - 1)] : -3.402823e+38f));\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 1, 11), \"float32\"), pool_max: T.Buffer((19, 1, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(19):\n            pad_temp = T.allocate([13], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((13,), data=pad_temp, align=32)\n            for ax2_s in range(13):\n                data_1 = T.Buffer((209,), data=data.data)\n                pad_temp_1[ax2_s] = T.if_then_else(1 <= ax2_s and ax2_s < 12, data_1[ax0 * 11 + ax2_s - 1], T.float32(-3.4028234663852886e+38))\n            for ax2 in range(6):\n                pool_max_1 = T.Buffer((114,), data=pool_max.data)\n                pool_max_1[ax0 * 6 + ax2] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_1: T.int32 = ax0 * 6 + ax2\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 2 + rv0])",
        "op_args": [
            19,
            1,
            5,
            11
        ],
        "input_shape": "[[19, 1, 11]]",
        "output_shape": "[[19, 1, 6]]"
    },
    {
        "op_name": "shape",
        "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 11 : ((ax0 == 2) ? 1 : ((ax0 == 1) ? 5 : 14)));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 11 : ((((int)threadIdx.x) == 2) ? 1 : ((((int)threadIdx.x) == 1) ? 5 : 14)));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 5, 1, 11), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 11, T.if_then_else(ax0 == 2, 1, T.if_then_else(ax0 == 1, 5, 14)))",
        "op_args": [
            14,
            5,
            1,
            11
        ],
        "input_shape": "[[14, 5, 1, 11]]",
        "output_shape": "[[4]]"
    },
    {
        "op_name": "pool2d",
        "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 11; ++ax0) {\n    float pad_temp[247];\n    for (int32_t ax1 = 0; ax1 < 3; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 19; ++ax2) {\n        for (int32_t ax3_s = 0; ax3_s < 13; ++ax3_s) {\n          pad_temp[((ax2 * 13) + ax3_s)] = (((1 <= ax2) && (1 <= ax3_s)) ? data[(((((ax0 * 648) + (ax1 * 216)) + (ax2 * 12)) + ax3_s) - 13)] : -3.402823e+38f);\n        }\n      }\n      for (int32_t ax2_1 = 0; ax2_1 < 9; ++ax2_1) {\n        for (int32_t ax3 = 0; ax3 < 6; ++ax3) {\n          pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)] = max(pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)], pad_temp[((((ax2_1 * 26) + (rv0 * 13)) + (ax3 * 2)) + rv1)]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))], (((1 <= (((((int)blockIdx.x) % 9) * 2) + rv0)) && (1 <= ((((int)threadIdx.x) * 2) + rv1))) ? data[(((((((int)blockIdx.x) * 24) + (rv0 * 12)) + (((int)threadIdx.x) * 2)) + rv1) - 13)] : -3.402823e+38f));\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 3, 18, 12), \"float32\"), pool_max: T.Buffer((11, 3, 9, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(11):\n            pad_temp = T.allocate([247], \"float32\", \"global\")\n            for ax1 in range(3):\n                pad_temp_1 = T.Buffer((247,), data=pad_temp)\n                for ax2, ax3_s in T.grid(19, 13):\n                    data_1 = T.Buffer((7128,), data=data.data)\n                    pad_temp_1[ax2 * 13 + ax3_s] = T.if_then_else(1 <= ax2 and 1 <= ax3_s, data_1[ax0 * 648 + ax1 * 216 + ax2 * 12 + ax3_s - 13], T.float32(-3.4028234663852886e+38))\n                for ax2, ax3 in T.grid(9, 6):\n                    pool_max_1 = T.Buffer((1782,), data=pool_max.data)\n                    pool_max_1[ax0 * 162 + ax1 * 54 + ax2 * 6 + ax3] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1 in T.grid(3, 3):\n                        cse_var_1: T.int32 = ax0 * 162 + ax1 * 54 + ax2 * 6 + ax3\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 26 + rv0 * 13 + ax3 * 2 + rv1])",
        "op_args": [
            11,
            3,
            18,
            4
        ],
        "input_shape": "[[11, 3, 18, 12]]",
        "output_shape": "[[11, 3, 9, 6]]"
    },
    {
        "op_name": "sigmoid",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 7; ++i1) {\n    for (int32_t i2 = 0; i2 < 17; ++i2) {\n      for (int32_t i3 = 0; i3 < 4; ++i3) {\n        compute[(((i1 * 68) + (i2 * 4)) + i3)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[(((i1 * 68) + (i2 * 4)) + i3)]))));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))]))));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 7, 17, 4), \"float32\"), compute: T.Buffer((1, 7, 17, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(7, 17, 4):\n            cse_var_1: T.int32 = i1 * 68 + i2 * 4 + i3\n            compute_1 = T.Buffer((476,), data=compute.data)\n            data_1 = T.Buffer((476,), data=data.data)\n            compute_1[cse_var_1] = T.sigmoid(data_1[cse_var_1])",
        "op_args": [
            1,
            7,
            17,
            4
        ],
        "input_shape": "[[1, 7, 17, 4]]",
        "output_shape": "[[1, 7, 17, 4]]"
    },
    {
        "op_name": "pool3d",
        "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 170; ++ax0_ax1_fused) {\n    float pad_temp[27];\n    for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 4; ++ax3) {\n        for (int32_t ax4 = 0; ax4 < 8; ++ax4) {\n          for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n            for (int32_t ax3_1 = 0; ax3_1 < 3; ++ax3_1) {\n              for (int32_t ax4_s = 0; ax4_s < 3; ++ax4_s) {\n                pad_temp[(((ax2_1 * 9) + (ax3_1 * 3)) + ax4_s)] = (((((1 <= ((ax2 * 2) + ax2_1)) && (((ax2_1 >> 1) + ax2) < 4)) && (1 <= ((ax3 * 2) + ax3_1))) && (1 <= ((ax4 * 2) + ax4_s))) ? data[((((((((ax0_ax1_fused * 896) + (ax2 * 256)) + (ax2_1 * 128)) + (ax3 * 32)) + (ax3_1 * 16)) + (ax4 * 2)) + ax4_s) - 145)] : -3.402823e+38f);\n              }\n            }\n          }\n          pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n                pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)] = max(pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)], pad_temp[(((rv0 * 9) + (rv1 * 3)) + rv2)]);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], (((((1 <= ((((((int)blockIdx.x) & 1) * 4) + ((((int)threadIdx.x) >> 5) * 2)) + rv0)) && (((((((int)threadIdx.x) >> 5) + (rv0 >> 1)) >> 1) + (((int)blockIdx.x) & 1)) < 2)) && (1 <= ((((((int)threadIdx.x) & 31) >> 3) * 2) + rv1))) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[((((((((((((int)blockIdx.x) >> 1) * 896) + ((((int)blockIdx.x) & 1) * 512)) + ((((int)threadIdx.x) >> 5) * 256)) + (rv0 * 128)) + (((((int)threadIdx.x) & 31) >> 3) * 32)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 145)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 17, 7, 8, 16), \"float32\"), pool_max: T.Buffer((10, 17, 4, 4, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(170):\n            pad_temp = T.allocate([27], \"float32\", \"global\")\n            for ax2, ax3, ax4 in T.grid(4, 4, 8):\n                pad_temp_1 = T.Buffer((27,), data=pad_temp)\n                for ax2_1, ax3_1, ax4_s in T.grid(3, 3, 3):\n                    cse_var_1: T.int32 = ax4 * 2\n                    data_1 = T.Buffer((152320,), data=data.data)\n                    pad_temp_1[ax2_1 * 9 + ax3_1 * 3 + ax4_s] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and ax2_1 // 2 + ax2 < 4 and 1 <= ax3 * 2 + ax3_1 and 1 <= cse_var_1 + ax4_s, data_1[ax0_ax1_fused * 896 + ax2 * 256 + ax2_1 * 128 + ax3 * 32 + ax3_1 * 16 + cse_var_1 + ax4_s - 145], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((21760,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused * 128 + ax2 * 32 + ax3 * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                    cse_var_2: T.int32 = ax0_ax1_fused * 128 + ax2 * 32 + ax3 * 8 + ax4\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0 * 9 + rv1 * 3 + rv2])",
        "op_args": [
            10,
            17,
            7,
            8
        ],
        "input_shape": "[[10, 17, 7, 8, 16]]",
        "output_shape": "[[10, 17, 4, 4, 8]]"
    },
    {
        "op_name": "sign",
        "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 1248; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_sign[ax0_ax1_fused_ax2_fused_ax3_fused] = ((0.000000e+00f < data[ax0_ax1_fused_ax2_fused_ax3_fused]) ? 1.000000e+00f : ((data[ax0_ax1_fused_ax2_fused_ax3_fused] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 2, 13, 3), \"float32\"), T_sign: T.Buffer((16, 2, 13, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(1248):\n            T_sign_1 = T.Buffer((1248,), data=T_sign.data)\n            data_1 = T.Buffer((1248,), data=data.data)\n            T_sign_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.if_then_else(T.float32(0) < data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(1), T.Select(data_1[ax0_ax1_fused_ax2_fused_ax3_fused] < T.float32(0), T.float32(-1), T.float32(0)))",
        "op_args": [
            16,
            2,
            13,
            3
        ],
        "input_shape": "[[16, 2, 13, 3]]",
        "output_shape": "[[16, 2, 13, 3]]"
    },
    {
        "op_name": "relu",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 6930; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = max(data[i0_i1_fused_i2_fused_i3_fused], 0.000000e+00f);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 14, 3, 11), \"float32\"), compute: T.Buffer((15, 14, 3, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(6930):\n            compute_1 = T.Buffer((6930,), data=compute.data)\n            data_1 = T.Buffer((6930,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.max(data_1[i0_i1_fused_i2_fused_i3_fused], T.float32(0))",
        "op_args": [
            15,
            14,
            3,
            11
        ],
        "input_shape": "[[15, 14, 3, 11]]",
        "output_shape": "[[15, 14, 3, 11]]"
    },
    {
        "op_name": "sqrt",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 20; ++i1) {\n      for (int32_t i2 = 0; i2 < 9; ++i2) {\n        compute[(((i0 * 180) + (i1 * 9)) + i2)] = sqrtf(data[(((i0 * 180) + (i1 * 9)) + i2)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = sqrtf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 20, 9, 1), \"float32\"), compute: T.Buffer((7, 20, 9, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i1, i2 in T.grid(20, 9):\n                cse_var_1: T.int32 = i0 * 180 + i1 * 9 + i2\n                compute_1 = T.Buffer((1260,), data=compute.data)\n                data_1 = T.Buffer((1260,), data=data.data)\n                compute_1[cse_var_1] = T.sqrt(data_1[cse_var_1])",
        "op_args": [
            7,
            20,
            9,
            1
        ],
        "input_shape": "[[7, 20, 9, 1]]",
        "output_shape": "[[7, 20, 9, 1]]"
    },
    {
        "op_name": "scale_shift_nchw",
        "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused < 1482; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused) {\n    for (int32_t b_inner = 0; b_inner < 5; ++b_inner) {\n      for (int32_t i_inner = 0; i_inner < 6; ++i_inner) {\n        ScaleShift[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 741) * 22230) + (b_inner * 4446)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 19) * 114)) + (i_inner * 19)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 19))] = ((data[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 741) * 22230) + (b_inner * 4446)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 19) * 114)) + (i_inner * 19)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 19))] * Scale[((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 57)]) + Shift[((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 57)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 11115) {\n    ScaleShift[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) % 2223) / 171)]) + Shift[((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) % 2223) / 171)]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 13, 18, 19), \"float32\"), Scale: T.Buffer((13,), \"float32\"), Shift: T.Buffer((13,), \"float32\"), ScaleShift: T.Buffer((10, 13, 18, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused in T.parallel(1482):\n            for b_inner, i_inner in T.grid(5, 6):\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741\n                cse_var_2: T.int32 = cse_var_3 // 57\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused // 741 * 22230 + b_inner * 4446 + cse_var_3 // 19 * 114 + i_inner * 19 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 19\n                ScaleShift_1 = T.Buffer((44460,), data=ScaleShift.data)\n                data_1 = T.Buffer((44460,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]",
        "op_args": [
            10,
            13,
            18,
            19
        ],
        "input_shape": "[[10, 13, 18, 19], [13], [13]]",
        "output_shape": "[[10, 13, 18, 19]]"
    },
    {
        "op_name": "tan",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 6; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3 = 0; i3 < 20; ++i3) {\n          compute[((((i0 * 1320) + (i1 * 220)) + (i2 * 20)) + i3)] = tanf(data[((((i0 * 1320) + (i1 * 220)) + (i2 * 20)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(55) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 6, 11, 20), \"float32\"), compute: T.Buffer((13, 6, 11, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3 in T.grid(6, 11, 20):\n                cse_var_1: T.int32 = i0 * 1320 + i1 * 220 + i2 * 20 + i3\n                compute_1 = T.Buffer((17160,), data=compute.data)\n                data_1 = T.Buffer((17160,), data=data.data)\n                compute_1[cse_var_1] = T.tan(data_1[cse_var_1])",
        "op_args": [
            13,
            6,
            11,
            20
        ],
        "input_shape": "[[13, 6, 11, 20]]",
        "output_shape": "[[13, 6, 11, 20]]"
    },
    {
        "op_name": "prelu",
        "c_code": "void default_function_kernel(float* Scale, float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 46512; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused]) ? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * Scale[(i0_i1_fused_i2_fused_i3_fused % 19)]));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ Scale, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] * Scale[(((int)threadIdx.x) % 19)]));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 17, 16, 19), \"float32\"), Scale: T.Buffer((19,), \"float32\"), compute: T.Buffer((9, 17, 16, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(46512):\n            compute_1 = T.Buffer((46512,), data=compute.data)\n            data_1 = T.Buffer((46512,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.if_then_else(T.float32(0) < data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused] * Scale[i0_i1_fused_i2_fused_i3_fused % 19])",
        "op_args": [
            9,
            17,
            16,
            19
        ],
        "input_shape": "[[9, 17, 16, 19], [19]]",
        "output_shape": "[[9, 17, 16, 19]]"
    },
    {
        "op_name": "tanh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 20; ++i1) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 13; ++i3) {\n        compute[(((i1 * 182) + (i2 * 13)) + i3)] = tanhf(data[(((i1 * 182) + (i2 * 13)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = tanhf(data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 20, 14, 13), \"float32\"), compute: T.Buffer((1, 20, 14, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(20, 14, 13):\n            cse_var_1: T.int32 = i1 * 182 + i2 * 13 + i3\n            compute_1 = T.Buffer((3640,), data=compute.data)\n            data_1 = T.Buffer((3640,), data=data.data)\n            compute_1[cse_var_1] = T.tanh(data_1[cse_var_1])",
        "op_args": [
            1,
            20,
            14,
            13
        ],
        "input_shape": "[[1, 20, 14, 13]]",
        "output_shape": "[[1, 20, 14, 13]]"
    },
    {
        "op_name": "scale_shift_nchwc",
        "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused < 196; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused) {\n    for (int32_t cb_outer_inner = 0; cb_outer_inner < 7; ++cb_outer_inner) {\n      for (int32_t i_inner = 0; i_inner < 16; ++i_inner) {\n        ScaleShift[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 28) * 3136) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 1568)) + (i_inner * 98)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 28) >> 1) * 7)) + cb_outer_inner)] = ((data[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 28) * 3136) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 1568)) + (i_inner * 98)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 28) >> 1) * 7)) + cb_outer_inner)] * Scale[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 7) + cb_outer_inner)]) + Shift[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 7) + cb_outer_inner)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) % 49) * 2) + (((int)threadIdx.x) >> 5)) / 49) * 7) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 7))]) + Shift[((((((((int)blockIdx.x) % 49) * 2) + (((int)threadIdx.x) >> 5)) / 49) * 7) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 7))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 16, 14, 7), \"float32\"), Scale: T.Buffer((2, 7), \"float32\"), Shift: T.Buffer((2, 7), \"float32\"), ScaleShift: T.Buffer((7, 2, 16, 14, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused in T.parallel(196):\n            for cb_outer_inner, i_inner in T.grid(7, 16):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 2\n                cse_var_2: T.int32 = cse_var_3 * 7 + cb_outer_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused // 28 * 3136 + cse_var_3 * 1568 + i_inner * 98 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 28 // 2 * 7 + cb_outer_inner\n                ScaleShift_1 = T.Buffer((21952,), data=ScaleShift.data)\n                data_1 = T.Buffer((21952,), data=data.data)\n                Scale_1 = T.Buffer((14,), data=Scale.data)\n                Shift_1 = T.Buffer((14,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]",
        "op_args": [
            7,
            7,
            16,
            14
        ],
        "input_shape": "[[7, 2, 16, 14, 7], [2, 7], [2, 7]]",
        "output_shape": "[[7, 2, 16, 14, 7]]"
    },
    {
        "op_name": "matmul",
        "c_code": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  for (int32_t ax1_outer_outer_outer = 0; ax1_outer_outer_outer < 2; ++ax1_outer_outer_outer) {\n    for (int32_t ax0_inner_init = 0; ax0_inner_init < 2; ++ax0_inner_init) {\n      T_matmul[((ax0_inner_init * 2) + ax1_outer_outer_outer)] = 0.000000e+00f;\n    }\n    for (int32_t k_inner = 0; k_inner < 2; ++k_inner) {\n      for (int32_t ax0_inner = 0; ax0_inner < 2; ++ax0_inner) {\n        T_matmul[((ax0_inner * 2) + ax1_outer_outer_outer)] = (T_matmul[((ax0_inner * 2) + ax1_outer_outer_outer)] + (left_matrix[((ax0_inner * 2) + k_inner)] * right_matrix[((k_inner * 2) + ax1_outer_outer_outer)]));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ T_matmul, float* __restrict__ left_matrix, float* __restrict__ right_matrix) {\n  float T_matmul_local[2];\n  __shared__ float left_matrix_shared[4];\n  __shared__ float right_matrix_shared[4];\n  T_matmul_local[0] = 0.000000e+00f;\n  T_matmul_local[1] = 0.000000e+00f;\n  for (int ax0_ax1_fused_outer_outer = 0; ax0_ax1_fused_outer_outer < 2; ++ax0_ax1_fused_outer_outer) {\n    left_matrix_shared[((ax0_ax1_fused_outer_outer * 2) + ((int)threadIdx.x))] = left_matrix[((ax0_ax1_fused_outer_outer * 2) + ((int)threadIdx.x))];\n  }\n  for (int ax0_ax1_fused_outer_outer_1 = 0; ax0_ax1_fused_outer_outer_1 < 2; ++ax0_ax1_fused_outer_outer_1) {\n    right_matrix_shared[((ax0_ax1_fused_outer_outer_1 * 2) + ((int)threadIdx.x))] = right_matrix[((ax0_ax1_fused_outer_outer_1 * 2) + ((int)threadIdx.x))];\n  }\n  __syncthreads();\n  for (int k_inner = 0; k_inner < 2; ++k_inner) {\n    T_matmul_local[0] = (T_matmul_local[0] + (left_matrix_shared[((((int)threadIdx.x) * 2) + k_inner)] * right_matrix_shared[(k_inner * 2)]));\n    T_matmul_local[1] = (T_matmul_local[1] + (left_matrix_shared[((((int)threadIdx.x) * 2) + k_inner)] * right_matrix_shared[((k_inner * 2) + 1)]));\n  }\n  T_matmul[(((int)threadIdx.x) * 2)] = T_matmul_local[0];\n  T_matmul[((((int)threadIdx.x) * 2) + 1)] = T_matmul_local[1];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(left_matrix: T.Buffer((2, 2), \"float32\"), right_matrix: T.Buffer((2, 2), \"float32\"), T_matmul: T.Buffer((2, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax1_outer_outer_outer in range(2):\n            T_matmul_1 = T.Buffer((4,), data=T_matmul.data)\n            for ax0_inner_init in range(2):\n                T_matmul_1[ax0_inner_init * 2 + ax1_outer_outer_outer] = T.float32(0)\n            for k_inner, ax0_inner in T.grid(2, 2):\n                cse_var_2: T.int32 = ax0_inner * 2\n                cse_var_1: T.int32 = cse_var_2 + ax1_outer_outer_outer\n                left_matrix_1 = T.Buffer((4,), data=left_matrix.data)\n                right_matrix_1 = T.Buffer((4,), data=right_matrix.data)\n                T_matmul_1[cse_var_1] = T_matmul_1[cse_var_1] + left_matrix_1[cse_var_2 + k_inner] * right_matrix_1[k_inner * 2 + ax1_outer_outer_outer]",
        "op_args": [
            7,
            2,
            2,
            2
        ],
        "input_shape": "[[2, 2], [2, 2]]",
        "output_shape": "[[2, 2]]"
    },
    {
        "op_name": "softmax",
        "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    float T_softmax_maxelem[4];\n    float T_softmax_expsum[4];\n    for (int32_t i1 = 0; i1 < 4; ++i1) {\n      for (int32_t i2 = 0; i2 < 4; ++i2) {\n        T_softmax_maxelem[i2] = -3.402823e+38f;\n        T_softmax_maxelem[i2] = max(T_softmax_maxelem[i2], data[(((i0 * 16) + (i1 * 4)) + i2)]);\n      }\n      for (int32_t i2_1 = 0; i2_1 < 4; ++i2_1) {\n        T_softmax_maxelem[i2_1] = expf((data[(((i0 * 16) + (i1 * 4)) + i2_1)] - T_softmax_maxelem[i2_1]));\n      }\n      for (int32_t i2_2 = 0; i2_2 < 4; ++i2_2) {\n        T_softmax_expsum[i2_2] = 0.000000e+00f;\n        T_softmax_expsum[i2_2] = (T_softmax_expsum[i2_2] + T_softmax_maxelem[i2_2]);\n      }\n      for (int32_t i2_3 = 0; i2_3 < 4; ++i2_3) {\n        T_softmax_norm[(((i0 * 16) + (i1 * 4)) + i2_3)] = (T_softmax_maxelem[i2_3] / T_softmax_expsum[i2_3]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 17) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 17) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) < 17) {\n    T_softmax_norm[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (__expf((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))])) / T_softmax_expsum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = 0.000000e+00f;\n  T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] + __expf((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))])));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 4, 4, 1), \"float32\"), T_softmax_norm: T.Buffer((17, 4, 4, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(17):\n            T_softmax_maxelem = T.allocate([4], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([4], \"float32\", \"global\")\n            for i1 in range(4):\n                T_softmax_maxelem_1 = T.Buffer((4,), data=T_softmax_maxelem, align=16)\n                data_1 = T.Buffer((272,), data=data.data)\n                for i2 in range(4):\n                    T_softmax_maxelem_1[i2] = T.float32(-3.4028234663852886e+38)\n                    T_softmax_maxelem_1[i2] = T.max(T_softmax_maxelem_1[i2], data_1[i0 * 16 + i1 * 4 + i2])\n                T_softmax_maxelem_2 = T.Buffer((4,), data=T_softmax_maxelem, align=16)\n                for i2 in range(4):\n                    T_softmax_maxelem_2[i2] = T.exp(data_1[i0 * 16 + i1 * 4 + i2] - T_softmax_maxelem_1[i2])\n                T_softmax_expsum_1 = T.Buffer((4,), data=T_softmax_expsum, align=16)\n                for i2 in range(4):\n                    T_softmax_expsum_1[i2] = T.float32(0)\n                    T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T_softmax_maxelem_2[i2]\n                for i2 in range(4):\n                    T_softmax_norm_1 = T.Buffer((272,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[i0 * 16 + i1 * 4 + i2] = T_softmax_maxelem_2[i2] / T_softmax_expsum_1[i2]",
        "op_args": [
            17,
            4,
            4,
            1
        ],
        "input_shape": "[[17, 4, 4, 1]]",
        "output_shape": "[[17, 4, 4, 1]]"
    },
    {
        "op_name": "combination_op",
        "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 392; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n      T_add[((ax0_ax1_fused_ax2_fused * 16) + ax3)] = (sqrtf(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)]) + cosf(data_1[((ax0_ax1_fused_ax2_fused * 16) + ax3)]));\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (sqrtf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]) + __cosf(data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 4, 7, 16), \"float32\"), data_1: T.Buffer((14, 4, 7, 16), \"float32\"), T_add: T.Buffer((14, 4, 7, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(392):\n            for ax3 in range(16):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 16 + ax3\n                T_add_1 = T.Buffer((6272,), data=T_add.data)\n                data_2 = T.Buffer((6272,), data=data.data)\n                data_3 = T.Buffer((6272,), data=data_1.data)\n                T_add_1[cse_var_1] = T.sqrt(data_2[cse_var_1]) + T.cos(data_3[cse_var_1])",
        "op_args": [
            14,
            4,
            7,
            16
        ],
        "input_shape": "[[14, 4, 7, 16], [14, 4, 7, 16]]",
        "output_shape": "[[14, 4, 7, 16]]"
    },
    {
        "op_name": "multi_out_op",
        "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 17; ++i1) {\n      for (int32_t i2 = 0; i2 < 12; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 3468) + (i1 * 204)) + (i2 * 17)) + i3)] = sqrtf((data[((((i0 * 3468) + (i1 * 204)) + (i2 * 17)) + i3)] + data_1[((((i0 * 3468) + (i1 * 204)) + (i2 * 17)) + i3)]));\n        }\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 68; ++i0_i1_fused) {\n    for (int32_t i2_1 = 0; i2_1 < 12; ++i2_1) {\n      for (int32_t i3_1 = 0; i3_1 < 17; ++i3_1) {\n        compute_1[(((i0_i1_fused * 204) + (i2_1 * 17)) + i3_1)] = cosf((data[(((i0_i1_fused * 204) + (i2_1 * 17)) + i3_1)] + data_1[(((i0_i1_fused * 204) + (i2_1 * 17)) + i3_1)]));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 17, 12, 17), \"float32\"), data_1: T.Buffer((4, 17, 12, 17), \"float32\"), compute: T.Buffer((4, 17, 12, 17), \"float32\"), compute_1: T.Buffer((4, 17, 12, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((13872,), data=data.data)\n        data_3 = T.Buffer((13872,), data=data_1.data)\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(17, 12, 17):\n                cse_var_1: T.int32 = i0 * 3468 + i1 * 204 + i2 * 17 + i3\n                compute_2 = T.Buffer((13872,), data=compute.data)\n                compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i0_i1_fused in T.parallel(68):\n            for i2, i3 in T.grid(12, 17):\n                cse_var_2: T.int32 = i0_i1_fused * 204 + i2 * 17 + i3\n                compute_2 = T.Buffer((13872,), data=compute_1.data)\n                compute_2[cse_var_2] = T.cos(data_2[cse_var_2] + data_3[cse_var_2])",
        "op_args": [
            4,
            17,
            12,
            17
        ],
        "input_shape": "[[4, 17, 12, 17], [4, 17, 12, 17], [4, 17, 12, 17]]",
        "output_shape": "[[4, 17, 12, 17]]"
    },
    {
        "op_name": "softmax_common",
        "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    float T_softmax_maxelem[168];\n    float T_softmax_expsum[14];\n    for (int32_t i1 = 0; i1 < 12; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        T_softmax_maxelem[((i1 * 14) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 3; ++k) {\n          T_softmax_maxelem[((i1 * 14) + i2)] = max(T_softmax_maxelem[((i1 * 14) + i2)], data[((((i0 * 504) + (i1 * 42)) + (i2 * 3)) + k)]);\n        }\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 12; ++i1_1) {\n      for (int32_t i2_1 = 0; i2_1 < 14; ++i2_1) {\n        T_softmax_expsum[i2_1] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 3; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[i2_1] = (T_softmax_expsum[i2_1] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)])));\n        }\n      }\n      for (int32_t i2_2 = 0; i2_2 < 14; ++i2_2) {\n        for (int32_t i3_s = 0; i3_s < 3; ++i3_s) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)])) / T_softmax_expsum[i2_2]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 189) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 3; ++k) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 189) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 96) + (((int)threadIdx.x) * 3)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 567) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(4) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 3; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))])));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 12, 14, 3), \"float32\"), T_softmax_norm: T.Buffer((18, 12, 14, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(18):\n            T_softmax_maxelem = T.allocate([168], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([14], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((168,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((9072,), data=data.data)\n            for i1, i2 in T.grid(12, 14):\n                T_softmax_maxelem_1[i1 * 14 + i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(3):\n                    cse_var_1: T.int32 = i1 * 14 + i2\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 504 + i1 * 42 + i2 * 3 + k])\n            for i1 in range(12):\n                T_softmax_expsum_1 = T.Buffer((14,), data=T_softmax_expsum, align=32)\n                for i2 in range(14):\n                    T_softmax_expsum_1[i2] = T.float32(0)\n                    for k in range(3):\n                        cse_var_3: T.int32 = i1 * 14 + i2\n                        cse_var_2: T.int32 = i0 * 504 + i1 * 42 + i2 * 3 + k\n                        T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3])\n                for i2, i3_s in T.grid(14, 3):\n                    cse_var_5: T.int32 = i1 * 14 + i2\n                    cse_var_4: T.int32 = i0 * 504 + i1 * 42 + i2 * 3 + i3_s\n                    T_softmax_norm_1 = T.Buffer((9072,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_4] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5]) / T_softmax_expsum_1[i2]",
        "op_args": [
            18,
            12,
            14,
            3
        ],
        "input_shape": "[[18, 12, 14, 3]]",
        "output_shape": "[[18, 12, 14, 3]]"
    },
    {
        "op_name": "space_to_depth",
        "c_code": "void default_function_kernel(float* data, float* space_to_depth) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 648; ++i0_i1_fused_i2_fused_i3_fused) {\n    space_to_depth[i0_i1_fused_i2_fused_i3_fused] = data[((((((i0_i1_fused_i2_fused_i3_fused / 36) * 36) + ((((i0_i1_fused_i2_fused_i3_fused % 36) / 3) % 3) * 12)) + ((((i0_i1_fused_i2_fused_i3_fused % 36) / 3) / 6) * 6)) + ((i0_i1_fused_i2_fused_i3_fused % 3) * 2)) + ((((i0_i1_fused_i2_fused_i3_fused % 36) / 3) % 6) / 3))];\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ data, float* __restrict__ space_to_depth) {\n  space_to_depth[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = data[((((((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 2)) / 9) * 36) + ((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 36) / 3) % 3) * 12)) + ((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 36) / 3) / 6) * 6)) + ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 3) * 2)) + ((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 36) / 3) % 6) / 3))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 3, 2, 6), \"float32\"), space_to_depth: T.Buffer((18, 12, 1, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(648):\n            cse_var_1: T.int32 = i0_i1_fused_i2_fused_i3_fused % 36 // 3\n            space_to_depth_1 = T.Buffer((648,), data=space_to_depth.data)\n            data_1 = T.Buffer((648,), data=data.data)\n            space_to_depth_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 36 * 36 + T.truncmod(cse_var_1, 3) * 12 + T.Div(cse_var_1, 6) * 6 + i0_i1_fused_i2_fused_i3_fused % 3 * 2 + T.Div(T.truncmod(cse_var_1, 6), 3)]",
        "op_args": [
            18,
            3,
            1,
            3
        ],
        "input_shape": "[[18, 3, 2, 6]]",
        "output_shape": "[[18, 12, 1, 3]]"
    },
    {
        "op_name": "strided_slice",
        "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  for (int32_t ax1 = 0; ax1 < 5; ++ax1) {\n    for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n      T_strided_slice[((ax1 * 7) + ax2)] = a[(((ax1 * 15) + ax2) + 183)];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  T_strided_slice[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = a[(((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) + 183)];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((2, 10, 15), \"float32\"), T_strided_slice: T.Buffer((1, 5, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax1, ax2 in T.grid(5, 7):\n            T_strided_slice_1 = T.Buffer((35,), data=T_strided_slice.data)\n            a_1 = T.Buffer((300,), data=a.data)\n            T_strided_slice_1[ax1 * 7 + ax2] = a_1[ax1 * 15 + ax2 + 183]",
        "op_args": [
            1,
            2,
            10,
            15
        ],
        "input_shape": "[[2, 10, 15]]",
        "output_shape": "[[1, 5, 7]]"
    },
    {
        "op_name": "unpack_NCHWc_to_nchw",
        "c_code": "void default_function_kernel(float* output_unpack, float* packed_out) {\n  #pragma omp parallel for\n  for (int32_t n_c_fused_h_fused = 0; n_c_fused_h_fused < 504; ++n_c_fused_h_fused) {\n    for (int32_t w = 0; w < 8; ++w) {\n      output_unpack[((n_c_fused_h_fused * 8) + w)] = packed_out[(((((n_c_fused_h_fused / 24) * 192) + ((n_c_fused_h_fused % 12) * 16)) + (w * 2)) + ((n_c_fused_h_fused % 24) / 12))];\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ output_unpack, float* __restrict__ packed_out) {\n  output_unpack[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = packed_out[(((((((int)blockIdx.x) / 3) * 192) + ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) % 12) * 16)) + ((((int)threadIdx.x) & 7) * 2)) + ((((((int)blockIdx.x) % 3) * 2) + (((int)threadIdx.x) >> 5)) / 3))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(packed_out: T.Buffer((3, 7, 12, 8, 2), \"float32\"), output_unpack: T.Buffer((3, 14, 12, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for n_c_fused_h_fused in T.parallel(504):\n            for w in range(8):\n                output_unpack_1 = T.Buffer((4032,), data=output_unpack.data)\n                packed_out_1 = T.Buffer((4032,), data=packed_out.data)\n                output_unpack_1[n_c_fused_h_fused * 8 + w] = packed_out_1[n_c_fused_h_fused // 24 * 192 + n_c_fused_h_fused % 12 * 16 + w * 2 + n_c_fused_h_fused % 24 // 12]",
        "op_args": [
            3,
            7,
            12,
            8
        ],
        "input_shape": "[[3, 7, 12, 8, 2]]",
        "output_shape": "[[3, 14, 12, 8]]"
    },
    {
        "op_name": "upsampling",
        "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i2 = 0; i2 < 40; ++i2) {\n      for (int32_t i3 = 0; i3 < 36; ++i3) {\n        resize[(((i0 * 1440) + (i2 * 36)) + i3)] = data[(((i0 * 360) + ((i2 / 2) * 18)) + (i3 / 2))];\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) / 40) * 360) + (((((int)blockIdx.x) % 40) / 2) * 18)) + (((int)threadIdx.x) / 2))];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 1, 20, 18), \"float32\"), resize: T.Buffer((11, 1, 40, 36), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i2, i3 in T.grid(40, 36):\n                resize_1 = T.Buffer((15840,), data=resize.data)\n                data_1 = T.Buffer((3960,), data=data.data)\n                resize_1[i0 * 1440 + i2 * 36 + i3] = data_1[i0 * 360 + T.Div(i2, 2) * 18 + T.Div(i3, 2)]",
        "op_args": [
            11,
            1,
            10,
            9
        ],
        "input_shape": "[[11, 1, 20, 18]]",
        "output_shape": "[[11, 1, 40, 36]]"
    },
    {
        "op_name": "rms_norm",
        "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 8; ++ax0) {\n    float T_multiply_red[168];\n    for (int32_t ax1 = 0; ax1 < 12; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 14; ++ax2) {\n        T_multiply_red[((ax1 * 14) + ax2)] = 0.000000e+00f;\n        for (int32_t k1 = 0; k1 < 10; ++k1) {\n          T_multiply_red[((ax1 * 14) + ax2)] = (T_multiply_red[((ax1 * 14) + ax2)] + (data[((((ax0 * 1680) + (k1 * 168)) + (ax1 * 14)) + ax2)] * data[((((ax0 * 1680) + (k1 * 168)) + (ax1 * 14)) + ax2)]));\n        }\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 10; ++ax1_1) {\n      for (int32_t ax2_1 = 0; ax2_1 < 12; ++ax2_1) {\n        for (int32_t ax3_s = 0; ax3_s < 14; ++ax3_s) {\n          T_cast[((((ax0 * 1680) + (ax1_1 * 168)) + (ax2_1 * 14)) + ax3_s)] = ((data[((((ax0 * 1680) + (ax1_1 * 168)) + (ax2_1 * 14)) + ax3_s)] * weight[ax1_1]) * (1.000000e+00f / sqrtf(((T_multiply_red[((ax2_1 * 14) + ax3_s)] * 1.000000e-01f) + 1.000000e-05f))));\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  T_cast[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] * weight[((((((int)blockIdx.x) % 48) * 5) + (((int)threadIdx.x) / 7)) / 24)]) * (1.000000e+00f / sqrtf(((T_multiply_red[(((((int)blockIdx.x) / 48) * 168) + (((((int)blockIdx.x) * 35) + ((int)threadIdx.x)) % 168))] * 1.000000e-01f) + 1.000000e-05f))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k1 = 0; k1 < 10; ++k1) {\n    T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + (data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) / 21) * 1680) + (k1 * 168)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 168))] * data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) / 21) * 1680) + (k1 * 168)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 168))]));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 10, 12, 14), \"float32\"), weight: T.Buffer((14,), \"float32\"), T_cast: T.Buffer((8, 10, 12, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(8):\n            T_multiply_red = T.allocate([168], \"float32\", \"global\")\n            T_multiply_red_1 = T.Buffer((168,), data=T_multiply_red)\n            data_1 = T.Buffer((13440,), data=data.data)\n            for ax1, ax2 in T.grid(12, 14):\n                T_multiply_red_1[ax1 * 14 + ax2] = T.float32(0)\n                for k1 in range(10):\n                    cse_var_3: T.int32 = ax1 * 14\n                    cse_var_2: T.int32 = cse_var_3 + ax2\n                    cse_var_1: T.int32 = ax0 * 1680 + k1 * 168 + cse_var_3 + ax2\n                    T_multiply_red_1[cse_var_2] = T_multiply_red_1[cse_var_2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax1, ax2, ax3_s in T.grid(10, 12, 14):\n                cse_var_5: T.int32 = ax2 * 14\n                cse_var_4: T.int32 = ax0 * 1680 + ax1 * 168 + cse_var_5 + ax3_s\n                T_cast_1 = T.Buffer((13440,), data=T_cast.data)\n                T_cast_1[cse_var_4] = data_1[cse_var_4] * weight[ax1] * T.rsqrt(T_multiply_red_1[cse_var_5 + ax3_s] * T.float32(0.10000000000000001) + T.float32(1.0000000000000001e-05))",
        "op_args": [
            8,
            10,
            12,
            14
        ],
        "input_shape": "[[8, 10, 12, 14], [14]]",
        "output_shape": "[[8, 10, 12, 14]]"
    }
]