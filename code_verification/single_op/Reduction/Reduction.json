[
    {
        "op_name": "sum",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[27];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 2210; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 27; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 27) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 0.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 1865; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 16) + (((int)threadIdx.x) >> 1)) < 29835) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 15, 18, 17), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([27], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((27,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(27):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(2210, 27):\n            data_1 = T.Buffer((59670,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 27 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(27):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]",
        "op_args": [
            13,
            15,
            18,
            17
        ],
        "input_shape": "[[13, 15, 18, 17]]",
        "output_shape": "[[]]"
    },
    {
        "op_name": "global_pool_max",
        "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 22; ++ax0_ax1_fused) {\n    adaptive_pool_max[ax0_ax1_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 4; ++rv0) {\n      adaptive_pool_max[ax0_ax1_fused] = max(adaptive_pool_max[ax0_ax1_fused], data[((ax0_ax1_fused * 4) + rv0)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(22) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 4; ++rv0) {\n    adaptive_pool_max[((int)threadIdx.x)] = max(adaptive_pool_max[((int)threadIdx.x)], data[((((int)threadIdx.x) * 4) + rv0)]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 2, 4, 1), \"float32\"), adaptive_pool_max: T.Buffer((11, 2, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(22):\n            adaptive_pool_max_1 = T.Buffer((22,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0 in range(4):\n                data_1 = T.Buffer((88,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused], data_1[ax0_ax1_fused * 4 + rv0])",
        "op_args": [
            11,
            2,
            4,
            1
        ],
        "input_shape": "[[11, 2, 4, 1]]",
        "output_shape": "[[11, 2, 1, 1]]"
    },
    {
        "op_name": "global_pool_avg",
        "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 5; ++ax0) {\n    float adaptive_pool_sum[1];\n    for (int32_t ax1 = 0; ax1 < 8; ++ax1) {\n      adaptive_pool_sum[0] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < 15; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 15; ++rv1) {\n          adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[((((ax0 * 1800) + (ax1 * 225)) + (rv0 * 15)) + rv1)]);\n        }\n      }\n      adaptive_pool_avg[((ax0 * 8) + ax1)] = (adaptive_pool_sum[0] * 4.444444e-03f);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] * 4.444444e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 15; ++rv0) {\n    for (int rv1 = 0; rv1 < 15; ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 4500) + (((int)threadIdx.x) * 225)) + (rv0 * 15)) + rv1)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 8, 15, 15), \"float32\"), adaptive_pool_avg: T.Buffer((5, 8, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(5):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            for ax1 in range(8):\n                adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n                adaptive_pool_sum_1[0] = T.float32(0)\n                for rv0, rv1 in T.grid(15, 15):\n                    data_1 = T.Buffer((9000,), data=data.data)\n                    adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0 * 1800 + ax1 * 225 + rv0 * 15 + rv1]\n                adaptive_pool_avg_1 = T.Buffer((40,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 8 + ax1] = adaptive_pool_sum_1[0] * T.float32(0.0044444444444444444)",
        "op_args": [
            5,
            8,
            15,
            15
        ],
        "input_shape": "[[5, 8, 15, 15]]",
        "output_shape": "[[5, 8, 1, 1]]"
    },
    {
        "op_name": "max",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[22];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 22; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 330; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 22; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 22) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 22; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 12; ++k0) {\n    for (int k1 = 0; k1 < 5; ++k1) {\n      for (int k2 = 0; k2 < 11; ++k2) {\n        for (int k3 = 0; k3 < 11; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 605) + (k1 * 121)) + (k2 * 11)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 5, 11, 11), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([22], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((22,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(22):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(330, 22):\n            data_1 = T.Buffer((7260,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 22 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(22):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])",
        "op_args": [
            12,
            5,
            11,
            11
        ],
        "input_shape": "[[12, 5, 11, 11]]",
        "output_shape": "[[]]"
    },
    {
        "op_name": "min",
        "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[14];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 14; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 144; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 14; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 14) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 14; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 3.402823e+38f;\n  for (int k0 = 0; k0 < 6; ++k0) {\n    for (int k1 = 0; k1 < 3; ++k1) {\n      for (int k2 = 0; k2 < 16; ++k2) {\n        for (int k3 = 0; k3 < 7; ++k3) {\n          data_red[0] = min(data_red[0], data[((((k0 * 336) + (k1 * 112)) + (k2 * 7)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 3, 16, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([14], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((14,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(14):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(144, 14):\n            data_1 = T.Buffer((2016,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 14 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(14):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])",
        "op_args": [
            6,
            3,
            16,
            7
        ],
        "input_shape": "[[6, 3, 16, 7]]",
        "output_shape": "[[]]"
    },
    {
        "op_name": "rms_norm",
        "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 8; ++ax0) {\n    float T_multiply_red[168];\n    for (int32_t ax1 = 0; ax1 < 12; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 14; ++ax2) {\n        T_multiply_red[((ax1 * 14) + ax2)] = 0.000000e+00f;\n        for (int32_t k1 = 0; k1 < 10; ++k1) {\n          T_multiply_red[((ax1 * 14) + ax2)] = (T_multiply_red[((ax1 * 14) + ax2)] + (data[((((ax0 * 1680) + (k1 * 168)) + (ax1 * 14)) + ax2)] * data[((((ax0 * 1680) + (k1 * 168)) + (ax1 * 14)) + ax2)]));\n        }\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 10; ++ax1_1) {\n      for (int32_t ax2_1 = 0; ax2_1 < 12; ++ax2_1) {\n        for (int32_t ax3_s = 0; ax3_s < 14; ++ax3_s) {\n          T_cast[((((ax0 * 1680) + (ax1_1 * 168)) + (ax2_1 * 14)) + ax3_s)] = ((data[((((ax0 * 1680) + (ax1_1 * 168)) + (ax2_1 * 14)) + ax3_s)] * weight[ax1_1]) * (1.000000e+00f / sqrtf(((T_multiply_red[((ax2_1 * 14) + ax3_s)] * 1.000000e-01f) + 1.000000e-05f))));\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  T_cast[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] * weight[((((((int)blockIdx.x) % 48) * 5) + (((int)threadIdx.x) / 7)) / 24)]) * (1.000000e+00f / sqrtf(((T_multiply_red[(((((int)blockIdx.x) / 48) * 168) + (((((int)blockIdx.x) * 35) + ((int)threadIdx.x)) % 168))] * 1.000000e-01f) + 1.000000e-05f))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k1 = 0; k1 < 10; ++k1) {\n    T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + (data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) / 21) * 1680) + (k1 * 168)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 168))] * data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) / 21) * 1680) + (k1 * 168)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 168))]));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 10, 12, 14), \"float32\"), weight: T.Buffer((14,), \"float32\"), T_cast: T.Buffer((8, 10, 12, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(8):\n            T_multiply_red = T.allocate([168], \"float32\", \"global\")\n            T_multiply_red_1 = T.Buffer((168,), data=T_multiply_red)\n            data_1 = T.Buffer((13440,), data=data.data)\n            for ax1, ax2 in T.grid(12, 14):\n                T_multiply_red_1[ax1 * 14 + ax2] = T.float32(0)\n                for k1 in range(10):\n                    cse_var_3: T.int32 = ax1 * 14\n                    cse_var_2: T.int32 = cse_var_3 + ax2\n                    cse_var_1: T.int32 = ax0 * 1680 + k1 * 168 + cse_var_3 + ax2\n                    T_multiply_red_1[cse_var_2] = T_multiply_red_1[cse_var_2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax1, ax2, ax3_s in T.grid(10, 12, 14):\n                cse_var_5: T.int32 = ax2 * 14\n                cse_var_4: T.int32 = ax0 * 1680 + ax1 * 168 + cse_var_5 + ax3_s\n                T_cast_1 = T.Buffer((13440,), data=T_cast.data)\n                T_cast_1[cse_var_4] = data_1[cse_var_4] * weight[ax1] * T.rsqrt(T_multiply_red_1[cse_var_5 + ax3_s] * T.float32(0.10000000000000001) + T.float32(1.0000000000000001e-05))",
        "op_args": [
            8,
            10,
            12,
            14
        ],
        "input_shape": "[[8, 10, 12, 14], [14]]",
        "output_shape": "[[8, 10, 12, 14]]"
    }
]