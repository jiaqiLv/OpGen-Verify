[
    {
        "op_name": "adaptive_pool_max",
        "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 2040; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n      adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < (((((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) % 8) == 0) ? ((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) >> 3) : (((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) >> 3) + 1)) - (((ax0_ax1_fused_ax2_fused & 7) * 5) >> 3)); ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 2; ++rv1) {\n          adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)] = max(adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)], data[((((((ax0_ax1_fused_ax2_fused >> 3) * 80) + ((((ax0_ax1_fused_ax2_fused & 7) * 5) >> 3) * 16)) + (rv0 * 16)) + (ax3 * 2)) + rv1)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < ((((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) % 8) == 0) ? (((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) >> 3) : ((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) >> 3) + 1)) - ((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < 2; ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))], data[((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) >> 4) * 80) + (((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) >> 3) * 16)) + (rv0 * 16)) + ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 2)) + rv1)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 17, 5, 16), \"float32\"), adaptive_pool_max: T.Buffer((15, 17, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(2040):\n            for ax3 in range(8):\n                adaptive_pool_max_1 = T.Buffer((16320,), data=adaptive_pool_max.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused * 8 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(T.Let(T.Let(T.Let(T.Select(cse_var_3 % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 // 8, where={cse_var_1: cse_var_3 // 8}), where={cse_var_3: cse_var_2 + 5}), where={cse_var_2: ax0_ax1_fused_ax2_fused % 8 * 5}), 2):\n                    cse_var_2 = T.int32()\n                    cse_var_3 = T.int32()\n                    cse_var_1 = T.int32()\n                    cse_var_4: T.int32 = ax0_ax1_fused_ax2_fused * 8 + ax3\n                    data_1 = T.Buffer((20400,), data=data.data)\n                    adaptive_pool_max_1[cse_var_4] = T.max(adaptive_pool_max_1[cse_var_4], data_1[ax0_ax1_fused_ax2_fused // 8 * 80 + ax0_ax1_fused_ax2_fused % 8 * 5 // 8 * 16 + rv0 * 16 + ax3 * 2 + rv1])",
        "op_args": [
            15,
            17,
            5,
            16
        ],
        "input_shape": "[[15, 17, 5, 16]]",
        "output_shape": "[[15, 17, 8, 8]]",
        "deepseek_c": "void default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 120; ++ax0_ax1_fused_ax2_fused_outer) {\n    for (int ax0_ax1_fused_ax2_fused_inner = 0; ax0_ax1_fused_ax2_fused_inner < 10; ++ax0_ax1_fused_ax2_fused_inner) {\n      adaptive_pool_max[((ax0_ax1_fused_ax2_fused_outer * 10) + ax0_ax1_fused_ax2_fused_inner)] = -3.402823e+38f;\n      for (int rv0 = 0; rv0 < (((((ax0_ax1_fused_ax2_fused_outer % 8) == 0) ? (ax0_ax1_fused_ax2_fused_inner >> 1) : ((ax0_ax1_fused_ax2_fused_inner >> 1) + 1)) - ((ax0_ax1_fused_ax2_fused_inner >> 1) >> 1)) * 2); ++rv0) {\n        for (int rv1 = 0; rv1 < 2; ++rv1) {\n          adaptive_pool_max[((ax0_ax1_fused_ax2_fused_outer * 10) + ax0_ax1_fused_ax2_fused_inner))] = max(adaptive_pool_max[((ax0_ax1_fused_ax2_fused_outer * 10) + ax0_ax1_fused_ax2_fused_inner))], data[((((((ax0_ax1_fused_ax2_fused_outer * 80) + (ax0_ax1_fused_ax2_fused_inner * 16)) + (rv0 * 16)) + (rv1 * 8)) + (((ax0_ax1_fused_ax2_fused_outer % 8) * 2) + (ax0_ax1_fused_ax2_fused_inner & 1)))]);\n        }\n      }\n    }\n  }\n}"
    },
    {
        "op_name": "adaptive_pool_avg",
        "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 195; ++ax0_ax1_fused) {\n    float adaptive_pool_sum[8];\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n        adaptive_pool_sum[ax3] = 0.000000e+00f;\n        for (int32_t rv0 = 0; rv0 < ((((ax2 + 1) % 8) == 0) ? ((ax2 + 1) >> 3) : (((ax2 + 1) >> 3) + 1)); ++rv0) {\n          for (int32_t rv1 = 0; rv1 < ((((((ax3 * 2) + 2) % 8) == 0) ? ((ax3 + 1) >> 2) : (((ax3 + 1) >> 2) + 1)) - (ax3 >> 2)); ++rv1) {\n            adaptive_pool_sum[ax3] = (adaptive_pool_sum[ax3] + data[((((ax0_ax1_fused * 2) + (rv0 * 2)) + (ax3 >> 2)) + rv1)]);\n          }\n        }\n      }\n      for (int32_t ax3_1 = 0; ax3_1 < 8; ++ax3_1) {\n        adaptive_pool_avg[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3_1)] = (adaptive_pool_sum[ax3_1] / (((float)((((ax2 + 1) % 8) == 0) ? ((ax2 + 1) >> 3) : (((ax2 + 1) >> 3) + 1))) * ((float)((((((ax3_1 * 2) + 2) % 8) == 0) ? ((ax3_1 + 1) >> 2) : (((ax3_1 + 1) >> 2) + 1)) - (ax3_1 >> 2)))));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] / (((float)(((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) % 8) == 0) ? (((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) >> 3) : ((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) >> 3) + 1))) * ((float)(((((((((int)threadIdx.x) & 7) * 2) + 2) % 8) == 0) ? (((((int)threadIdx.x) & 7) + 1) >> 2) : ((((((int)threadIdx.x) & 7) + 1) >> 2) + 1)) - ((((int)threadIdx.x) & 7) >> 2)))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < (((((((((int)blockIdx.x) & 1) * 4) + (((int)threadIdx.x) >> 3)) + 1) % 8) == 0) ? ((((((int)threadIdx.x) + 8) >> 5) + (((int)blockIdx.x) & 1)) >> 1) : (((((((int)threadIdx.x) + 8) >> 5) + (((int)blockIdx.x) & 1)) >> 1) + 1)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((int)threadIdx.x) & 7) * 2) + 2) % 8) == 0) ? (((((int)threadIdx.x) & 7) + 1) >> 2) : ((((((int)threadIdx.x) & 7) + 1) >> 2) + 1)) - ((((int)threadIdx.x) & 7) >> 2)); ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data[(((((((int)blockIdx.x) >> 1) * 2) + (rv0 * 2)) + ((((int)threadIdx.x) & 7) >> 2)) + rv1)]);\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 13, 1, 2), \"float32\"), adaptive_pool_avg: T.Buffer((15, 13, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(195):\n            adaptive_pool_sum = T.allocate([8], \"float32\", \"global\")\n            for ax2 in range(8):\n                adaptive_pool_sum_1 = T.Buffer((8,), data=adaptive_pool_sum, align=32)\n                for ax3 in range(8):\n                    adaptive_pool_sum_1[ax3] = T.float32(0)\n                    for rv0, rv1 in T.grid(T.Let(T.Select((ax2 + 1) % 8 == 0, cse_var_1, cse_var_1 + 1), where={cse_var_1: (ax2 + 1) // 8}), T.Let(T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_2, cse_var_2 + 1) - ax3 // 4, where={cse_var_2: (ax3 + 1) // 4})):\n                        cse_var_1 = T.int32()\n                        cse_var_2 = T.int32()\n                        data_1 = T.Buffer((390,), data=data.data)\n                        adaptive_pool_sum_1[ax3] = adaptive_pool_sum_1[ax3] + data_1[ax0_ax1_fused * 2 + rv0 * 2 + ax3 // 4 + rv1]\n                for ax3 in range(8):\n                    cse_var_5: T.int32 = ax2 + 1\n                    cse_var_4: T.int32 = cse_var_5 // 8\n                    cse_var_3: T.int32 = (ax3 + 1) // 4\n                    adaptive_pool_avg_1 = T.Buffer((12480,), data=adaptive_pool_avg.data)\n                    adaptive_pool_avg_1[ax0_ax1_fused * 64 + ax2 * 8 + ax3] = adaptive_pool_sum_1[ax3] / (T.Cast(\"float32\", T.Select(cse_var_5 % 8 == 0, cse_var_4, cse_var_4 + 1)) * T.Cast(\"float32\", T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_3, cse_var_3 + 1) - ax3 // 4))",
        "op_args": [
            15,
            13,
            1,
            2
        ],
        "input_shape": "[[15, 13, 1, 2]]",
        "output_shape": "[[15, 13, 8, 8]]",
        "deepseek_c": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 15; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 1; ++ax2) {\n      float adaptive_pool_sum[1];\n      adaptive_pool_sum[0] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < (((((((((int)ax0_ax1_fused) & 1) * 4) + (((int)ax2) >> 3)) + 1) % 8) == 0) ? ((((((int)ax2) + 8) >> 5) + (((int)ax0_ax1_fused) & 1)) >> 1) : (((((((int)ax2) + 8) >> 5) + (((int)ax0_ax1_fused) & 1)) >> 1) + 1)); ++rv0) {\n        for (int32_t rv1 = 0; rv1 < (((((((((int)ax2) & 7) * 2) + 2) % 8) == 0) ? (((((int)ax2) & 7) + 1) >> 2) : ((((((int)ax2) & 7) + 1) >> 2) + 1)) - ((((int)ax2) & 7) >> 2)); ++rv1) {\n          adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[(((((((int)ax0_ax1_fused) >> 1) * 2) + (rv0 * 2)) + ((((int)ax2) & 7) >> 2)) + rv1)]);\n        }\n      }\n      adaptive_pool_avg[((ax0_ax1_fused * 2) + ax2)] = (adaptive_pool_sum[0] / (((float)(((((((((int)ax0_ax1_fused) & 1) * 4) + (((int)ax2) >> 3)) + 1) % 8) == 0) ? ((((((int)ax0_ax1_fused) & 1) * 4) + (((int)ax2) >> 3)) + 1) >> 3) : ((((((((int)ax0_ax1_fused) & 1) * 4) + (((int)ax2) >> 3)) + 1) >> 3) + 1))) * ((float)(((((((((int)ax2) & 7) * 2) + 2) % 8) == 0) ? (((((int)ax2) & 7) + 1) >> 2) : ((((((int)ax2) & 7) + 1) >> 2) + 1)) - ((((int)ax2) & 7) >> 2)))));\n    }\n  }\n}"
    },
    {
        "op_name": "fast_erf",
        "c_code": "void default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 648; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 6; ++ax3) {\n      T_fast_erf[((ax0_ax1_fused_ax2_fused * 6) + ax3)] = ((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_fast_erf, float* __restrict__ data) {\n  T_fast_erf[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 12, 6, 6), \"float32\"), T_fast_erf: T.Buffer((9, 12, 6, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(648):\n            for ax3 in range(6):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 6 + ax3\n                T_fast_erf_1 = T.Buffer((3888,), data=T_fast_erf.data)\n                data_1 = T.Buffer((3888,), data=data.data)\n                T_fast_erf_1[cse_var_1] = T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-2.7261423674040941e-10) + T.float32(2.7706814620387377e-08)) + T.float32(-2.101023937939317e-06)) + T.float32(-5.6925062381196767e-05)) + T.float32(-0.00073499063728377223)) + T.float32(-0.0029545999132096767)) + T.float32(-0.016096033155918121)) / (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-1.4566071513399947e-05) + T.float32(-0.00021337404905352741)) + T.float32(-0.001682827016338706)) + T.float32(-0.0073733292520046234)) + T.float32(-0.014264739118516445))",
        "op_args": [
            9,
            12,
            6,
            6
        ],
        "input_shape": "[[9, 12, 6, 6]]",
        "output_shape": "[[9, 12, 6, 6]]",
        "deepseek_c": "void default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3888; ++i0_i1_fused_i2_fused_i3_fused) {\n    T_fast_erf[i0_i1_fused_i2_fused_i3_fused] = ((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n  }\n}"
    },
    {
        "op_name": "lrn",
        "c_code": "void default_function_kernel(float* T_divide, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 1560; ++ax0_ax1_fused_ax2_fused) {\n    float tensor[1];\n    for (int32_t ax3 = 0; ax3 < 9; ++ax3) {\n      tensor[0] = 0.000000e+00f;\n      tensor[0] = (tensor[0] + (data[((ax0_ax1_fused_ax2_fused * 9) + ax3)] * data[((ax0_ax1_fused_ax2_fused * 9) + ax3)]));\n      T_divide[((ax0_ax1_fused_ax2_fused * 9) + ax3)] = (data[((ax0_ax1_fused_ax2_fused * 9) + ax3)] / powf((2.000000e+00f + (1.000000e-04f * tensor[0])), 7.500000e-01f));\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel_1(float* __restrict__ T_divide, float* __restrict__ data, float* __restrict__ tensor) {\n  T_divide[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] / powf((2.000000e+00f + (1.000000e-04f * tensor[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))])), 7.500000e-01f));\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ tensor) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 1755) {\n    tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 1755) {\n    tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + (data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 10, 13, 9), \"float32\"), T_divide: T.Buffer((12, 10, 13, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(1560):\n            tensor = T.allocate([1], \"float32\", \"global\")\n            for ax3 in range(9):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 9 + ax3\n                tensor_1 = T.Buffer((1,), data=tensor, align=4)\n                tensor_1[0] = T.float32(0)\n                data_1 = T.Buffer((14040,), data=data.data)\n                tensor_1[0] = tensor_1[0] + data_1[cse_var_1] * data_1[cse_var_1]\n                T_divide_1 = T.Buffer((14040,), data=T_divide.data)\n                T_divide_1[cse_var_1] = data_1[cse_var_1] / T.pow(T.float32(2) + T.float32(9.9999997473787516e-05) * tensor_1[0], T.float32(0.75))",
        "op_args": [
            12,
            10,
            13,
            9
        ],
        "input_shape": "[[12, 10, 13, 9]]",
        "output_shape": "[[12, 10, 13, 9]]",
        "deepseek_c": "void default_function_kernel(float* T_divide, float* data, float* tensor) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 1560; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 9; ++ax3) {\n      tensor[((ax0_ax1_fused_ax2_fused * 9) + ax3)] = 0.000000e+00f;\n    }\n    for (int32_t ax3_1 = 0; ax3_1 < 9; ++ax3_1) {\n      tensor[((ax0_ax1_fused_ax2_fused * 9) + ax3_1)] = (tensor[((ax0_ax1_fused_ax2_fused * 9) + ax3_1)] + (data[((ax0_ax1_fused_ax2_fused * 9) + ax3_1)] * data[((ax0_ax1_fused_ax2_fused * 9) + ax3_1)]));\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_1 = 0; ax0_ax1_fused_ax2_fused_1 < 1560; ++ax0_ax1_fused_ax2_fused_1) {\n    T_divide[ax0_ax1_fused_ax2_fused_1] = (data[ax0_ax1_fused_ax2_fused_1] / powf(2.000000e+00f + (1.000000e-04f * tensor[ax0_ax1_fused_ax2_fused_1]), 7.500000e-01f));\n  }\n}"
    },
    {
        "op_name": "pool1d",
        "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 19; ++ax0) {\n    float pad_temp[13];\n    for (int32_t ax2_s = 0; ax2_s < 13; ++ax2_s) {\n      pad_temp[ax2_s] = (((1 <= ax2_s) && (ax2_s < 12)) ? data[(((ax0 * 11) + ax2_s) - 1)] : -3.402823e+38f);\n    }\n    for (int32_t ax2 = 0; ax2 < 6; ++ax2) {\n      pool_max[((ax0 * 6) + ax2)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n        pool_max[((ax0 * 6) + ax2)] = max(pool_max[((ax0 * 6) + ax2)], pad_temp[((ax2 * 2) + rv0)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  if (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 114) {\n    pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    if (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 114) {\n      pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))], (((1 <= ((((((int)blockIdx.x) + ((int)threadIdx.x)) % 6) * 2) + rv0)) && (((rv0 >> 1) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 6)) < 6)) ? data[(((((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) / 6) * 11) + (((((int)blockIdx.x) + ((int)threadIdx.x)) % 6) * 2)) + rv0) - 1)] : -3.402823e+38f));\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 1, 11), \"float32\"), pool_max: T.Buffer((19, 1, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(19):\n            pad_temp = T.allocate([13], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((13,), data=pad_temp, align=32)\n            for ax2_s in range(13):\n                data_1 = T.Buffer((209,), data=data.data)\n                pad_temp_1[ax2_s] = T.if_then_else(1 <= ax2_s and ax2_s < 12, data_1[ax0 * 11 + ax2_s - 1], T.float32(-3.4028234663852886e+38))\n            for ax2 in range(6):\n                pool_max_1 = T.Buffer((114,), data=pool_max.data)\n                pool_max_1[ax0 * 6 + ax2] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_1: T.int32 = ax0 * 6 + ax2\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 2 + rv0])",
        "op_args": [
            19,
            1,
            5,
            11
        ],
        "input_shape": "[[19, 1, 11]]",
        "output_shape": "[[19, 1, 6]]",
        "deepseek_c": "void default_function_kernel(float* data, float* pool_max) {\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 19; ++ax0_ax1_fused) {\n    pool_max[ax0_ax1_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n      pool_max[ax0_ax1_fused] = max(pool_max[ax0_ax1_fused], (((1 <= (((ax0_ax1_fused % 6) * 2) + rv0)) && (((rv0 >> 1) + (ax0_ax1_fused % 6)) < 6)) ? data[((((ax0_ax1_fused / 6) * 11) + ((ax0_ax1_fused % 6) * 2)) + rv0)] : -3.402823e+38f));\n    }\n  }\n}"
    },
    {
        "op_name": "pool2d",
        "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 11; ++ax0) {\n    float pad_temp[247];\n    for (int32_t ax1 = 0; ax1 < 3; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 19; ++ax2) {\n        for (int32_t ax3_s = 0; ax3_s < 13; ++ax3_s) {\n          pad_temp[((ax2 * 13) + ax3_s)] = (((1 <= ax2) && (1 <= ax3_s)) ? data[(((((ax0 * 648) + (ax1 * 216)) + (ax2 * 12)) + ax3_s) - 13)] : -3.402823e+38f);\n        }\n      }\n      for (int32_t ax2_1 = 0; ax2_1 < 9; ++ax2_1) {\n        for (int32_t ax3 = 0; ax3 < 6; ++ax3) {\n          pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)] = max(pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)], pad_temp[((((ax2_1 * 26) + (rv0 * 13)) + (ax3 * 2)) + rv1)]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))], (((1 <= (((((int)blockIdx.x) % 9) * 2) + rv0)) && (1 <= ((((int)threadIdx.x) * 2) + rv1))) ? data[(((((((int)blockIdx.x) * 24) + (rv0 * 12)) + (((int)threadIdx.x) * 2)) + rv1) - 13)] : -3.402823e+38f));\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 3, 18, 12), \"float32\"), pool_max: T.Buffer((11, 3, 9, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(11):\n            pad_temp = T.allocate([247], \"float32\", \"global\")\n            for ax1 in range(3):\n                pad_temp_1 = T.Buffer((247,), data=pad_temp)\n                for ax2, ax3_s in T.grid(19, 13):\n                    data_1 = T.Buffer((7128,), data=data.data)\n                    pad_temp_1[ax2 * 13 + ax3_s] = T.if_then_else(1 <= ax2 and 1 <= ax3_s, data_1[ax0 * 648 + ax1 * 216 + ax2 * 12 + ax3_s - 13], T.float32(-3.4028234663852886e+38))\n                for ax2, ax3 in T.grid(9, 6):\n                    pool_max_1 = T.Buffer((1782,), data=pool_max.data)\n                    pool_max_1[ax0 * 162 + ax1 * 54 + ax2 * 6 + ax3] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1 in T.grid(3, 3):\n                        cse_var_1: T.int32 = ax0 * 162 + ax1 * 54 + ax2 * 6 + ax3\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 26 + rv0 * 13 + ax3 * 2 + rv1])",
        "op_args": [
            11,
            3,
            18,
            4
        ],
        "input_shape": "[[11, 3, 18, 12]]",
        "output_shape": "[[11, 3, 9, 6]]",
        "deepseek_c": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 33; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 18; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 12; ++ax3) {\n        pool_max[(((ax0_ax1_fused * 216) + (ax2 * 12)) + ax3)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n            pool_max[(((ax0_ax1_fused * 216) + (ax2 * 12)) + ax3)] = max(pool_max[(((ax0_ax1_fused * 216) + (ax2 * 12)) + ax3)], (((1 <= (ax0_ax1_fused + rv0)) && (1 <= (ax3 + rv1))) ? data[((((ax0_ax1_fused * 216) + (rv0 * 72)) + (ax2 * 12)) + (ax3 + rv1))] : -3.402823e+38f));\n          }\n        }\n      }\n    }\n  }\n}"
    },
    {
        "op_name": "pool3d",
        "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 170; ++ax0_ax1_fused) {\n    float pad_temp[27];\n    for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 4; ++ax3) {\n        for (int32_t ax4 = 0; ax4 < 8; ++ax4) {\n          for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n            for (int32_t ax3_1 = 0; ax3_1 < 3; ++ax3_1) {\n              for (int32_t ax4_s = 0; ax4_s < 3; ++ax4_s) {\n                pad_temp[(((ax2_1 * 9) + (ax3_1 * 3)) + ax4_s)] = (((((1 <= ((ax2 * 2) + ax2_1)) && (((ax2_1 >> 1) + ax2) < 4)) && (1 <= ((ax3 * 2) + ax3_1))) && (1 <= ((ax4 * 2) + ax4_s))) ? data[((((((((ax0_ax1_fused * 896) + (ax2 * 256)) + (ax2_1 * 128)) + (ax3 * 32)) + (ax3_1 * 16)) + (ax4 * 2)) + ax4_s) - 145)] : -3.402823e+38f);\n              }\n            }\n          }\n          pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n                pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)] = max(pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)], pad_temp[(((rv0 * 9) + (rv1 * 3)) + rv2)]);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], (((((1 <= ((((((int)blockIdx.x) & 1) * 4) + ((((int)threadIdx.x) >> 5) * 2)) + rv0)) && (((((((int)threadIdx.x) >> 5) + (rv0 >> 1)) >> 1) + (((int)blockIdx.x) & 1)) < 2)) && (1 <= ((((((int)threadIdx.x) & 31) >> 3) * 2) + rv1))) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[((((((((((((int)blockIdx.x) >> 1) * 896) + ((((int)blockIdx.x) & 1) * 512)) + ((((int)threadIdx.x) >> 5) * 256)) + (rv0 * 128)) + (((((int)threadIdx.x) & 31) >> 3) * 32)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 145)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 17, 7, 8, 16), \"float32\"), pool_max: T.Buffer((10, 17, 4, 4, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(170):\n            pad_temp = T.allocate([27], \"float32\", \"global\")\n            for ax2, ax3, ax4 in T.grid(4, 4, 8):\n                pad_temp_1 = T.Buffer((27,), data=pad_temp)\n                for ax2_1, ax3_1, ax4_s in T.grid(3, 3, 3):\n                    cse_var_1: T.int32 = ax4 * 2\n                    data_1 = T.Buffer((152320,), data=data.data)\n                    pad_temp_1[ax2_1 * 9 + ax3_1 * 3 + ax4_s] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and ax2_1 // 2 + ax2 < 4 and 1 <= ax3 * 2 + ax3_1 and 1 <= cse_var_1 + ax4_s, data_1[ax0_ax1_fused * 896 + ax2 * 256 + ax2_1 * 128 + ax3 * 32 + ax3_1 * 16 + cse_var_1 + ax4_s - 145], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((21760,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused * 128 + ax2 * 32 + ax3 * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                    cse_var_2: T.int32 = ax0_ax1_fused * 128 + ax2 * 32 + ax3 * 8 + ax4\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0 * 9 + rv1 * 3 + rv2])",
        "op_args": [
            10,
            17,
            7,
            8
        ],
        "input_shape": "[[10, 17, 7, 8, 16]]",
        "output_shape": "[[10, 17, 4, 4, 8]]",
        "deepseek_c": "void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], (((((1 <= ((((((int)blockIdx.x) & 1) * 4) + ((((int)threadIdx.x) >> 5) * 2)) + rv0)) && (((((((int)threadIdx.x) >> 5) + (rv0 >> 1)) >> 1) + (((int)blockIdx.x) & 1)) < 2)) && (1 <= ((((((int)threadIdx.x) & 31) >> 3) * 2) + rv1))) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[((((((((((((int)blockIdx.x) >> 1) * 896) + ((((int)blockIdx.x) & 1) * 512)) + ((((int)threadIdx.x) >> 5) * 256)) + (rv0 * 128)) + (((((int)threadIdx.x) & 31) >> 3) * 32)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 145)] : -3.402823e+38f));\n      }\n    }\n  }\n}"
    },
    {
        "op_name": "matmul",
        "c_code": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  for (int32_t ax1_outer_outer_outer = 0; ax1_outer_outer_outer < 2; ++ax1_outer_outer_outer) {\n    for (int32_t ax0_inner_init = 0; ax0_inner_init < 2; ++ax0_inner_init) {\n      T_matmul[((ax0_inner_init * 2) + ax1_outer_outer_outer)] = 0.000000e+00f;\n    }\n    for (int32_t k_inner = 0; k_inner < 2; ++k_inner) {\n      for (int32_t ax0_inner = 0; ax0_inner < 2; ++ax0_inner) {\n        T_matmul[((ax0_inner * 2) + ax1_outer_outer_outer)] = (T_matmul[((ax0_inner * 2) + ax1_outer_outer_outer)] + (left_matrix[((ax0_inner * 2) + k_inner)] * right_matrix[((k_inner * 2) + ax1_outer_outer_outer)]));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ T_matmul, float* __restrict__ left_matrix, float* __restrict__ right_matrix) {\n  float T_matmul_local[2];\n  __shared__ float left_matrix_shared[4];\n  __shared__ float right_matrix_shared[4];\n  T_matmul_local[0] = 0.000000e+00f;\n  T_matmul_local[1] = 0.000000e+00f;\n  for (int ax0_ax1_fused_outer_outer = 0; ax0_ax1_fused_outer_outer < 2; ++ax0_ax1_fused_outer_outer) {\n    left_matrix_shared[((ax0_ax1_fused_outer_outer * 2) + ((int)threadIdx.x))] = left_matrix[((ax0_ax1_fused_outer_outer * 2) + ((int)threadIdx.x))];\n  }\n  for (int ax0_ax1_fused_outer_outer_1 = 0; ax0_ax1_fused_outer_outer_1 < 2; ++ax0_ax1_fused_outer_outer_1) {\n    right_matrix_shared[((ax0_ax1_fused_outer_outer_1 * 2) + ((int)threadIdx.x))] = right_matrix[((ax0_ax1_fused_outer_outer_1 * 2) + ((int)threadIdx.x))];\n  }\n  __syncthreads();\n  for (int k_inner = 0; k_inner < 2; ++k_inner) {\n    T_matmul_local[0] = (T_matmul_local[0] + (left_matrix_shared[((((int)threadIdx.x) * 2) + k_inner)] * right_matrix_shared[(k_inner * 2)]));\n    T_matmul_local[1] = (T_matmul_local[1] + (left_matrix_shared[((((int)threadIdx.x) * 2) + k_inner)] * right_matrix_shared[((k_inner * 2) + 1)]));\n  }\n  T_matmul[(((int)threadIdx.x) * 2)] = T_matmul_local[0];\n  T_matmul[((((int)threadIdx.x) * 2) + 1)] = T_matmul_local[1];\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(left_matrix: T.Buffer((2, 2), \"float32\"), right_matrix: T.Buffer((2, 2), \"float32\"), T_matmul: T.Buffer((2, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax1_outer_outer_outer in range(2):\n            T_matmul_1 = T.Buffer((4,), data=T_matmul.data)\n            for ax0_inner_init in range(2):\n                T_matmul_1[ax0_inner_init * 2 + ax1_outer_outer_outer] = T.float32(0)\n            for k_inner, ax0_inner in T.grid(2, 2):\n                cse_var_2: T.int32 = ax0_inner * 2\n                cse_var_1: T.int32 = cse_var_2 + ax1_outer_outer_outer\n                left_matrix_1 = T.Buffer((4,), data=left_matrix.data)\n                right_matrix_1 = T.Buffer((4,), data=right_matrix.data)\n                T_matmul_1[cse_var_1] = T_matmul_1[cse_var_1] + left_matrix_1[cse_var_2 + k_inner] * right_matrix_1[k_inner * 2 + ax1_outer_outer_outer]",
        "op_args": [
            7,
            2,
            2,
            2
        ],
        "input_shape": "[[2, 2], [2, 2]]",
        "output_shape": "[[2, 2]]",
        "deepseek_c": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  float T_matmul_local[2];\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 4; ++ax0_ax1_fused_ax2_fused_outer) {\n    T_matmul_local[0] = 0.000000e+00f;\n    T_matmul_local[1] = 0.000000e+00f;\n    for (int32_t k_inner = 0; k_inner < 2; ++k_inner) {\n      T_matmul_local[0] = (T_matmul_local[0] + (left_matrix[((ax0_ax1_fused_ax2_fused_outer * 2) + k_inner)] * right_matrix[((k_inner * 2) + 0)]));\n      T_matmul_local[1] = (T_matmul_local[1] + (left_matrix[((ax0_ax1_fused_ax2_fused_outer * 2) + k_inner)] * right_matrix[((k_inner * 2) + 1)]));\n    }\n    T_matmul[((ax0_ax1_fused_ax2_fused_outer * 2) + 0)] = T_matmul_local[0];\n    T_matmul[((ax0_ax1_fused_ax2_fused_outer * 2) + 1)] = T_matmul_local[1];\n  }\n}"
    }
]