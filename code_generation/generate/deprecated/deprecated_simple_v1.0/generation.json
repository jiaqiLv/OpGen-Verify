{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 112; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 19; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 19) + i3)] = sinf(data[((i0_i1_fused_i2_fused * 19) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 8, 2, 19), \"float32\"), compute: T.Buffer((7, 8, 2, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(112):\n            for i3 in range(19):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 19 + i3\n                compute_1 = T.Buffer((2128,), data=compute.data)\n                data_1 = T.Buffer((2128,), data=data.data)\n                compute_1[cse_var_1] = T.sin(data_1[cse_var_1])", "op_args": [7, 8, 2, 19], "input_shape": "[[7, 8, 2, 19]]", "output_shape": "[[7, 8, 2, 19]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3808; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 17, 1, 16), \"float32\"), compute: T.Buffer((14, 17, 1, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3808):\n            compute_1 = T.Buffer((3808,), data=compute.data)\n            data_1 = T.Buffer((3808,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [14, 17, 1, 16], "input_shape": "[[14, 17, 1, 16]]", "output_shape": "[[14, 17, 1, 16]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 2; ++i0) {\n    for (int32_t i1 = 0; i1 < 19; ++i1) {\n      for (int32_t i2 = 0; i2 < 18; ++i2) {\n        for (int32_t i3 = 0; i3 < 2; ++i3) {\n          compute[((((i0 * 684) + (i1 * 36)) + (i2 * 2)) + i3)] = sinf(data[((((i0 * 684) + (i1 * 36)) + (i2 * 2)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 19, 18, 2), \"float32\"), compute: T.Buffer((2, 19, 18, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(2):\n            for i1, i2, i3 in T.grid(19, 18, 2):\n                cse_var_1: T.int32 = i0 * 684 + i1 * 36 + i2 * 2 + i3\n                compute_1 = T.Buffer((1368,), data=compute.data)\n                data_1 = T.Buffer((1368,), data=data.data)\n                compute_1[cse_var_1] = T.sin(data_1[cse_var_1])", "op_args": [2, 19, 18, 2], "input_shape": "[[2, 19, 18, 2]]", "output_shape": "[[2, 19, 18, 2]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2340; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 15, 13, 6), \"float32\"), compute: T.Buffer((2, 15, 13, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2340):\n            compute_1 = T.Buffer((2340,), data=compute.data)\n            data_1 = T.Buffer((2340,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [2, 15, 13, 6], "input_shape": "[[2, 15, 13, 6]]", "output_shape": "[[2, 15, 13, 6]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 14; ++i0) {\n    for (int32_t i1 = 0; i1 < 18; ++i1) {\n      for (int32_t i2 = 0; i2 < 19; ++i2) {\n        for (int32_t i3 = 0; i3 < 20; ++i3) {\n          compute[((((i0 * 6840) + (i1 * 380)) + (i2 * 20)) + i3)] = sinf(data[((((i0 * 6840) + (i1 * 380)) + (i2 * 20)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 18, 19, 20), \"float32\"), compute: T.Buffer((14, 18, 19, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(14):\n            for i1, i2, i3 in T.grid(18, 19, 20):\n                cse_var_1: T.int32 = i0 * 6840 + i1 * 380 + i2 * 20 + i3\n                compute_1 = T.Buffer((95760,), data=compute.data)\n                data_1 = T.Buffer((95760,), data=data.data)\n                compute_1[cse_var_1] = T.sin(data_1[cse_var_1])", "op_args": [14, 18, 19, 20], "input_shape": "[[14, 18, 19, 20]]", "output_shape": "[[14, 18, 19, 20]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 165; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 18; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 18) + i3)] = sinf(data[((i0_i1_fused_i2_fused * 18) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 3, 11, 18), \"float32\"), compute: T.Buffer((5, 3, 11, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(165):\n            for i3 in range(18):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 18 + i3\n                compute_1 = T.Buffer((2970,), data=compute.data)\n                data_1 = T.Buffer((2970,), data=data.data)\n                compute_1[cse_var_1] = T.sin(data_1[cse_var_1])", "op_args": [5, 3, 11, 18], "input_shape": "[[5, 3, 11, 18]]", "output_shape": "[[5, 3, 11, 18]]"}{"op_name": "adaptive_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 1344; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < ((((((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 4) + 4) % 8) == 0) ? (((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 5) + 5) >> 1) : ((((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 5) + 5) >> 1) + 1)) - ((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 20) >> 3)); ++rv0) {\n      for (int32_t rv1 = 0; rv1 < (((((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 2) + 2) % 8) == 0) ? ((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 9) + 9) >> 2) : (((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 9) + 9) >> 2) + 1)) - (((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 18) >> 3)); ++rv1) {\n        adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = max(adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused], data[((((((ax0_ax1_fused_ax2_fused_ax3_fused >> 6) * 360) + (((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 20) >> 3) * 18)) + (rv0 * 18)) + (((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 18) >> 3)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < (((((((((int)blockIdx.x) & 7) * 4) + 4) % 8) == 0) ? ((((((int)blockIdx.x) & 7) * 5) + 5) >> 1) : (((((((int)blockIdx.x) & 7) * 5) + 5) >> 1) + 1)) - (((((int)blockIdx.x) & 7) * 20) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < ((((((((int)threadIdx.x) * 2) + 2) % 8) == 0) ? (((((int)threadIdx.x) * 9) + 9) >> 2) : ((((((int)threadIdx.x) * 9) + 9) >> 2) + 1)) - ((((int)threadIdx.x) * 18) >> 3)); ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))], data[((((((((int)blockIdx.x) >> 3) * 360) + ((((((int)blockIdx.x) & 7) * 20) >> 3) * 18)) + (rv0 * 18)) + ((((int)threadIdx.x) * 18) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 3, 20, 18), \"float32\"), adaptive_pool_max: T.Buffer((7, 3, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(1344):\n            adaptive_pool_max_1 = T.Buffer((1344,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(T.Let(T.Let(T.Select((cse_var_2 * 4 + 4) % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 * 20 // 8, where={cse_var_1: (cse_var_2 * 5 + 5) // 2}), where={cse_var_2: ax0_ax1_fused_ax2_fused_ax3_fused % 64 // 8}), T.Let(T.Let(T.Select((cse_var_4 * 2 + 2) % 8 == 0, cse_var_3, cse_var_3 + 1) - cse_var_4 * 18 // 8, where={cse_var_3: (cse_var_4 * 9 + 9) // 4}), where={cse_var_4: ax0_ax1_fused_ax2_fused_ax3_fused % 8})):\n                cse_var_2 = T.int32()\n                cse_var_1 = T.int32()\n                cse_var_4 = T.int32()\n                cse_var_3 = T.int32()\n                data_1 = T.Buffer((7560,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused], data_1[ax0_ax1_fused_ax2_fused_ax3_fused // 64 * 360 + ax0_ax1_fused_ax2_fused_ax3_fused % 64 // 8 * 20 // 8 * 18 + rv0 * 18 + ax0_ax1_fused_ax2_fused_ax3_fused % 8 * 18 // 8 + rv1])", "op_args": [7, 3, 20, 18], "input_shape": "[[7, 3, 20, 18]]", "output_shape": "[[7, 3, 8, 8]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 156; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(13) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 1, 2, 13), \"float32\"), compute: T.Buffer((6, 1, 2, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(156):\n            compute_1 = T.Buffer((156,), data=compute.data)\n            data_1 = T.Buffer((156,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [6, 1, 2, 13], "input_shape": "[[6, 1, 2, 13]]", "output_shape": "[[6, 1, 2, 13]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 40; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 19; ++i2) {\n      for (int32_t i3 = 0; i3 < 18; ++i3) {\n        compute[(((i0_i1_fused * 342) + (i2 * 18)) + i3)] = sinf(data[(((i0_i1_fused * 342) + (i2 * 18)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 2, 19, 18), \"float32\"), compute: T.Buffer((20, 2, 19, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(40):\n            for i2, i3 in T.grid(19, 18):\n                cse_var_1: T.int32 = i0_i1_fused * 342 + i2 * 18 + i3\n                compute_1 = T.Buffer((13680,), data=compute.data)\n                data_1 = T.Buffer((13680,), data=data.data)\n                compute_1[cse_var_1] = T.sin(data_1[cse_var_1])", "op_args": [20, 2, 19, 18], "input_shape": "[[20, 2, 19, 18]]", "output_shape": "[[20, 2, 19, 18]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 10; ++i1) {\n    for (int32_t i2 = 0; i2 < 9; ++i2) {\n      for (int32_t i3 = 0; i3 < 14; ++i3) {\n        compute[(((i1 * 126) + (i2 * 14)) + i3)] = sinf(data[(((i1 * 126) + (i2 * 14)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 10, 9, 14), \"float32\"), compute: T.Buffer((1, 10, 9, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(10, 9, 14):\n            cse_var_1: T.int32 = i1 * 126 + i2 * 14 + i3\n            compute_1 = T.Buffer((1260,), data=compute.data)\n            data_1 = T.Buffer((1260,), data=data.data)\n            compute_1[cse_var_1] = T.sin(data_1[cse_var_1])", "op_args": [1, 10, 9, 14], "input_shape": "[[1, 10, 9, 14]]", "output_shape": "[[1, 10, 9, 14]]"}{"op_name": "adaptive_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 21760; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < ((((((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 4) + 4) % 8) == 0) ? (((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 3) + 3) >> 1) : ((((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 3) + 3) >> 1) + 1)) - ((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 12) >> 3)); ++rv0) {\n      for (int32_t rv1 = 0; rv1 < (((((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 7) + 7) % 8) == 0) ? ((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 7) + 7) >> 3) : (((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 7) + 7) >> 3) + 1)) - (((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 7) >> 3)); ++rv1) {\n        adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = max(adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused], data[((((((ax0_ax1_fused_ax2_fused_ax3_fused >> 6) * 84) + (((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 12) >> 3) * 7)) + (rv0 * 7)) + (((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 7) >> 3)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < ((((((((((int)threadIdx.x) >> 3) * 4) + 4) % 8) == 0) ? (((((int)blockIdx.x) & 1) * 6) + ((((((int)threadIdx.x) >> 3) * 3) + 3) >> 1)) : ((((((int)blockIdx.x) & 1) * 6) + ((((((int)threadIdx.x) >> 3) * 3) + 3) >> 1)) + 1)) - (((((int)threadIdx.x) >> 3) * 12) >> 3)) - ((((int)blockIdx.x) & 1) * 6)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((int)threadIdx.x) & 7) * 7) + 7) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 7) + 7) >> 3) : (((((((int)threadIdx.x) & 7) * 7) + 7) >> 3) + 1)) - (((((int)threadIdx.x) & 7) * 7) >> 3)); ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((((int)blockIdx.x) * 42) + ((((((int)threadIdx.x) >> 3) * 12) >> 3) * 7)) + (rv0 * 7)) + (((((int)threadIdx.x) & 7) * 7) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 20, 12, 7), \"float32\"), adaptive_pool_max: T.Buffer((17, 20, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(21760):\n            adaptive_pool_max_1 = T.Buffer((21760,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(T.Let(T.Let(T.Select((cse_var_2 * 4 + 4) % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 * 12 // 8, where={cse_var_1: (cse_var_2 * 3 + 3) // 2}), where={cse_var_2: ax0_ax1_fused_ax2_fused_ax3_fused % 64 // 8}), T.Let(T.Let(T.Let(T.Select(cse_var_5 % 8 == 0, cse_var_3, cse_var_3 + 1) - cse_var_4 // 8, where={cse_var_3: cse_var_5 // 8}), where={cse_var_5: cse_var_4 + 7}), where={cse_var_4: ax0_ax1_fused_ax2_fused_ax3_fused % 8 * 7})):\n                cse_var_2 = T.int32()\n                cse_var_1 = T.int32()\n                cse_var_4 = T.int32()\n                cse_var_5 = T.int32()\n                cse_var_3 = T.int32()\n                data_1 = T.Buffer((28560,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused], data_1[ax0_ax1_fused_ax2_fused_ax3_fused // 64 * 84 + ax0_ax1_fused_ax2_fused_ax3_fused % 64 // 8 * 12 // 8 * 7 + rv0 * 7 + ax0_ax1_fused_ax2_fused_ax3_fused % 8 * 7 // 8 + rv1])", "op_args": [17, 20, 12, 7], "input_shape": "[[17, 20, 12, 7]]", "output_shape": "[[17, 20, 8, 8]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2048; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 2, 16, 4), \"float32\"), compute: T.Buffer((16, 2, 16, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2048):\n            compute_1 = T.Buffer((2048,), data=compute.data)\n            data_1 = T.Buffer((2048,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [16, 2, 16, 4], "input_shape": "[[16, 2, 16, 4]]", "output_shape": "[[16, 2, 16, 4]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 11552; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(19) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 19) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 19) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 19, 8, 19), \"float32\"), compute: T.Buffer((4, 19, 8, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(11552):\n            compute_1 = T.Buffer((11552,), data=compute.data)\n            data_1 = T.Buffer((11552,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [4, 19, 8, 19], "input_shape": "[[4, 19, 8, 19]]", "output_shape": "[[4, 19, 8, 19]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2080; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(13) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 16, 2, 5), \"float32\"), compute: T.Buffer((13, 16, 2, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2080):\n            compute_1 = T.Buffer((2080,), data=compute.data)\n            data_1 = T.Buffer((2080,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [13, 16, 2, 5], "input_shape": "[[13, 16, 2, 5]]", "output_shape": "[[13, 16, 2, 5]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 63954; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) < 31977) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 17, 11, 19), \"float32\"), compute: T.Buffer((18, 17, 11, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(63954):\n            compute_1 = T.Buffer((63954,), data=compute.data)\n            data_1 = T.Buffer((63954,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [18, 17, 11, 19], "input_shape": "[[18, 17, 11, 19]]", "output_shape": "[[18, 17, 11, 19]]"}{"op_name": "adaptive_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 9; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 20; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n          adaptive_pool_max[((((ax0 * 1280) + (ax1 * 64)) + (ax2 * 8)) + ax3)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < (((((ax2 + 1) % 8) == 0) ? (((ax2 * 17) + 17) >> 3) : ((((ax2 * 17) + 17) >> 3) + 1)) - (ax2 * 2)); ++rv0) {\n            for (int32_t rv1 = 0; rv1 < ((((((ax3 * 5) + 5) % 8) == 0) ? (((ax3 * 13) + 13) >> 3) : ((((ax3 * 13) + 13) >> 3) + 1)) - ((ax3 * 13) >> 3)); ++rv1) {\n              adaptive_pool_max[((((ax0 * 1280) + (ax1 * 64)) + (ax2 * 8)) + ax3)] = max(adaptive_pool_max[((((ax0 * 1280) + (ax1 * 64)) + (ax2 * 8)) + ax3)], data[((((((ax0 * 4420) + (ax1 * 221)) + (ax2 * 26)) + (rv0 * 13)) + ((ax3 * 13) >> 3)) + rv1)]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < ((((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) % 8) == 0) ? ((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) * 17) + 17) >> 3) : (((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) * 17) + 17) >> 3) + 1)) - ((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) * 2)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((int)threadIdx.x) & 7) * 5) + 5) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 13) + 13) >> 3) : (((((((int)threadIdx.x) & 7) * 13) + 13) >> 3) + 1)) - (((((int)threadIdx.x) & 7) * 13) >> 3)); ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))], data[((((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 4)) >> 2) * 221) + ((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) * 26)) + (rv0 * 13)) + (((((int)threadIdx.x) & 7) * 13) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 20, 17, 13), \"float32\"), adaptive_pool_max: T.Buffer((9, 20, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(9):\n            for ax1, ax2, ax3 in T.grid(20, 8, 8):\n                adaptive_pool_max_1 = T.Buffer((11520,), data=adaptive_pool_max.data)\n                adaptive_pool_max_1[ax0 * 1280 + ax1 * 64 + ax2 * 8 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(T.Let(T.Select((ax2 + 1) % 8 == 0, cse_var_1, cse_var_1 + 1) - ax2 * 2, where={cse_var_1: (ax2 * 17 + 17) // 8}), T.Let(T.Select((ax3 * 5 + 5) % 8 == 0, cse_var_2, cse_var_2 + 1) - ax3 * 13 // 8, where={cse_var_2: (ax3 * 13 + 13) // 8})):\n                    cse_var_1 = T.int32()\n                    cse_var_2 = T.int32()\n                    cse_var_3: T.int32 = ax0 * 1280 + ax1 * 64 + ax2 * 8 + ax3\n                    data_1 = T.Buffer((39780,), data=data.data)\n                    adaptive_pool_max_1[cse_var_3] = T.max(adaptive_pool_max_1[cse_var_3], data_1[ax0 * 4420 + ax1 * 221 + ax2 * 26 + rv0 * 13 + ax3 * 13 // 8 + rv1])", "op_args": [9, 20, 17, 13], "input_shape": "[[9, 20, 17, 13]]", "output_shape": "[[9, 20, 8, 8]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 195; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 2; ++i2) {\n      for (int32_t i3 = 0; i3 < 8; ++i3) {\n        compute[(((i0_i1_fused * 16) + (i2 * 8)) + i3)] = sinf(data[(((i0_i1_fused * 16) + (i2 * 8)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 195) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 13, 2, 8), \"float32\"), compute: T.Buffer((15, 13, 2, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(195):\n            for i2, i3 in T.grid(2, 8):\n                cse_var_1: T.int32 = i0_i1_fused * 16 + i2 * 8 + i3\n                compute_1 = T.Buffer((3120,), data=compute.data)\n                data_1 = T.Buffer((3120,), data=data.data)\n                compute_1[cse_var_1] = T.sin(data_1[cse_var_1])", "op_args": [15, 13, 2, 8], "input_shape": "[[15, 13, 2, 8]]", "output_shape": "[[15, 13, 2, 8]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1568; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 14, 7, 2), \"float32\"), compute: T.Buffer((8, 14, 7, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1568):\n            compute_1 = T.Buffer((1568,), data=compute.data)\n            data_1 = T.Buffer((1568,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [8, 14, 7, 2], "input_shape": "[[8, 14, 7, 2]]", "output_shape": "[[8, 14, 7, 2]]"}{"op_name": "adaptive_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 2040; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n      adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < (((((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) % 8) == 0) ? ((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) >> 3) : (((((ax0_ax1_fused_ax2_fused & 7) * 5) + 5) >> 3) + 1)) - (((ax0_ax1_fused_ax2_fused & 7) * 5) >> 3)); ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 2; ++rv1) {\n          adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)] = max(adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)], data[((((((ax0_ax1_fused_ax2_fused >> 3) * 80) + ((((ax0_ax1_fused_ax2_fused & 7) * 5) >> 3) * 16)) + (rv0 * 16)) + (ax3 * 2)) + rv1)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < ((((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) % 8) == 0) ? (((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) >> 3) : ((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) + 5) >> 3) + 1)) - ((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < 2; ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))], data[((((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) >> 4) * 80) + (((((((((int)blockIdx.x) * 15) + (((int)threadIdx.x) >> 2)) & 15) >> 1) * 5) >> 3) * 16)) + (rv0 * 16)) + ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 2)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 17, 5, 16), \"float32\"), adaptive_pool_max: T.Buffer((15, 17, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(2040):\n            for ax3 in range(8):\n                adaptive_pool_max_1 = T.Buffer((16320,), data=adaptive_pool_max.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused * 8 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(T.Let(T.Let(T.Let(T.Select(cse_var_3 % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 // 8, where={cse_var_1: cse_var_3 // 8}), where={cse_var_3: cse_var_2 + 5}), where={cse_var_2: ax0_ax1_fused_ax2_fused % 8 * 5}), 2):\n                    cse_var_2 = T.int32()\n                    cse_var_3 = T.int32()\n                    cse_var_1 = T.int32()\n                    cse_var_4: T.int32 = ax0_ax1_fused_ax2_fused * 8 + ax3\n                    data_1 = T.Buffer((20400,), data=data.data)\n                    adaptive_pool_max_1[cse_var_4] = T.max(adaptive_pool_max_1[cse_var_4], data_1[ax0_ax1_fused_ax2_fused // 8 * 80 + ax0_ax1_fused_ax2_fused % 8 * 5 // 8 * 16 + rv0 * 16 + ax3 * 2 + rv1])", "op_args": [15, 17, 5, 16], "input_shape": "[[15, 17, 5, 16]]", "output_shape": "[[15, 17, 8, 8]]"}{"op_name": "sin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 8; ++i0) {\n    for (int32_t i1 = 0; i1 < 19; ++i1) {\n      for (int32_t i2 = 0; i2 < 5; ++i2) {\n        for (int32_t i3 = 0; i3 < 4; ++i3) {\n          compute[((((i0 * 380) + (i1 * 20)) + (i2 * 4)) + i3)] = sinf(data[((((i0 * 380) + (i1 * 20)) + (i2 * 4)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 19, 5, 4), \"float32\"), compute: T.Buffer((8, 19, 5, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(8):\n            for i1, i2, i3 in T.grid(19, 5, 4):\n                cse_var_1: T.int32 = i0 * 380 + i1 * 20 + i2 * 4 + i3\n                compute_1 = T.Buffer((3040,), data=compute.data)\n                data_1 = T.Buffer((3040,), data=data.data)\n                compute_1[cse_var_1] = T.sin(data_1[cse_var_1])", "op_args": [8, 19, 5, 4], "input_shape": "[[8, 19, 5, 4]]", "output_shape": "[[8, 19, 5, 4]]"}{"op_name": "abs", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1440; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = fabsf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 16, 9, 5), \"float32\"), compute: T.Buffer((2, 16, 9, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1440):\n            compute_1 = T.Buffer((1440,), data=compute.data)\n            data_1 = T.Buffer((1440,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.fabs(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [2, 16, 9, 5], "input_shape": "[[2, 16, 9, 5]]", "output_shape": "[[2, 16, 9, 5]]"}{"op_name": "abs", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 24; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 12; ++i2) {\n      for (int32_t i3 = 0; i3 < 8; ++i3) {\n        compute[(((i0_i1_fused * 96) + (i2 * 8)) + i3)] = fabsf(data[(((i0_i1_fused * 96) + (i2 * 8)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(9) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 3, 12, 8), \"float32\"), compute: T.Buffer((8, 3, 12, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(24):\n            for i2, i3 in T.grid(12, 8):\n                cse_var_1: T.int32 = i0_i1_fused * 96 + i2 * 8 + i3\n                compute_1 = T.Buffer((2304,), data=compute.data)\n                data_1 = T.Buffer((2304,), data=data.data)\n                compute_1[cse_var_1] = T.fabs(data_1[cse_var_1])", "op_args": [8, 3, 12, 8], "input_shape": "[[8, 3, 12, 8]]", "output_shape": "[[8, 3, 12, 8]]"}{"op_name": "abs", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 48; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3 = 0; i3 < 12; ++i3) {\n        compute[(((i0_i1_fused * 48) + (i2 * 12)) + i3)] = fabsf(data[(((i0_i1_fused * 48) + (i2 * 12)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 3, 4, 12), \"float32\"), compute: T.Buffer((16, 3, 4, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(48):\n            for i2, i3 in T.grid(4, 12):\n                cse_var_1: T.int32 = i0_i1_fused * 48 + i2 * 12 + i3\n                compute_1 = T.Buffer((2304,), data=compute.data)\n                data_1 = T.Buffer((2304,), data=data.data)\n                compute_1[cse_var_1] = T.fabs(data_1[cse_var_1])", "op_args": [16, 3, 4, 12], "input_shape": "[[16, 3, 4, 12]]", "output_shape": "[[16, 3, 4, 12]]"}{"op_name": "adaptive_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 1352; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n      adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < (((((((ax0_ax1_fused_ax2_fused & 7) * 2) + 2) % 8) == 0) ? ((((ax0_ax1_fused_ax2_fused & 7) * 9) + 9) >> 2) : (((((ax0_ax1_fused_ax2_fused & 7) * 9) + 9) >> 2) + 1)) - (((ax0_ax1_fused_ax2_fused & 7) * 18) >> 3)); ++rv0) {\n        for (int32_t rv1 = 0; rv1 < ((((((ax3 * 2) + 2) % 8) == 0) ? ((ax3 + 1) >> 2) : (((ax3 + 1) >> 2) + 1)) - (ax3 >> 2)); ++rv1) {\n          adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)] = max(adaptive_pool_max[((ax0_ax1_fused_ax2_fused * 8) + ax3)], data[((((((ax0_ax1_fused_ax2_fused >> 3) * 36) + ((((ax0_ax1_fused_ax2_fused & 7) * 18) >> 3) * 2)) + (rv0 * 2)) + (ax3 >> 2)) + rv1)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < ((((((((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 2) + 2) % 8) == 0) ? (((((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 9) + 9) >> 2) : ((((((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 9) + 9) >> 2) + 1)) - ((((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 18) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 2) + 2) % 8) == 0) ? (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) + 1) >> 2) : ((((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) + 1) >> 2) + 1)) - ((((((int)threadIdx.x) >> 1) + ((int)blockIdx.x)) & 3) >> 1)); ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))], data[((((((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 1)) >> 5) * 36) + (((((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 18) >> 3) * 2)) + (rv0 * 2)) + ((((((int)threadIdx.x) >> 1) + ((int)blockIdx.x)) & 3) >> 1)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 13, 18, 2), \"float32\"), adaptive_pool_max: T.Buffer((13, 13, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(1352):\n            for ax3 in range(8):\n                adaptive_pool_max_1 = T.Buffer((10816,), data=adaptive_pool_max.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused * 8 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(T.Let(T.Let(T.Select((cse_var_2 * 2 + 2) % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 * 18 // 8, where={cse_var_1: (cse_var_2 * 9 + 9) // 4}), where={cse_var_2: ax0_ax1_fused_ax2_fused % 8}), T.Let(T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_3, cse_var_3 + 1) - ax3 // 4, where={cse_var_3: (ax3 + 1) // 4})):\n                    cse_var_2 = T.int32()\n                    cse_var_1 = T.int32()\n                    cse_var_3 = T.int32()\n                    cse_var_4: T.int32 = ax0_ax1_fused_ax2_fused * 8 + ax3\n                    data_1 = T.Buffer((6084,), data=data.data)\n                    adaptive_pool_max_1[cse_var_4] = T.max(adaptive_pool_max_1[cse_var_4], data_1[ax0_ax1_fused_ax2_fused // 8 * 36 + ax0_ax1_fused_ax2_fused % 8 * 18 // 8 * 2 + rv0 * 2 + ax3 // 4 + rv1])", "op_args": [13, 13, 18, 2], "input_shape": "[[13, 13, 18, 2]]", "output_shape": "[[13, 13, 8, 8]]"}{"op_name": "abs", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 30; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = fabsf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((int)threadIdx.x)] = fabsf(data[((int)threadIdx.x)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 3, 2, 1), \"float32\"), compute: T.Buffer((5, 3, 2, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(30):\n            compute_1 = T.Buffer((30,), data=compute.data)\n            data_1 = T.Buffer((30,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.fabs(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [5, 3, 2, 1], "input_shape": "[[5, 3, 2, 1]]", "output_shape": "[[5, 3, 2, 1]]"}{"op_name": "abs", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 21; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 12; ++i2) {\n      for (int32_t i3 = 0; i3 < 9; ++i3) {\n        compute[(((i0_i1_fused * 108) + (i2 * 9)) + i3)] = fabsf(data[(((i0_i1_fused * 108) + (i2 * 9)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 7, 12, 9), \"float32\"), compute: T.Buffer((3, 7, 12, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(21):\n            for i2, i3 in T.grid(12, 9):\n                cse_var_1: T.int32 = i0_i1_fused * 108 + i2 * 9 + i3\n                compute_1 = T.Buffer((2268,), data=compute.data)\n                data_1 = T.Buffer((2268,), data=data.data)\n                compute_1[cse_var_1] = T.fabs(data_1[cse_var_1])", "op_args": [3, 7, 12, 9], "input_shape": "[[3, 7, 12, 9]]", "output_shape": "[[3, 7, 12, 9]]"}{"op_name": "adaptive_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 13; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n          adaptive_pool_max[((((ax0 * 1216) + (ax1 * 64)) + (ax2 * 8)) + ax3)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 2; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < ((((((ax3 * 3) + 3) % 8) == 0) ? (((ax3 * 3) + 3) >> 3) : ((((ax3 * 3) + 3) >> 3) + 1)) - ((ax3 * 3) >> 3)); ++rv1) {\n              adaptive_pool_max[((((ax0 * 1216) + (ax1 * 64)) + (ax2 * 8)) + ax3)] = max(adaptive_pool_max[((((ax0 * 1216) + (ax1 * 64)) + (ax2 * 8)) + ax3)], data[((((((ax0 * 912) + (ax1 * 48)) + (ax2 * 6)) + (rv0 * 3)) + ((ax3 * 3) >> 3)) + rv1)]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 2; ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((int)threadIdx.x) & 7) * 3) + 3) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 3) + 3) >> 3) : (((((((int)threadIdx.x) & 7) * 3) + 3) >> 3) + 1)) - (((((int)threadIdx.x) & 7) * 3) >> 3)); ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], data[(((((((int)blockIdx.x) * 48) + ((((int)threadIdx.x) >> 3) * 6)) + (rv0 * 3)) + (((((int)threadIdx.x) & 7) * 3) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 19, 16, 3), \"float32\"), adaptive_pool_max: T.Buffer((13, 19, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(13):\n            for ax1, ax2, ax3 in T.grid(19, 8, 8):\n                adaptive_pool_max_1 = T.Buffer((15808,), data=adaptive_pool_max.data)\n                adaptive_pool_max_1[ax0 * 1216 + ax1 * 64 + ax2 * 8 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(2, T.Let(T.Let(T.Let(T.Select(cse_var_3 % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 // 8, where={cse_var_1: cse_var_3 // 8}), where={cse_var_3: cse_var_2 + 3}), where={cse_var_2: ax3 * 3})):\n                    cse_var_2 = T.int32()\n                    cse_var_3 = T.int32()\n                    cse_var_1 = T.int32()\n                    cse_var_4: T.int32 = ax0 * 1216 + ax1 * 64 + ax2 * 8 + ax3\n                    data_1 = T.Buffer((11856,), data=data.data)\n                    adaptive_pool_max_1[cse_var_4] = T.max(adaptive_pool_max_1[cse_var_4], data_1[ax0 * 912 + ax1 * 48 + ax2 * 6 + rv0 * 3 + ax3 * 3 // 8 + rv1])", "op_args": [13, 19, 16, 3], "input_shape": "[[13, 19, 16, 3]]", "output_shape": "[[13, 19, 8, 8]]"}{"op_name": "abs", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 576; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 3; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 3) + i3)] = fabsf(data[((i0_i1_fused_i2_fused * 3) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 16, 12, 3), \"float32\"), compute: T.Buffer((3, 16, 12, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(576):\n            for i3 in range(3):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 3 + i3\n                compute_1 = T.Buffer((1728,), data=compute.data)\n                data_1 = T.Buffer((1728,), data=data.data)\n                compute_1[cse_var_1] = T.fabs(data_1[cse_var_1])", "op_args": [3, 16, 12, 3], "input_shape": "[[3, 16, 12, 3]]", "output_shape": "[[3, 16, 12, 3]]"}{"op_name": "adaptive_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 70; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n        adaptive_pool_max[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 2; ++rv0) {\n          for (int32_t rv1 = 0; rv1 < ((((((ax3 * 5) + 5) % 8) == 0) ? (((ax3 * 5) + 5) >> 3) : ((((ax3 * 5) + 5) >> 3) + 1)) - ((ax3 * 5) >> 3)); ++rv1) {\n            adaptive_pool_max[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3)] = max(adaptive_pool_max[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3)], data[(((((ax0_ax1_fused * 80) + (ax2 * 10)) + (rv0 * 5)) + ((ax3 * 5) >> 3)) + rv1)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 2; ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 5) + 5) % 8) == 0) ? ((((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 5) + 5) >> 3) : (((((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 5) + 5) >> 3) + 1)) - (((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 5) >> 3)); ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))], data[(((((((((int)blockIdx.x) * 7) + (((int)threadIdx.x) >> 2)) >> 1) * 10) + (rv0 * 5)) + (((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 5) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 14, 16, 5), \"float32\"), adaptive_pool_max: T.Buffer((5, 14, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(70):\n            for ax2, ax3 in T.grid(8, 8):\n                adaptive_pool_max_1 = T.Buffer((4480,), data=adaptive_pool_max.data)\n                adaptive_pool_max_1[ax0_ax1_fused * 64 + ax2 * 8 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(2, T.Let(T.Let(T.Let(T.Select(cse_var_3 % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 // 8, where={cse_var_1: cse_var_3 // 8}), where={cse_var_3: cse_var_2 + 5}), where={cse_var_2: ax3 * 5})):\n                    cse_var_2 = T.int32()\n                    cse_var_3 = T.int32()\n                    cse_var_1 = T.int32()\n                    cse_var_4: T.int32 = ax0_ax1_fused * 64 + ax2 * 8 + ax3\n                    data_1 = T.Buffer((5600,), data=data.data)\n                    adaptive_pool_max_1[cse_var_4] = T.max(adaptive_pool_max_1[cse_var_4], data_1[ax0_ax1_fused * 80 + ax2 * 10 + rv0 * 5 + ax3 * 5 // 8 + rv1])", "op_args": [5, 14, 16, 5], "input_shape": "[[5, 14, 16, 5]]", "output_shape": "[[5, 14, 8, 8]]"}{"op_name": "abs", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 405; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 8; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 8) + i3)] = fabsf(data[((i0_i1_fused_i2_fused * 8) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 5, 9, 8), \"float32\"), compute: T.Buffer((9, 5, 9, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(405):\n            for i3 in range(8):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 8 + i3\n                compute_1 = T.Buffer((3240,), data=compute.data)\n                data_1 = T.Buffer((3240,), data=data.data)\n                compute_1[cse_var_1] = T.fabs(data_1[cse_var_1])", "op_args": [9, 5, 9, 8], "input_shape": "[[9, 5, 9, 8]]", "output_shape": "[[9, 5, 9, 8]]"}{"op_name": "abs", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 264; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 14; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 14) + i3)] = fabsf(data[((i0_i1_fused_i2_fused * 14) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(42) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 11, 6, 14), \"float32\"), compute: T.Buffer((4, 11, 6, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(264):\n            for i3 in range(14):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 14 + i3\n                compute_1 = T.Buffer((3696,), data=compute.data)\n                data_1 = T.Buffer((3696,), data=data.data)\n                compute_1[cse_var_1] = T.fabs(data_1[cse_var_1])", "op_args": [4, 11, 6, 14], "input_shape": "[[4, 11, 6, 14]]", "output_shape": "[[4, 11, 6, 14]]"}{"op_name": "adaptive_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 13376; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < ((((((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 4) + 4) % 8) == 0) ? (((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 5) + 5) >> 1) : ((((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 5) + 5) >> 1) + 1)) - ((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 20) >> 3)); ++rv0) {\n      for (int32_t rv1 = 0; rv1 < (((((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 3) + 3) % 8) == 0) ? ((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 19) + 19) >> 3) : (((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 19) + 19) >> 3) + 1)) - (((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 19) >> 3)); ++rv1) {\n        adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = max(adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused], data[((((((ax0_ax1_fused_ax2_fused_ax3_fused >> 6) * 380) + (((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 20) >> 3) * 19)) + (rv0 * 19)) + (((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 19) >> 3)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < ((((((((((((int)blockIdx.x) * 19) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 4) + 4) % 8) == 0) ? (((((((((int)blockIdx.x) * 19) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 5) + 5) >> 1) : ((((((((((int)blockIdx.x) * 19) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 5) + 5) >> 1) + 1)) - ((((((((int)blockIdx.x) * 19) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 20) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((((int)blockIdx.x) * 6) + ((int)threadIdx.x)) & 7) * 3) + 3) % 8) == 0) ? ((((((((int)blockIdx.x) * 6) + ((int)threadIdx.x)) & 7) * 19) + 19) >> 3) : (((((((((int)blockIdx.x) * 6) + ((int)threadIdx.x)) & 7) * 19) + 19) >> 3) + 1)) - (((((((int)blockIdx.x) * 6) + ((int)threadIdx.x)) & 7) * 19) >> 3)); ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], data[((((((((((int)blockIdx.x) * 19) + (((int)threadIdx.x) >> 1)) >> 5) * 380) + (((((((((int)blockIdx.x) * 19) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 20) >> 3) * 19)) + (rv0 * 19)) + (((((((int)blockIdx.x) * 6) + ((int)threadIdx.x)) & 7) * 19) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 11, 20, 19), \"float32\"), adaptive_pool_max: T.Buffer((19, 11, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(13376):\n            adaptive_pool_max_1 = T.Buffer((13376,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(T.Let(T.Let(T.Select((cse_var_2 * 4 + 4) % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 * 20 // 8, where={cse_var_1: (cse_var_2 * 5 + 5) // 2}), where={cse_var_2: ax0_ax1_fused_ax2_fused_ax3_fused % 64 // 8}), T.Let(T.Let(T.Let(T.Select((cse_var_4 * 3 + 3) % 8 == 0, cse_var_3, cse_var_3 + 1) - cse_var_5 // 8, where={cse_var_3: (cse_var_5 + 19) // 8}), where={cse_var_5: cse_var_4 * 19}), where={cse_var_4: ax0_ax1_fused_ax2_fused_ax3_fused % 8})):\n                cse_var_2 = T.int32()\n                cse_var_1 = T.int32()\n                cse_var_4 = T.int32()\n                cse_var_5 = T.int32()\n                cse_var_3 = T.int32()\n                data_1 = T.Buffer((79420,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused], data_1[ax0_ax1_fused_ax2_fused_ax3_fused // 64 * 380 + ax0_ax1_fused_ax2_fused_ax3_fused % 64 // 8 * 20 // 8 * 19 + rv0 * 19 + ax0_ax1_fused_ax2_fused_ax3_fused % 8 * 19 // 8 + rv1])", "op_args": [19, 11, 20, 19], "input_shape": "[[19, 11, 20, 19]]", "output_shape": "[[19, 11, 8, 8]]"}{"op_name": "abs", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 294; ++i0_i1_fused_i2_fused) {\n    compute[i0_i1_fused_i2_fused] = fabsf(data[i0_i1_fused_i2_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) < 147) {\n    compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 7, 6, 1), \"float32\"), compute: T.Buffer((7, 7, 6, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(294):\n            compute_1 = T.Buffer((294,), data=compute.data)\n            data_1 = T.Buffer((294,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused] = T.fabs(data_1[i0_i1_fused_i2_fused])", "op_args": [7, 7, 6, 1], "input_shape": "[[7, 7, 6, 1]]", "output_shape": "[[7, 7, 6, 1]]"}{"op_name": "cos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3094; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = cosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = __cosf(data[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 13, 7), \"float32\"), compute: T.Buffer((17, 2, 13, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3094):\n            compute_1 = T.Buffer((3094,), data=compute.data)\n            data_1 = T.Buffer((3094,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cos(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [17, 2, 13, 7], "input_shape": "[[17, 2, 13, 7]]", "output_shape": "[[17, 2, 13, 7]]"}{"op_name": "adaptive_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 10880; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < ((((((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 4) + 4) % 8) == 0) ? (((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 3) + 3) >> 1) : ((((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 3) + 3) >> 1) + 1)) - ((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 12) >> 3)); ++rv0) {\n      for (int32_t rv1 = 0; rv1 < (((((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 3) + 3) % 8) == 0) ? ((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 3) + 3) >> 3) : (((((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 3) + 3) >> 3) + 1)) - (((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 3) >> 3)); ++rv1) {\n        adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = max(adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused], data[((((((ax0_ax1_fused_ax2_fused_ax3_fused >> 6) * 36) + (((((ax0_ax1_fused_ax2_fused_ax3_fused & 63) >> 3) * 12) >> 3) * 3)) + (rv0 * 3)) + (((ax0_ax1_fused_ax2_fused_ax3_fused & 7) * 3) >> 3)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < ((((((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 4) + 4) % 8) == 0) ? (((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 3) + 3) >> 1) : ((((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 3) + 3) >> 1) + 1)) - ((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 12) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 3) + 3) % 8) == 0) ? ((((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 3) + 3) >> 3) : (((((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 3) + 3) >> 3) + 1)) - (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 3) >> 3)); ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))], data[((((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) >> 5) * 36) + (((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 12) >> 3) * 3)) + (rv0 * 3)) + (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 3) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 17, 12, 3), \"float32\"), adaptive_pool_max: T.Buffer((10, 17, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(10880):\n            adaptive_pool_max_1 = T.Buffer((10880,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(T.Let(T.Let(T.Select((cse_var_2 * 4 + 4) % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 * 12 // 8, where={cse_var_1: (cse_var_2 * 3 + 3) // 2}), where={cse_var_2: ax0_ax1_fused_ax2_fused_ax3_fused % 64 // 8}), T.Let(T.Let(T.Let(T.Select(cse_var_5 % 8 == 0, cse_var_3, cse_var_3 + 1) - cse_var_4 // 8, where={cse_var_3: cse_var_5 // 8}), where={cse_var_5: cse_var_4 + 3}), where={cse_var_4: ax0_ax1_fused_ax2_fused_ax3_fused % 8 * 3})):\n                cse_var_2 = T.int32()\n                cse_var_1 = T.int32()\n                cse_var_4 = T.int32()\n                cse_var_5 = T.int32()\n                cse_var_3 = T.int32()\n                data_1 = T.Buffer((6120,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused], data_1[ax0_ax1_fused_ax2_fused_ax3_fused // 64 * 36 + ax0_ax1_fused_ax2_fused_ax3_fused % 64 // 8 * 12 // 8 * 3 + rv0 * 3 + ax0_ax1_fused_ax2_fused_ax3_fused % 8 * 3 // 8 + rv1])", "op_args": [10, 17, 12, 3], "input_shape": "[[10, 17, 12, 3]]", "output_shape": "[[10, 17, 8, 8]]"}{"op_name": "cos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 480; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = cosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(10) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] = __cosf(data[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 2, 15, 8), \"float32\"), compute: T.Buffer((2, 2, 15, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(480):\n            compute_1 = T.Buffer((480,), data=compute.data)\n            data_1 = T.Buffer((480,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cos(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [2, 2, 15, 8], "input_shape": "[[2, 2, 15, 8]]", "output_shape": "[[2, 2, 15, 8]]"}{"op_name": "cos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i3 = 0; i3 < 18; ++i3) {\n        compute[(((i0 * 36) + (i1 * 18)) + i3)] = cosf(data[(((i0 * 36) + (i1 * 18)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 12)) < 21) {\n    compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = __cosf(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 1, 18), \"float32\"), compute: T.Buffer((7, 2, 1, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i1, i3 in T.grid(2, 18):\n                cse_var_1: T.int32 = i0 * 36 + i1 * 18 + i3\n                compute_1 = T.Buffer((252,), data=compute.data)\n                data_1 = T.Buffer((252,), data=data.data)\n                compute_1[cse_var_1] = T.cos(data_1[cse_var_1])", "op_args": [7, 2, 1, 18], "input_shape": "[[7, 2, 1, 18]]", "output_shape": "[[7, 2, 1, 18]]"}{"op_name": "adaptive_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 195; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n        adaptive_pool_max[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < ((((((ax2 * 6) + 6) % 8) == 0) ? (((ax2 * 3) + 3) >> 2) : ((((ax2 * 3) + 3) >> 2) + 1)) - ((ax2 * 6) >> 3)); ++rv0) {\n          for (int32_t rv1 = 0; rv1 < ((((((ax3 * 4) + 4) % 8) == 0) ? (((ax3 * 5) + 5) >> 1) : ((((ax3 * 5) + 5) >> 1) + 1)) - ((ax3 * 20) >> 3)); ++rv1) {\n            adaptive_pool_max[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3)] = max(adaptive_pool_max[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3)], data[(((((ax0_ax1_fused * 120) + (((ax2 * 6) >> 3) * 20)) + (rv0 * 20)) + ((ax3 * 20) >> 3)) + rv1)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < (((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 6) + 6) % 8) == 0) ? ((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 3) + 3) >> 2) : (((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 3) + 3) >> 2) + 1)) - (((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 6) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((int)threadIdx.x) & 7) * 4) + 4) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 5) + 5) >> 1) : (((((((int)threadIdx.x) & 7) * 5) + 5) >> 1) + 1)) - (((((int)threadIdx.x) & 7) * 20) >> 3)); ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))], data[((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) >> 3) * 120) + ((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 6) >> 3) * 20)) + (rv0 * 20)) + (((((int)threadIdx.x) & 7) * 20) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 15, 6, 20), \"float32\"), adaptive_pool_max: T.Buffer((13, 15, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(195):\n            for ax2, ax3 in T.grid(8, 8):\n                adaptive_pool_max_1 = T.Buffer((12480,), data=adaptive_pool_max.data)\n                adaptive_pool_max_1[ax0_ax1_fused * 64 + ax2 * 8 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(T.Let(T.Let(T.Select((cse_var_2 + 6) % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_2 // 8, where={cse_var_1: (ax2 * 3 + 3) // 4}), where={cse_var_2: ax2 * 6}), T.Let(T.Select((ax3 * 4 + 4) % 8 == 0, cse_var_3, cse_var_3 + 1) - ax3 * 20 // 8, where={cse_var_3: (ax3 * 5 + 5) // 2})):\n                    cse_var_2 = T.int32()\n                    cse_var_1 = T.int32()\n                    cse_var_3 = T.int32()\n                    cse_var_4: T.int32 = ax0_ax1_fused * 64 + ax2 * 8 + ax3\n                    data_1 = T.Buffer((23400,), data=data.data)\n                    adaptive_pool_max_1[cse_var_4] = T.max(adaptive_pool_max_1[cse_var_4], data_1[ax0_ax1_fused * 120 + ax2 * 6 // 8 * 20 + rv0 * 20 + ax3 * 20 // 8 + rv1])", "op_args": [13, 15, 6, 20], "input_shape": "[[13, 15, 6, 20]]", "output_shape": "[[13, 15, 8, 8]]"}{"op_name": "cos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 6; ++i0) {\n    for (int32_t i1 = 0; i1 < 4; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        for (int32_t i3 = 0; i3 < 13; ++i3) {\n          compute[((((i0 * 728) + (i1 * 182)) + (i2 * 13)) + i3)] = cosf(data[((((i0 * 728) + (i1 * 182)) + (i2 * 13)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = __cosf(data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 4, 14, 13), \"float32\"), compute: T.Buffer((6, 4, 14, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(6):\n            for i1, i2, i3 in T.grid(4, 14, 13):\n                cse_var_1: T.int32 = i0 * 728 + i1 * 182 + i2 * 13 + i3\n                compute_1 = T.Buffer((4368,), data=compute.data)\n                data_1 = T.Buffer((4368,), data=data.data)\n                compute_1[cse_var_1] = T.cos(data_1[cse_var_1])", "op_args": [6, 4, 14, 13], "input_shape": "[[6, 4, 14, 13]]", "output_shape": "[[6, 4, 14, 13]]"}{"op_name": "atan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 180; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 6; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 15; ++i3_s) {\n        compute[(((i0_i1_fused * 90) + (i2 * 15)) + i3_s)] = atanf(data[(((i0_i1_fused * 90) + (i2 * 15)) + i3_s)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 9, 6, 15), \"float32\"), compute: T.Buffer((20, 9, 6, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(180):\n            for i2, i3_s in T.grid(6, 15):\n                cse_var_1: T.int32 = i0_i1_fused * 90 + i2 * 15 + i3_s\n                compute_1 = T.Buffer((16200,), data=compute.data)\n                data_1 = T.Buffer((16200,), data=data.data)\n                compute_1[cse_var_1] = T.atan(data_1[cse_var_1])", "op_args": [20, 9, 6, 15], "input_shape": "[[20, 9, 6, 15]]", "output_shape": "[[20, 9, 6, 15]]"}{"op_name": "atan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3536; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = atanf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(52) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 13, 8), \"float32\"), compute: T.Buffer((17, 2, 13, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3536):\n            compute_1 = T.Buffer((3536,), data=compute.data)\n            data_1 = T.Buffer((3536,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.atan(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [17, 2, 13, 8], "input_shape": "[[17, 2, 13, 8]]", "output_shape": "[[17, 2, 13, 8]]"}{"op_name": "add", "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n    for (int32_t ax3 = 0; ax3 < 3; ++ax3) {\n      T_add[((ax2 * 3) + ax3)] = (data[((ax2 * 3) + ax3)] + data_1[((ax2 * 3) + ax3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((int)threadIdx.x)] = (data[((int)threadIdx.x)] + data_1[((int)threadIdx.x)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 1, 4, 3), \"float32\"), data_1: T.Buffer((1, 1, 4, 3), \"float32\"), T_add: T.Buffer((1, 1, 4, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax2, ax3 in T.grid(4, 3):\n            cse_var_1: T.int32 = ax2 * 3 + ax3\n            T_add_1 = T.Buffer((12,), data=T_add.data)\n            data_2 = T.Buffer((12,), data=data.data)\n            data_3 = T.Buffer((12,), data=data_1.data)\n            T_add_1[cse_var_1] = data_2[cse_var_1] + data_3[cse_var_1]", "op_args": [1, 1, 4, 3], "input_shape": "[[1, 1, 4, 3], [1, 1, 4, 3]]", "output_shape": "[[1, 1, 4, 3]]"}{"op_name": "atan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1056; ++i0_i1_fused_i2_fused) {\n    compute[i0_i1_fused_i2_fused] = atanf(data[i0_i1_fused_i2_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(22) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 6, 16, 1), \"float32\"), compute: T.Buffer((11, 6, 16, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1056):\n            compute_1 = T.Buffer((1056,), data=compute.data)\n            data_1 = T.Buffer((1056,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused] = T.atan(data_1[i0_i1_fused_i2_fused])", "op_args": [11, 6, 16, 1], "input_shape": "[[11, 6, 16, 1]]", "output_shape": "[[11, 6, 16, 1]]"}{"op_name": "atan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 9216; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = atanf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 16, 4, 18), \"float32\"), compute: T.Buffer((8, 16, 4, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(9216):\n            compute_1 = T.Buffer((9216,), data=compute.data)\n            data_1 = T.Buffer((9216,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.atan(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [8, 16, 4, 18], "input_shape": "[[8, 16, 4, 18]]", "output_shape": "[[8, 16, 4, 18]]"}{"op_name": "add", "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 12; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      for (int32_t ax3 = 0; ax3 < 5; ++ax3) {\n        T_add[(((ax0 * 50) + (ax1 * 5)) + ax3)] = (data[(((ax0 * 50) + (ax1 * 5)) + ax3)] + data_1[(((ax0 * 50) + (ax1 * 5)) + ax3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 10, 1, 5), \"float32\"), data_1: T.Buffer((12, 10, 1, 5), \"float32\"), T_add: T.Buffer((12, 10, 1, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(12):\n            for ax1, ax3 in T.grid(10, 5):\n                cse_var_1: T.int32 = ax0 * 50 + ax1 * 5 + ax3\n                T_add_1 = T.Buffer((600,), data=T_add.data)\n                data_2 = T.Buffer((600,), data=data.data)\n                data_3 = T.Buffer((600,), data=data_1.data)\n                T_add_1[cse_var_1] = data_2[cse_var_1] + data_3[cse_var_1]", "op_args": [12, 10, 1, 5], "input_shape": "[[12, 10, 1, 5], [12, 10, 1, 5]]", "output_shape": "[[12, 10, 1, 5]]"}{"op_name": "atan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 18; ++i1) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 7; ++i3) {\n        compute[(((i1 * 98) + (i2 * 7)) + i3)] = atanf(data[(((i1 * 98) + (i2 * 7)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 18, 14, 7), \"float32\"), compute: T.Buffer((1, 18, 14, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(18, 14, 7):\n            cse_var_1: T.int32 = i1 * 98 + i2 * 7 + i3\n            compute_1 = T.Buffer((1764,), data=compute.data)\n            data_1 = T.Buffer((1764,), data=data.data)\n            compute_1[cse_var_1] = T.atan(data_1[cse_var_1])", "op_args": [1, 18, 14, 7], "input_shape": "[[1, 18, 14, 7]]", "output_shape": "[[1, 18, 14, 7]]"}{"op_name": "add", "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 20; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 9; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n          T_add[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)] = (data[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)] + data_1[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 10, 9, 18), \"float32\"), data_1: T.Buffer((20, 10, 9, 18), \"float32\"), T_add: T.Buffer((20, 10, 9, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(20):\n            for ax1, ax2, ax3 in T.grid(10, 9, 18):\n                cse_var_1: T.int32 = ax0 * 1620 + ax1 * 162 + ax2 * 18 + ax3\n                T_add_1 = T.Buffer((32400,), data=T_add.data)\n                data_2 = T.Buffer((32400,), data=data.data)\n                data_3 = T.Buffer((32400,), data=data_1.data)\n                T_add_1[cse_var_1] = data_2[cse_var_1] + data_3[cse_var_1]", "op_args": [20, 10, 9, 18], "input_shape": "[[20, 10, 9, 18], [20, 10, 9, 18]]", "output_shape": "[[20, 10, 9, 18]]"}{"op_name": "atan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 270; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 16; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 9; ++i3_s) {\n        compute[(((i0_i1_fused * 144) + (i2 * 9)) + i3_s)] = atanf(data[(((i0_i1_fused * 144) + (i2 * 9)) + i3_s)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 18, 16, 9), \"float32\"), compute: T.Buffer((15, 18, 16, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(270):\n            for i2, i3_s in T.grid(16, 9):\n                cse_var_1: T.int32 = i0_i1_fused * 144 + i2 * 9 + i3_s\n                compute_1 = T.Buffer((38880,), data=compute.data)\n                data_1 = T.Buffer((38880,), data=data.data)\n                compute_1[cse_var_1] = T.atan(data_1[cse_var_1])", "op_args": [15, 18, 16, 9], "input_shape": "[[15, 18, 16, 9]]", "output_shape": "[[15, 18, 16, 9]]"}{"op_name": "add", "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 2400; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_add[ax0_ax1_fused_ax2_fused_ax3_fused] = (data[ax0_ax1_fused_ax2_fused_ax3_fused] + data_1[ax0_ax1_fused_ax2_fused_ax3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(5) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 5, 10, 3), \"float32\"), data_1: T.Buffer((16, 5, 10, 3), \"float32\"), T_add: T.Buffer((16, 5, 10, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(2400):\n            T_add_1 = T.Buffer((2400,), data=T_add.data)\n            data_2 = T.Buffer((2400,), data=data.data)\n            data_3 = T.Buffer((2400,), data=data_1.data)\n            T_add_1[ax0_ax1_fused_ax2_fused_ax3_fused] = data_2[ax0_ax1_fused_ax2_fused_ax3_fused] + data_3[ax0_ax1_fused_ax2_fused_ax3_fused]", "op_args": [16, 5, 10, 3], "input_shape": "[[16, 5, 10, 3], [16, 5, 10, 3]]", "output_shape": "[[16, 5, 10, 3]]"}{"op_name": "atan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 140; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 10; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 5; ++i3_s) {\n        compute[(((i0_i1_fused * 50) + (i2 * 5)) + i3_s)] = atanf(data[(((i0_i1_fused * 50) + (i2 * 5)) + i3_s)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 20, 10, 5), \"float32\"), compute: T.Buffer((7, 20, 10, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(140):\n            for i2, i3_s in T.grid(10, 5):\n                cse_var_1: T.int32 = i0_i1_fused * 50 + i2 * 5 + i3_s\n                compute_1 = T.Buffer((7000,), data=compute.data)\n                data_1 = T.Buffer((7000,), data=data.data)\n                compute_1[cse_var_1] = T.atan(data_1[cse_var_1])", "op_args": [7, 20, 10, 5], "input_shape": "[[7, 20, 10, 5]]", "output_shape": "[[7, 20, 10, 5]]"}{"op_name": "atan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1428; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 9; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 9) + i3_s)] = atanf(data[((i0_i1_fused_i2_fused * 9) + i3_s)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 12, 7, 9), \"float32\"), compute: T.Buffer((17, 12, 7, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1428):\n            for i3_s in range(9):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 9 + i3_s\n                compute_1 = T.Buffer((12852,), data=compute.data)\n                data_1 = T.Buffer((12852,), data=data.data)\n                compute_1[cse_var_1] = T.atan(data_1[cse_var_1])", "op_args": [17, 12, 7, 9], "input_shape": "[[17, 12, 7, 9]]", "output_shape": "[[17, 12, 7, 9]]"}{"op_name": "atan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 5; ++i0) {\n    for (int32_t i1 = 0; i1 < 20; ++i1) {\n      for (int32_t i2 = 0; i2 < 4; ++i2) {\n        for (int32_t i3 = 0; i3 < 9; ++i3) {\n          compute[((((i0 * 720) + (i1 * 36)) + (i2 * 9)) + i3)] = atanf(data[((((i0 * 720) + (i1 * 36)) + (i2 * 9)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 20, 4, 9), \"float32\"), compute: T.Buffer((5, 20, 4, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(5):\n            for i1, i2, i3 in T.grid(20, 4, 9):\n                cse_var_1: T.int32 = i0 * 720 + i1 * 36 + i2 * 9 + i3\n                compute_1 = T.Buffer((3600,), data=compute.data)\n                data_1 = T.Buffer((3600,), data=data.data)\n                compute_1[cse_var_1] = T.atan(data_1[cse_var_1])", "op_args": [5, 20, 4, 9], "input_shape": "[[5, 20, 4, 9]]", "output_shape": "[[5, 20, 4, 9]]"}{"op_name": "atan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 80; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 13; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 13; ++i3_s) {\n        compute[(((i0_i1_fused * 169) + (i2 * 13)) + i3_s)] = atanf(data[(((i0_i1_fused * 169) + (i2 * 13)) + i3_s)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(52) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 8, 13, 13), \"float32\"), compute: T.Buffer((10, 8, 13, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(80):\n            for i2, i3_s in T.grid(13, 13):\n                cse_var_1: T.int32 = i0_i1_fused * 169 + i2 * 13 + i3_s\n                compute_1 = T.Buffer((13520,), data=compute.data)\n                data_1 = T.Buffer((13520,), data=data.data)\n                compute_1[cse_var_1] = T.atan(data_1[cse_var_1])", "op_args": [10, 8, 13, 13], "input_shape": "[[10, 8, 13, 13]]", "output_shape": "[[10, 8, 13, 13]]"}{"op_name": "adaptive_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  float adaptive_pool_sum[8];\n  for (int32_t ax1 = 0; ax1 < 17; ++ax1) {\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n        adaptive_pool_sum[ax3] = 0.000000e+00f;\n        for (int32_t rv0 = 0; rv0 < ((((((ax2 * 7) + 7) % 8) == 0) ? (((ax2 * 15) + 15) >> 3) : ((((ax2 * 15) + 15) >> 3) + 1)) - ((ax2 * 15) >> 3)); ++rv0) {\n          for (int32_t rv1 = 0; rv1 < ((((((ax3 * 2) + 2) % 8) == 0) ? (((ax3 * 5) + 5) >> 2) : ((((ax3 * 5) + 5) >> 2) + 1)) - ((ax3 * 10) >> 3)); ++rv1) {\n            adaptive_pool_sum[ax3] = (adaptive_pool_sum[ax3] + data[(((((ax1 * 150) + (((ax2 * 15) >> 3) * 10)) + (rv0 * 10)) + ((ax3 * 10) >> 3)) + rv1)]);\n          }\n        }\n      }\n      for (int32_t ax3_1 = 0; ax3_1 < 8; ++ax3_1) {\n        adaptive_pool_avg[(((ax1 * 64) + (ax2 * 8)) + ax3_1)] = (adaptive_pool_sum[ax3_1] / (((float)((((((ax2 * 7) + 7) % 8) == 0) ? (((ax2 * 15) + 15) >> 3) : ((((ax2 * 15) + 15) >> 3) + 1)) - ((ax2 * 15) >> 3))) * ((float)((((((ax3_1 * 2) + 2) % 8) == 0) ? (((ax3_1 * 5) + 5) >> 2) : ((((ax3_1 * 5) + 5) >> 2) + 1)) - ((ax3_1 * 10) >> 3)))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] / (((float)((((((((((int)blockIdx.x) & 3) * 14) + ((((int)threadIdx.x) >> 3) * 7)) + 7) % 8) == 0) ? ((((((int)blockIdx.x) & 3) * 15) + ((((((int)threadIdx.x) >> 3) * 15) + 15) >> 1)) >> 2) : (((((((int)blockIdx.x) & 3) * 15) + ((((((int)threadIdx.x) >> 3) * 15) + 15) >> 1)) >> 2) + 1)) - ((((((int)blockIdx.x) & 3) * 15) + ((((int)threadIdx.x) >> 3) * 7)) >> 2))) * ((float)(((((((((int)threadIdx.x) & 7) * 2) + 2) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 5) + 5) >> 2) : (((((((int)threadIdx.x) & 7) * 5) + 5) >> 2) + 1)) - (((((int)threadIdx.x) & 7) * 10) >> 3)))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < ((((((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 7) + 7) % 8) == 0) ? (((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 15) + 15) >> 3) : ((((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 15) + 15) >> 3) + 1)) - ((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 15) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 2) + 2) % 8) == 0) ? ((((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 5) + 5) >> 2) : (((((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 5) + 5) >> 2) + 1)) - (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 10) >> 3)); ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] + data[((((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) >> 5) * 150) + (((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) & 31) >> 2) * 15) >> 3) * 10)) + (rv0 * 10)) + (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) & 7) * 10) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 17, 15, 10), \"float32\"), adaptive_pool_avg: T.Buffer((1, 17, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        adaptive_pool_sum = T.allocate([8], \"float32\", \"global\")\n        for ax1, ax2 in T.grid(17, 8):\n            adaptive_pool_sum_1 = T.Buffer((8,), data=adaptive_pool_sum, align=32)\n            for ax3 in range(8):\n                adaptive_pool_sum_1[ax3] = T.float32(0)\n                for rv0, rv1 in T.grid(T.Let(T.Select((ax2 * 7 + 7) % 8 == 0, cse_var_1, cse_var_1 + 1) - ax2 * 15 // 8, where={cse_var_1: (ax2 * 15 + 15) // 8}), T.Let(T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_2, cse_var_2 + 1) - ax3 * 10 // 8, where={cse_var_2: (ax3 * 5 + 5) // 4})):\n                    cse_var_1 = T.int32()\n                    cse_var_2 = T.int32()\n                    data_1 = T.Buffer((2550,), data=data.data)\n                    adaptive_pool_sum_1[ax3] = adaptive_pool_sum_1[ax3] + data_1[ax1 * 150 + ax2 * 15 // 8 * 10 + rv0 * 10 + ax3 * 10 // 8 + rv1]\n            for ax3 in range(8):\n                cse_var_5: T.int32 = ax2 * 15\n                cse_var_4: T.int32 = (ax3 * 5 + 5) // 4\n                cse_var_3: T.int32 = (cse_var_5 + 15) // 8\n                adaptive_pool_avg_1 = T.Buffer((1088,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax1 * 64 + ax2 * 8 + ax3] = adaptive_pool_sum_1[ax3] / (T.Cast(\"float32\", T.Select((ax2 * 7 + 7) % 8 == 0, cse_var_3, cse_var_3 + 1) - cse_var_5 // 8) * T.Cast(\"float32\", T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_4, cse_var_4 + 1) - ax3 * 10 // 8))", "op_args": [1, 17, 15, 10], "input_shape": "[[1, 17, 15, 10]]", "output_shape": "[[1, 17, 8, 8]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[45];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 45; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 374; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 45; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 45) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 45; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 0.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 526; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 16) + (((int)threadIdx.x) >> 1)) < 8415) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 11, 15, 17), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([45], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((45,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(45):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(374, 45):\n            data_1 = T.Buffer((16830,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 45 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(45):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [6, 11, 15, 17], "input_shape": "[[6, 11, 15, 17]]", "output_shape": "[[]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[8];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 8; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 375; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 8; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 8) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 8; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 0.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 94; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 4) + (((int)threadIdx.x) >> 3)) < 375) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 15, 20, 1), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([8], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((8,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(8):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(375, 8):\n            data_1 = T.Buffer((3000,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 8 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(8):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [10, 15, 20, 1], "input_shape": "[[10, 15, 20, 1]]", "output_shape": "[[]]"}{"op_name": "adaptive_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 195; ++ax0_ax1_fused) {\n    float adaptive_pool_sum[8];\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n        adaptive_pool_sum[ax3] = 0.000000e+00f;\n        for (int32_t rv0 = 0; rv0 < ((((ax2 + 1) % 8) == 0) ? ((ax2 + 1) >> 3) : (((ax2 + 1) >> 3) + 1)); ++rv0) {\n          for (int32_t rv1 = 0; rv1 < ((((((ax3 * 2) + 2) % 8) == 0) ? ((ax3 + 1) >> 2) : (((ax3 + 1) >> 2) + 1)) - (ax3 >> 2)); ++rv1) {\n            adaptive_pool_sum[ax3] = (adaptive_pool_sum[ax3] + data[((((ax0_ax1_fused * 2) + (rv0 * 2)) + (ax3 >> 2)) + rv1)]);\n          }\n        }\n      }\n      for (int32_t ax3_1 = 0; ax3_1 < 8; ++ax3_1) {\n        adaptive_pool_avg[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3_1)] = (adaptive_pool_sum[ax3_1] / (((float)((((ax2 + 1) % 8) == 0) ? ((ax2 + 1) >> 3) : (((ax2 + 1) >> 3) + 1))) * ((float)((((((ax3_1 * 2) + 2) % 8) == 0) ? ((ax3_1 + 1) >> 2) : (((ax3_1 + 1) >> 2) + 1)) - (ax3_1 >> 2)))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] / (((float)(((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) % 8) == 0) ? (((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) >> 3) : ((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) & 7) + 1) >> 3) + 1))) * ((float)(((((((((int)threadIdx.x) & 7) * 2) + 2) % 8) == 0) ? (((((int)threadIdx.x) & 7) + 1) >> 2) : ((((((int)threadIdx.x) & 7) + 1) >> 2) + 1)) - ((((int)threadIdx.x) & 7) >> 2)))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < (((((((((int)blockIdx.x) & 1) * 4) + (((int)threadIdx.x) >> 3)) + 1) % 8) == 0) ? ((((((int)threadIdx.x) + 8) >> 5) + (((int)blockIdx.x) & 1)) >> 1) : (((((((int)threadIdx.x) + 8) >> 5) + (((int)blockIdx.x) & 1)) >> 1) + 1)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((int)threadIdx.x) & 7) * 2) + 2) % 8) == 0) ? (((((int)threadIdx.x) & 7) + 1) >> 2) : ((((((int)threadIdx.x) & 7) + 1) >> 2) + 1)) - ((((int)threadIdx.x) & 7) >> 2)); ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data[(((((((int)blockIdx.x) >> 1) * 2) + (rv0 * 2)) + ((((int)threadIdx.x) & 7) >> 2)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 13, 1, 2), \"float32\"), adaptive_pool_avg: T.Buffer((15, 13, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(195):\n            adaptive_pool_sum = T.allocate([8], \"float32\", \"global\")\n            for ax2 in range(8):\n                adaptive_pool_sum_1 = T.Buffer((8,), data=adaptive_pool_sum, align=32)\n                for ax3 in range(8):\n                    adaptive_pool_sum_1[ax3] = T.float32(0)\n                    for rv0, rv1 in T.grid(T.Let(T.Select((ax2 + 1) % 8 == 0, cse_var_1, cse_var_1 + 1), where={cse_var_1: (ax2 + 1) // 8}), T.Let(T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_2, cse_var_2 + 1) - ax3 // 4, where={cse_var_2: (ax3 + 1) // 4})):\n                        cse_var_1 = T.int32()\n                        cse_var_2 = T.int32()\n                        data_1 = T.Buffer((390,), data=data.data)\n                        adaptive_pool_sum_1[ax3] = adaptive_pool_sum_1[ax3] + data_1[ax0_ax1_fused * 2 + rv0 * 2 + ax3 // 4 + rv1]\n                for ax3 in range(8):\n                    cse_var_5: T.int32 = ax2 + 1\n                    cse_var_4: T.int32 = cse_var_5 // 8\n                    cse_var_3: T.int32 = (ax3 + 1) // 4\n                    adaptive_pool_avg_1 = T.Buffer((12480,), data=adaptive_pool_avg.data)\n                    adaptive_pool_avg_1[ax0_ax1_fused * 64 + ax2 * 8 + ax3] = adaptive_pool_sum_1[ax3] / (T.Cast(\"float32\", T.Select(cse_var_5 % 8 == 0, cse_var_4, cse_var_4 + 1)) * T.Cast(\"float32\", T.Select((ax3 * 2 + 2) % 8 == 0, cse_var_3, cse_var_3 + 1) - ax3 // 4))", "op_args": [15, 13, 1, 2], "input_shape": "[[15, 13, 1, 2]]", "output_shape": "[[15, 13, 8, 8]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[64];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 64; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 297; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 64; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 64) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 64; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 0.000000e+00f;\n  for (int k0 = 0; k0 < 12; ++k0) {\n    for (int k1 = 0; k1 < 11; ++k1) {\n      for (int k2 = 0; k2 < 9; ++k2) {\n        for (int k3 = 0; k3 < 16; ++k3) {\n          data_red[0] = (data_red[0] + data[((((k0 * 1584) + (k1 * 144)) + (k2 * 16)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 11, 9, 16), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([64], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((64,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(64):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(297, 64):\n            data_1 = T.Buffer((19008,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 64 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(64):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [12, 11, 9, 16], "input_shape": "[[12, 11, 9, 16]]", "output_shape": "[[]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[9];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 9; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 2366; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 9; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 9) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 9; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 0.000000e+00f;\n  for (int k0 = 0; k0 < 13; ++k0) {\n    for (int k1 = 0; k1 < 14; ++k1) {\n      for (int k2 = 0; k2 < 9; ++k2) {\n        for (int k3 = 0; k3 < 13; ++k3) {\n          data_red[0] = (data_red[0] + data[((((k0 * 1638) + (k1 * 117)) + (k2 * 13)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 14, 9, 13), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([9], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((9,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(9):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(2366, 9):\n            data_1 = T.Buffer((21294,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 9 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(9):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [13, 14, 9, 13], "input_shape": "[[13, 14, 9, 13]]", "output_shape": "[[]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[17];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 17; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 182; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 17; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 17) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 17; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 0.000000e+00f;\n  for (int k0 = 0; k0 < 13; ++k0) {\n    for (int k1 = 0; k1 < 14; ++k1) {\n      for (int k2 = 0; k2 < 17; ++k2) {\n        data_red[0] = (data_red[0] + data[(((k0 * 238) + (k1 * 17)) + k2)]);\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 14, 17, 1), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([17], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((17,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(17):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(182, 17):\n            data_1 = T.Buffer((3094,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 17 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(17):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [13, 14, 17, 1], "input_shape": "[[13, 14, 17, 1]]", "output_shape": "[[]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[12];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 12; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 1440; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 12; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 12) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 12; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 0.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 540; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    normal_reduce_temp0[0] = (normal_reduce_temp0[0] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 16, 6, 15), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([12], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((12,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(12):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(1440, 12):\n            data_1 = T.Buffer((17280,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 12 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(12):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [12, 16, 6, 15], "input_shape": "[[12, 16, 6, 15]]", "output_shape": "[[]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[51];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 51; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 216; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 51; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 51) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 51; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 0.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 345; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 4) + (((int)threadIdx.x) >> 3)) < 1377) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 17, 9, 9), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([51], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((51,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(51):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(216, 51):\n            data_1 = T.Buffer((11016,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 51 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(51):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [8, 17, 9, 9], "input_shape": "[[8, 17, 9, 9]]", "output_shape": "[[]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[15];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 15; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 200; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 15; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 15) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 15; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 0.000000e+00f;\n  for (int k0 = 0; k0 < 6; ++k0) {\n    for (int k1 = 0; k1 < 5; ++k1) {\n      for (int k2 = 0; k2 < 5; ++k2) {\n        for (int k3 = 0; k3 < 20; ++k3) {\n          data_red[0] = (data_red[0] + data[((((k0 * 500) + (k1 * 100)) + (k2 * 20)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 5, 5, 20), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([15], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((15,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(15):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(200, 15):\n            data_1 = T.Buffer((3000,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 15 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(15):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [6, 5, 5, 20], "input_shape": "[[6, 5, 5, 20]]", "output_shape": "[[]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[27];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 2210; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 27; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 27) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 0.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 1865; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 16) + (((int)threadIdx.x) >> 1)) < 29835) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 15, 18, 17), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([27], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((27,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(27):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(2210, 27):\n            data_1 = T.Buffer((59670,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 27 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(27):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [13, 15, 18, 17], "input_shape": "[[13, 15, 18, 17]]", "output_shape": "[[]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[27];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 448; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 27; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 27) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 0.000000e+00f;\n  for (int k0 = 0; k0 < 18; ++k0) {\n    for (int k1 = 0; k1 < 3; ++k1) {\n      for (int k2 = 0; k2 < 14; ++k2) {\n        for (int k3 = 0; k3 < 16; ++k3) {\n          data_red[0] = (data_red[0] + data[((((k0 * 672) + (k1 * 224)) + (k2 * 16)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 3, 14, 16), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([27], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((27,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(27):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(448, 27):\n            data_1 = T.Buffer((12096,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 27 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(27):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [18, 3, 14, 16], "input_shape": "[[18, 3, 14, 16]]", "output_shape": "[[]]"}{"op_name": "adaptive_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 16; ++ax0) {\n    float adaptive_pool_sum[64];\n    for (int32_t ax1 = 0; ax1 < 17; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n          adaptive_pool_sum[((ax2 * 8) + ax3)] = 0.000000e+00f;\n          for (int32_t rv0 = 0; rv0 < (((((ax2 + 1) % 8) == 0) ? (((ax2 * 17) + 17) >> 3) : ((((ax2 * 17) + 17) >> 3) + 1)) - (ax2 * 2)); ++rv0) {\n            for (int32_t rv1 = 0; rv1 < ((((((ax3 * 4) + 4) % 8) == 0) ? (((ax3 * 3) + 3) >> 1) : ((((ax3 * 3) + 3) >> 1) + 1)) - ((ax3 * 12) >> 3)); ++rv1) {\n              adaptive_pool_sum[((ax2 * 8) + ax3)] = (adaptive_pool_sum[((ax2 * 8) + ax3)] + data[((((((ax0 * 3468) + (ax1 * 204)) + (ax2 * 24)) + (rv0 * 12)) + ((ax3 * 12) >> 3)) + rv1)]);\n            }\n          }\n        }\n      }\n      for (int32_t ax2_1 = 0; ax2_1 < 8; ++ax2_1) {\n        for (int32_t ax3_1 = 0; ax3_1 < 8; ++ax3_1) {\n          adaptive_pool_avg[((((ax0 * 1088) + (ax1 * 64)) + (ax2_1 * 8)) + ax3_1)] = (adaptive_pool_sum[((ax2_1 * 8) + ax3_1)] / (((float)(((((ax2_1 + 1) % 8) == 0) ? (((ax2_1 * 17) + 17) >> 3) : ((((ax2_1 * 17) + 17) >> 3) + 1)) - (ax2_1 * 2))) * ((float)((((((ax3_1 * 4) + 4) % 8) == 0) ? (((ax3_1 * 3) + 3) >> 1) : ((((ax3_1 * 3) + 3) >> 1) + 1)) - ((ax3_1 * 12) >> 3)))));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] / (((float)(((((((((((int)blockIdx.x) & 1) * 4) + (((int)threadIdx.x) >> 3)) + 1) % 8) == 0) ? ((((((int)blockIdx.x) & 1) * 17) + ((((((int)threadIdx.x) >> 3) * 17) + 17) >> 2)) >> 1) : (((((((int)blockIdx.x) & 1) * 17) + ((((((int)threadIdx.x) >> 3) * 17) + 17) >> 2)) >> 1) + 1)) - ((((int)threadIdx.x) >> 3) * 2)) - ((((int)blockIdx.x) & 1) * 8))) * ((float)(((((((((int)threadIdx.x) & 7) * 4) + 4) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 3) + 3) >> 1) : (((((((int)threadIdx.x) & 7) * 3) + 3) >> 1) + 1)) - (((((int)threadIdx.x) & 7) * 12) >> 3)))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < ((((((((int)threadIdx.x) >> 3) + 1) % 8) == 0) ? ((((((int)threadIdx.x) >> 3) * 17) + 17) >> 3) : (((((((int)threadIdx.x) >> 3) * 17) + 17) >> 3) + 1)) - ((((int)threadIdx.x) >> 3) * 2)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((int)threadIdx.x) & 7) * 4) + 4) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 3) + 3) >> 1) : (((((((int)threadIdx.x) & 7) * 3) + 3) >> 1) + 1)) - (((((int)threadIdx.x) & 7) * 12) >> 3)); ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + data[(((((((int)blockIdx.x) * 204) + ((((int)threadIdx.x) >> 3) * 24)) + (rv0 * 12)) + (((((int)threadIdx.x) & 7) * 12) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 17, 17, 12), \"float32\"), adaptive_pool_avg: T.Buffer((16, 17, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(16):\n            adaptive_pool_sum = T.allocate([64], \"float32\", \"global\")\n            for ax1 in range(17):\n                adaptive_pool_sum_1 = T.Buffer((64,), data=adaptive_pool_sum)\n                for ax2, ax3 in T.grid(8, 8):\n                    adaptive_pool_sum_1[ax2 * 8 + ax3] = T.float32(0)\n                    for rv0, rv1 in T.grid(T.Let(T.Select((ax2 + 1) % 8 == 0, cse_var_1, cse_var_1 + 1) - ax2 * 2, where={cse_var_1: (ax2 * 17 + 17) // 8}), T.Let(T.Select((ax3 * 4 + 4) % 8 == 0, cse_var_2, cse_var_2 + 1) - ax3 * 12 // 8, where={cse_var_2: (ax3 * 3 + 3) // 2})):\n                        cse_var_1 = T.int32()\n                        cse_var_2 = T.int32()\n                        cse_var_3: T.int32 = ax2 * 8 + ax3\n                        data_1 = T.Buffer((55488,), data=data.data)\n                        adaptive_pool_sum_1[cse_var_3] = adaptive_pool_sum_1[cse_var_3] + data_1[ax0 * 3468 + ax1 * 204 + ax2 * 24 + rv0 * 12 + ax3 * 12 // 8 + rv1]\n                for ax2, ax3 in T.grid(8, 8):\n                    cse_var_6: T.int32 = ax2 * 8\n                    cse_var_5: T.int32 = (ax2 * 17 + 17) // 8\n                    cse_var_4: T.int32 = (ax3 * 3 + 3) // 2\n                    adaptive_pool_avg_1 = T.Buffer((17408,), data=adaptive_pool_avg.data)\n                    adaptive_pool_avg_1[ax0 * 1088 + ax1 * 64 + cse_var_6 + ax3] = adaptive_pool_sum_1[cse_var_6 + ax3] / (T.Cast(\"float32\", T.Select((ax2 + 1) % 8 == 0, cse_var_5, cse_var_5 + 1) - ax2 * 2) * T.Cast(\"float32\", T.Select((ax3 * 4 + 4) % 8 == 0, cse_var_4, cse_var_4 + 1) - ax3 * 12 // 8))", "op_args": [16, 17, 17, 12], "input_shape": "[[16, 17, 17, 12]]", "output_shape": "[[16, 17, 8, 8]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[16];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 16; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 255; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 16; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 16) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 16; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 0.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 128; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 2) + (((int)threadIdx.x) >> 4)) < 255) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 5, 4, 17), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([16], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((16,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(16):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(255, 16):\n            data_1 = T.Buffer((4080,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 16 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(16):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [12, 5, 4, 17], "input_shape": "[[12, 5, 4, 17]]", "output_shape": "[[]]"}{"op_name": "adaptive_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 168; ++ax0_ax1_fused) {\n    float adaptive_pool_sum[8];\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n        adaptive_pool_sum[ax3] = 0.000000e+00f;\n        for (int32_t rv1 = 0; rv1 < (((((ax3 + 1) % 8) == 0) ? (((ax3 * 17) + 17) >> 3) : ((((ax3 * 17) + 17) >> 3) + 1)) - (ax3 * 2)); ++rv1) {\n          adaptive_pool_sum[ax3] = (adaptive_pool_sum[ax3] + data[((((ax0_ax1_fused * 136) + (ax2 * 17)) + (ax3 * 2)) + rv1)]);\n        }\n      }\n      for (int32_t ax3_1 = 0; ax3_1 < 8; ++ax3_1) {\n        adaptive_pool_avg[(((ax0_ax1_fused * 64) + (ax2 * 8)) + ax3_1)] = (adaptive_pool_sum[ax3_1] / ((float)(((((ax3_1 + 1) % 8) == 0) ? (((ax3_1 * 17) + 17) >> 3) : ((((ax3_1 * 17) + 17) >> 3) + 1)) - (ax3_1 * 2))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] / ((float)((((((((int)threadIdx.x) & 7) + 1) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 17) + 17) >> 3) : (((((((int)threadIdx.x) & 7) * 17) + 17) >> 3) + 1)) - ((((int)threadIdx.x) & 7) * 2))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv1 = 0; rv1 < ((((((((int)threadIdx.x) & 7) + 1) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 17) + 17) >> 3) : (((((((int)threadIdx.x) & 7) * 17) + 17) >> 3) + 1)) - ((((int)threadIdx.x) & 7) * 2)); ++rv1) {\n    adaptive_pool_sum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 136) + ((((int)threadIdx.x) >> 3) * 17)) + ((((int)threadIdx.x) & 7) * 2)) + rv1)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 14, 8, 17), \"float32\"), adaptive_pool_avg: T.Buffer((12, 14, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(168):\n            adaptive_pool_sum = T.allocate([8], \"float32\", \"global\")\n            for ax2 in range(8):\n                adaptive_pool_sum_1 = T.Buffer((8,), data=adaptive_pool_sum, align=32)\n                for ax3 in range(8):\n                    adaptive_pool_sum_1[ax3] = T.float32(0)\n                    for rv1 in range(T.Let(T.Select((ax3 + 1) % 8 == 0, cse_var_1, cse_var_1 + 1) - ax3 * 2, where={cse_var_1: (ax3 * 17 + 17) // 8})):\n                        cse_var_1 = T.int32()\n                        data_1 = T.Buffer((22848,), data=data.data)\n                        adaptive_pool_sum_1[ax3] = adaptive_pool_sum_1[ax3] + data_1[ax0_ax1_fused * 136 + ax2 * 17 + ax3 * 2 + rv1]\n                for ax3 in range(8):\n                    cse_var_2: T.int32 = (ax3 * 17 + 17) // 8\n                    adaptive_pool_avg_1 = T.Buffer((10752,), data=adaptive_pool_avg.data)\n                    adaptive_pool_avg_1[ax0_ax1_fused * 64 + ax2 * 8 + ax3] = adaptive_pool_sum_1[ax3] / T.Cast(\"float32\", T.Select((ax3 + 1) % 8 == 0, cse_var_2, cse_var_2 + 1) - ax3 * 2)", "op_args": [12, 14, 8, 17], "input_shape": "[[12, 14, 8, 17]]", "output_shape": "[[12, 14, 8, 8]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[42];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 42; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 120; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 42; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 42) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 42; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 0.000000e+00f;\n  for (int k0 = 0; k0 < 20; ++k0) {\n    for (int k1 = 0; k1 < 14; ++k1) {\n      for (int k2 = 0; k2 < 2; ++k2) {\n        for (int k3 = 0; k3 < 9; ++k3) {\n          data_red[0] = (data_red[0] + data[((((k0 * 252) + (k1 * 18)) + (k2 * 9)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 14, 2, 9), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([42], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((42,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(42):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(120, 42):\n            data_1 = T.Buffer((5040,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 42 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(42):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [20, 14, 2, 9], "input_shape": "[[20, 14, 2, 9]]", "output_shape": "[[]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[19];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 19; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 156; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 19; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 19) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 19; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 0.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 93; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 8) + (((int)threadIdx.x) >> 2)) < 741) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 1, 12, 19), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([19], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((19,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(19):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(156, 19):\n            data_1 = T.Buffer((2964,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 19 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(19):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [13, 1, 12, 19], "input_shape": "[[13, 1, 12, 19]]", "output_shape": "[[]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[57];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 57; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 48; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 57; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 57) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 57; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 0.000000e+00f;\n  for (int k0 = 0; k0 < 18; ++k0) {\n    for (int k1 = 0; k1 < 4; ++k1) {\n      for (int k2 = 0; k2 < 19; ++k2) {\n        for (int k3 = 0; k3 < 2; ++k3) {\n          data_red[0] = (data_red[0] + data[((((k0 * 152) + (k1 * 38)) + (k2 * 2)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 4, 19, 2), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([57], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((57,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(57):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(48, 57):\n            data_1 = T.Buffer((2736,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 57 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(57):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [18, 4, 19, 2], "input_shape": "[[18, 4, 19, 2]]", "output_shape": "[[]]"}{"op_name": "adaptive_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 10; ++ax0) {\n    float adaptive_pool_sum[1];\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 8; ++ax3) {\n        adaptive_pool_sum[0] = 0.000000e+00f;\n        for (int32_t rv0 = 0; rv0 < ((((((ax2 * 3) + 3) % 8) == 0) ? (((ax2 * 19) + 19) >> 3) : ((((ax2 * 19) + 19) >> 3) + 1)) - ((ax2 * 19) >> 3)); ++rv0) {\n          for (int32_t rv1 = 0; rv1 < ((((((ax3 * 5) + 5) % 8) == 0) ? (((ax3 * 5) + 5) >> 3) : ((((ax3 * 5) + 5) >> 3) + 1)) - ((ax3 * 5) >> 3)); ++rv1) {\n            adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[(((((ax0 * 95) + (((ax2 * 19) >> 3) * 5)) + (rv0 * 5)) + ((ax3 * 5) >> 3)) + rv1)]);\n          }\n        }\n        adaptive_pool_avg[(((ax0 * 64) + (ax2 * 8)) + ax3)] = (adaptive_pool_sum[0] / (((float)((((((ax2 * 3) + 3) % 8) == 0) ? (((ax2 * 19) + 19) >> 3) : ((((ax2 * 19) + 19) >> 3) + 1)) - ((ax2 * 19) >> 3))) * ((float)((((((ax3 * 5) + 5) % 8) == 0) ? (((ax3 * 5) + 5) >> 3) : ((((ax3 * 5) + 5) >> 3) + 1)) - ((ax3 * 5) >> 3)))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] / (((float)(((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 3) + 3) % 8) == 0) ? ((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 19) + 19) >> 3) : (((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 19) + 19) >> 3) + 1)) - (((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 19) >> 3))) * ((float)(((((((((int)threadIdx.x) & 7) * 5) + 5) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 5) + 5) >> 3) : (((((((int)threadIdx.x) & 7) * 5) + 5) >> 3) + 1)) - (((((int)threadIdx.x) & 7) * 5) >> 3)))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < (((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 3) + 3) % 8) == 0) ? ((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 19) + 19) >> 3) : (((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 19) + 19) >> 3) + 1)) - (((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 19) >> 3)); ++rv0) {\n    for (int rv1 = 0; rv1 < (((((((((int)threadIdx.x) & 7) * 5) + 5) % 8) == 0) ? ((((((int)threadIdx.x) & 7) * 5) + 5) >> 3) : (((((((int)threadIdx.x) & 7) * 5) + 5) >> 3) + 1)) - (((((int)threadIdx.x) & 7) * 5) >> 3)); ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] + data[((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) >> 3) * 95) + ((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) & 7) * 19) >> 3) * 5)) + (rv0 * 5)) + (((((int)threadIdx.x) & 7) * 5) >> 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 1, 19, 5), \"float32\"), adaptive_pool_avg: T.Buffer((10, 1, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(10):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            for ax2, ax3 in T.grid(8, 8):\n                cse_var_4: T.int32 = ax2 * 19\n                cse_var_3: T.int32 = ax3 * 5\n                cse_var_5: T.int32 = cse_var_3 + 5\n                cse_var_2: T.int32 = cse_var_5 // 8\n                cse_var_1: T.int32 = (cse_var_4 + 19) // 8\n                adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n                adaptive_pool_sum_1[0] = T.float32(0)\n                for rv0, rv1 in T.grid(T.Select((ax2 * 3 + 3) % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_4 // 8, T.Select(cse_var_5 % 8 == 0, cse_var_2, cse_var_2 + 1) - cse_var_3 // 8):\n                    data_1 = T.Buffer((950,), data=data.data)\n                    adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0 * 95 + cse_var_4 // 8 * 5 + rv0 * 5 + cse_var_3 // 8 + rv1]\n                adaptive_pool_avg_1 = T.Buffer((640,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 64 + ax2 * 8 + ax3] = adaptive_pool_sum_1[0] / (T.Cast(\"float32\", T.Select((ax2 * 3 + 3) % 8 == 0, cse_var_1, cse_var_1 + 1) - cse_var_4 // 8) * T.Cast(\"float32\", T.Select(cse_var_5 % 8 == 0, cse_var_2, cse_var_2 + 1) - cse_var_3 // 8))", "op_args": [10, 1, 19, 5], "input_shape": "[[10, 1, 19, 5]]", "output_shape": "[[10, 1, 8, 8]]"}{"op_name": "sum", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[27];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 0.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 24; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 27; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] + data[((k0_k1_fused_k2_fused_k3_fused_outer * 27) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 0.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] + data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 0.000000e+00f;\n  for (int k0 = 0; k0 < 3; ++k0) {\n    for (int k1 = 0; k1 < 6; ++k1) {\n      for (int k2 = 0; k2 < 12; ++k2) {\n        for (int k3 = 0; k3 < 3; ++k3) {\n          data_red[0] = (data_red[0] + data[((((k0 * 216) + (k1 * 36)) + (k2 * 3)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 6, 12, 3), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([27], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((27,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(27):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(24, 27):\n            data_1 = T.Buffer((648,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] + data_1[k0_k1_fused_k2_fused_k3_fused_outer * 27 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(0)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(27):\n            data_red_1[0] = data_red_1[0] + data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [3, 6, 12, 3], "input_shape": "[[3, 6, 12, 3]]", "output_shape": "[[]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5814; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 6)) < 969) {\n    compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 6, 17, 19), \"float32\"), compute: T.Buffer((3, 6, 17, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(5814):\n            compute_1 = T.Buffer((5814,), data=compute.data)\n            data_1 = T.Buffer((5814,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cosh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [3, 6, 17, 19], "input_shape": "[[3, 6, 17, 19]]", "output_shape": "[[3, 6, 17, 19]]"}{"op_name": "fast_softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  float T_softmax_maxelem[1];\n  float T_softmax_expsum[1];\n  for (int32_t i2 = 0; i2 < 18; ++i2) {\n    T_softmax_maxelem[0] = -3.402823e+38f;\n    for (int32_t k = 0; k < 2; ++k) {\n      T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[((i2 * 2) + k)]);\n    }\n    T_softmax_expsum[0] = 0.000000e+00f;\n    for (int32_t k_1 = 0; k_1 < 2; ++k_1) {\n        int32_t v_ = ((int32_t)(floorf(((max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((i2 * 2) + k_1)] - T_softmax_maxelem[0])));\n    }\n    for (int32_t i3_s = 0; i3_s < 2; ++i3_s) {\n        int32_t v__1 = ((int32_t)(floorf(((max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_norm[((i2 * 2) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((i2 * 2) + i3_s)] - T_softmax_maxelem[0])) / T_softmax_expsum[0]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int k = 0; k < 2; ++k) {\n    T_softmax_maxelem[((int)threadIdx.x)] = max(T_softmax_maxelem[((int)threadIdx.x)], data[((((int)threadIdx.x) * 2) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)])) / T_softmax_expsum[((int)blockIdx.x)]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(18) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((int)threadIdx.x)] = 0.000000e+00f;\n  for (int k = 0; k < 2; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((int)threadIdx.x)] = (T_softmax_expsum[((int)threadIdx.x)] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)threadIdx.x) * 2) + k)] - T_softmax_maxelem[((int)threadIdx.x)])));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 1, 18, 2), \"float32\"), T_softmax_norm: T.Buffer((1, 1, 18, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n        T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n        for i2 in range(18):\n            T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n            T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n            data_1 = T.Buffer((36,), data=data.data)\n            for k in range(2):\n                T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i2 * 2 + k])\n            T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n            T_softmax_expsum_1[0] = T.float32(0)\n            for k in range(2):\n                cse_var_1: T.int32 = i2 * 2 + k\n                T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[0])\n            for i3_s in range(2):\n                cse_var_2: T.int32 = i2 * 2 + i3_s\n                T_softmax_norm_1 = T.Buffer((36,), data=T_softmax_norm.data)\n                T_softmax_norm_1[cse_var_2] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[0]) / T_softmax_expsum_1[0]", "op_args": [1, 1, 18, 2], "input_shape": "[[1, 1, 18, 2]]", "output_shape": "[[1, 1, 18, 2]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 2; ++i0) {\n    for (int32_t i1 = 0; i1 < 15; ++i1) {\n      for (int32_t i2 = 0; i2 < 2; ++i2) {\n        for (int32_t i3 = 0; i3 < 8; ++i3) {\n          compute[((((i0 * 240) + (i1 * 16)) + (i2 * 8)) + i3)] = coshf(data[((((i0 * 240) + (i1 * 16)) + (i2 * 8)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 15, 2, 8), \"float32\"), compute: T.Buffer((2, 15, 2, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(2):\n            for i1, i2, i3 in T.grid(15, 2, 8):\n                cse_var_1: T.int32 = i0 * 240 + i1 * 16 + i2 * 8 + i3\n                compute_1 = T.Buffer((480,), data=compute.data)\n                data_1 = T.Buffer((480,), data=data.data)\n                compute_1[cse_var_1] = T.cosh(data_1[cse_var_1])", "op_args": [2, 15, 2, 8], "input_shape": "[[2, 15, 2, 8]]", "output_shape": "[[2, 15, 2, 8]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 18; ++i1) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3 = 0; i3 < 20; ++i3) {\n        compute[(((i1 * 80) + (i2 * 20)) + i3)] = coshf(data[(((i1 * 80) + (i2 * 20)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 18, 4, 20), \"float32\"), compute: T.Buffer((1, 18, 4, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(18, 4, 20):\n            cse_var_1: T.int32 = i1 * 80 + i2 * 20 + i3\n            compute_1 = T.Buffer((1440,), data=compute.data)\n            data_1 = T.Buffer((1440,), data=data.data)\n            compute_1[cse_var_1] = T.cosh(data_1[cse_var_1])", "op_args": [1, 18, 4, 20], "input_shape": "[[1, 18, 4, 20]]", "output_shape": "[[1, 18, 4, 20]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 7650; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(17) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 17, 15, 10), \"float32\"), compute: T.Buffer((3, 17, 15, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(7650):\n            compute_1 = T.Buffer((7650,), data=compute.data)\n            data_1 = T.Buffer((7650,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cosh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [3, 17, 15, 10], "input_shape": "[[3, 17, 15, 10]]", "output_shape": "[[3, 17, 15, 10]]"}{"op_name": "fast_softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        T_softmax_maxelem[0] = -3.402823e+38f;\n        for (int32_t k = 0; k < 12; ++k) {\n          T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k)]);\n        }\n        T_softmax_expsum[0] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 12; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + k_1)] - T_softmax_maxelem[0])));\n        }\n        for (int32_t i3_s = 0; i3_s < 12; ++i3_s) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 72) + (i1 * 36)) + (i2 * 12)) + i3_s)] - T_softmax_maxelem[0])) / T_softmax_expsum[0]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 12; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 24) + (((int)threadIdx.x) * 12)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 1)) < 33) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 12; ++k) {\n    if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 1)) < 33) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 96) + (((int)threadIdx.x) * 12)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 99) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)])) / T_softmax_expsum[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) / 3)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 2, 3, 12), \"float32\"), T_softmax_norm: T.Buffer((11, 2, 3, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i1, i2 in T.grid(2, 3):\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((792,), data=data.data)\n                for k in range(12):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0 * 72 + i1 * 36 + i2 * 12 + k])\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(12):\n                    cse_var_1: T.int32 = i0 * 72 + i1 * 36 + i2 * 12 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[0])\n                for i3_s in range(12):\n                    cse_var_2: T.int32 = i0 * 72 + i1 * 36 + i2 * 12 + i3_s\n                    T_softmax_norm_1 = T.Buffer((792,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_2] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[0]) / T_softmax_expsum_1[0]", "op_args": [11, 2, 3, 12], "input_shape": "[[11, 2, 3, 12]]", "output_shape": "[[11, 2, 3, 12]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 28; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 3; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 3) + i3)] = coshf(data[((i0_i1_fused_i2_fused * 3) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(21) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 7, 1, 3), \"float32\"), compute: T.Buffer((4, 7, 1, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(28):\n            for i3 in range(3):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 3 + i3\n                compute_1 = T.Buffer((84,), data=compute.data)\n                data_1 = T.Buffer((84,), data=data.data)\n                compute_1[cse_var_1] = T.cosh(data_1[cse_var_1])", "op_args": [4, 7, 1, 3], "input_shape": "[[4, 7, 1, 3]]", "output_shape": "[[4, 7, 1, 3]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2432; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 16, 1, 8), \"float32\"), compute: T.Buffer((19, 16, 1, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2432):\n            compute_1 = T.Buffer((2432,), data=compute.data)\n            data_1 = T.Buffer((2432,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cosh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [19, 16, 1, 8], "input_shape": "[[19, 16, 1, 8]]", "output_shape": "[[19, 16, 1, 8]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 504; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 2, 14, 2), \"float32\"), compute: T.Buffer((9, 2, 14, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(504):\n            compute_1 = T.Buffer((504,), data=compute.data)\n            data_1 = T.Buffer((504,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cosh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [9, 2, 14, 2], "input_shape": "[[9, 2, 14, 2]]", "output_shape": "[[9, 2, 14, 2]]"}{"op_name": "fast_softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    float T_softmax_maxelem[120];\n    float T_softmax_expsum[120];\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i2 = 0; i2 < 15; ++i2) {\n        T_softmax_maxelem[((i1 * 15) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 8; ++k) {\n          T_softmax_maxelem[((i1 * 15) + i2)] = max(T_softmax_maxelem[((i1 * 15) + i2)], data[((((i0 * 960) + (i1 * 120)) + (i2 * 8)) + k)]);\n        }\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 8; ++i1_1) {\n      for (int32_t i2_1 = 0; i2_1 < 15; ++i2_1) {\n        T_softmax_expsum[((i1_1 * 15) + i2_1)] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 8; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[((i1_1 * 15) + i2_1)] = (T_softmax_expsum[((i1_1 * 15) + i2_1)] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 960) + (i1_1 * 120)) + (i2_1 * 8)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)])));\n        }\n      }\n    }\n    for (int32_t i1_2 = 0; i1_2 < 8; ++i1_2) {\n      for (int32_t i2_2 = 0; i2_2 < 15; ++i2_2) {\n        for (int32_t i3_s = 0; i3_s < 8; ++i3_s) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 960) + (i1_2 * 120)) + (i2_2 * 8)) + i3_s)] - T_softmax_maxelem[((i1_2 * 15) + i2_2)])) / T_softmax_expsum[((i1_2 * 15) + i2_2)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 135) {\n    T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 8; ++k) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 135) {\n        int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))])) / T_softmax_expsum[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 8; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 192) + (((int)threadIdx.x) * 8)) + k)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 8, 15, 8), \"float32\"), T_softmax_norm: T.Buffer((18, 8, 15, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(18):\n            T_softmax_maxelem = T.allocate([120], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([120], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((120,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((17280,), data=data.data)\n            for i1, i2 in T.grid(8, 15):\n                T_softmax_maxelem_1[i1 * 15 + i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(8):\n                    cse_var_1: T.int32 = i1 * 15 + i2\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 960 + i1 * 120 + i2 * 8 + k])\n            T_softmax_expsum_1 = T.Buffer((120,), data=T_softmax_expsum)\n            for i1, i2 in T.grid(8, 15):\n                T_softmax_expsum_1[i1 * 15 + i2] = T.float32(0)\n                for k in range(8):\n                    cse_var_3: T.int32 = i1 * 15 + i2\n                    cse_var_2: T.int32 = i0 * 960 + i1 * 120 + i2 * 8 + k\n                    T_softmax_expsum_1[cse_var_3] = T_softmax_expsum_1[cse_var_3] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3])\n            for i1, i2, i3_s in T.grid(8, 15, 8):\n                cse_var_5: T.int32 = i1 * 15 + i2\n                cse_var_4: T.int32 = i0 * 960 + i1 * 120 + i2 * 8 + i3_s\n                T_softmax_norm_1 = T.Buffer((17280,), data=T_softmax_norm.data)\n                T_softmax_norm_1[cse_var_4] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5]) / T_softmax_expsum_1[cse_var_5]", "op_args": [18, 8, 15, 8], "input_shape": "[[18, 8, 15, 8]]", "output_shape": "[[18, 8, 15, 8]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 75; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 5; ++i2) {\n      for (int32_t i3 = 0; i3 < 12; ++i3) {\n        compute[(((i0_i1_fused * 60) + (i2 * 12)) + i3)] = coshf(data[(((i0_i1_fused * 60) + (i2 * 12)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 15, 5, 12), \"float32\"), compute: T.Buffer((5, 15, 5, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(75):\n            for i2, i3 in T.grid(5, 12):\n                cse_var_1: T.int32 = i0_i1_fused * 60 + i2 * 12 + i3\n                compute_1 = T.Buffer((4500,), data=compute.data)\n                data_1 = T.Buffer((4500,), data=data.data)\n                compute_1[cse_var_1] = T.cosh(data_1[cse_var_1])", "op_args": [5, 15, 5, 12], "input_shape": "[[5, 15, 5, 12]]", "output_shape": "[[5, 15, 5, 12]]"}{"op_name": "fast_softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 260; ++i0_i1_fused) {\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      T_softmax_maxelem[0] = -3.402823e+38f;\n      for (int32_t k = 0; k < 15; ++k) {\n        T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[(((i0_i1_fused * 45) + (i2 * 15)) + k)]);\n      }\n      T_softmax_expsum[0] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 15; ++k_1) {\n          int32_t v_ = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 45) + (i2 * 15)) + k_1)] - T_softmax_maxelem[0])));\n      }\n      for (int32_t i3_s = 0; i3_s < 15; ++i3_s) {\n          int32_t v__1 = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_norm[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 45) + (i2 * 15)) + i3_s)] - T_softmax_maxelem[0])) / T_softmax_expsum[0]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 195) {\n    T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 15; ++k) {\n    if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 195) {\n        int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(52) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)])) / T_softmax_expsum[(((((int)blockIdx.x) * 52) + ((int)threadIdx.x)) / 15)]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) < 195) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 15; ++k) {\n    if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) < 195) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 960) + (((int)threadIdx.x) * 15)) + k)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 20, 3, 15), \"float32\"), T_softmax_norm: T.Buffer((13, 20, 3, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(260):\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i2 in range(3):\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((11700,), data=data.data)\n                for k in range(15):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0_i1_fused * 45 + i2 * 15 + k])\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(15):\n                    cse_var_1: T.int32 = i0_i1_fused * 45 + i2 * 15 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[0])\n                for i3_s in range(15):\n                    cse_var_2: T.int32 = i0_i1_fused * 45 + i2 * 15 + i3_s\n                    T_softmax_norm_1 = T.Buffer((11700,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_2] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[0]) / T_softmax_expsum_1[0]", "op_args": [13, 20, 3, 15], "input_shape": "[[13, 20, 3, 15]]", "output_shape": "[[13, 20, 3, 15]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 48; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 6; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 6) + i3)] = coshf(data[((i0_i1_fused_i2_fused * 6) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 4, 6, 6), \"float32\"), compute: T.Buffer((2, 4, 6, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(48):\n            for i3 in range(6):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 6 + i3\n                compute_1 = T.Buffer((288,), data=compute.data)\n                data_1 = T.Buffer((288,), data=data.data)\n                compute_1[cse_var_1] = T.cosh(data_1[cse_var_1])", "op_args": [2, 4, 6, 6], "input_shape": "[[2, 4, 6, 6]]", "output_shape": "[[2, 4, 6, 6]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 416; ++i0_i1_fused_i2_fused) {\n    compute[i0_i1_fused_i2_fused] = coshf(data[i0_i1_fused_i2_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 4, 8, 1), \"float32\"), compute: T.Buffer((13, 4, 8, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(416):\n            compute_1 = T.Buffer((416,), data=compute.data)\n            data_1 = T.Buffer((416,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused] = T.cosh(data_1[i0_i1_fused_i2_fused])", "op_args": [13, 4, 8, 1], "input_shape": "[[13, 4, 8, 1]]", "output_shape": "[[13, 4, 8, 1]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1176; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 7, 4, 3), \"float32\"), compute: T.Buffer((14, 7, 4, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1176):\n            compute_1 = T.Buffer((1176,), data=compute.data)\n            data_1 = T.Buffer((1176,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cosh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [14, 7, 4, 3], "input_shape": "[[14, 7, 4, 3]]", "output_shape": "[[14, 7, 4, 3]]"}{"op_name": "fast_softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 90; ++i0_i1_fused) {\n    float T_softmax_maxelem[5];\n    float T_softmax_expsum[5];\n    for (int32_t i2 = 0; i2 < 5; ++i2) {\n      T_softmax_maxelem[i2] = -3.402823e+38f;\n      for (int32_t k = 0; k < 9; ++k) {\n        T_softmax_maxelem[i2] = max(T_softmax_maxelem[i2], data[(((i0_i1_fused * 45) + (i2 * 9)) + k)]);\n      }\n    }\n    for (int32_t i2_1 = 0; i2_1 < 5; ++i2_1) {\n      T_softmax_expsum[i2_1] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 9; ++k_1) {\n          int32_t v_ = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_expsum[i2_1] = (T_softmax_expsum[i2_1] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 45) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1])));\n      }\n    }\n    for (int32_t i2_2 = 0; i2_2 < 5; ++i2_2) {\n      for (int32_t i3_s = 0; i3_s < 9; ++i3_s) {\n          int32_t v__1 = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_norm[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 45) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2])) / T_softmax_expsum[i2_2]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 225) {\n    T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 9; ++k) {\n    if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 225) {\n        int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 1)) < 225) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 9; ++k) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 1)) < 225) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 36) + (((int)threadIdx.x) * 9)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 2025) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 18, 5, 9), \"float32\"), T_softmax_norm: T.Buffer((5, 18, 5, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(90):\n            T_softmax_maxelem = T.allocate([5], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([5], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((5,), data=T_softmax_maxelem, align=16)\n            data_1 = T.Buffer((4050,), data=data.data)\n            for i2 in range(5):\n                T_softmax_maxelem_1[i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(9):\n                    T_softmax_maxelem_1[i2] = T.max(T_softmax_maxelem_1[i2], data_1[i0_i1_fused * 45 + i2 * 9 + k])\n            T_softmax_expsum_1 = T.Buffer((5,), data=T_softmax_expsum, align=16)\n            for i2 in range(5):\n                T_softmax_expsum_1[i2] = T.float32(0)\n                for k in range(9):\n                    cse_var_1: T.int32 = i0_i1_fused * 45 + i2 * 9 + k\n                    T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[i2])\n            for i2, i3_s in T.grid(5, 9):\n                cse_var_2: T.int32 = i0_i1_fused * 45 + i2 * 9 + i3_s\n                T_softmax_norm_1 = T.Buffer((4050,), data=T_softmax_norm.data)\n                T_softmax_norm_1[cse_var_2] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[i2]) / T_softmax_expsum_1[i2]", "op_args": [5, 18, 5, 9], "input_shape": "[[5, 18, 5, 9]]", "output_shape": "[[5, 18, 5, 9]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1152; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 16, 12, 3), \"float32\"), compute: T.Buffer((2, 16, 12, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1152):\n            compute_1 = T.Buffer((1152,), data=compute.data)\n            data_1 = T.Buffer((1152,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cosh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [2, 16, 12, 3], "input_shape": "[[2, 16, 12, 3]]", "output_shape": "[[2, 16, 12, 3]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 243; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 243) {\n    compute[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 3, 9, 3), \"float32\"), compute: T.Buffer((3, 3, 9, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(243):\n            compute_1 = T.Buffer((243,), data=compute.data)\n            data_1 = T.Buffer((243,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cosh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [3, 3, 9, 3], "input_shape": "[[3, 3, 9, 3]]", "output_shape": "[[3, 3, 9, 3]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 6; ++i0) {\n    for (int32_t i2 = 0; i2 < 16; ++i2) {\n      for (int32_t i3 = 0; i3 < 17; ++i3) {\n        compute[(((i0 * 272) + (i2 * 17)) + i3)] = coshf(data[(((i0 * 272) + (i2 * 17)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 1, 16, 17), \"float32\"), compute: T.Buffer((6, 1, 16, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(6):\n            for i2, i3 in T.grid(16, 17):\n                cse_var_1: T.int32 = i0 * 272 + i2 * 17 + i3\n                compute_1 = T.Buffer((1632,), data=compute.data)\n                data_1 = T.Buffer((1632,), data=data.data)\n                compute_1[cse_var_1] = T.cosh(data_1[cse_var_1])", "op_args": [6, 1, 16, 17], "input_shape": "[[6, 1, 16, 17]]", "output_shape": "[[6, 1, 16, 17]]"}{"op_name": "fast_softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    float T_softmax_maxelem[13];\n    float T_softmax_expsum[1];\n    for (int32_t i1 = 0; i1 < 20; ++i1) {\n      for (int32_t i2 = 0; i2 < 13; ++i2) {\n        T_softmax_maxelem[i2] = -3.402823e+38f;\n        for (int32_t k = 0; k < 16; ++k) {\n          T_softmax_maxelem[i2] = max(T_softmax_maxelem[i2], data[((((i0 * 4160) + (i1 * 208)) + (i2 * 16)) + k)]);\n        }\n      }\n      for (int32_t i2_1 = 0; i2_1 < 13; ++i2_1) {\n        T_softmax_expsum[0] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 16; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + k_1)] - T_softmax_maxelem[i2_1])));\n        }\n        for (int32_t i3_s = 0; i3_s < 16; ++i3_s) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 4160) + (i1 * 208)) + (i2_1 * 16)) + i3_s)] - T_softmax_maxelem[i2_1])) / T_softmax_expsum[0]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))])) / T_softmax_expsum[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 16; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 64) + (((int)threadIdx.x) * 16)) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(16) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 16; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))])));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 20, 13, 16), \"float32\"), T_softmax_norm: T.Buffer((4, 20, 13, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            T_softmax_maxelem = T.allocate([13], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i1 in range(20):\n                T_softmax_maxelem_1 = T.Buffer((13,), data=T_softmax_maxelem, align=32)\n                data_1 = T.Buffer((16640,), data=data.data)\n                for i2 in range(13):\n                    T_softmax_maxelem_1[i2] = T.float32(-3.4028234663852886e+38)\n                    for k in range(16):\n                        T_softmax_maxelem_1[i2] = T.max(T_softmax_maxelem_1[i2], data_1[i0 * 4160 + i1 * 208 + i2 * 16 + k])\n                for i2 in range(13):\n                    T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                    T_softmax_expsum_1[0] = T.float32(0)\n                    for k in range(16):\n                        cse_var_1: T.int32 = i0 * 4160 + i1 * 208 + i2 * 16 + k\n                        T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[i2])\n                    for i3_s in range(16):\n                        cse_var_2: T.int32 = i0 * 4160 + i1 * 208 + i2 * 16 + i3_s\n                        T_softmax_norm_1 = T.Buffer((16640,), data=T_softmax_norm.data)\n                        T_softmax_norm_1[cse_var_2] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[i2]) / T_softmax_expsum_1[0]", "op_args": [4, 20, 13, 16], "input_shape": "[[4, 20, 13, 16]]", "output_shape": "[[4, 20, 13, 16]]"}{"op_name": "cosh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 4; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 9; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 9) + i3)] = coshf(data[((i0_i1_fused_i2_fused * 9) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((int)threadIdx.x)] = coshf(data[((int)threadIdx.x)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 1, 1, 9), \"float32\"), compute: T.Buffer((4, 1, 1, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(4):\n            for i3 in range(9):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 9 + i3\n                compute_1 = T.Buffer((36,), data=compute.data)\n                data_1 = T.Buffer((36,), data=data.data)\n                compute_1[cse_var_1] = T.cosh(data_1[cse_var_1])", "op_args": [4, 1, 1, 9], "input_shape": "[[4, 1, 1, 9]]", "output_shape": "[[4, 1, 1, 9]]"}{"op_name": "acos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1496; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = acosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(17) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 17, 1, 11), \"float32\"), compute: T.Buffer((8, 17, 1, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1496):\n            compute_1 = T.Buffer((1496,), data=compute.data)\n            data_1 = T.Buffer((1496,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.acos(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [8, 17, 1, 11], "input_shape": "[[8, 17, 1, 11]]", "output_shape": "[[8, 17, 1, 11]]"}{"op_name": "fast_softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 20; ++i0) {\n    float T_softmax_maxelem[180];\n    float T_softmax_expsum[20];\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 20; ++i2) {\n        T_softmax_maxelem[((i1 * 20) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 5; ++k) {\n          T_softmax_maxelem[((i1 * 20) + i2)] = max(T_softmax_maxelem[((i1 * 20) + i2)], data[((((i0 * 900) + (i1 * 100)) + (i2 * 5)) + k)]);\n        }\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 9; ++i1_1) {\n      for (int32_t i2_1 = 0; i2_1 < 20; ++i2_1) {\n        T_softmax_expsum[i2_1] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 5; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[i2_1] = (T_softmax_expsum[i2_1] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 900) + (i1_1 * 100)) + (i2_1 * 5)) + k_1)] - T_softmax_maxelem[((i1_1 * 20) + i2_1)])));\n        }\n      }\n      for (int32_t i2_2 = 0; i2_2 < 20; ++i2_2) {\n        for (int32_t i3_s = 0; i3_s < 5; ++i3_s) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 900) + (i1_1 * 100)) + (i2_2 * 5)) + i3_s)] - T_softmax_maxelem[((i1_1 * 20) + i2_2)])) / T_softmax_expsum[i2_2]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 5; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 10) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(16) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)])) / T_softmax_expsum[(((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 5)]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 225) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 5; ++k) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 225) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 160) + (((int)threadIdx.x) * 5)) + k)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 9, 20, 5), \"float32\"), T_softmax_norm: T.Buffer((20, 9, 20, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(20):\n            T_softmax_maxelem = T.allocate([180], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([20], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((180,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((18000,), data=data.data)\n            for i1, i2 in T.grid(9, 20):\n                T_softmax_maxelem_1[i1 * 20 + i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(5):\n                    cse_var_1: T.int32 = i1 * 20 + i2\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 900 + i1 * 100 + i2 * 5 + k])\n            for i1 in range(9):\n                T_softmax_expsum_1 = T.Buffer((20,), data=T_softmax_expsum)\n                for i2 in range(20):\n                    T_softmax_expsum_1[i2] = T.float32(0)\n                    for k in range(5):\n                        cse_var_3: T.int32 = i1 * 20 + i2\n                        cse_var_2: T.int32 = i0 * 900 + i1 * 100 + i2 * 5 + k\n                        T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3])\n                for i2, i3_s in T.grid(20, 5):\n                    cse_var_5: T.int32 = i1 * 20 + i2\n                    cse_var_4: T.int32 = i0 * 900 + i1 * 100 + i2 * 5 + i3_s\n                    T_softmax_norm_1 = T.Buffer((18000,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_4] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5]) / T_softmax_expsum_1[i2]", "op_args": [20, 9, 20, 5], "input_shape": "[[20, 9, 20, 5]]", "output_shape": "[[20, 9, 20, 5]]"}{"op_name": "acos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 19; ++i1) {\n    for (int32_t i2 = 0; i2 < 5; ++i2) {\n      for (int32_t i3 = 0; i3 < 10; ++i3) {\n        compute[(((i1 * 50) + (i2 * 10)) + i3)] = acosf(data[(((i1 * 50) + (i2 * 10)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 1)) < 475) {\n    compute[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 19, 5, 10), \"float32\"), compute: T.Buffer((1, 19, 5, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(19, 5, 10):\n            cse_var_1: T.int32 = i1 * 50 + i2 * 10 + i3\n            compute_1 = T.Buffer((950,), data=compute.data)\n            data_1 = T.Buffer((950,), data=data.data)\n            compute_1[cse_var_1] = T.acos(data_1[cse_var_1])", "op_args": [1, 19, 5, 10], "input_shape": "[[1, 19, 5, 10]]", "output_shape": "[[1, 19, 5, 10]]"}{"op_name": "acos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 60; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 14; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 14) + i3)] = acosf(data[((i0_i1_fused_i2_fused * 14) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 20, 1, 14), \"float32\"), compute: T.Buffer((3, 20, 1, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(60):\n            for i3 in range(14):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 14 + i3\n                compute_1 = T.Buffer((840,), data=compute.data)\n                data_1 = T.Buffer((840,), data=data.data)\n                compute_1[cse_var_1] = T.acos(data_1[cse_var_1])", "op_args": [3, 20, 1, 14], "input_shape": "[[3, 20, 1, 14]]", "output_shape": "[[3, 20, 1, 14]]"}{"op_name": "acos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 4; ++i1) {\n    for (int32_t i2 = 0; i2 < 8; ++i2) {\n      for (int32_t i3 = 0; i3 < 10; ++i3) {\n        compute[(((i1 * 80) + (i2 * 10)) + i3)] = acosf(data[(((i1 * 80) + (i2 * 10)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 4, 8, 10), \"float32\"), compute: T.Buffer((1, 4, 8, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(4, 8, 10):\n            cse_var_1: T.int32 = i1 * 80 + i2 * 10 + i3\n            compute_1 = T.Buffer((320,), data=compute.data)\n            data_1 = T.Buffer((320,), data=data.data)\n            compute_1[cse_var_1] = T.acos(data_1[cse_var_1])", "op_args": [1, 4, 8, 10], "input_shape": "[[1, 4, 8, 10]]", "output_shape": "[[1, 4, 8, 10]]"}{"op_name": "acos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 3960; ++i0_i1_fused_i2_fused) {\n    compute[i0_i1_fused_i2_fused] = acosf(data[i0_i1_fused_i2_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) < 495) {\n    compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 18, 11, 1), \"float32\"), compute: T.Buffer((20, 18, 11, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(3960):\n            compute_1 = T.Buffer((3960,), data=compute.data)\n            data_1 = T.Buffer((3960,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused] = T.acos(data_1[i0_i1_fused_i2_fused])", "op_args": [20, 18, 11, 1], "input_shape": "[[20, 18, 11, 1]]", "output_shape": "[[20, 18, 11, 1]]"}{"op_name": "fast_softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 28; ++i0_i1_fused) {\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i2 = 0; i2 < 10; ++i2) {\n      T_softmax_maxelem[0] = -3.402823e+38f;\n      for (int32_t k = 0; k < 17; ++k) {\n        T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[(((i0_i1_fused * 170) + (i2 * 17)) + k)]);\n      }\n      for (int32_t i3 = 0; i3 < 17; ++i3) {\n        T_softmax_expsum[0] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 17; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 170) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0])));\n        }\n          int32_t v__1 = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_norm[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 170) + (i2 * 17)) + i3)] - T_softmax_maxelem[0])) / T_softmax_expsum[0]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)])) / T_softmax_expsum[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 35) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 17; ++k) {\n    if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 35) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 544) + (((int)threadIdx.x) * 17)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(10) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 17; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 170) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))])));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 4, 10, 17), \"float32\"), T_softmax_norm: T.Buffer((7, 4, 10, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(28):\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i2 in range(10):\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((4760,), data=data.data)\n                for k in range(17):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0_i1_fused * 170 + i2 * 17 + k])\n                for i3 in range(17):\n                    cse_var_1: T.int32 = i0_i1_fused * 170 + i2 * 17 + i3\n                    T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                    T_softmax_expsum_1[0] = T.float32(0)\n                    for k in range(17):\n                        cse_var_2: T.int32 = i0_i1_fused * 170 + i2 * 17 + k\n                        T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[0])\n                    T_softmax_norm_1 = T.Buffer((4760,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[0]) / T_softmax_expsum_1[0]", "op_args": [7, 4, 10, 17], "input_shape": "[[7, 4, 10, 17]]", "output_shape": "[[7, 4, 10, 17]]"}{"op_name": "acos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i2 = 0; i2 < 18; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 16; ++i3_s) {\n          compute[((((i0 * 2304) + (i1 * 288)) + (i2 * 16)) + i3_s)] = acosf(data[((((i0 * 2304) + (i1 * 288)) + (i2 * 16)) + i3_s)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 8, 18, 16), \"float32\"), compute: T.Buffer((7, 8, 18, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i1, i2, i3_s in T.grid(8, 18, 16):\n                cse_var_1: T.int32 = i0 * 2304 + i1 * 288 + i2 * 16 + i3_s\n                compute_1 = T.Buffer((16128,), data=compute.data)\n                data_1 = T.Buffer((16128,), data=data.data)\n                compute_1[cse_var_1] = T.acos(data_1[cse_var_1])", "op_args": [7, 8, 18, 16], "input_shape": "[[7, 8, 18, 16]]", "output_shape": "[[7, 8, 18, 16]]"}{"op_name": "acos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1650; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = acosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(33) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 33) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 33) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 11, 10, 5), \"float32\"), compute: T.Buffer((3, 11, 10, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1650):\n            compute_1 = T.Buffer((1650,), data=compute.data)\n            data_1 = T.Buffer((1650,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.acos(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [3, 11, 10, 5], "input_shape": "[[3, 11, 10, 5]]", "output_shape": "[[3, 11, 10, 5]]"}{"op_name": "acos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 110; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 18; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 10; ++i3_s) {\n        compute[(((i0_i1_fused * 180) + (i2 * 10)) + i3_s)] = acosf(data[(((i0_i1_fused * 180) + (i2 * 10)) + i3_s)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 2475) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 10, 18, 10), \"float32\"), compute: T.Buffer((11, 10, 18, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(110):\n            for i2, i3_s in T.grid(18, 10):\n                cse_var_1: T.int32 = i0_i1_fused * 180 + i2 * 10 + i3_s\n                compute_1 = T.Buffer((19800,), data=compute.data)\n                data_1 = T.Buffer((19800,), data=data.data)\n                compute_1[cse_var_1] = T.acos(data_1[cse_var_1])", "op_args": [11, 10, 18, 10], "input_shape": "[[11, 10, 18, 10]]", "output_shape": "[[11, 10, 18, 10]]"}{"op_name": "fast_softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 20; ++i0) {\n    float T_softmax_maxelem[30];\n    float T_softmax_expsum[1];\n    for (int32_t i1 = 0; i1 < 15; ++i1) {\n      for (int32_t i2 = 0; i2 < 2; ++i2) {\n        T_softmax_maxelem[((i1 * 2) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 15; ++k) {\n          T_softmax_maxelem[((i1 * 2) + i2)] = max(T_softmax_maxelem[((i1 * 2) + i2)], data[((((i0 * 450) + (i1 * 30)) + (i2 * 15)) + k)]);\n        }\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 15; ++i1_1) {\n      for (int32_t i2_1 = 0; i2_1 < 2; ++i2_1) {\n        T_softmax_expsum[0] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 15; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)])));\n        }\n        for (int32_t i3_s = 0; i3_s < 15; ++i3_s) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 450) + (i1_1 * 30)) + (i2_1 * 15)) + i3_s)] - T_softmax_maxelem[((i1_1 * 2) + i2_1)])) / T_softmax_expsum[0]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(10) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 15; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 150) + (((int)threadIdx.x) * 15)) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 15; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 30) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 1125) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 15)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 15, 2, 15), \"float32\"), T_softmax_norm: T.Buffer((20, 15, 2, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(20):\n            T_softmax_maxelem = T.allocate([30], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((30,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((9000,), data=data.data)\n            for i1, i2 in T.grid(15, 2):\n                T_softmax_maxelem_1[i1 * 2 + i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(15):\n                    cse_var_1: T.int32 = i1 * 2 + i2\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 450 + i1 * 30 + i2 * 15 + k])\n            for i1, i2 in T.grid(15, 2):\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(15):\n                    cse_var_3: T.int32 = i1 * 2 + i2\n                    cse_var_2: T.int32 = i0 * 450 + i1 * 30 + i2 * 15 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3])\n                for i3_s in range(15):\n                    cse_var_5: T.int32 = i1 * 2 + i2\n                    cse_var_4: T.int32 = i0 * 450 + i1 * 30 + i2 * 15 + i3_s\n                    T_softmax_norm_1 = T.Buffer((9000,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_4] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5]) / T_softmax_expsum_1[0]", "op_args": [20, 15, 2, 15], "input_shape": "[[20, 15, 2, 15]]", "output_shape": "[[20, 15, 2, 15]]"}{"op_name": "acos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 280; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = acosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 1, 10, 2), \"float32\"), compute: T.Buffer((14, 1, 10, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(280):\n            compute_1 = T.Buffer((280,), data=compute.data)\n            data_1 = T.Buffer((280,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.acos(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [14, 1, 10, 2], "input_shape": "[[14, 1, 10, 2]]", "output_shape": "[[14, 1, 10, 2]]"}{"op_name": "acos", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1008; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 17; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 17) + i3)] = acosf(data[((i0_i1_fused_i2_fused * 17) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 7, 16, 17), \"float32\"), compute: T.Buffer((9, 7, 16, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1008):\n            for i3 in range(17):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 17 + i3\n                compute_1 = T.Buffer((17136,), data=compute.data)\n                data_1 = T.Buffer((17136,), data=data.data)\n                compute_1[cse_var_1] = T.acos(data_1[cse_var_1])", "op_args": [9, 7, 16, 17], "input_shape": "[[9, 7, 16, 17]]", "output_shape": "[[9, 7, 16, 17]]"}{"op_name": "asin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 16; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 10; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 7; ++i3_s) {\n          compute[((((i0 * 630) + (i1 * 70)) + (i2 * 7)) + i3_s)] = asinf(data[((((i0 * 630) + (i1 * 70)) + (i2 * 7)) + i3_s)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 9, 10, 7), \"float32\"), compute: T.Buffer((16, 9, 10, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(16):\n            for i1, i2, i3_s in T.grid(9, 10, 7):\n                cse_var_1: T.int32 = i0 * 630 + i1 * 70 + i2 * 7 + i3_s\n                compute_1 = T.Buffer((10080,), data=compute.data)\n                data_1 = T.Buffer((10080,), data=data.data)\n                compute_1[cse_var_1] = T.asin(data_1[cse_var_1])", "op_args": [16, 9, 10, 7], "input_shape": "[[16, 9, 10, 7]]", "output_shape": "[[16, 9, 10, 7]]"}{"op_name": "fast_softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    float T_softmax_maxelem[18];\n    float T_softmax_expsum[9];\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 9; ++i2) {\n        T_softmax_maxelem[((i1 * 9) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 10; ++k) {\n          T_softmax_maxelem[((i1 * 9) + i2)] = max(T_softmax_maxelem[((i1 * 9) + i2)], data[((((i0 * 180) + (i1 * 90)) + (i2 * 10)) + k)]);\n        }\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 2; ++i1_1) {\n      for (int32_t i2_1 = 0; i2_1 < 9; ++i2_1) {\n        T_softmax_expsum[i2_1] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 10; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[i2_1] = (T_softmax_expsum[i2_1] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 180) + (i1_1 * 90)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 9) + i2_1)])));\n        }\n      }\n      for (int32_t i2_2 = 0; i2_2 < 9; ++i2_2) {\n        for (int32_t i3_s = 0; i3_s < 10; ++i3_s) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 180) + (i1_1 * 90)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 9) + i2_2)])) / T_softmax_expsum[i2_2]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 315) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)])) / T_softmax_expsum[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]);\n  }\n}\n\nextern \"C\" __global__ void default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((int)blockIdx.x)] = -3.402823e+38f;\n  for (int k = 0; k < 10; ++k) {\n    T_softmax_maxelem[((int)blockIdx.x)] = max(T_softmax_maxelem[((int)blockIdx.x)], data[((((int)blockIdx.x) * 10) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(4) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 1)) < 63) {\n    T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 10; ++k) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 1)) < 63) {\n        int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 9, 10), \"float32\"), T_softmax_norm: T.Buffer((7, 2, 9, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            T_softmax_maxelem = T.allocate([18], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([9], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((18,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((1260,), data=data.data)\n            for i1, i2 in T.grid(2, 9):\n                T_softmax_maxelem_1[i1 * 9 + i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(10):\n                    cse_var_1: T.int32 = i1 * 9 + i2\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 180 + i1 * 90 + i2 * 10 + k])\n            for i1 in range(2):\n                T_softmax_expsum_1 = T.Buffer((9,), data=T_softmax_expsum, align=32)\n                for i2 in range(9):\n                    T_softmax_expsum_1[i2] = T.float32(0)\n                    for k in range(10):\n                        cse_var_3: T.int32 = i1 * 9 + i2\n                        cse_var_2: T.int32 = i0 * 180 + i1 * 90 + i2 * 10 + k\n                        T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3])\n                for i2, i3_s in T.grid(9, 10):\n                    cse_var_5: T.int32 = i1 * 9 + i2\n                    cse_var_4: T.int32 = i0 * 180 + i1 * 90 + i2 * 10 + i3_s\n                    T_softmax_norm_1 = T.Buffer((1260,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_4] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5]) / T_softmax_expsum_1[i2]", "op_args": [7, 2, 9, 10], "input_shape": "[[7, 2, 9, 10]]", "output_shape": "[[7, 2, 9, 10]]"}{"op_name": "asin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 324; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = asinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 1, 3, 9), \"float32\"), compute: T.Buffer((12, 1, 3, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(324):\n            compute_1 = T.Buffer((324,), data=compute.data)\n            data_1 = T.Buffer((324,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.asin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [12, 1, 3, 9], "input_shape": "[[12, 1, 3, 9]]", "output_shape": "[[12, 1, 3, 9]]"}{"op_name": "batch_to_space_nd", "c_code": "void default_function_kernel(float* T_strided_slice, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 3; ++ax0) {\n    float T_transpose[3040];\n    float T_reshape[80];\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n        for (int32_t ax1_1 = 0; ax1_1 < 2; ++ax1_1) {\n          for (int32_t ax4 = 0; ax4 < 2; ++ax4) {\n            for (int32_t ax5 = 0; ax5 < 20; ++ax5) {\n              T_reshape[(((ax1_1 * 40) + (ax4 * 20)) + ax5)] = data[((((((ax2 * 4560) + (ax1_1 * 2280)) + (ax0 * 760)) + (ax1 * 40)) + (ax4 * 20)) + ax5)];\n            }\n          }\n        }\n        for (int32_t ax3 = 0; ax3 < 2; ++ax3) {\n          for (int32_t ax4_1 = 0; ax4_1 < 2; ++ax4_1) {\n            for (int32_t ax5_1 = 0; ax5_1 < 20; ++ax5_1) {\n              T_transpose[(((((ax1 * 160) + (ax2 * 80)) + (ax3 * 40)) + (ax4_1 * 20)) + ax5_1)] = T_reshape[(((ax4_1 * 40) + (ax3 * 20)) + ax5_1)];\n            }\n          }\n        }\n      }\n    }\n    for (int32_t ax1_2 = 0; ax1_2 < 38; ++ax1_2) {\n      for (int32_t ax2_1 = 0; ax2_1 < 4; ++ax2_1) {\n        for (int32_t ax3_1 = 0; ax3_1 < 20; ++ax3_1) {\n          T_strided_slice[((((ax0 * 3040) + (ax1_2 * 80)) + (ax2_1 * 20)) + ax3_1)] = T_transpose[(((ax1_2 * 80) + (ax2_1 * 20)) + ax3_1)];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ data) {\n  T_strided_slice[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) % 20) / 10) * 4560) + (((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 2)) % 10) / 5) * 2280)) + ((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) / 20) * 40)) + (((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) % 10) / 5) * 20)) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 20))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 19, 2, 20), \"float32\"), T_strided_slice: T.Buffer((3, 38, 4, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(3):\n            T_transpose = T.allocate([3040], \"float32\", \"global\")\n            T_reshape = T.allocate([80], \"float32\", \"global\")\n            for ax1, ax2 in T.grid(19, 2):\n                T_reshape_1 = T.Buffer((80,), data=T_reshape)\n                for ax1_1, ax4, ax5 in T.grid(2, 2, 20):\n                    cse_var_1: T.int32 = ax4 * 20\n                    data_1 = T.Buffer((11400,), data=data.data)\n                    T_reshape_1[ax1_1 * 40 + cse_var_1 + ax5] = data_1[ax2 * 4560 + ax1_1 * 2280 + ax0 * 760 + ax1 * 40 + cse_var_1 + ax5]\n                for ax3, ax4, ax5 in T.grid(2, 2, 20):\n                    T_transpose_1 = T.Buffer((3040,), data=T_transpose)\n                    T_transpose_1[ax1 * 160 + ax2 * 80 + ax3 * 40 + ax4 * 20 + ax5] = T_reshape_1[ax4 * 40 + ax3 * 20 + ax5]\n            for ax1, ax2, ax3 in T.grid(38, 4, 20):\n                cse_var_3: T.int32 = ax1 * 80\n                cse_var_2: T.int32 = ax2 * 20\n                T_strided_slice_1 = T.Buffer((9120,), data=T_strided_slice.data)\n                T_transpose_1 = T.Buffer((3040,), data=T_transpose)\n                T_strided_slice_1[ax0 * 3040 + cse_var_3 + cse_var_2 + ax3] = T_transpose_1[cse_var_3 + cse_var_2 + ax3]", "op_args": [15, 19, 2, 20], "input_shape": "[[15, 19, 2, 20]]", "output_shape": "[[3, 38, 4, 20]]"}{"op_name": "asin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 240; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 16; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 7; ++i3_s) {\n        compute[(((i0_i1_fused * 112) + (i2 * 7)) + i3_s)] = asinf(data[(((i0_i1_fused * 112) + (i2 * 7)) + i3_s)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(21) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 12, 16, 7), \"float32\"), compute: T.Buffer((20, 12, 16, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(240):\n            for i2, i3_s in T.grid(16, 7):\n                cse_var_1: T.int32 = i0_i1_fused * 112 + i2 * 7 + i3_s\n                compute_1 = T.Buffer((26880,), data=compute.data)\n                data_1 = T.Buffer((26880,), data=data.data)\n                compute_1[cse_var_1] = T.asin(data_1[cse_var_1])", "op_args": [20, 12, 16, 7], "input_shape": "[[20, 12, 16, 7]]", "output_shape": "[[20, 12, 16, 7]]"}{"op_name": "batch_to_space_nd", "c_code": "void default_function_kernel(float* T_strided_slice, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 216; ++ax0_ax1_fused_ax2_fused) {\n    float T_reshape[20];\n    if (0 <= (((ax0_ax1_fused_ax2_fused % 72) >> 1) - (((ax0_ax1_fused_ax2_fused % 72) >> 2) * 2))) {\n      for (int32_t ax5 = 0; ax5 < 20; ++ax5) {\n        T_reshape[ax5] = data[((((ax0_ax1_fused_ax2_fused & 3) * 1080) + ((ax0_ax1_fused_ax2_fused >> 2) * 20)) + ax5)];\n      }\n    }\n    for (int32_t ax3 = 0; ax3 < 20; ++ax3) {\n      T_strided_slice[((ax0_ax1_fused_ax2_fused * 20) + ax3)] = T_reshape[ax3];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ data) {\n  T_strided_slice[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) & 3) * 1080) + ((((int)blockIdx.x) >> 2) * 20)) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 18, 1, 20), \"float32\"), T_strided_slice: T.Buffer((3, 36, 2, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(216):\n            T_reshape = T.allocate([20], \"float32\", \"global\")\n            cse_var_1 = T.int32()\n            if T.Let(T.likely(0 <= cse_var_1 // 2 - cse_var_1 // 4 * 2), where={cse_var_1: ax0_ax1_fused_ax2_fused % 72}):\n                T_reshape_1 = T.Buffer((20,), data=T_reshape)\n                data_1 = T.Buffer((4320,), data=data.data)\n                for ax5 in range(20):\n                    T_reshape_1[ax5] = data_1[ax0_ax1_fused_ax2_fused % 4 * 1080 + ax0_ax1_fused_ax2_fused // 4 * 20 + ax5]\n            for ax3 in range(20):\n                T_strided_slice_1 = T.Buffer((4320,), data=T_strided_slice.data)\n                T_reshape_1 = T.Buffer((20,), data=T_reshape)\n                T_strided_slice_1[ax0_ax1_fused_ax2_fused * 20 + ax3] = T_reshape_1[ax3]", "op_args": [12, 18, 1, 20], "input_shape": "[[12, 18, 1, 20]]", "output_shape": "[[3, 36, 2, 20]]"}{"op_name": "asin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 9; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 7; ++i3_s) {\n          compute[((((i0 * 847) + (i1 * 77)) + (i2 * 7)) + i3_s)] = asinf(data[((((i0 * 847) + (i1 * 77)) + (i2 * 7)) + i3_s)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 7623) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 11, 11, 7), \"float32\"), compute: T.Buffer((9, 11, 11, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(9):\n            for i1, i2, i3_s in T.grid(11, 11, 7):\n                cse_var_1: T.int32 = i0 * 847 + i1 * 77 + i2 * 7 + i3_s\n                compute_1 = T.Buffer((7623,), data=compute.data)\n                data_1 = T.Buffer((7623,), data=data.data)\n                compute_1[cse_var_1] = T.asin(data_1[cse_var_1])", "op_args": [9, 11, 11, 7], "input_shape": "[[9, 11, 11, 7]]", "output_shape": "[[9, 11, 11, 7]]"}{"op_name": "batch_to_space_nd", "c_code": "void default_function_kernel(float* T_strided_slice, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 1600; ++ax0_ax1_fused_ax2_fused) {\n    float T_reshape[18];\n    float T_reshape_1[18];\n    float T_transpose[1];\n    for (int32_t ax5 = 0; ax5 < 18; ++ax5) {\n      T_reshape[ax5] = data[(((((((ax0_ax1_fused_ax2_fused % 80) / 40) * 14400) + ((ax0_ax1_fused_ax2_fused & 1) * 7200)) + ((ax0_ax1_fused_ax2_fused / 80) * 360)) + (((ax0_ax1_fused_ax2_fused % 40) >> 1) * 18)) + ax5)];\n    }\n    for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n      T_transpose[0] = T_reshape[ax3];\n      T_reshape_1[ax3] = T_transpose[0];\n    }\n    for (int32_t ax3_1 = 0; ax3_1 < 18; ++ax3_1) {\n      T_strided_slice[((ax0_ax1_fused_ax2_fused * 18) + ax3_1)] = T_reshape_1[ax3_1];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ data) {\n  T_strided_slice[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) % 24) / 12) * 14400) + (((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) / 6)) % 6) / 3) * 7200)) + ((((int)blockIdx.x) / 24) * 360)) + (((((((int)blockIdx.x) % 12) * 5) + (((int)threadIdx.x) / 12)) / 3) * 18)) + (((((int)blockIdx.x) * 6) + ((int)threadIdx.x)) % 18))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 5, 20, 18), \"float32\"), T_strided_slice: T.Buffer((4, 10, 40, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(1600):\n            T_reshape = T.allocate([18], \"float32\", \"global\")\n            T_reshape_1 = T.allocate([18], \"float32\", \"global\")\n            T_transpose = T.allocate([1], \"float32\", \"global\")\n            T_reshape_2 = T.Buffer((18,), data=T_reshape)\n            for ax5 in range(18):\n                data_1 = T.Buffer((34200,), data=data.data)\n                T_reshape_2[ax5] = data_1[ax0_ax1_fused_ax2_fused % 80 // 40 * 14400 + ax0_ax1_fused_ax2_fused % 2 * 7200 + ax0_ax1_fused_ax2_fused // 80 * 360 + ax0_ax1_fused_ax2_fused % 40 // 2 * 18 + ax5]\n            T_reshape_3 = T.Buffer((18,), data=T_reshape_1)\n            for ax3 in range(18):\n                T_transpose_1 = T.Buffer((1,), data=T_transpose, align=4)\n                T_transpose_1[0] = T_reshape_2[ax3]\n                T_reshape_3[ax3] = T_transpose_1[0]\n            for ax3 in range(18):\n                T_strided_slice_1 = T.Buffer((28800,), data=T_strided_slice.data)\n                T_strided_slice_1[ax0_ax1_fused_ax2_fused * 18 + ax3] = T_reshape_3[ax3]", "op_args": [19, 5, 20, 18], "input_shape": "[[19, 5, 20, 18]]", "output_shape": "[[4, 10, 40, 18]]"}{"op_name": "asin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 450; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 15; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 15) + i3)] = asinf(data[((i0_i1_fused_i2_fused * 15) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 15, 3, 15), \"float32\"), compute: T.Buffer((10, 15, 3, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(450):\n            for i3 in range(15):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 15 + i3\n                compute_1 = T.Buffer((6750,), data=compute.data)\n                data_1 = T.Buffer((6750,), data=data.data)\n                compute_1[cse_var_1] = T.asin(data_1[cse_var_1])", "op_args": [10, 15, 3, 15], "input_shape": "[[10, 15, 3, 15]]", "output_shape": "[[10, 15, 3, 15]]"}{"op_name": "asin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1170; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = asinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 9, 13, 2), \"float32\"), compute: T.Buffer((5, 9, 13, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1170):\n            compute_1 = T.Buffer((1170,), data=compute.data)\n            data_1 = T.Buffer((1170,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.asin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [5, 9, 13, 2], "input_shape": "[[5, 9, 13, 2]]", "output_shape": "[[5, 9, 13, 2]]"}{"op_name": "global_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 90; ++ax0_ax1_fused) {\n    adaptive_pool_max[ax0_ax1_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 12; ++rv0) {\n      for (int32_t rv1 = 0; rv1 < 13; ++rv1) {\n        adaptive_pool_max[ax0_ax1_fused] = max(adaptive_pool_max[ax0_ax1_fused], data[(((ax0_ax1_fused * 156) + (rv0 * 13)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 12; ++rv0) {\n    for (int rv1 = 0; rv1 < 13; ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))], data[((((((int)blockIdx.x) * 936) + (((int)threadIdx.x) * 156)) + (rv0 * 13)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 9, 12, 13), \"float32\"), adaptive_pool_max: T.Buffer((10, 9, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(90):\n            adaptive_pool_max_1 = T.Buffer((90,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(12, 13):\n                data_1 = T.Buffer((14040,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused], data_1[ax0_ax1_fused * 156 + rv0 * 13 + rv1])", "op_args": [10, 9, 12, 13], "input_shape": "[[10, 9, 12, 13]]", "output_shape": "[[10, 9, 1, 1]]"}{"op_name": "asin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1428; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 11; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 11) + i3_s)] = asinf(data[((i0_i1_fused_i2_fused * 11) + i3_s)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) < 3927) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 14, 6, 11), \"float32\"), compute: T.Buffer((17, 14, 6, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1428):\n            for i3_s in range(11):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 11 + i3_s\n                compute_1 = T.Buffer((15708,), data=compute.data)\n                data_1 = T.Buffer((15708,), data=data.data)\n                compute_1[cse_var_1] = T.asin(data_1[cse_var_1])", "op_args": [17, 14, 6, 11], "input_shape": "[[17, 14, 6, 11]]", "output_shape": "[[17, 14, 6, 11]]"}{"op_name": "global_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 225; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 2; ++rv0) {\n      for (int32_t rv1 = 0; rv1 < 16; ++rv1) {\n        adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = max(adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused], data[(((ax0_ax1_fused_ax2_fused_ax3_fused * 32) + (rv0 * 16)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 225) {\n    adaptive_pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int rv0 = 0; rv0 < 2; ++rv0) {\n    for (int rv1 = 0; rv1 < 16; ++rv1) {\n      if (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 225) {\n        adaptive_pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))], data[((((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 32)) + (rv0 * 16)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 15, 2, 16), \"float32\"), adaptive_pool_max: T.Buffer((15, 15, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(225):\n            adaptive_pool_max_1 = T.Buffer((225,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(2, 16):\n                data_1 = T.Buffer((7200,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused], data_1[ax0_ax1_fused_ax2_fused_ax3_fused * 32 + rv0 * 16 + rv1])", "op_args": [15, 15, 2, 16], "input_shape": "[[15, 15, 2, 16]]", "output_shape": "[[15, 15, 1, 1]]"}{"op_name": "asin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 2850; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 11; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 11) + i3_s)] = asinf(data[((i0_i1_fused_i2_fused * 11) + i3_s)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 10, 15, 11), \"float32\"), compute: T.Buffer((19, 10, 15, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(2850):\n            for i3_s in range(11):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 11 + i3_s\n                compute_1 = T.Buffer((31350,), data=compute.data)\n                data_1 = T.Buffer((31350,), data=data.data)\n                compute_1[cse_var_1] = T.asin(data_1[cse_var_1])", "op_args": [19, 10, 15, 11], "input_shape": "[[19, 10, 15, 11]]", "output_shape": "[[19, 10, 15, 11]]"}{"op_name": "global_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 49; ++ax0_ax1_fused) {\n    adaptive_pool_max[ax0_ax1_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 18; ++rv0) {\n      for (int32_t rv1 = 0; rv1 < 6; ++rv1) {\n        adaptive_pool_max[ax0_ax1_fused] = max(adaptive_pool_max[ax0_ax1_fused], data[(((ax0_ax1_fused * 108) + (rv0 * 6)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) < 49) {\n    adaptive_pool_max[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int rv0 = 0; rv0 < 18; ++rv0) {\n    for (int rv1 = 0; rv1 < 6; ++rv1) {\n      if (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) < 49) {\n        adaptive_pool_max[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))], data[((((((int)blockIdx.x) * 432) + (((int)threadIdx.x) * 108)) + (rv0 * 6)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 7, 18, 6), \"float32\"), adaptive_pool_max: T.Buffer((7, 7, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(49):\n            adaptive_pool_max_1 = T.Buffer((49,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(18, 6):\n                data_1 = T.Buffer((5292,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused], data_1[ax0_ax1_fused * 108 + rv0 * 6 + rv1])", "op_args": [7, 7, 18, 6], "input_shape": "[[7, 7, 18, 6]]", "output_shape": "[[7, 7, 1, 1]]"}{"op_name": "asin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 11232; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = asinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 13, 8, 18), \"float32\"), compute: T.Buffer((6, 13, 8, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(11232):\n            compute_1 = T.Buffer((11232,), data=compute.data)\n            data_1 = T.Buffer((11232,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.asin(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [6, 13, 8, 18], "input_shape": "[[6, 13, 8, 18]]", "output_shape": "[[6, 13, 8, 18]]"}{"op_name": "global_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 22; ++ax0_ax1_fused) {\n    adaptive_pool_max[ax0_ax1_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 4; ++rv0) {\n      adaptive_pool_max[ax0_ax1_fused] = max(adaptive_pool_max[ax0_ax1_fused], data[((ax0_ax1_fused * 4) + rv0)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(22) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 4; ++rv0) {\n    adaptive_pool_max[((int)threadIdx.x)] = max(adaptive_pool_max[((int)threadIdx.x)], data[((((int)threadIdx.x) * 4) + rv0)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 2, 4, 1), \"float32\"), adaptive_pool_max: T.Buffer((11, 2, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(22):\n            adaptive_pool_max_1 = T.Buffer((22,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0 in range(4):\n                data_1 = T.Buffer((88,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused], data_1[ax0_ax1_fused * 4 + rv0])", "op_args": [11, 2, 4, 1], "input_shape": "[[11, 2, 4, 1]]", "output_shape": "[[11, 2, 1, 1]]"}{"op_name": "asin", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 5; ++i0) {\n    for (int32_t i1 = 0; i1 < 12; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 2; ++i3) {\n          compute[((((i0 * 72) + (i1 * 6)) + (i2 * 2)) + i3)] = asinf(data[((((i0 * 72) + (i1 * 6)) + (i2 * 2)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 45) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 12, 3, 2), \"float32\"), compute: T.Buffer((5, 12, 3, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(5):\n            for i1, i2, i3 in T.grid(12, 3, 2):\n                cse_var_1: T.int32 = i0 * 72 + i1 * 6 + i2 * 2 + i3\n                compute_1 = T.Buffer((360,), data=compute.data)\n                data_1 = T.Buffer((360,), data=data.data)\n                compute_1[cse_var_1] = T.asin(data_1[cse_var_1])", "op_args": [5, 12, 3, 2], "input_shape": "[[5, 12, 3, 2]]", "output_shape": "[[5, 12, 3, 2]]"}{"op_name": "asinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 16; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i2 = 0; i2 < 19; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 6; ++i3_s) {\n          compute[((((i0 * 912) + (i1 * 114)) + (i2 * 6)) + i3_s)] = asinhf(data[((((i0 * 912) + (i1 * 114)) + (i2 * 6)) + i3_s)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 8, 19, 6), \"float32\"), compute: T.Buffer((16, 8, 19, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(16):\n            for i1, i2, i3_s in T.grid(8, 19, 6):\n                cse_var_1: T.int32 = i0 * 912 + i1 * 114 + i2 * 6 + i3_s\n                compute_1 = T.Buffer((14592,), data=compute.data)\n                data_1 = T.Buffer((14592,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])", "op_args": [16, 8, 19, 6], "input_shape": "[[16, 8, 19, 6]]", "output_shape": "[[16, 8, 19, 6]]"}{"op_name": "global_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 220; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 8; ++rv0) {\n      for (int32_t rv1 = 0; rv1 < 8; ++rv1) {\n        adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused] = max(adaptive_pool_max[ax0_ax1_fused_ax2_fused_ax3_fused], data[(((ax0_ax1_fused_ax2_fused_ax3_fused * 64) + (rv0 * 8)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 8; ++rv0) {\n    for (int rv1 = 0; rv1 < 8; ++rv1) {\n      adaptive_pool_max[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))], data[((((((int)blockIdx.x) * 128) + (((int)threadIdx.x) * 64)) + (rv0 * 8)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 11, 8, 8), \"float32\"), adaptive_pool_max: T.Buffer((20, 11, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(220):\n            adaptive_pool_max_1 = T.Buffer((220,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(8, 8):\n                data_1 = T.Buffer((14080,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused], data_1[ax0_ax1_fused_ax2_fused_ax3_fused * 64 + rv0 * 8 + rv1])", "op_args": [20, 11, 8, 8], "input_shape": "[[20, 11, 8, 8]]", "output_shape": "[[20, 11, 1, 1]]"}{"op_name": "asinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 28; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      for (int32_t i3 = 0; i3 < 10; ++i3) {\n        compute[(((i0_i1_fused * 30) + (i2 * 10)) + i3)] = asinhf(data[(((i0_i1_fused * 30) + (i2 * 10)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 14, 3, 10), \"float32\"), compute: T.Buffer((2, 14, 3, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(28):\n            for i2, i3 in T.grid(3, 10):\n                cse_var_1: T.int32 = i0_i1_fused * 30 + i2 * 10 + i3\n                compute_1 = T.Buffer((840,), data=compute.data)\n                data_1 = T.Buffer((840,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])", "op_args": [2, 14, 3, 10], "input_shape": "[[2, 14, 3, 10]]", "output_shape": "[[2, 14, 3, 10]]"}{"op_name": "asinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 936; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 18; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 18) + i3)] = asinhf(data[((i0_i1_fused_i2_fused * 18) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(39) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 4, 13, 18), \"float32\"), compute: T.Buffer((18, 4, 13, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(936):\n            for i3 in range(18):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 18 + i3\n                compute_1 = T.Buffer((16848,), data=compute.data)\n                data_1 = T.Buffer((16848,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])", "op_args": [18, 4, 13, 18], "input_shape": "[[18, 4, 13, 18]]", "output_shape": "[[18, 4, 13, 18]]"}{"op_name": "global_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 15; ++ax0_ax1_fused_ax2_fused) {\n    adaptive_pool_max[ax0_ax1_fused_ax2_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 17; ++rv0) {\n      for (int32_t rv1 = 0; rv1 < 4; ++rv1) {\n        adaptive_pool_max[ax0_ax1_fused_ax2_fused] = max(adaptive_pool_max[ax0_ax1_fused_ax2_fused], data[(((ax0_ax1_fused_ax2_fused * 68) + (rv0 * 4)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(15) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 17; ++rv0) {\n    for (int rv1 = 0; rv1 < 4; ++rv1) {\n      adaptive_pool_max[((int)threadIdx.x)] = max(adaptive_pool_max[((int)threadIdx.x)], data[(((((int)threadIdx.x) * 68) + (rv0 * 4)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 5, 17, 4), \"float32\"), adaptive_pool_max: T.Buffer((3, 5, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(15):\n            adaptive_pool_max_1 = T.Buffer((15,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused_ax2_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(17, 4):\n                data_1 = T.Buffer((1020,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused_ax2_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused_ax2_fused], data_1[ax0_ax1_fused_ax2_fused * 68 + rv0 * 4 + rv1])", "op_args": [3, 5, 17, 4], "input_shape": "[[3, 5, 17, 4]]", "output_shape": "[[3, 5, 1, 1]]"}{"op_name": "asinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 28; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 17; ++i2) {\n      for (int32_t i3 = 0; i3 < 8; ++i3) {\n        compute[(((i0_i1_fused * 136) + (i2 * 8)) + i3)] = asinhf(data[(((i0_i1_fused * 136) + (i2 * 8)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 2, 17, 8), \"float32\"), compute: T.Buffer((14, 2, 17, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(28):\n            for i2, i3 in T.grid(17, 8):\n                cse_var_1: T.int32 = i0_i1_fused * 136 + i2 * 8 + i3\n                compute_1 = T.Buffer((3808,), data=compute.data)\n                data_1 = T.Buffer((3808,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])", "op_args": [14, 2, 17, 8], "input_shape": "[[14, 2, 17, 8]]", "output_shape": "[[14, 2, 17, 8]]"}{"op_name": "global_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n    adaptive_pool_max[ax1] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 20; ++rv0) {\n      for (int32_t rv1 = 0; rv1 < 16; ++rv1) {\n        adaptive_pool_max[ax1] = max(adaptive_pool_max[ax1], data[(((ax1 * 320) + (rv0 * 16)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(19) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 20; ++rv0) {\n    for (int rv1 = 0; rv1 < 16; ++rv1) {\n      adaptive_pool_max[((int)threadIdx.x)] = max(adaptive_pool_max[((int)threadIdx.x)], data[(((((int)threadIdx.x) * 320) + (rv0 * 16)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 19, 20, 16), \"float32\"), adaptive_pool_max: T.Buffer((1, 19, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax1 in range(19):\n            adaptive_pool_max_1 = T.Buffer((19,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax1] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(20, 16):\n                data_1 = T.Buffer((6080,), data=data.data)\n                adaptive_pool_max_1[ax1] = T.max(adaptive_pool_max_1[ax1], data_1[ax1 * 320 + rv0 * 16 + rv1])", "op_args": [1, 19, 20, 16], "input_shape": "[[1, 19, 20, 16]]", "output_shape": "[[1, 19, 1, 1]]"}{"op_name": "asinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 240; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 19; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 19) + i3)] = asinhf(data[((i0_i1_fused_i2_fused * 19) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 4, 15, 19), \"float32\"), compute: T.Buffer((4, 4, 15, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(240):\n            for i3 in range(19):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 19 + i3\n                compute_1 = T.Buffer((4560,), data=compute.data)\n                data_1 = T.Buffer((4560,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])", "op_args": [4, 4, 15, 19], "input_shape": "[[4, 4, 15, 19]]", "output_shape": "[[4, 4, 15, 19]]"}{"op_name": "asinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 240; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 15; ++i3_s) {\n        compute[(((i0_i1_fused * 210) + (i2 * 15)) + i3_s)] = asinhf(data[(((i0_i1_fused * 210) + (i2 * 15)) + i3_s)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 20, 14, 15), \"float32\"), compute: T.Buffer((12, 20, 14, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(240):\n            for i2, i3_s in T.grid(14, 15):\n                cse_var_1: T.int32 = i0_i1_fused * 210 + i2 * 15 + i3_s\n                compute_1 = T.Buffer((50400,), data=compute.data)\n                data_1 = T.Buffer((50400,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])", "op_args": [12, 20, 14, 15], "input_shape": "[[12, 20, 14, 15]]", "output_shape": "[[12, 20, 14, 15]]"}{"op_name": "global_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 10; ++ax0) {\n    adaptive_pool_max[ax0] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 6; ++rv0) {\n      for (int32_t rv1 = 0; rv1 < 18; ++rv1) {\n        adaptive_pool_max[ax0] = max(adaptive_pool_max[ax0], data[(((ax0 * 108) + (rv0 * 18)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(10) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 6; ++rv0) {\n    for (int rv1 = 0; rv1 < 18; ++rv1) {\n      adaptive_pool_max[((int)threadIdx.x)] = max(adaptive_pool_max[((int)threadIdx.x)], data[(((((int)threadIdx.x) * 108) + (rv0 * 18)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 1, 6, 18), \"float32\"), adaptive_pool_max: T.Buffer((10, 1, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(10):\n            adaptive_pool_max_1 = T.Buffer((10,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1 in T.grid(6, 18):\n                data_1 = T.Buffer((1080,), data=data.data)\n                adaptive_pool_max_1[ax0] = T.max(adaptive_pool_max_1[ax0], data_1[ax0 * 108 + rv0 * 18 + rv1])", "op_args": [10, 1, 6, 18], "input_shape": "[[10, 1, 6, 18]]", "output_shape": "[[10, 1, 1, 1]]"}{"op_name": "asinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 14; ++i0) {\n    for (int32_t i1 = 0; i1 < 13; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 12; ++i3_s) {\n          compute[((((i0 * 2184) + (i1 * 168)) + (i2 * 12)) + i3_s)] = asinhf(data[((((i0 * 2184) + (i1 * 168)) + (i2 * 12)) + i3_s)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(52) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 13, 14, 12), \"float32\"), compute: T.Buffer((14, 13, 14, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(14):\n            for i1, i2, i3_s in T.grid(13, 14, 12):\n                cse_var_1: T.int32 = i0 * 2184 + i1 * 168 + i2 * 12 + i3_s\n                compute_1 = T.Buffer((30576,), data=compute.data)\n                data_1 = T.Buffer((30576,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])", "op_args": [14, 13, 14, 12], "input_shape": "[[14, 13, 14, 12]]", "output_shape": "[[14, 13, 14, 12]]"}{"op_name": "asinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 180; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 13; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 13) + i3)] = asinhf(data[((i0_i1_fused_i2_fused * 13) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(39) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 3, 6, 13), \"float32\"), compute: T.Buffer((10, 3, 6, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(180):\n            for i3 in range(13):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 13 + i3\n                compute_1 = T.Buffer((2340,), data=compute.data)\n                data_1 = T.Buffer((2340,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])", "op_args": [10, 3, 6, 13], "input_shape": "[[10, 3, 6, 13]]", "output_shape": "[[10, 3, 6, 13]]"}{"op_name": "global_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 12; ++ax0_ax1_fused) {\n    adaptive_pool_max[ax0_ax1_fused] = -3.402823e+38f;\n    for (int32_t rv1 = 0; rv1 < 2; ++rv1) {\n      adaptive_pool_max[ax0_ax1_fused] = max(adaptive_pool_max[ax0_ax1_fused], data[((ax0_ax1_fused * 2) + rv1)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  adaptive_pool_max[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int rv1 = 0; rv1 < 2; ++rv1) {\n    adaptive_pool_max[((int)threadIdx.x)] = max(adaptive_pool_max[((int)threadIdx.x)], data[((((int)threadIdx.x) * 2) + rv1)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 3, 1, 2), \"float32\"), adaptive_pool_max: T.Buffer((4, 3, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(12):\n            adaptive_pool_max_1 = T.Buffer((12,), data=adaptive_pool_max.data)\n            adaptive_pool_max_1[ax0_ax1_fused] = T.float32(-3.4028234663852886e+38)\n            for rv1 in range(2):\n                data_1 = T.Buffer((24,), data=data.data)\n                adaptive_pool_max_1[ax0_ax1_fused] = T.max(adaptive_pool_max_1[ax0_ax1_fused], data_1[ax0_ax1_fused * 2 + rv1])", "op_args": [4, 3, 1, 2], "input_shape": "[[4, 3, 1, 2]]", "output_shape": "[[4, 3, 1, 1]]"}{"op_name": "asinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 10; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i2 = 0; i2 < 10; ++i2) {\n        for (int32_t i3 = 0; i3 < 13; ++i3) {\n          compute[((((i0 * 1040) + (i1 * 130)) + (i2 * 13)) + i3)] = asinhf(data[((((i0 * 1040) + (i1 * 130)) + (i2 * 13)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(52) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 8, 10, 13), \"float32\"), compute: T.Buffer((10, 8, 10, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(10):\n            for i1, i2, i3 in T.grid(8, 10, 13):\n                cse_var_1: T.int32 = i0 * 1040 + i1 * 130 + i2 * 13 + i3\n                compute_1 = T.Buffer((10400,), data=compute.data)\n                data_1 = T.Buffer((10400,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])", "op_args": [10, 8, 10, 13], "input_shape": "[[10, 8, 10, 13]]", "output_shape": "[[10, 8, 10, 13]]"}{"op_name": "global_pool_max", "c_code": "void default_function_kernel(float* adaptive_pool_max, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 17; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      adaptive_pool_max[((ax0 * 19) + ax1)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < 12; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 2; ++rv1) {\n          adaptive_pool_max[((ax0 * 19) + ax1)] = max(adaptive_pool_max[((ax0 * 19) + ax1)], data[((((ax0 * 456) + (ax1 * 24)) + (rv0 * 2)) + rv1)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(14) default_function_kernel(float* __restrict__ adaptive_pool_max, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 14) + ((int)threadIdx.x)) < 323) {\n    adaptive_pool_max[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int rv0 = 0; rv0 < 12; ++rv0) {\n    for (int rv1 = 0; rv1 < 2; ++rv1) {\n      if (((((int)blockIdx.x) * 14) + ((int)threadIdx.x)) < 323) {\n        adaptive_pool_max[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] = max(adaptive_pool_max[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))], data[((((((int)blockIdx.x) * 336) + (((int)threadIdx.x) * 24)) + (rv0 * 2)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 19, 12, 2), \"float32\"), adaptive_pool_max: T.Buffer((17, 19, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(17):\n            for ax1 in range(19):\n                adaptive_pool_max_1 = T.Buffer((323,), data=adaptive_pool_max.data)\n                adaptive_pool_max_1[ax0 * 19 + ax1] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(12, 2):\n                    cse_var_1: T.int32 = ax0 * 19 + ax1\n                    data_1 = T.Buffer((7752,), data=data.data)\n                    adaptive_pool_max_1[cse_var_1] = T.max(adaptive_pool_max_1[cse_var_1], data_1[ax0 * 456 + ax1 * 24 + rv0 * 2 + rv1])", "op_args": [17, 19, 12, 2], "input_shape": "[[17, 19, 12, 2]]", "output_shape": "[[17, 19, 1, 1]]"}{"op_name": "asinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 6; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 15; ++i3_s) {\n          compute[((((i0 * 1260) + (i1 * 210)) + (i2 * 15)) + i3_s)] = asinhf(data[((((i0 * 1260) + (i1 * 210)) + (i2 * 15)) + i3_s)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 12)) < 1365) {\n    compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 6, 14, 15), \"float32\"), compute: T.Buffer((13, 6, 14, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3_s in T.grid(6, 14, 15):\n                cse_var_1: T.int32 = i0 * 1260 + i1 * 210 + i2 * 15 + i3_s\n                compute_1 = T.Buffer((16380,), data=compute.data)\n                data_1 = T.Buffer((16380,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])", "op_args": [13, 6, 14, 15], "input_shape": "[[13, 6, 14, 15]]", "output_shape": "[[13, 6, 14, 15]]"}{"op_name": "global_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 10; ++ax0) {\n    float adaptive_pool_sum[1];\n    for (int32_t ax1 = 0; ax1 < 13; ++ax1) {\n      adaptive_pool_sum[0] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < 17; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n          adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[((((ax0 * 663) + (ax1 * 51)) + (rv0 * 3)) + rv1)]);\n        }\n      }\n      adaptive_pool_avg[((ax0 * 13) + ax1)] = (adaptive_pool_sum[0] * 1.960784e-02f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(5) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))] * 1.960784e-02f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 17; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 102) + (((int)threadIdx.x) * 51)) + (rv0 * 3)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 13, 17, 3), \"float32\"), adaptive_pool_avg: T.Buffer((10, 13, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(10):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            for ax1 in range(13):\n                adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n                adaptive_pool_sum_1[0] = T.float32(0)\n                for rv0, rv1 in T.grid(17, 3):\n                    data_1 = T.Buffer((6630,), data=data.data)\n                    adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0 * 663 + ax1 * 51 + rv0 * 3 + rv1]\n                adaptive_pool_avg_1 = T.Buffer((130,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 13 + ax1] = adaptive_pool_sum_1[0] * T.float32(0.019607843137254902)", "op_args": [10, 13, 17, 3], "input_shape": "[[10, 13, 17, 3]]", "output_shape": "[[10, 13, 1, 1]]"}{"op_name": "atanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 17; ++i1) {\n    for (int32_t i2 = 0; i2 < 11; ++i2) {\n      for (int32_t i3 = 0; i3 < 2; ++i3) {\n        compute[(((i1 * 22) + (i2 * 2)) + i3)] = atanhf(data[(((i1 * 22) + (i2 * 2)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 1)) < 187) {\n    compute[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 17, 11, 2), \"float32\"), compute: T.Buffer((1, 17, 11, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(17, 11, 2):\n            cse_var_1: T.int32 = i1 * 22 + i2 * 2 + i3\n            compute_1 = T.Buffer((374,), data=compute.data)\n            data_1 = T.Buffer((374,), data=data.data)\n            compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])", "op_args": [1, 17, 11, 2], "input_shape": "[[1, 17, 11, 2]]", "output_shape": "[[1, 17, 11, 2]]"}{"op_name": "global_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 12; ++ax0) {\n    float adaptive_pool_sum[1];\n    for (int32_t ax1 = 0; ax1 < 2; ++ax1) {\n      adaptive_pool_sum[0] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < 5; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 20; ++rv1) {\n          adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[((((ax0 * 200) + (ax1 * 100)) + (rv0 * 20)) + rv1)]);\n        }\n      }\n      adaptive_pool_avg[((ax0 * 2) + ax1)] = (adaptive_pool_sum[0] * 1.000000e-02f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((int)threadIdx.x)] = (adaptive_pool_sum[((int)threadIdx.x)] * 1.000000e-02f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((int)threadIdx.x)] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 5; ++rv0) {\n    for (int rv1 = 0; rv1 < 20; ++rv1) {\n      adaptive_pool_sum[((int)threadIdx.x)] = (adaptive_pool_sum[((int)threadIdx.x)] + data[(((((int)threadIdx.x) * 100) + (rv0 * 20)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 2, 5, 20), \"float32\"), adaptive_pool_avg: T.Buffer((12, 2, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(12):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            for ax1 in range(2):\n                adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n                adaptive_pool_sum_1[0] = T.float32(0)\n                for rv0, rv1 in T.grid(5, 20):\n                    data_1 = T.Buffer((2400,), data=data.data)\n                    adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0 * 200 + ax1 * 100 + rv0 * 20 + rv1]\n                adaptive_pool_avg_1 = T.Buffer((24,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 2 + ax1] = adaptive_pool_sum_1[0] * T.float32(0.01)", "op_args": [12, 2, 5, 20], "input_shape": "[[12, 2, 5, 20]]", "output_shape": "[[12, 2, 1, 1]]"}{"op_name": "atanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 272; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 18; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 6; ++i3_s) {\n        compute[(((i0_i1_fused * 108) + (i2 * 6)) + i3_s)] = atanhf(data[(((i0_i1_fused * 108) + (i2 * 6)) + i3_s)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 16, 18, 6), \"float32\"), compute: T.Buffer((17, 16, 18, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(272):\n            for i2, i3_s in T.grid(18, 6):\n                cse_var_1: T.int32 = i0_i1_fused * 108 + i2 * 6 + i3_s\n                compute_1 = T.Buffer((29376,), data=compute.data)\n                data_1 = T.Buffer((29376,), data=data.data)\n                compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])", "op_args": [17, 16, 18, 6], "input_shape": "[[17, 16, 18, 6]]", "output_shape": "[[17, 16, 18, 6]]"}{"op_name": "atanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 20; ++i1) {\n    for (int32_t i2 = 0; i2 < 5; ++i2) {\n      for (int32_t i3 = 0; i3 < 16; ++i3) {\n        compute[(((i1 * 80) + (i2 * 16)) + i3)] = atanhf(data[(((i1 * 80) + (i2 * 16)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 20, 5, 16), \"float32\"), compute: T.Buffer((1, 20, 5, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(20, 5, 16):\n            cse_var_1: T.int32 = i1 * 80 + i2 * 16 + i3\n            compute_1 = T.Buffer((1600,), data=compute.data)\n            data_1 = T.Buffer((1600,), data=data.data)\n            compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])", "op_args": [1, 20, 5, 16], "input_shape": "[[1, 20, 5, 16]]", "output_shape": "[[1, 20, 5, 16]]"}{"op_name": "global_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 34; ++ax0_ax1_fused) {\n    float adaptive_pool_sum[1];\n    adaptive_pool_sum[0] = 0.000000e+00f;\n    for (int32_t rv0 = 0; rv0 < 15; ++rv0) {\n      for (int32_t rv1 = 0; rv1 < 12; ++rv1) {\n        adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[(((ax0_ax1_fused * 180) + (rv0 * 12)) + rv1)]);\n      }\n    }\n    adaptive_pool_avg[ax0_ax1_fused] = (adaptive_pool_sum[0] * 5.555556e-03f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 17) {\n    adaptive_pool_avg[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * 5.555556e-03f);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 15; ++rv0) {\n    for (int rv1 = 0; rv1 < 12; ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 360) + (((int)threadIdx.x) * 180)) + (rv0 * 12)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 15, 12), \"float32\"), adaptive_pool_avg: T.Buffer((17, 2, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(34):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n            adaptive_pool_sum_1[0] = T.float32(0)\n            for rv0, rv1 in T.grid(15, 12):\n                data_1 = T.Buffer((6120,), data=data.data)\n                adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0_ax1_fused * 180 + rv0 * 12 + rv1]\n            adaptive_pool_avg_1 = T.Buffer((34,), data=adaptive_pool_avg.data)\n            adaptive_pool_avg_1[ax0_ax1_fused] = adaptive_pool_sum_1[0] * T.float32(0.0055555555555555558)", "op_args": [17, 2, 15, 12], "input_shape": "[[17, 2, 15, 12]]", "output_shape": "[[17, 2, 1, 1]]"}{"op_name": "atanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 136; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 13; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 13) + i3)] = atanhf(data[((i0_i1_fused_i2_fused * 13) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(13) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 17, 1, 13), \"float32\"), compute: T.Buffer((8, 17, 1, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(136):\n            for i3 in range(13):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 13 + i3\n                compute_1 = T.Buffer((1768,), data=compute.data)\n                data_1 = T.Buffer((1768,), data=data.data)\n                compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])", "op_args": [8, 17, 1, 13], "input_shape": "[[8, 17, 1, 13]]", "output_shape": "[[8, 17, 1, 13]]"}{"op_name": "global_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 38; ++ax0_ax1_fused_ax2_fused) {\n    float adaptive_pool_sum[1];\n    adaptive_pool_sum[0] = 0.000000e+00f;\n    for (int32_t rv0 = 0; rv0 < 4; ++rv0) {\n      for (int32_t rv1 = 0; rv1 < 2; ++rv1) {\n        adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[(((ax0_ax1_fused_ax2_fused * 8) + (rv0 * 2)) + rv1)]);\n      }\n    }\n    adaptive_pool_avg[ax0_ax1_fused_ax2_fused] = (adaptive_pool_sum[0] * 1.250000e-01f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  if (((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 1)) < 19) {\n    adaptive_pool_avg[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] * 1.250000e-01f);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 19) {\n    adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int rv0 = 0; rv0 < 4; ++rv0) {\n    for (int rv1 = 0; rv1 < 2; ++rv1) {\n      if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 19) {\n        adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 8)) + (rv0 * 2)) + rv1)]);\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 19, 4, 2), \"float32\"), adaptive_pool_avg: T.Buffer((2, 19, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(38):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n            adaptive_pool_sum_1[0] = T.float32(0)\n            for rv0, rv1 in T.grid(4, 2):\n                data_1 = T.Buffer((304,), data=data.data)\n                adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0_ax1_fused_ax2_fused * 8 + rv0 * 2 + rv1]\n            adaptive_pool_avg_1 = T.Buffer((38,), data=adaptive_pool_avg.data)\n            adaptive_pool_avg_1[ax0_ax1_fused_ax2_fused] = adaptive_pool_sum_1[0] * T.float32(0.125)", "op_args": [2, 19, 4, 2], "input_shape": "[[2, 19, 4, 2]]", "output_shape": "[[2, 19, 1, 1]]"}{"op_name": "atanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 4352; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 10; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 10) + i3_s)] = atanhf(data[((i0_i1_fused_i2_fused * 10) + i3_s)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 16, 17, 10), \"float32\"), compute: T.Buffer((16, 16, 17, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(4352):\n            for i3_s in range(10):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 10 + i3_s\n                compute_1 = T.Buffer((43520,), data=compute.data)\n                data_1 = T.Buffer((43520,), data=data.data)\n                compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])", "op_args": [16, 16, 17, 10], "input_shape": "[[16, 16, 17, 10]]", "output_shape": "[[16, 16, 17, 10]]"}{"op_name": "global_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 2; ++ax0) {\n    float adaptive_pool_sum[1];\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      adaptive_pool_sum[0] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < 9; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 19; ++rv1) {\n          adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[((((ax0 * 1710) + (ax1 * 171)) + (rv0 * 19)) + rv1)]);\n        }\n      }\n      adaptive_pool_avg[((ax0 * 10) + ax1)] = (adaptive_pool_sum[0] * 5.847953e-03f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((int)threadIdx.x)] = (adaptive_pool_sum[((int)threadIdx.x)] * 5.847953e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((int)threadIdx.x)] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 9; ++rv0) {\n    for (int rv1 = 0; rv1 < 19; ++rv1) {\n      adaptive_pool_sum[((int)threadIdx.x)] = (adaptive_pool_sum[((int)threadIdx.x)] + data[(((((int)threadIdx.x) * 171) + (rv0 * 19)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 10, 9, 19), \"float32\"), adaptive_pool_avg: T.Buffer((2, 10, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(2):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            for ax1 in range(10):\n                adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n                adaptive_pool_sum_1[0] = T.float32(0)\n                for rv0, rv1 in T.grid(9, 19):\n                    data_1 = T.Buffer((3420,), data=data.data)\n                    adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0 * 1710 + ax1 * 171 + rv0 * 19 + rv1]\n                adaptive_pool_avg_1 = T.Buffer((20,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 10 + ax1] = adaptive_pool_sum_1[0] * T.float32(0.0058479532163742687)", "op_args": [2, 10, 9, 19], "input_shape": "[[2, 10, 9, 19]]", "output_shape": "[[2, 10, 1, 1]]"}{"op_name": "atanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 64; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 8; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 8) + i3)] = atanhf(data[((i0_i1_fused_i2_fused * 8) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 2, 4, 8), \"float32\"), compute: T.Buffer((8, 2, 4, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(64):\n            for i3 in range(8):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 8 + i3\n                compute_1 = T.Buffer((512,), data=compute.data)\n                data_1 = T.Buffer((512,), data=data.data)\n                compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])", "op_args": [8, 2, 4, 8], "input_shape": "[[8, 2, 4, 8]]", "output_shape": "[[8, 2, 4, 8]]"}{"op_name": "global_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 7; ++ax0) {\n    float adaptive_pool_sum[2];\n    for (int32_t ax1 = 0; ax1 < 2; ++ax1) {\n      adaptive_pool_sum[ax1] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < 20; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 12; ++rv1) {\n          adaptive_pool_sum[ax1] = (adaptive_pool_sum[ax1] + data[((((ax0 * 480) + (ax1 * 240)) + (rv0 * 12)) + rv1)]);\n        }\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 2; ++ax1_1) {\n      adaptive_pool_avg[((ax0 * 2) + ax1_1)] = (adaptive_pool_sum[ax1_1] * 4.166667e-03f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(14) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((int)threadIdx.x)] = (adaptive_pool_sum[((int)threadIdx.x)] * 4.166667e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(14) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((int)threadIdx.x)] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 20; ++rv0) {\n    for (int rv1 = 0; rv1 < 12; ++rv1) {\n      adaptive_pool_sum[((int)threadIdx.x)] = (adaptive_pool_sum[((int)threadIdx.x)] + data[(((((int)threadIdx.x) * 240) + (rv0 * 12)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 20, 12), \"float32\"), adaptive_pool_avg: T.Buffer((7, 2, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(7):\n            adaptive_pool_sum = T.allocate([2], \"float32\", \"global\")\n            adaptive_pool_sum_1 = T.Buffer((2,), data=adaptive_pool_sum, align=8)\n            for ax1 in range(2):\n                adaptive_pool_sum_1[ax1] = T.float32(0)\n                for rv0, rv1 in T.grid(20, 12):\n                    data_1 = T.Buffer((3360,), data=data.data)\n                    adaptive_pool_sum_1[ax1] = adaptive_pool_sum_1[ax1] + data_1[ax0 * 480 + ax1 * 240 + rv0 * 12 + rv1]\n            for ax1 in range(2):\n                adaptive_pool_avg_1 = T.Buffer((14,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 2 + ax1] = adaptive_pool_sum_1[ax1] * T.float32(0.0041666666666666666)", "op_args": [7, 2, 20, 12], "input_shape": "[[7, 2, 20, 12]]", "output_shape": "[[7, 2, 1, 1]]"}{"op_name": "atanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 57024; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = atanhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 16, 18, 18), \"float32\"), compute: T.Buffer((11, 16, 18, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(57024):\n            compute_1 = T.Buffer((57024,), data=compute.data)\n            data_1 = T.Buffer((57024,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.atanh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [11, 16, 18, 18], "input_shape": "[[11, 16, 18, 18]]", "output_shape": "[[11, 16, 18, 18]]"}{"op_name": "global_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 5; ++ax0) {\n    float adaptive_pool_sum[1];\n    for (int32_t ax1 = 0; ax1 < 8; ++ax1) {\n      adaptive_pool_sum[0] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < 15; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 15; ++rv1) {\n          adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[((((ax0 * 1800) + (ax1 * 225)) + (rv0 * 15)) + rv1)]);\n        }\n      }\n      adaptive_pool_avg[((ax0 * 8) + ax1)] = (adaptive_pool_sum[0] * 4.444444e-03f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] * 4.444444e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 15; ++rv0) {\n    for (int rv1 = 0; rv1 < 15; ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 4500) + (((int)threadIdx.x) * 225)) + (rv0 * 15)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 8, 15, 15), \"float32\"), adaptive_pool_avg: T.Buffer((5, 8, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(5):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            for ax1 in range(8):\n                adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n                adaptive_pool_sum_1[0] = T.float32(0)\n                for rv0, rv1 in T.grid(15, 15):\n                    data_1 = T.Buffer((9000,), data=data.data)\n                    adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0 * 1800 + ax1 * 225 + rv0 * 15 + rv1]\n                adaptive_pool_avg_1 = T.Buffer((40,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 8 + ax1] = adaptive_pool_sum_1[0] * T.float32(0.0044444444444444444)", "op_args": [5, 8, 15, 15], "input_shape": "[[5, 8, 15, 15]]", "output_shape": "[[5, 8, 1, 1]]"}{"op_name": "atanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 2880; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 8; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 8) + i3_s)] = atanhf(data[((i0_i1_fused_i2_fused * 8) + i3_s)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 16, 12, 8), \"float32\"), compute: T.Buffer((15, 16, 12, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(2880):\n            for i3_s in range(8):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 8 + i3_s\n                compute_1 = T.Buffer((23040,), data=compute.data)\n                data_1 = T.Buffer((23040,), data=data.data)\n                compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])", "op_args": [15, 16, 12, 8], "input_shape": "[[15, 16, 12, 8]]", "output_shape": "[[15, 16, 12, 8]]"}{"op_name": "global_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 18; ++ax0) {\n    float adaptive_pool_sum[19];\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      adaptive_pool_sum[ax1] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 9; ++rv1) {\n          adaptive_pool_sum[ax1] = (adaptive_pool_sum[ax1] + data[((((ax0 * 513) + (ax1 * 27)) + (rv0 * 9)) + rv1)]);\n        }\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 19; ++ax1_1) {\n      adaptive_pool_avg[((ax0 * 19) + ax1_1)] = (adaptive_pool_sum[ax1_1] * 3.703704e-02f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 1)) < 171) {\n    adaptive_pool_avg[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] * 3.703704e-02f);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 9; ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 54) + (((int)threadIdx.x) * 27)) + (rv0 * 9)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 19, 3, 9), \"float32\"), adaptive_pool_avg: T.Buffer((18, 19, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(18):\n            adaptive_pool_sum = T.allocate([19], \"float32\", \"global\")\n            adaptive_pool_sum_1 = T.Buffer((19,), data=adaptive_pool_sum)\n            for ax1 in range(19):\n                adaptive_pool_sum_1[ax1] = T.float32(0)\n                for rv0, rv1 in T.grid(3, 9):\n                    data_1 = T.Buffer((9234,), data=data.data)\n                    adaptive_pool_sum_1[ax1] = adaptive_pool_sum_1[ax1] + data_1[ax0 * 513 + ax1 * 27 + rv0 * 9 + rv1]\n            for ax1 in range(19):\n                adaptive_pool_avg_1 = T.Buffer((342,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 19 + ax1] = adaptive_pool_sum_1[ax1] * T.float32(0.037037037037037035)", "op_args": [18, 19, 3, 9], "input_shape": "[[18, 19, 3, 9]]", "output_shape": "[[18, 19, 1, 1]]"}{"op_name": "atanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 11; ++i3) {\n          compute[((((i0 * 297) + (i1 * 33)) + (i2 * 11)) + i3)] = atanhf(data[((((i0 * 297) + (i1 * 33)) + (i2 * 11)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(33) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 33) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 33) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 9, 3, 11), \"float32\"), compute: T.Buffer((18, 9, 3, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(18):\n            for i1, i2, i3 in T.grid(9, 3, 11):\n                cse_var_1: T.int32 = i0 * 297 + i1 * 33 + i2 * 11 + i3\n                compute_1 = T.Buffer((5346,), data=compute.data)\n                data_1 = T.Buffer((5346,), data=data.data)\n                compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])", "op_args": [18, 9, 3, 11], "input_shape": "[[18, 9, 3, 11]]", "output_shape": "[[18, 9, 3, 11]]"}{"op_name": "global_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 48; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    float adaptive_pool_sum[1];\n    adaptive_pool_sum[0] = 0.000000e+00f;\n    for (int32_t rv0 = 0; rv0 < 14; ++rv0) {\n      for (int32_t rv1 = 0; rv1 < 10; ++rv1) {\n        adaptive_pool_sum[0] = (adaptive_pool_sum[0] + data[(((ax0_ax1_fused_ax2_fused_ax3_fused * 140) + (rv0 * 10)) + rv1)]);\n      }\n    }\n    adaptive_pool_avg[ax0_ax1_fused_ax2_fused_ax3_fused] = (adaptive_pool_sum[0] * 7.142857e-03f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] * 7.142857e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 14; ++rv0) {\n    for (int rv1 = 0; rv1 < 10; ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 1680) + (((int)threadIdx.x) * 140)) + (rv0 * 10)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 6, 14, 10), \"float32\"), adaptive_pool_avg: T.Buffer((8, 6, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(48):\n            adaptive_pool_sum = T.allocate([1], \"float32\", \"global\")\n            adaptive_pool_sum_1 = T.Buffer((1,), data=adaptive_pool_sum, align=4)\n            adaptive_pool_sum_1[0] = T.float32(0)\n            for rv0, rv1 in T.grid(14, 10):\n                data_1 = T.Buffer((6720,), data=data.data)\n                adaptive_pool_sum_1[0] = adaptive_pool_sum_1[0] + data_1[ax0_ax1_fused_ax2_fused_ax3_fused * 140 + rv0 * 10 + rv1]\n            adaptive_pool_avg_1 = T.Buffer((48,), data=adaptive_pool_avg.data)\n            adaptive_pool_avg_1[ax0_ax1_fused_ax2_fused_ax3_fused] = adaptive_pool_sum_1[0] * T.float32(0.0071428571428571426)", "op_args": [8, 6, 14, 10], "input_shape": "[[8, 6, 14, 10]]", "output_shape": "[[8, 6, 1, 1]]"}{"op_name": "global_pool_avg", "c_code": "void default_function_kernel(float* adaptive_pool_avg, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 7; ++ax0) {\n    float adaptive_pool_sum[8];\n    for (int32_t ax1 = 0; ax1 < 8; ++ax1) {\n      adaptive_pool_sum[ax1] = 0.000000e+00f;\n      for (int32_t rv0 = 0; rv0 < 10; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 11; ++rv1) {\n          adaptive_pool_sum[ax1] = (adaptive_pool_sum[ax1] + data[((((ax0 * 880) + (ax1 * 110)) + (rv0 * 11)) + rv1)]);\n        }\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 8; ++ax1_1) {\n      adaptive_pool_avg[((ax0 * 8) + ax1_1)] = (adaptive_pool_sum[ax1_1] * 9.090909e-03f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ adaptive_pool_avg, float* __restrict__ adaptive_pool_sum) {\n  adaptive_pool_avg[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] * 9.090909e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ adaptive_pool_sum, float* __restrict__ data) {\n  adaptive_pool_sum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int rv0 = 0; rv0 < 10; ++rv0) {\n    for (int rv1 = 0; rv1 < 11; ++rv1) {\n      adaptive_pool_sum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (adaptive_pool_sum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] + data[((((((int)blockIdx.x) * 440) + (((int)threadIdx.x) * 110)) + (rv0 * 11)) + rv1)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 8, 10, 11), \"float32\"), adaptive_pool_avg: T.Buffer((7, 8, 1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(7):\n            adaptive_pool_sum = T.allocate([8], \"float32\", \"global\")\n            adaptive_pool_sum_1 = T.Buffer((8,), data=adaptive_pool_sum, align=32)\n            for ax1 in range(8):\n                adaptive_pool_sum_1[ax1] = T.float32(0)\n                for rv0, rv1 in T.grid(10, 11):\n                    data_1 = T.Buffer((6160,), data=data.data)\n                    adaptive_pool_sum_1[ax1] = adaptive_pool_sum_1[ax1] + data_1[ax0 * 880 + ax1 * 110 + rv0 * 11 + rv1]\n            for ax1 in range(8):\n                adaptive_pool_avg_1 = T.Buffer((56,), data=adaptive_pool_avg.data)\n                adaptive_pool_avg_1[ax0 * 8 + ax1] = adaptive_pool_sum_1[ax1] * T.float32(0.0090909090909090905)", "op_args": [7, 8, 10, 11], "input_shape": "[[7, 8, 10, 11]]", "output_shape": "[[7, 8, 1, 1]]"}{"op_name": "atanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 15300; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = atanhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 9, 20, 17), \"float32\"), compute: T.Buffer((5, 9, 20, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(15300):\n            compute_1 = T.Buffer((15300,), data=compute.data)\n            data_1 = T.Buffer((15300,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.atanh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [5, 9, 20, 17], "input_shape": "[[5, 9, 20, 17]]", "output_shape": "[[5, 9, 20, 17]]"}{"op_name": "dilate", "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 4032; ++i0_i1_fused_i2_fused_i3_fused) {\n    DilatedInput[i0_i1_fused_i2_fused_i3_fused] = data[i0_i1_fused_i2_fused_i3_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 8, 14, 12), \"float32\"), DilatedInput: T.Buffer((3, 8, 14, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(4032):\n            DilatedInput_1 = T.Buffer((4032,), data=DilatedInput.data)\n            data_1 = T.Buffer((4032,), data=data.data)\n            DilatedInput_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused]", "op_args": [3, 8, 14, 12], "input_shape": "[[3, 8, 14, 12]]", "output_shape": "[[3, 8, 14, 12]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 88; ++i0_i1_fused) {\n    for (int32_t i3 = 0; i3 < 17; ++i3) {\n      compute[((i0_i1_fused * 17) + i3)] = ceilf(data[((i0_i1_fused * 17) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 187) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 11, 1, 17), \"float32\"), compute: T.Buffer((8, 11, 1, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(88):\n            for i3 in range(17):\n                cse_var_1: T.int32 = i0_i1_fused * 17 + i3\n                compute_1 = T.Buffer((1496,), data=compute.data)\n                data_1 = T.Buffer((1496,), data=data.data)\n                compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])", "op_args": [8, 11, 1, 17], "input_shape": "[[8, 11, 1, 17]]", "output_shape": "[[8, 11, 1, 17]]"}{"op_name": "dilate", "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 360; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 4; ++i3) {\n      DilatedInput[((i0_i1_fused_i2_fused * 4) + i3)] = data[((i0_i1_fused_i2_fused * 4) + i3)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 4, 9, 4), \"float32\"), DilatedInput: T.Buffer((10, 4, 9, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(360):\n            for i3 in range(4):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 4 + i3\n                DilatedInput_1 = T.Buffer((1440,), data=DilatedInput.data)\n                data_1 = T.Buffer((1440,), data=data.data)\n                DilatedInput_1[cse_var_1] = data_1[cse_var_1]", "op_args": [10, 4, 9, 4], "input_shape": "[[10, 4, 9, 4]]", "output_shape": "[[10, 4, 9, 4]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 28050; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ceilf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 15, 10, 17), \"float32\"), compute: T.Buffer((11, 15, 10, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(28050):\n            compute_1 = T.Buffer((28050,), data=compute.data)\n            data_1 = T.Buffer((28050,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.ceil(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [11, 15, 10, 17], "input_shape": "[[11, 15, 10, 17]]", "output_shape": "[[11, 15, 10, 17]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 13; ++i1) {\n    for (int32_t i2 = 0; i2 < 10; ++i2) {\n      for (int32_t i3 = 0; i3 < 17; ++i3) {\n        compute[(((i1 * 170) + (i2 * 17)) + i3)] = ceilf(data[(((i1 * 170) + (i2 * 17)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 13, 10, 17), \"float32\"), compute: T.Buffer((1, 13, 10, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(13, 10, 17):\n            cse_var_1: T.int32 = i1 * 170 + i2 * 17 + i3\n            compute_1 = T.Buffer((2210,), data=compute.data)\n            data_1 = T.Buffer((2210,), data=data.data)\n            compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])", "op_args": [1, 13, 10, 17], "input_shape": "[[1, 13, 10, 17]]", "output_shape": "[[1, 13, 10, 17]]"}{"op_name": "dilate", "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 6; ++i0) {\n    for (int32_t i1 = 0; i1 < 13; ++i1) {\n      for (int32_t i2 = 0; i2 < 7; ++i2) {\n        for (int32_t i3 = 0; i3 < 9; ++i3) {\n          DilatedInput[((((i0 * 819) + (i1 * 63)) + (i2 * 9)) + i3)] = data[((((i0 * 819) + (i1 * 63)) + (i2 * 9)) + i3)];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(21) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 13, 7, 9), \"float32\"), DilatedInput: T.Buffer((6, 13, 7, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(6):\n            for i1, i2, i3 in T.grid(13, 7, 9):\n                cse_var_1: T.int32 = i0 * 819 + i1 * 63 + i2 * 9 + i3\n                DilatedInput_1 = T.Buffer((4914,), data=DilatedInput.data)\n                data_1 = T.Buffer((4914,), data=data.data)\n                DilatedInput_1[cse_var_1] = data_1[cse_var_1]", "op_args": [6, 13, 7, 9], "input_shape": "[[6, 13, 7, 9]]", "output_shape": "[[6, 13, 7, 9]]"}{"op_name": "dilate", "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3264; ++i0_i1_fused_i2_fused_i3_fused) {\n    DilatedInput[i0_i1_fused_i2_fused_i3_fused] = data[i0_i1_fused_i2_fused_i3_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 2, 6, 17), \"float32\"), DilatedInput: T.Buffer((16, 2, 6, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3264):\n            DilatedInput_1 = T.Buffer((3264,), data=DilatedInput.data)\n            data_1 = T.Buffer((3264,), data=data.data)\n            DilatedInput_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused]", "op_args": [16, 2, 6, 17], "input_shape": "[[16, 2, 6, 17]]", "output_shape": "[[16, 2, 6, 17]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 480; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 13; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 13) + i3)] = ceilf(data[((i0_i1_fused_i2_fused * 13) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(39) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 8, 12, 13), \"float32\"), compute: T.Buffer((5, 8, 12, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(480):\n            for i3 in range(13):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 13 + i3\n                compute_1 = T.Buffer((6240,), data=compute.data)\n                data_1 = T.Buffer((6240,), data=data.data)\n                compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])", "op_args": [5, 8, 12, 13], "input_shape": "[[5, 8, 12, 13]]", "output_shape": "[[5, 8, 12, 13]]"}{"op_name": "dilate", "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5040; ++i0_i1_fused_i2_fused_i3_fused) {\n    DilatedInput[i0_i1_fused_i2_fused_i3_fused] = data[i0_i1_fused_i2_fused_i3_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 4, 7, 18), \"float32\"), DilatedInput: T.Buffer((10, 4, 7, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(5040):\n            DilatedInput_1 = T.Buffer((5040,), data=DilatedInput.data)\n            data_1 = T.Buffer((5040,), data=data.data)\n            DilatedInput_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused]", "op_args": [10, 4, 7, 18], "input_shape": "[[10, 4, 7, 18]]", "output_shape": "[[10, 4, 7, 18]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 6120; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ceilf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 10, 3, 17), \"float32\"), compute: T.Buffer((12, 10, 3, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(6120):\n            compute_1 = T.Buffer((6120,), data=compute.data)\n            data_1 = T.Buffer((6120,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.ceil(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [12, 10, 3, 17], "input_shape": "[[12, 10, 3, 17]]", "output_shape": "[[12, 10, 3, 17]]"}{"op_name": "dilate", "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 8640; ++i0_i1_fused_i2_fused_i3_fused) {\n    DilatedInput[i0_i1_fused_i2_fused_i3_fused] = data[i0_i1_fused_i2_fused_i3_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 18, 8, 15), \"float32\"), DilatedInput: T.Buffer((4, 18, 8, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(8640):\n            DilatedInput_1 = T.Buffer((8640,), data=DilatedInput.data)\n            data_1 = T.Buffer((8640,), data=data.data)\n            DilatedInput_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused]", "op_args": [4, 18, 8, 15], "input_shape": "[[4, 18, 8, 15]]", "output_shape": "[[4, 18, 8, 15]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 60; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 5; ++i2) {\n      for (int32_t i3 = 0; i3 < 9; ++i3) {\n        compute[(((i0_i1_fused * 45) + (i2 * 9)) + i3)] = ceilf(data[(((i0_i1_fused * 45) + (i2 * 9)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(25) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 25) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 25) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 10, 5, 9), \"float32\"), compute: T.Buffer((6, 10, 5, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(60):\n            for i2, i3 in T.grid(5, 9):\n                cse_var_1: T.int32 = i0_i1_fused * 45 + i2 * 9 + i3\n                compute_1 = T.Buffer((2700,), data=compute.data)\n                data_1 = T.Buffer((2700,), data=data.data)\n                compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])", "op_args": [6, 10, 5, 9], "input_shape": "[[6, 10, 5, 9]]", "output_shape": "[[6, 10, 5, 9]]"}{"op_name": "dilate", "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2464; ++i0_i1_fused_i2_fused_i3_fused) {\n    DilatedInput[i0_i1_fused_i2_fused_i3_fused] = data[i0_i1_fused_i2_fused_i3_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 11, 16, 7), \"float32\"), DilatedInput: T.Buffer((2, 11, 16, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2464):\n            DilatedInput_1 = T.Buffer((2464,), data=DilatedInput.data)\n            data_1 = T.Buffer((2464,), data=data.data)\n            DilatedInput_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused]", "op_args": [2, 11, 16, 7], "input_shape": "[[2, 11, 16, 7]]", "output_shape": "[[2, 11, 16, 7]]"}{"op_name": "dilate", "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 36; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 13; ++i2) {\n      for (int32_t i3 = 0; i3 < 2; ++i3) {\n        DilatedInput[(((i0_i1_fused * 26) + (i2 * 2)) + i3)] = data[(((i0_i1_fused * 26) + (i2 * 2)) + i3)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 117) {\n    DilatedInput[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 4, 13, 2), \"float32\"), DilatedInput: T.Buffer((9, 4, 13, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(36):\n            for i2, i3 in T.grid(13, 2):\n                cse_var_1: T.int32 = i0_i1_fused * 26 + i2 * 2 + i3\n                DilatedInput_1 = T.Buffer((936,), data=DilatedInput.data)\n                data_1 = T.Buffer((936,), data=data.data)\n                DilatedInput_1[cse_var_1] = data_1[cse_var_1]", "op_args": [9, 4, 13, 2], "input_shape": "[[9, 4, 13, 2]]", "output_shape": "[[9, 4, 13, 2]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 64; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ceilf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 1, 2, 4), \"float32\"), compute: T.Buffer((8, 1, 2, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(64):\n            compute_1 = T.Buffer((64,), data=compute.data)\n            data_1 = T.Buffer((64,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.ceil(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [8, 1, 2, 4], "input_shape": "[[8, 1, 2, 4]]", "output_shape": "[[8, 1, 2, 4]]"}{"op_name": "dilate", "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 100800; ++i0_i1_fused_i2_fused_i3_fused) {\n    DilatedInput[i0_i1_fused_i2_fused_i3_fused] = data[i0_i1_fused_i2_fused_i3_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 14, 20, 20), \"float32\"), DilatedInput: T.Buffer((18, 14, 20, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(100800):\n            DilatedInput_1 = T.Buffer((100800,), data=DilatedInput.data)\n            data_1 = T.Buffer((100800,), data=data.data)\n            DilatedInput_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused]", "op_args": [18, 14, 20, 20], "input_shape": "[[18, 14, 20, 20]]", "output_shape": "[[18, 14, 20, 20]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 24; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 2; ++i3) {\n        compute[(((i0_i1_fused * 28) + (i2 * 2)) + i3)] = ceilf(data[(((i0_i1_fused * 28) + (i2 * 2)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(14) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 6, 14, 2), \"float32\"), compute: T.Buffer((4, 6, 14, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(24):\n            for i2, i3 in T.grid(14, 2):\n                cse_var_1: T.int32 = i0_i1_fused * 28 + i2 * 2 + i3\n                compute_1 = T.Buffer((672,), data=compute.data)\n                data_1 = T.Buffer((672,), data=data.data)\n                compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])", "op_args": [4, 6, 14, 2], "input_shape": "[[4, 6, 14, 2]]", "output_shape": "[[4, 6, 14, 2]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 76; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 20; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 20) + i3)] = ceilf(data[((i0_i1_fused_i2_fused * 20) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 19, 2, 20), \"float32\"), compute: T.Buffer((2, 19, 2, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(76):\n            for i3 in range(20):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 20 + i3\n                compute_1 = T.Buffer((1520,), data=compute.data)\n                data_1 = T.Buffer((1520,), data=data.data)\n                compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])", "op_args": [2, 19, 2, 20], "input_shape": "[[2, 19, 2, 20]]", "output_shape": "[[2, 19, 2, 20]]"}{"op_name": "dilate", "c_code": "void default_function_kernel(float* DilatedInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 4560; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 19; ++i3) {\n      DilatedInput[((i0_i1_fused_i2_fused * 19) + i3)] = data[((i0_i1_fused_i2_fused * 19) + i3)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ DilatedInput, float* __restrict__ data) {\n  DilatedInput[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 16, 15, 19), \"float32\"), DilatedInput: T.Buffer((19, 16, 15, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(4560):\n            for i3 in range(19):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 19 + i3\n                DilatedInput_1 = T.Buffer((86640,), data=DilatedInput.data)\n                data_1 = T.Buffer((86640,), data=data.data)\n                DilatedInput_1[cse_var_1] = data_1[cse_var_1]", "op_args": [19, 16, 15, 19], "input_shape": "[[19, 16, 15, 19]]", "output_shape": "[[19, 16, 15, 19]]"}{"op_name": "flatten", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 8; ++i) {\n    for (int32_t j = 0; j < 238; ++j) {\n      compute[((i * 238) + j)] = data[((i * 238) + j)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 119) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 17, 1, 14), \"float32\"), compute: T.Buffer((8, 238), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(8):\n            for j in range(238):\n                cse_var_1: T.int32 = i * 238 + j\n                compute_1 = T.Buffer((1904,), data=compute.data)\n                data_1 = T.Buffer((1904,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1]", "op_args": [8, 17, 1, 14], "input_shape": "[[8, 17, 1, 14]]", "output_shape": "[[8, 238]]"}{"op_name": "flatten", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 6; ++i) {\n    for (int32_t j = 0; j < 4788; ++j) {\n      compute[((i * 4788) + j)] = data[((i * 4788) + j)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 19, 14, 18), \"float32\"), compute: T.Buffer((6, 4788), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(6):\n            for j in range(4788):\n                cse_var_1: T.int32 = i * 4788 + j\n                compute_1 = T.Buffer((28728,), data=compute.data)\n                data_1 = T.Buffer((28728,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1]", "op_args": [6, 19, 14, 18], "input_shape": "[[6, 19, 14, 18]]", "output_shape": "[[6, 4788]]"}{"op_name": "flatten", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 26928; ++i_j_fused) {\n    compute[i_j_fused] = data[i_j_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 8, 18, 17), \"float32\"), compute: T.Buffer((11, 2448), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(26928):\n            compute_1 = T.Buffer((26928,), data=compute.data)\n            data_1 = T.Buffer((26928,), data=data.data)\n            compute_1[i_j_fused] = data_1[i_j_fused]", "op_args": [11, 8, 18, 17], "input_shape": "[[11, 8, 18, 17]]", "output_shape": "[[11, 2448]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 13; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 15; ++i3) {\n          compute[((((i0 * 585) + (i1 * 45)) + (i2 * 15)) + i3)] = ceilf(data[((((i0 * 585) + (i1 * 45)) + (i2 * 15)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 10) + (((int)threadIdx.x) / 5)) < 1521) {\n    compute[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 13, 3, 15), \"float32\"), compute: T.Buffer((13, 13, 3, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3 in T.grid(13, 3, 15):\n                cse_var_1: T.int32 = i0 * 585 + i1 * 45 + i2 * 15 + i3\n                compute_1 = T.Buffer((7605,), data=compute.data)\n                data_1 = T.Buffer((7605,), data=data.data)\n                compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])", "op_args": [13, 13, 3, 15], "input_shape": "[[13, 13, 3, 15]]", "output_shape": "[[13, 13, 3, 15]]"}{"op_name": "flatten", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 15; ++i) {\n    for (int32_t j = 0; j < 2520; ++j) {\n      compute[((i * 2520) + j)] = data[((i * 2520) + j)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 18, 7, 20), \"float32\"), compute: T.Buffer((15, 2520), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(15):\n            for j in range(2520):\n                cse_var_1: T.int32 = i * 2520 + j\n                compute_1 = T.Buffer((37800,), data=compute.data)\n                data_1 = T.Buffer((37800,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1]", "op_args": [15, 18, 7, 20], "input_shape": "[[15, 18, 7, 20]]", "output_shape": "[[15, 2520]]"}{"op_name": "ceil", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 15; ++i1) {\n      for (int32_t i2 = 0; i2 < 2; ++i2) {\n        for (int32_t i3 = 0; i3 < 13; ++i3) {\n          compute[((((i0 * 390) + (i1 * 26)) + (i2 * 13)) + i3)] = ceilf(data[((((i0 * 390) + (i1 * 26)) + (i2 * 13)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) < 2145) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 15, 2, 13), \"float32\"), compute: T.Buffer((11, 15, 2, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i2, i3 in T.grid(15, 2, 13):\n                cse_var_1: T.int32 = i0 * 390 + i1 * 26 + i2 * 13 + i3\n                compute_1 = T.Buffer((4290,), data=compute.data)\n                data_1 = T.Buffer((4290,), data=data.data)\n                compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])", "op_args": [11, 15, 2, 13], "input_shape": "[[11, 15, 2, 13]]", "output_shape": "[[11, 15, 2, 13]]"}{"op_name": "flatten", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t j = 0; j < 2288; ++j) {\n    compute[j] = data[j];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 11, 13, 16), \"float32\"), compute: T.Buffer((1, 2288), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for j in range(2288):\n            compute_1 = T.Buffer((2288,), data=compute.data)\n            data_1 = T.Buffer((2288,), data=data.data)\n            compute_1[j] = data_1[j]", "op_args": [1, 11, 13, 16], "input_shape": "[[1, 11, 13, 16]]", "output_shape": "[[1, 2288]]"}{"op_name": "flatten", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 72; ++i_j_fused) {\n    compute[i_j_fused] = data[i_j_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 3, 1, 8), \"float32\"), compute: T.Buffer((3, 24), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(72):\n            compute_1 = T.Buffer((72,), data=compute.data)\n            data_1 = T.Buffer((72,), data=data.data)\n            compute_1[i_j_fused] = data_1[i_j_fused]", "op_args": [3, 3, 1, 8], "input_shape": "[[3, 3, 1, 8]]", "output_shape": "[[3, 24]]"}{"op_name": "flatten", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 1575; ++i_j_fused) {\n    compute[i_j_fused] = data[i_j_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 7, 15, 1), \"float32\"), compute: T.Buffer((15, 105), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(1575):\n            compute_1 = T.Buffer((1575,), data=compute.data)\n            data_1 = T.Buffer((1575,), data=data.data)\n            compute_1[i_j_fused] = data_1[i_j_fused]", "op_args": [15, 7, 15, 1], "input_shape": "[[15, 7, 15, 1]]", "output_shape": "[[15, 105]]"}{"op_name": "erf", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1320; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 8; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 8) + i3_s)] = erff(data[((i0_i1_fused_i2_fused * 8) + i3_s)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 11, 10, 8), \"float32\"), compute: T.Buffer((12, 11, 10, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1320):\n            for i3_s in range(8):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 8 + i3_s\n                compute_1 = T.Buffer((10560,), data=compute.data)\n                data_1 = T.Buffer((10560,), data=data.data)\n                compute_1[cse_var_1] = T.erf(data_1[cse_var_1])", "op_args": [12, 11, 10, 8], "input_shape": "[[12, 11, 10, 8]]", "output_shape": "[[12, 11, 10, 8]]"}{"op_name": "flatten", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 17; ++i) {\n    for (int32_t j = 0; j < 270; ++j) {\n      compute[((i * 270) + j)] = data[((i * 270) + j)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 3, 9, 10), \"float32\"), compute: T.Buffer((17, 270), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(17):\n            for j in range(270):\n                cse_var_1: T.int32 = i * 270 + j\n                compute_1 = T.Buffer((4590,), data=compute.data)\n                data_1 = T.Buffer((4590,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1]", "op_args": [17, 3, 9, 10], "input_shape": "[[17, 3, 9, 10]]", "output_shape": "[[17, 270]]"}{"op_name": "erf", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 72; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = erff(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((int)blockIdx.x)] = erff(data[((int)blockIdx.x)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 1, 3, 8), \"float32\"), compute: T.Buffer((3, 1, 3, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(72):\n            compute_1 = T.Buffer((72,), data=compute.data)\n            data_1 = T.Buffer((72,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.erf(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [3, 1, 3, 8], "input_shape": "[[3, 1, 3, 8]]", "output_shape": "[[3, 1, 3, 8]]"}{"op_name": "flatten", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 3080; ++i_j_fused) {\n    compute[i_j_fused] = data[i_j_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 2)) < 770) {\n    compute[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 2, 7, 11), \"float32\"), compute: T.Buffer((20, 154), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(3080):\n            compute_1 = T.Buffer((3080,), data=compute.data)\n            data_1 = T.Buffer((3080,), data=data.data)\n            compute_1[i_j_fused] = data_1[i_j_fused]", "op_args": [20, 2, 7, 11], "input_shape": "[[20, 2, 7, 11]]", "output_shape": "[[20, 154]]"}{"op_name": "erf", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 3; ++i0) {\n    for (int32_t i1 = 0; i1 < 16; ++i1) {\n      for (int32_t i2 = 0; i2 < 9; ++i2) {\n        for (int32_t i3 = 0; i3 < 15; ++i3) {\n          compute[((((i0 * 2160) + (i1 * 135)) + (i2 * 15)) + i3)] = erff(data[((((i0 * 2160) + (i1 * 135)) + (i2 * 15)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 16, 9, 15), \"float32\"), compute: T.Buffer((3, 16, 9, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(3):\n            for i1, i2, i3 in T.grid(16, 9, 15):\n                cse_var_1: T.int32 = i0 * 2160 + i1 * 135 + i2 * 15 + i3\n                compute_1 = T.Buffer((6480,), data=compute.data)\n                data_1 = T.Buffer((6480,), data=data.data)\n                compute_1[cse_var_1] = T.erf(data_1[cse_var_1])", "op_args": [3, 16, 9, 15], "input_shape": "[[3, 16, 9, 15]]", "output_shape": "[[3, 16, 9, 15]]"}{"op_name": "flatten", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 19152; ++i_j_fused) {\n    compute[i_j_fused] = data[i_j_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 14, 8, 19), \"float32\"), compute: T.Buffer((9, 2128), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(19152):\n            compute_1 = T.Buffer((19152,), data=compute.data)\n            data_1 = T.Buffer((19152,), data=data.data)\n            compute_1[i_j_fused] = data_1[i_j_fused]", "op_args": [9, 14, 8, 19], "input_shape": "[[9, 14, 8, 19]]", "output_shape": "[[9, 2128]]"}{"op_name": "erf", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 17280; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = erff(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(15) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 16, 15, 18), \"float32\"), compute: T.Buffer((4, 16, 15, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(17280):\n            compute_1 = T.Buffer((17280,), data=compute.data)\n            data_1 = T.Buffer((17280,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.erf(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [4, 16, 15, 18], "input_shape": "[[4, 16, 15, 18]]", "output_shape": "[[4, 16, 15, 18]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 255; ++i_j_fused) {\n    for (int32_t k = 0; k < 7; ++k) {\n      for (int32_t l = 0; l < 18; ++l) {\n        new_buffer[(((i_j_fused * 126) + (k * 18)) + l)] = data[(((i_j_fused * 126) + (k * 18)) + l)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 17, 7, 18), \"float32\"), buffer: T.Buffer((15, 17, 7, 18), \"float32\"), new_buffer: T.Buffer((15, 17, 7, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(255):\n            for k, l in T.grid(7, 18):\n                cse_var_1: T.int32 = i_j_fused * 126 + k * 18 + l\n                new_buffer_1 = T.Buffer((32130,), data=new_buffer.data)\n                data_1 = T.Buffer((32130,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [15, 17, 7, 18], "input_shape": "[[15, 17, 7, 18], [15, 17, 7, 18]]", "output_shape": "[[15, 17, 7, 18]]"}{"op_name": "erf", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 312; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = erff(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 6, 1, 4), \"float32\"), compute: T.Buffer((13, 6, 1, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(312):\n            compute_1 = T.Buffer((312,), data=compute.data)\n            data_1 = T.Buffer((312,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.erf(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [13, 6, 1, 4], "input_shape": "[[13, 6, 1, 4]]", "output_shape": "[[13, 6, 1, 4]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 3; ++i) {\n    for (int32_t j = 0; j < 3; ++j) {\n      for (int32_t k = 0; k < 18; ++k) {\n        for (int32_t l = 0; l < 10; ++l) {\n          new_buffer[((((i * 540) + (j * 180)) + (k * 10)) + l)] = data[((((i * 540) + (j * 180)) + (k * 10)) + l)];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 405) {\n    new_buffer[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 3, 18, 10), \"float32\"), buffer: T.Buffer((3, 3, 18, 10), \"float32\"), new_buffer: T.Buffer((3, 3, 18, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(3):\n            for j, k, l in T.grid(3, 18, 10):\n                cse_var_1: T.int32 = i * 540 + j * 180 + k * 10 + l\n                new_buffer_1 = T.Buffer((1620,), data=new_buffer.data)\n                data_1 = T.Buffer((1620,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [3, 3, 18, 10], "input_shape": "[[3, 3, 18, 10], [3, 3, 18, 10]]", "output_shape": "[[3, 3, 18, 10]]"}{"op_name": "erf", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 10; ++i0) {\n    for (int32_t i1 = 0; i1 < 18; ++i1) {\n      for (int32_t i2 = 0; i2 < 7; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 3; ++i3_s) {\n          compute[((((i0 * 378) + (i1 * 21)) + (i2 * 3)) + i3_s)] = erff(data[((((i0 * 378) + (i1 * 21)) + (i2 * 3)) + i3_s)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 18, 7, 3), \"float32\"), compute: T.Buffer((10, 18, 7, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(10):\n            for i1, i2, i3_s in T.grid(18, 7, 3):\n                cse_var_1: T.int32 = i0 * 378 + i1 * 21 + i2 * 3 + i3_s\n                compute_1 = T.Buffer((3780,), data=compute.data)\n                data_1 = T.Buffer((3780,), data=data.data)\n                compute_1[cse_var_1] = T.erf(data_1[cse_var_1])", "op_args": [10, 18, 7, 3], "input_shape": "[[10, 18, 7, 3]]", "output_shape": "[[10, 18, 7, 3]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 55; ++i_j_fused) {\n    for (int32_t k = 0; k < 15; ++k) {\n      new_buffer[((i_j_fused * 15) + k)] = data[((i_j_fused * 15) + k)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(55) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 5, 15, 1), \"float32\"), buffer: T.Buffer((11, 5, 15, 1), \"float32\"), new_buffer: T.Buffer((11, 5, 15, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(55):\n            for k in range(15):\n                cse_var_1: T.int32 = i_j_fused * 15 + k\n                new_buffer_1 = T.Buffer((825,), data=new_buffer.data)\n                data_1 = T.Buffer((825,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [11, 5, 15, 1], "input_shape": "[[11, 5, 15, 1], [11, 5, 15, 1]]", "output_shape": "[[11, 5, 15, 1]]"}{"op_name": "erf", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 30; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 6; ++i2) {\n      for (int32_t i3 = 0; i3 < 15; ++i3) {\n        compute[(((i0_i1_fused * 90) + (i2 * 15)) + i3)] = erff(data[(((i0_i1_fused * 90) + (i2 * 15)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 10, 6, 15), \"float32\"), compute: T.Buffer((3, 10, 6, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(30):\n            for i2, i3 in T.grid(6, 15):\n                cse_var_1: T.int32 = i0_i1_fused * 90 + i2 * 15 + i3\n                compute_1 = T.Buffer((2700,), data=compute.data)\n                data_1 = T.Buffer((2700,), data=data.data)\n                compute_1[cse_var_1] = T.erf(data_1[cse_var_1])", "op_args": [3, 10, 6, 15], "input_shape": "[[3, 10, 6, 15]]", "output_shape": "[[3, 10, 6, 15]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused_k_fused = 0; i_j_fused_k_fused < 770; ++i_j_fused_k_fused) {\n    for (int32_t l = 0; l < 5; ++l) {\n      new_buffer[((i_j_fused_k_fused * 5) + l)] = data[((i_j_fused_k_fused * 5) + l)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(22) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 11, 7, 5), \"float32\"), buffer: T.Buffer((10, 11, 7, 5), \"float32\"), new_buffer: T.Buffer((10, 11, 7, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused_k_fused in T.parallel(770):\n            for l in range(5):\n                cse_var_1: T.int32 = i_j_fused_k_fused * 5 + l\n                new_buffer_1 = T.Buffer((3850,), data=new_buffer.data)\n                data_1 = T.Buffer((3850,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [10, 11, 7, 5], "input_shape": "[[10, 11, 7, 5], [10, 11, 7, 5]]", "output_shape": "[[10, 11, 7, 5]]"}{"op_name": "erf", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 3; ++i0) {\n    for (int32_t i1 = 0; i1 < 20; ++i1) {\n      for (int32_t i2 = 0; i2 < 17; ++i2) {\n        for (int32_t i3 = 0; i3 < 19; ++i3) {\n          compute[((((i0 * 6460) + (i1 * 323)) + (i2 * 19)) + i3)] = erff(data[((((i0 * 6460) + (i1 * 323)) + (i2 * 19)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 20, 17, 19), \"float32\"), compute: T.Buffer((3, 20, 17, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(3):\n            for i1, i2, i3 in T.grid(20, 17, 19):\n                cse_var_1: T.int32 = i0 * 6460 + i1 * 323 + i2 * 19 + i3\n                compute_1 = T.Buffer((19380,), data=compute.data)\n                data_1 = T.Buffer((19380,), data=data.data)\n                compute_1[cse_var_1] = T.erf(data_1[cse_var_1])", "op_args": [3, 20, 17, 19], "input_shape": "[[3, 20, 17, 19]]", "output_shape": "[[3, 20, 17, 19]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 14; ++i_j_fused) {\n    for (int32_t k = 0; k < 18; ++k) {\n      for (int32_t l = 0; l < 16; ++l) {\n        new_buffer[(((i_j_fused * 288) + (k * 16)) + l)] = data[(((i_j_fused * 288) + (k * 16)) + l)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 1, 18, 16), \"float32\"), buffer: T.Buffer((14, 1, 18, 16), \"float32\"), new_buffer: T.Buffer((14, 1, 18, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(14):\n            for k, l in T.grid(18, 16):\n                cse_var_1: T.int32 = i_j_fused * 288 + k * 16 + l\n                new_buffer_1 = T.Buffer((4032,), data=new_buffer.data)\n                data_1 = T.Buffer((4032,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [14, 1, 18, 16], "input_shape": "[[14, 1, 18, 16], [14, 1, 18, 16]]", "output_shape": "[[14, 1, 18, 16]]"}{"op_name": "erf", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 266; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 18; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 5; ++i3_s) {\n        compute[(((i0_i1_fused * 90) + (i2 * 5)) + i3_s)] = erff(data[(((i0_i1_fused * 90) + (i2 * 5)) + i3_s)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 19, 18, 5), \"float32\"), compute: T.Buffer((14, 19, 18, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(266):\n            for i2, i3_s in T.grid(18, 5):\n                cse_var_1: T.int32 = i0_i1_fused * 90 + i2 * 5 + i3_s\n                compute_1 = T.Buffer((23940,), data=compute.data)\n                data_1 = T.Buffer((23940,), data=data.data)\n                compute_1[cse_var_1] = T.erf(data_1[cse_var_1])", "op_args": [14, 19, 18, 5], "input_shape": "[[14, 19, 18, 5]]", "output_shape": "[[14, 19, 18, 5]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused_k_fused = 0; i_j_fused_k_fused < 429; ++i_j_fused_k_fused) {\n    for (int32_t l = 0; l < 4; ++l) {\n      new_buffer[((i_j_fused_k_fused * 4) + l)] = data[((i_j_fused_k_fused * 4) + l)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 13, 3, 4), \"float32\"), buffer: T.Buffer((11, 13, 3, 4), \"float32\"), new_buffer: T.Buffer((11, 13, 3, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused_k_fused in T.parallel(429):\n            for l in range(4):\n                cse_var_1: T.int32 = i_j_fused_k_fused * 4 + l\n                new_buffer_1 = T.Buffer((1716,), data=new_buffer.data)\n                data_1 = T.Buffer((1716,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [11, 13, 3, 4], "input_shape": "[[11, 13, 3, 4], [11, 13, 3, 4]]", "output_shape": "[[11, 13, 3, 4]]"}{"op_name": "erf", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 10; ++i0) {\n    for (int32_t i1 = 0; i1 < 3; ++i1) {\n      for (int32_t i2 = 0; i2 < 8; ++i2) {\n        for (int32_t i3 = 0; i3 < 9; ++i3) {\n          compute[((((i0 * 216) + (i1 * 72)) + (i2 * 9)) + i3)] = erff(data[((((i0 * 216) + (i1 * 72)) + (i2 * 9)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 3, 8, 9), \"float32\"), compute: T.Buffer((10, 3, 8, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(10):\n            for i1, i2, i3 in T.grid(3, 8, 9):\n                cse_var_1: T.int32 = i0 * 216 + i1 * 72 + i2 * 9 + i3\n                compute_1 = T.Buffer((2160,), data=compute.data)\n                data_1 = T.Buffer((2160,), data=data.data)\n                compute_1[cse_var_1] = T.erf(data_1[cse_var_1])", "op_args": [10, 3, 8, 9], "input_shape": "[[10, 3, 8, 9]]", "output_shape": "[[10, 3, 8, 9]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 10; ++i) {\n    for (int32_t j = 0; j < 12; ++j) {\n      for (int32_t k = 0; k < 16; ++k) {\n        for (int32_t l = 0; l < 19; ++l) {\n          new_buffer[((((i * 3648) + (j * 304)) + (k * 19)) + l)] = data[((((i * 3648) + (j * 304)) + (k * 19)) + l)];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 12, 16, 19), \"float32\"), buffer: T.Buffer((10, 12, 16, 19), \"float32\"), new_buffer: T.Buffer((10, 12, 16, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(10):\n            for j, k, l in T.grid(12, 16, 19):\n                cse_var_1: T.int32 = i * 3648 + j * 304 + k * 19 + l\n                new_buffer_1 = T.Buffer((36480,), data=new_buffer.data)\n                data_1 = T.Buffer((36480,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [10, 12, 16, 19], "input_shape": "[[10, 12, 16, 19], [10, 12, 16, 19]]", "output_shape": "[[10, 12, 16, 19]]"}{"op_name": "exp", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 42; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 5; ++i2) {\n      for (int32_t i3 = 0; i3 < 4; ++i3) {\n        compute[(((i0_i1_fused * 20) + (i2 * 4)) + i3)] = expf(data[(((i0_i1_fused * 20) + (i2 * 4)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) < 105) {\n    compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 14, 5, 4), \"float32\"), compute: T.Buffer((3, 14, 5, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(42):\n            for i2, i3 in T.grid(5, 4):\n                cse_var_1: T.int32 = i0_i1_fused * 20 + i2 * 4 + i3\n                compute_1 = T.Buffer((840,), data=compute.data)\n                data_1 = T.Buffer((840,), data=data.data)\n                compute_1[cse_var_1] = T.exp(data_1[cse_var_1])", "op_args": [3, 14, 5, 4], "input_shape": "[[3, 14, 5, 4]]", "output_shape": "[[3, 14, 5, 4]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  for (int32_t j = 0; j < 16; ++j) {\n    for (int32_t k = 0; k < 10; ++k) {\n      for (int32_t l = 0; l < 2; ++l) {\n        new_buffer[(((j * 20) + (k * 2)) + l)] = data[(((j * 20) + (k * 2)) + l)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 16, 10, 2), \"float32\"), buffer: T.Buffer((1, 16, 10, 2), \"float32\"), new_buffer: T.Buffer((1, 16, 10, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for j, k, l in T.grid(16, 10, 2):\n            cse_var_1: T.int32 = j * 20 + k * 2 + l\n            new_buffer_1 = T.Buffer((320,), data=new_buffer.data)\n            data_1 = T.Buffer((320,), data=data.data)\n            new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [1, 16, 10, 2], "input_shape": "[[1, 16, 10, 2], [1, 16, 10, 2]]", "output_shape": "[[1, 16, 10, 2]]"}{"op_name": "exp", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 12; ++i0) {\n    for (int32_t i1 = 0; i1 < 3; ++i1) {\n      for (int32_t i2 = 0; i2 < 18; ++i2) {\n        for (int32_t i3 = 0; i3 < 16; ++i3) {\n          compute[((((i0 * 864) + (i1 * 288)) + (i2 * 16)) + i3)] = expf(data[((((i0 * 864) + (i1 * 288)) + (i2 * 16)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 3, 18, 16), \"float32\"), compute: T.Buffer((12, 3, 18, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(12):\n            for i1, i2, i3 in T.grid(3, 18, 16):\n                cse_var_1: T.int32 = i0 * 864 + i1 * 288 + i2 * 16 + i3\n                compute_1 = T.Buffer((10368,), data=compute.data)\n                data_1 = T.Buffer((10368,), data=data.data)\n                compute_1[cse_var_1] = T.exp(data_1[cse_var_1])", "op_args": [12, 3, 18, 16], "input_shape": "[[12, 3, 18, 16]]", "output_shape": "[[12, 3, 18, 16]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 198; ++i_j_fused) {\n    for (int32_t k = 0; k < 13; ++k) {\n      for (int32_t l = 0; l < 18; ++l) {\n        new_buffer[(((i_j_fused * 234) + (k * 18)) + l)] = data[(((i_j_fused * 234) + (k * 18)) + l)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 11, 13, 18), \"float32\"), buffer: T.Buffer((18, 11, 13, 18), \"float32\"), new_buffer: T.Buffer((18, 11, 13, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(198):\n            for k, l in T.grid(13, 18):\n                cse_var_1: T.int32 = i_j_fused * 234 + k * 18 + l\n                new_buffer_1 = T.Buffer((46332,), data=new_buffer.data)\n                data_1 = T.Buffer((46332,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [18, 11, 13, 18], "input_shape": "[[18, 11, 13, 18], [18, 11, 13, 18]]", "output_shape": "[[18, 11, 13, 18]]"}{"op_name": "exp", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 10; ++i1) {\n      for (int32_t i2 = 0; i2 < 16; ++i2) {\n        for (int32_t i3 = 0; i3 < 18; ++i3) {\n          compute[((((i0 * 2880) + (i1 * 288)) + (i2 * 18)) + i3)] = expf(data[((((i0 * 2880) + (i1 * 288)) + (i2 * 18)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 10, 16, 18), \"float32\"), compute: T.Buffer((7, 10, 16, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i1, i2, i3 in T.grid(10, 16, 18):\n                cse_var_1: T.int32 = i0 * 2880 + i1 * 288 + i2 * 18 + i3\n                compute_1 = T.Buffer((20160,), data=compute.data)\n                data_1 = T.Buffer((20160,), data=data.data)\n                compute_1[cse_var_1] = T.exp(data_1[cse_var_1])", "op_args": [7, 10, 16, 18], "input_shape": "[[7, 10, 16, 18]]", "output_shape": "[[7, 10, 16, 18]]"}{"op_name": "exp", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 90; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 2; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 2) + i3)] = expf(data[((i0_i1_fused_i2_fused * 2) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 5, 6, 2), \"float32\"), compute: T.Buffer((3, 5, 6, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(90):\n            for i3 in range(2):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 2 + i3\n                compute_1 = T.Buffer((180,), data=compute.data)\n                data_1 = T.Buffer((180,), data=data.data)\n                compute_1[cse_var_1] = T.exp(data_1[cse_var_1])", "op_args": [3, 5, 6, 2], "input_shape": "[[3, 5, 6, 2]]", "output_shape": "[[3, 5, 6, 2]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 54; ++i_j_fused) {\n    for (int32_t k = 0; k < 13; ++k) {\n      for (int32_t l = 0; l < 7; ++l) {\n        new_buffer[(((i_j_fused * 91) + (k * 7)) + l)] = data[(((i_j_fused * 91) + (k * 7)) + l)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(13) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 6, 13, 7), \"float32\"), buffer: T.Buffer((9, 6, 13, 7), \"float32\"), new_buffer: T.Buffer((9, 6, 13, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(54):\n            for k, l in T.grid(13, 7):\n                cse_var_1: T.int32 = i_j_fused * 91 + k * 7 + l\n                new_buffer_1 = T.Buffer((4914,), data=new_buffer.data)\n                data_1 = T.Buffer((4914,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [9, 6, 13, 7], "input_shape": "[[9, 6, 13, 7], [9, 6, 13, 7]]", "output_shape": "[[9, 6, 13, 7]]"}{"op_name": "exp", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 480; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = expf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 12, 5, 1), \"float32\"), compute: T.Buffer((8, 12, 5, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(480):\n            compute_1 = T.Buffer((480,), data=compute.data)\n            data_1 = T.Buffer((480,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.exp(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [8, 12, 5, 1], "input_shape": "[[8, 12, 5, 1]]", "output_shape": "[[8, 12, 5, 1]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  for (int32_t j = 0; j < 8; ++j) {\n    for (int32_t k = 0; k < 10; ++k) {\n      for (int32_t l = 0; l < 4; ++l) {\n        new_buffer[(((j * 40) + (k * 4)) + l)] = data[(((j * 40) + (k * 4)) + l)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 8, 10, 4), \"float32\"), buffer: T.Buffer((1, 8, 10, 4), \"float32\"), new_buffer: T.Buffer((1, 8, 10, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for j, k, l in T.grid(8, 10, 4):\n            cse_var_1: T.int32 = j * 40 + k * 4 + l\n            new_buffer_1 = T.Buffer((320,), data=new_buffer.data)\n            data_1 = T.Buffer((320,), data=data.data)\n            new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [1, 8, 10, 4], "input_shape": "[[1, 8, 10, 4], [1, 8, 10, 4]]", "output_shape": "[[1, 8, 10, 4]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 3; ++i) {\n    for (int32_t j = 0; j < 15; ++j) {\n      for (int32_t k = 0; k < 6; ++k) {\n        for (int32_t l = 0; l < 18; ++l) {\n          new_buffer[((((i * 1620) + (j * 108)) + (k * 18)) + l)] = data[((((i * 1620) + (j * 108)) + (k * 18)) + l)];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) / 12)) < 405) {\n    new_buffer[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 15, 6, 18), \"float32\"), buffer: T.Buffer((3, 15, 6, 18), \"float32\"), new_buffer: T.Buffer((3, 15, 6, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(3):\n            for j, k, l in T.grid(15, 6, 18):\n                cse_var_1: T.int32 = i * 1620 + j * 108 + k * 18 + l\n                new_buffer_1 = T.Buffer((4860,), data=new_buffer.data)\n                data_1 = T.Buffer((4860,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [3, 15, 6, 18], "input_shape": "[[3, 15, 6, 18], [3, 15, 6, 18]]", "output_shape": "[[3, 15, 6, 18]]"}{"op_name": "exp", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 10; ++i0) {\n    for (int32_t i1 = 0; i1 < 3; ++i1) {\n      for (int32_t i2 = 0; i2 < 13; ++i2) {\n        for (int32_t i3 = 0; i3 < 6; ++i3) {\n          compute[((((i0 * 234) + (i1 * 78)) + (i2 * 6)) + i3)] = expf(data[((((i0 * 234) + (i1 * 78)) + (i2 * 6)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 3, 13, 6), \"float32\"), compute: T.Buffer((10, 3, 13, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(10):\n            for i1, i2, i3 in T.grid(3, 13, 6):\n                cse_var_1: T.int32 = i0 * 234 + i1 * 78 + i2 * 6 + i3\n                compute_1 = T.Buffer((2340,), data=compute.data)\n                data_1 = T.Buffer((2340,), data=data.data)\n                compute_1[cse_var_1] = T.exp(data_1[cse_var_1])", "op_args": [10, 3, 13, 6], "input_shape": "[[10, 3, 13, 6]]", "output_shape": "[[10, 3, 13, 6]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused_k_fused = 0; i_j_fused_k_fused < 360; ++i_j_fused_k_fused) {\n    for (int32_t l = 0; l < 4; ++l) {\n      new_buffer[((i_j_fused_k_fused * 4) + l)] = data[((i_j_fused_k_fused * 4) + l)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 3, 12, 4), \"float32\"), buffer: T.Buffer((10, 3, 12, 4), \"float32\"), new_buffer: T.Buffer((10, 3, 12, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused_k_fused in T.parallel(360):\n            for l in range(4):\n                cse_var_1: T.int32 = i_j_fused_k_fused * 4 + l\n                new_buffer_1 = T.Buffer((1440,), data=new_buffer.data)\n                data_1 = T.Buffer((1440,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [10, 3, 12, 4], "input_shape": "[[10, 3, 12, 4], [10, 3, 12, 4]]", "output_shape": "[[10, 3, 12, 4]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 100; ++i_j_fused) {\n    for (int32_t k = 0; k < 2; ++k) {\n      for (int32_t l = 0; l < 15; ++l) {\n        new_buffer[(((i_j_fused * 30) + (k * 15)) + l)] = data[(((i_j_fused * 30) + (k * 15)) + l)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(15) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 10, 2, 15), \"float32\"), buffer: T.Buffer((10, 10, 2, 15), \"float32\"), new_buffer: T.Buffer((10, 10, 2, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(100):\n            for k, l in T.grid(2, 15):\n                cse_var_1: T.int32 = i_j_fused * 30 + k * 15 + l\n                new_buffer_1 = T.Buffer((3000,), data=new_buffer.data)\n                data_1 = T.Buffer((3000,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [10, 10, 2, 15], "input_shape": "[[10, 10, 2, 15], [10, 10, 2, 15]]", "output_shape": "[[10, 10, 2, 15]]"}{"op_name": "exp", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 19; ++i1) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3 = 0; i3 < 10; ++i3) {\n        compute[(((i1 * 40) + (i2 * 10)) + i3)] = expf(data[(((i1 * 40) + (i2 * 10)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 19, 4, 10), \"float32\"), compute: T.Buffer((1, 19, 4, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(19, 4, 10):\n            cse_var_1: T.int32 = i1 * 40 + i2 * 10 + i3\n            compute_1 = T.Buffer((760,), data=compute.data)\n            data_1 = T.Buffer((760,), data=data.data)\n            compute_1[cse_var_1] = T.exp(data_1[cse_var_1])", "op_args": [1, 19, 4, 10], "input_shape": "[[1, 19, 4, 10]]", "output_shape": "[[1, 19, 4, 10]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused_k_fused_l_fused = 0; i_j_fused_k_fused_l_fused < 1536; ++i_j_fused_k_fused_l_fused) {\n    new_buffer[i_j_fused_k_fused_l_fused] = data[i_j_fused_k_fused_l_fused];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 16, 2, 8), \"float32\"), buffer: T.Buffer((6, 16, 2, 8), \"float32\"), new_buffer: T.Buffer((6, 16, 2, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused_k_fused_l_fused in T.parallel(1536):\n            new_buffer_1 = T.Buffer((1536,), data=new_buffer.data)\n            data_1 = T.Buffer((1536,), data=data.data)\n            new_buffer_1[i_j_fused_k_fused_l_fused] = data_1[i_j_fused_k_fused_l_fused]", "op_args": [6, 16, 2, 8], "input_shape": "[[6, 16, 2, 8], [6, 16, 2, 8]]", "output_shape": "[[6, 16, 2, 8]]"}{"op_name": "exp", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 42; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 11; ++i2) {\n      for (int32_t i3 = 0; i3 < 12; ++i3) {\n        compute[(((i0_i1_fused * 132) + (i2 * 12)) + i3)] = expf(data[(((i0_i1_fused * 132) + (i2 * 12)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(21) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 14, 11, 12), \"float32\"), compute: T.Buffer((3, 14, 11, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(42):\n            for i2, i3 in T.grid(11, 12):\n                cse_var_1: T.int32 = i0_i1_fused * 132 + i2 * 12 + i3\n                compute_1 = T.Buffer((5544,), data=compute.data)\n                data_1 = T.Buffer((5544,), data=data.data)\n                compute_1[cse_var_1] = T.exp(data_1[cse_var_1])", "op_args": [3, 14, 11, 12], "input_shape": "[[3, 14, 11, 12]]", "output_shape": "[[3, 14, 11, 12]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused_k_fused = 0; i_j_fused_k_fused < 504; ++i_j_fused_k_fused) {\n    for (int32_t l = 0; l < 8; ++l) {\n      new_buffer[((i_j_fused_k_fused * 8) + l)] = data[((i_j_fused_k_fused * 8) + l)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 3, 12, 8), \"float32\"), buffer: T.Buffer((14, 3, 12, 8), \"float32\"), new_buffer: T.Buffer((14, 3, 12, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused_k_fused in T.parallel(504):\n            for l in range(8):\n                cse_var_1: T.int32 = i_j_fused_k_fused * 8 + l\n                new_buffer_1 = T.Buffer((4032,), data=new_buffer.data)\n                data_1 = T.Buffer((4032,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [14, 3, 12, 8], "input_shape": "[[14, 3, 12, 8], [14, 3, 12, 8]]", "output_shape": "[[14, 3, 12, 8]]"}{"op_name": "exp", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 5; ++i0) {\n    for (int32_t i1 = 0; i1 < 5; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        for (int32_t i3 = 0; i3 < 10; ++i3) {\n          compute[((((i0 * 700) + (i1 * 140)) + (i2 * 10)) + i3)] = expf(data[((((i0 * 700) + (i1 * 140)) + (i2 * 10)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 5, 14, 10), \"float32\"), compute: T.Buffer((5, 5, 14, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(5):\n            for i1, i2, i3 in T.grid(5, 14, 10):\n                cse_var_1: T.int32 = i0 * 700 + i1 * 140 + i2 * 10 + i3\n                compute_1 = T.Buffer((3500,), data=compute.data)\n                data_1 = T.Buffer((3500,), data=data.data)\n                compute_1[cse_var_1] = T.exp(data_1[cse_var_1])", "op_args": [5, 5, 14, 10], "input_shape": "[[5, 5, 14, 10]]", "output_shape": "[[5, 5, 14, 10]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused_k_fused = 0; i_j_fused_k_fused < 1638; ++i_j_fused_k_fused) {\n    for (int32_t l = 0; l < 17; ++l) {\n      new_buffer[((i_j_fused_k_fused * 17) + l)] = data[((i_j_fused_k_fused * 17) + l)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  if (((((int)blockIdx.x) * 10) + (((int)threadIdx.x) / 6)) < 4641) {\n    new_buffer[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 9, 13, 17), \"float32\"), buffer: T.Buffer((14, 9, 13, 17), \"float32\"), new_buffer: T.Buffer((14, 9, 13, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused_k_fused in T.parallel(1638):\n            for l in range(17):\n                cse_var_1: T.int32 = i_j_fused_k_fused * 17 + l\n                new_buffer_1 = T.Buffer((27846,), data=new_buffer.data)\n                data_1 = T.Buffer((27846,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [14, 9, 13, 17], "input_shape": "[[14, 9, 13, 17], [14, 9, 13, 17]]", "output_shape": "[[14, 9, 13, 17]]"}{"op_name": "exp", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 380; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 13; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 13) + i3)] = expf(data[((i0_i1_fused_i2_fused * 13) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) < 1235) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 1, 19, 13), \"float32\"), compute: T.Buffer((20, 1, 19, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(380):\n            for i3 in range(13):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 13 + i3\n                compute_1 = T.Buffer((4940,), data=compute.data)\n                data_1 = T.Buffer((4940,), data=data.data)\n                compute_1[cse_var_1] = T.exp(data_1[cse_var_1])", "op_args": [20, 1, 19, 13], "input_shape": "[[20, 1, 19, 13]]", "output_shape": "[[20, 1, 19, 13]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused_k_fused = 0; i_j_fused_k_fused < 8; ++i_j_fused_k_fused) {\n    for (int32_t l = 0; l < 20; ++l) {\n      new_buffer[((i_j_fused_k_fused * 20) + l)] = data[((i_j_fused_k_fused * 20) + l)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 2, 1, 20), \"float32\"), buffer: T.Buffer((4, 2, 1, 20), \"float32\"), new_buffer: T.Buffer((4, 2, 1, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused_k_fused in T.parallel(8):\n            for l in range(20):\n                cse_var_1: T.int32 = i_j_fused_k_fused * 20 + l\n                new_buffer_1 = T.Buffer((160,), data=new_buffer.data)\n                data_1 = T.Buffer((160,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [4, 2, 1, 20], "input_shape": "[[4, 2, 1, 20], [4, 2, 1, 20]]", "output_shape": "[[4, 2, 1, 20]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  for (int32_t j = 0; j < 7; ++j) {\n    for (int32_t k = 0; k < 4; ++k) {\n      for (int32_t l = 0; l < 13; ++l) {\n        new_buffer[(((j * 52) + (k * 13)) + l)] = data[(((j * 52) + (k * 13)) + l)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(3) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  if (((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) < 364) {\n    new_buffer[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 7, 4, 13), \"float32\"), buffer: T.Buffer((1, 7, 4, 13), \"float32\"), new_buffer: T.Buffer((1, 7, 4, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for j, k, l in T.grid(7, 4, 13):\n            cse_var_1: T.int32 = j * 52 + k * 13 + l\n            new_buffer_1 = T.Buffer((364,), data=new_buffer.data)\n            data_1 = T.Buffer((364,), data=data.data)\n            new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [1, 7, 4, 13], "input_shape": "[[1, 7, 4, 13], [1, 7, 4, 13]]", "output_shape": "[[1, 7, 4, 13]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 20; ++i) {\n    for (int32_t j = 0; j < 10; ++j) {\n      for (int32_t k = 0; k < 4; ++k) {\n        for (int32_t l = 0; l < 10; ++l) {\n          new_buffer[((((i * 400) + (j * 40)) + (k * 10)) + l)] = data[((((i * 400) + (j * 40)) + (k * 10)) + l)];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 10, 4, 10), \"float32\"), buffer: T.Buffer((20, 10, 4, 10), \"float32\"), new_buffer: T.Buffer((20, 10, 4, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(20):\n            for j, k, l in T.grid(10, 4, 10):\n                cse_var_1: T.int32 = i * 400 + j * 40 + k * 10 + l\n                new_buffer_1 = T.Buffer((8000,), data=new_buffer.data)\n                data_1 = T.Buffer((8000,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [20, 10, 4, 10], "input_shape": "[[20, 10, 4, 10], [20, 10, 4, 10]]", "output_shape": "[[20, 10, 4, 10]]"}{"op_name": "fast_erf", "c_code": "void default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 8; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 4; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 5; ++ax2) {\n        T_fast_erf[(((ax0 * 20) + (ax1 * 5)) + ax2)] = ((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0 * 20) + (ax1 * 5)) + ax2)], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_fast_erf, float* __restrict__ data) {\n  T_fast_erf[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 4, 5, 1), \"float32\"), T_fast_erf: T.Buffer((8, 4, 5, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(8):\n            for ax1, ax2 in T.grid(4, 5):\n                cse_var_1: T.int32 = ax0 * 20 + ax1 * 5 + ax2\n                T_fast_erf_1 = T.Buffer((160,), data=T_fast_erf.data)\n                data_1 = T.Buffer((160,), data=data.data)\n                T_fast_erf_1[cse_var_1] = T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-2.7261423674040941e-10) + T.float32(2.7706814620387377e-08)) + T.float32(-2.101023937939317e-06)) + T.float32(-5.6925062381196767e-05)) + T.float32(-0.00073499063728377223)) + T.float32(-0.0029545999132096767)) + T.float32(-0.016096033155918121)) / (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-1.4566071513399947e-05) + T.float32(-0.00021337404905352741)) + T.float32(-0.001682827016338706)) + T.float32(-0.0073733292520046234)) + T.float32(-0.014264739118516445))", "op_args": [8, 4, 5, 1], "input_shape": "[[8, 4, 5, 1]]", "output_shape": "[[8, 4, 5, 1]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i = 0; i < 2; ++i) {\n    for (int32_t j = 0; j < 17; ++j) {\n      for (int32_t k = 0; k < 16; ++k) {\n        for (int32_t l = 0; l < 16; ++l) {\n          new_buffer[((((i * 4352) + (j * 256)) + (k * 16)) + l)] = data[((((i * 4352) + (j * 256)) + (k * 16)) + l)];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(17) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 17, 16, 16), \"float32\"), buffer: T.Buffer((2, 17, 16, 16), \"float32\"), new_buffer: T.Buffer((2, 17, 16, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i in T.parallel(2):\n            for j, k, l in T.grid(17, 16, 16):\n                cse_var_1: T.int32 = i * 4352 + j * 256 + k * 16 + l\n                new_buffer_1 = T.Buffer((8704,), data=new_buffer.data)\n                data_1 = T.Buffer((8704,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [2, 17, 16, 16], "input_shape": "[[2, 17, 16, 16], [2, 17, 16, 16]]", "output_shape": "[[2, 17, 16, 16]]"}{"op_name": "fast_erf", "c_code": "void default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 91; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 4; ++ax3) {\n        T_fast_erf[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)] = ((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[(((ax0_ax1_fused * 28) + (ax2 * 4)) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(49) default_function_kernel(float* __restrict__ T_fast_erf, float* __restrict__ data) {\n  T_fast_erf[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))] = ((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 7, 7, 4), \"float32\"), T_fast_erf: T.Buffer((13, 7, 7, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(91):\n            for ax2, ax3 in T.grid(7, 4):\n                cse_var_1: T.int32 = ax0_ax1_fused * 28 + ax2 * 4 + ax3\n                T_fast_erf_1 = T.Buffer((2548,), data=T_fast_erf.data)\n                data_1 = T.Buffer((2548,), data=data.data)\n                T_fast_erf_1[cse_var_1] = T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-2.7261423674040941e-10) + T.float32(2.7706814620387377e-08)) + T.float32(-2.101023937939317e-06)) + T.float32(-5.6925062381196767e-05)) + T.float32(-0.00073499063728377223)) + T.float32(-0.0029545999132096767)) + T.float32(-0.016096033155918121)) / (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-1.4566071513399947e-05) + T.float32(-0.00021337404905352741)) + T.float32(-0.001682827016338706)) + T.float32(-0.0073733292520046234)) + T.float32(-0.014264739118516445))", "op_args": [13, 7, 7, 4], "input_shape": "[[13, 7, 7, 4]]", "output_shape": "[[13, 7, 7, 4]]"}{"op_name": "fifo_buffer", "c_code": "void default_function_kernel(float* data, float* new_buffer) {\n  #pragma omp parallel for\n  for (int32_t i_j_fused = 0; i_j_fused < 285; ++i_j_fused) {\n    for (int32_t k = 0; k < 15; ++k) {\n      for (int32_t l = 0; l < 20; ++l) {\n        new_buffer[(((i_j_fused * 300) + (k * 20)) + l)] = data[(((i_j_fused * 300) + (k * 20)) + l)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ data, float* __restrict__ new_buffer) {\n  new_buffer[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 19, 15, 20), \"float32\"), buffer: T.Buffer((15, 19, 15, 20), \"float32\"), new_buffer: T.Buffer((15, 19, 15, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_j_fused in T.parallel(285):\n            for k, l in T.grid(15, 20):\n                cse_var_1: T.int32 = i_j_fused * 300 + k * 20 + l\n                new_buffer_1 = T.Buffer((85500,), data=new_buffer.data)\n                data_1 = T.Buffer((85500,), data=data.data)\n                new_buffer_1[cse_var_1] = data_1[cse_var_1]", "op_args": [15, 19, 15, 20], "input_shape": "[[15, 19, 15, 20], [15, 19, 15, 20]]", "output_shape": "[[15, 19, 15, 20]]"}{"op_name": "fast_erf", "c_code": "void default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 648; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 6; ++ax3) {\n      T_fast_erf[((ax0_ax1_fused_ax2_fused * 6) + ax3)] = ((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_fast_erf, float* __restrict__ data) {\n  T_fast_erf[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 12, 6, 6), \"float32\"), T_fast_erf: T.Buffer((9, 12, 6, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(648):\n            for ax3 in range(6):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 6 + ax3\n                T_fast_erf_1 = T.Buffer((3888,), data=T_fast_erf.data)\n                data_1 = T.Buffer((3888,), data=data.data)\n                T_fast_erf_1[cse_var_1] = T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-2.7261423674040941e-10) + T.float32(2.7706814620387377e-08)) + T.float32(-2.101023937939317e-06)) + T.float32(-5.6925062381196767e-05)) + T.float32(-0.00073499063728377223)) + T.float32(-0.0029545999132096767)) + T.float32(-0.016096033155918121)) / (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-1.4566071513399947e-05) + T.float32(-0.00021337404905352741)) + T.float32(-0.001682827016338706)) + T.float32(-0.0073733292520046234)) + T.float32(-0.014264739118516445))", "op_args": [9, 12, 6, 6], "input_shape": "[[9, 12, 6, 6]]", "output_shape": "[[9, 12, 6, 6]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 45; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 8; ++i2) {\n      for (int32_t i3 = 0; i3 < 14; ++i3) {\n        depth_to_space[(((i0_i1_fused * 112) + (i2 * 14)) + i3)] = data[(((((((i0_i1_fused / 3) * 392) + ((i2 % 2) * 168)) + ((i3 % 2) * 84)) + ((i0_i1_fused % 3) * 28)) + ((i2 / 2) * 7)) + (i3 / 2))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(42) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) >> 3) * 392) + (((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 14)) & 7) % 2) * 168)) + (((((int)threadIdx.x) % 14) % 2) * 84)) + (((((((int)blockIdx.x) & 7) * 3) + (((int)threadIdx.x) / 14)) >> 3) * 28)) + (((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 14)) & 7) / 2) * 7)) + ((((int)threadIdx.x) % 14) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 14, 4, 7), \"float32\"), depth_to_space: T.Buffer((15, 3, 8, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(45):\n            for i2, i3 in T.grid(8, 14):\n                depth_to_space_1 = T.Buffer((5040,), data=depth_to_space.data)\n                data_1 = T.Buffer((5880,), data=data.data)\n                depth_to_space_1[i0_i1_fused * 112 + i2 * 14 + i3] = data_1[i0_i1_fused // 3 * 392 + T.truncmod(i2, 2) * 168 + T.truncmod(i3, 2) * 84 + i0_i1_fused % 3 * 28 + T.Div(i2, 2) * 7 + T.Div(i3, 2)]", "op_args": [15, 14, 4, 7], "input_shape": "[[15, 14, 4, 7]]", "output_shape": "[[15, 3, 8, 14]]"}{"op_name": "fast_erf", "c_code": "void default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 2340; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_fast_erf[ax0_ax1_fused_ax2_fused_ax3_fused] = ((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_fast_erf, float* __restrict__ data) {\n  T_fast_erf[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 4, 13, 5), \"float32\"), T_fast_erf: T.Buffer((9, 4, 13, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(2340):\n            T_fast_erf_1 = T.Buffer((2340,), data=T_fast_erf.data)\n            data_1 = T.Buffer((2340,), data=data.data)\n            T_fast_erf_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.float32(-2.7261423674040941e-10) + T.float32(2.7706814620387377e-08)) + T.float32(-2.101023937939317e-06)) + T.float32(-5.6925062381196767e-05)) + T.float32(-0.00073499063728377223)) + T.float32(-0.0029545999132096767)) + T.float32(-0.016096033155918121)) / (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(4)), T.float32(-4)) * T.float32(-1.4566071513399947e-05) + T.float32(-0.00021337404905352741)) + T.float32(-0.001682827016338706)) + T.float32(-0.0073733292520046234)) + T.float32(-0.014264739118516445))", "op_args": [9, 4, 13, 5], "input_shape": "[[9, 4, 13, 5]]", "output_shape": "[[9, 4, 13, 5]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 54; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 18; ++i2) {\n      for (int32_t i3 = 0; i3 < 26; ++i3) {\n        depth_to_space[(((i0_i1_fused * 468) + (i2 * 26)) + i3)] = data[(((((((i0_i1_fused / 3) * 1404) + ((i2 % 2) * 702)) + ((i3 % 2) * 351)) + ((i0_i1_fused % 3) * 117)) + ((i2 / 2) * 13)) + (i3 / 2))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) / 26) * 1404) + ((((((((int)blockIdx.x) * 27) + (((int)threadIdx.x) >> 1)) % 234) / 13) % 2) * 702)) + (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 26) % 2) * 351)) + (((((((int)blockIdx.x) % 26) * 3) + (((int)threadIdx.x) / 18)) / 26) * 117)) + ((((((((int)blockIdx.x) * 27) + (((int)threadIdx.x) >> 1)) % 234) / 13) / 2) * 13)) + ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 26) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 12, 9, 13), \"float32\"), depth_to_space: T.Buffer((18, 3, 18, 26), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(54):\n            for i2, i3 in T.grid(18, 26):\n                depth_to_space_1 = T.Buffer((25272,), data=depth_to_space.data)\n                data_1 = T.Buffer((25272,), data=data.data)\n                depth_to_space_1[i0_i1_fused * 468 + i2 * 26 + i3] = data_1[i0_i1_fused // 3 * 1404 + T.truncmod(i2, 2) * 702 + T.truncmod(i3, 2) * 351 + i0_i1_fused % 3 * 117 + T.Div(i2, 2) * 13 + T.Div(i3, 2)]", "op_args": [18, 12, 9, 13], "input_shape": "[[18, 12, 9, 13]]", "output_shape": "[[18, 3, 18, 26]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 180; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 20; ++i3) {\n      depth_to_space[((i0_i1_fused_i2_fused * 20) + i3)] = data[(((((((i0_i1_fused_i2_fused / 36) * 840) + (((i0_i1_fused_i2_fused % 12) % 2) * 360)) + ((i3 % 2) * 180)) + (((i0_i1_fused_i2_fused % 36) / 12) * 60)) + (((i0_i1_fused_i2_fused % 12) / 2) * 10)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 225) {\n    depth_to_space[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) / 45) * 840) + ((((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) % 60) / 5) % 2) * 360)) + (((((((int)blockIdx.x) * 12) + ((int)threadIdx.x)) % 20) % 2) * 180)) + (((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) % 45) / 15) * 60)) + ((((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) % 60) / 5) / 2) * 10)) + ((((((int)blockIdx.x) * 12) + ((int)threadIdx.x)) % 20) / 2))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 14, 6, 10), \"float32\"), depth_to_space: T.Buffer((5, 3, 12, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(180):\n            for i3 in range(20):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused % 12\n                depth_to_space_1 = T.Buffer((3600,), data=depth_to_space.data)\n                data_1 = T.Buffer((4200,), data=data.data)\n                depth_to_space_1[i0_i1_fused_i2_fused * 20 + i3] = data_1[i0_i1_fused_i2_fused // 36 * 840 + T.truncmod(cse_var_1, 2) * 360 + T.truncmod(i3, 2) * 180 + i0_i1_fused_i2_fused % 36 // 12 * 60 + T.Div(cse_var_1, 2) * 10 + T.Div(i3, 2)]", "op_args": [5, 14, 6, 10], "input_shape": "[[5, 14, 6, 10]]", "output_shape": "[[5, 3, 12, 20]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 4; ++i1) {\n      for (int32_t i2 = 0; i2 < 10; ++i2) {\n        for (int32_t i3 = 0; i3 < 22; ++i3) {\n          depth_to_space[((((i0 * 880) + (i1 * 220)) + (i2 * 22)) + i3)] = data[((((((i0 * 880) + ((i2 % 2) * 440)) + ((i3 % 2) * 220)) + (i1 * 55)) + ((i2 / 2) * 11)) + (i3 / 2))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) / 44) * 880) + ((((((((int)blockIdx.x) % 11) * 10) + (((int)threadIdx.x) >> 1)) / 11) % 2) * 440)) + (((((((int)blockIdx.x) * 20) + ((int)threadIdx.x)) % 22) % 2) * 220)) + (((((int)blockIdx.x) % 44) / 11) * 55)) + ((((((((int)blockIdx.x) % 11) * 10) + (((int)threadIdx.x) >> 1)) / 11) / 2) * 11)) + ((((((int)blockIdx.x) * 20) + ((int)threadIdx.x)) % 22) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 16, 5, 11), \"float32\"), depth_to_space: T.Buffer((11, 4, 10, 22), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i2, i3 in T.grid(4, 10, 22):\n                cse_var_1: T.int32 = i0 * 880\n                depth_to_space_1 = T.Buffer((9680,), data=depth_to_space.data)\n                data_1 = T.Buffer((9680,), data=data.data)\n                depth_to_space_1[cse_var_1 + i1 * 220 + i2 * 22 + i3] = data_1[cse_var_1 + T.truncmod(i2, 2) * 440 + T.truncmod(i3, 2) * 220 + i1 * 55 + T.Div(i2, 2) * 11 + T.Div(i3, 2)]", "op_args": [11, 16, 5, 11], "input_shape": "[[11, 16, 5, 11]]", "output_shape": "[[11, 4, 10, 22]]"}{"op_name": "fast_exp", "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 3; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 15; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 14; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 2; ++ax3) {\n            int32_t v_ = ((int32_t)(floorf(((max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_fast_exp[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((ax0 * 420) + (ax1 * 28)) + (ax2 * 2)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 15, 14, 2), \"float32\"), T_fast_exp: T.Buffer((3, 15, 14, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(3):\n            for ax1, ax2, ax3 in T.grid(15, 14, 2):\n                cse_var_1: T.int32 = ax0 * 420 + ax1 * 28 + ax2 * 2 + ax3\n                T_fast_exp_1 = T.Buffer((1260,), data=T_fast_exp.data)\n                data_1 = T.Buffer((1260,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])", "op_args": [3, 15, 14, 2], "input_shape": "[[3, 15, 14, 2]]", "output_shape": "[[3, 15, 14, 2]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 504; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 6; ++i3) {\n      depth_to_space[((i0_i1_fused_i2_fused * 6) + i3)] = data[((((((i0_i1_fused_i2_fused / 36) * 270) + (((i0_i1_fused_i2_fused % 36) % 2) * 108)) + ((i3 % 2) * 54)) + (((i0_i1_fused_i2_fused % 36) / 2) * 3)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) >> 2) * 270) + (((((((int)blockIdx.x) & 3) * 9) + (((int)threadIdx.x) / 6)) % 2) * 108)) + (((((int)threadIdx.x) % 6) % 2) * 54)) + (((((((int)blockIdx.x) & 3) * 9) + (((int)threadIdx.x) / 6)) / 2) * 3)) + ((((int)threadIdx.x) % 6) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 5, 18, 3), \"float32\"), depth_to_space: T.Buffer((14, 1, 36, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(504):\n            for i3 in range(6):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused % 36\n                depth_to_space_1 = T.Buffer((3024,), data=depth_to_space.data)\n                data_1 = T.Buffer((3780,), data=data.data)\n                depth_to_space_1[i0_i1_fused_i2_fused * 6 + i3] = data_1[i0_i1_fused_i2_fused // 36 * 270 + T.truncmod(cse_var_1, 2) * 108 + T.truncmod(i3, 2) * 54 + T.Div(cse_var_1, 2) * 3 + T.Div(i3, 2)]", "op_args": [14, 5, 18, 3], "input_shape": "[[14, 5, 18, 3]]", "output_shape": "[[14, 1, 36, 6]]"}{"op_name": "fast_exp", "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 32; ++ax0_ax1_fused_ax2_fused) {\n      int32_t v_ = ((int32_t)(floorf(((max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_fast_exp[ax0_ax1_fused_ax2_fused] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[ax0_ax1_fused_ax2_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((int)threadIdx.x)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((int)threadIdx.x)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 1, 16, 1), \"float32\"), T_fast_exp: T.Buffer((2, 1, 16, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(32):\n            T_fast_exp_1 = T.Buffer((32,), data=T_fast_exp.data)\n            data_1 = T.Buffer((32,), data=data.data)\n            T_fast_exp_1[ax0_ax1_fused_ax2_fused] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[ax0_ax1_fused_ax2_fused])", "op_args": [2, 1, 16, 1], "input_shape": "[[2, 1, 16, 1]]", "output_shape": "[[2, 1, 16, 1]]"}{"op_name": "fast_exp", "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 81; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 12; ++ax3) {\n          int32_t v_ = ((int32_t)(floorf(((max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_fast_exp[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[(((ax0_ax1_fused * 96) + (ax2 * 12)) + ax3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 9, 8, 12), \"float32\"), T_fast_exp: T.Buffer((9, 9, 8, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(81):\n            for ax2, ax3 in T.grid(8, 12):\n                cse_var_1: T.int32 = ax0_ax1_fused * 96 + ax2 * 12 + ax3\n                T_fast_exp_1 = T.Buffer((7776,), data=T_fast_exp.data)\n                data_1 = T.Buffer((7776,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])", "op_args": [9, 9, 8, 12], "input_shape": "[[9, 9, 8, 12]]", "output_shape": "[[9, 9, 8, 12]]"}{"op_name": "fast_exp", "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 28; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n      int32_t v_ = ((int32_t)(floorf(((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_fast_exp[ax0_ax1_fused_ax2_fused_ax3_fused] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[ax0_ax1_fused_ax2_fused_ax3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((int)threadIdx.x)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((int)threadIdx.x)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((int)threadIdx.x)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 2, 7, 1), \"float32\"), T_fast_exp: T.Buffer((2, 2, 7, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(28):\n            T_fast_exp_1 = T.Buffer((28,), data=T_fast_exp.data)\n            data_1 = T.Buffer((28,), data=data.data)\n            T_fast_exp_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])", "op_args": [2, 2, 7, 1], "input_shape": "[[2, 2, 7, 1]]", "output_shape": "[[2, 2, 7, 1]]"}{"op_name": "fast_exp", "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 15; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n            int32_t v_ = ((int32_t)(floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_fast_exp[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 19, 2, 16), \"float32\"), T_fast_exp: T.Buffer((15, 19, 2, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(15):\n            for ax1, ax2, ax3 in T.grid(19, 2, 16):\n                cse_var_1: T.int32 = ax0 * 608 + ax1 * 32 + ax2 * 16 + ax3\n                T_fast_exp_1 = T.Buffer((9120,), data=T_fast_exp.data)\n                data_1 = T.Buffer((9120,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])", "op_args": [15, 19, 2, 16], "input_shape": "[[15, 19, 2, 16]]", "output_shape": "[[15, 19, 2, 16]]"}{"op_name": "fast_exp", "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 9; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 9; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 17; ++ax3) {\n            int32_t v_ = ((int32_t)(floorf(((max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_fast_exp[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((ax0 * 1530) + (ax1 * 153)) + (ax2 * 17)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) < 6885) {\n      int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_fast_exp[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 10, 9, 17), \"float32\"), T_fast_exp: T.Buffer((9, 10, 9, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(9):\n            for ax1, ax2, ax3 in T.grid(10, 9, 17):\n                cse_var_1: T.int32 = ax0 * 1530 + ax1 * 153 + ax2 * 17 + ax3\n                T_fast_exp_1 = T.Buffer((13770,), data=T_fast_exp.data)\n                data_1 = T.Buffer((13770,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])", "op_args": [9, 10, 9, 17], "input_shape": "[[9, 10, 9, 17]]", "output_shape": "[[9, 10, 9, 17]]"}{"op_name": "fast_exp", "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 20; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 3; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 14; ++ax3) {\n            int32_t v_ = ((int32_t)(floorf(((max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_fast_exp[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((ax0 * 168) + (ax1 * 56)) + (ax2 * 14)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(42) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 3, 4, 14), \"float32\"), T_fast_exp: T.Buffer((20, 3, 4, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(20):\n            for ax1, ax2, ax3 in T.grid(3, 4, 14):\n                cse_var_1: T.int32 = ax0 * 168 + ax1 * 56 + ax2 * 14 + ax3\n                T_fast_exp_1 = T.Buffer((3360,), data=T_fast_exp.data)\n                data_1 = T.Buffer((3360,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])", "op_args": [20, 3, 4, 14], "input_shape": "[[20, 3, 4, 14]]", "output_shape": "[[20, 3, 4, 14]]"}{"op_name": "fast_exp", "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 204; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 3; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n          int32_t v_ = ((int32_t)(floorf(((max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_fast_exp[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[(((ax0_ax1_fused * 48) + (ax2 * 16)) + ax3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 17, 3, 16), \"float32\"), T_fast_exp: T.Buffer((12, 17, 3, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(204):\n            for ax2, ax3 in T.grid(3, 16):\n                cse_var_1: T.int32 = ax0_ax1_fused * 48 + ax2 * 16 + ax3\n                T_fast_exp_1 = T.Buffer((9792,), data=T_fast_exp.data)\n                data_1 = T.Buffer((9792,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])", "op_args": [12, 17, 3, 16], "input_shape": "[[12, 17, 3, 16]]", "output_shape": "[[12, 17, 3, 16]]"}{"op_name": "fast_exp", "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 6; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 11; ++ax2) {\n        for (int32_t ax3_s = 0; ax3_s < 16; ++ax3_s) {\n            int32_t v_ = ((int32_t)(floorf(((max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_fast_exp[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((ax0 * 3344) + (ax1 * 176)) + (ax2 * 16)) + ax3_s)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 19, 11, 16), \"float32\"), T_fast_exp: T.Buffer((6, 19, 11, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(6):\n            for ax1, ax2, ax3_s in T.grid(19, 11, 16):\n                cse_var_1: T.int32 = ax0 * 3344 + ax1 * 176 + ax2 * 16 + ax3_s\n                T_fast_exp_1 = T.Buffer((20064,), data=T_fast_exp.data)\n                data_1 = T.Buffer((20064,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])", "op_args": [6, 19, 11, 16], "input_shape": "[[6, 19, 11, 16]]", "output_shape": "[[6, 19, 11, 16]]"}{"op_name": "fast_exp", "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 38; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 7; ++ax3) {\n          int32_t v_ = ((int32_t)(floorf(((max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_fast_exp[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[(((ax0_ax1_fused * 14) + (ax2 * 7)) + ax3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 2)) < 133) {\n      int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_fast_exp[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 19, 2, 7), \"float32\"), T_fast_exp: T.Buffer((2, 19, 2, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(38):\n            for ax2, ax3 in T.grid(2, 7):\n                cse_var_1: T.int32 = ax0_ax1_fused * 14 + ax2 * 7 + ax3\n                T_fast_exp_1 = T.Buffer((532,), data=T_fast_exp.data)\n                data_1 = T.Buffer((532,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])", "op_args": [2, 19, 2, 7], "input_shape": "[[2, 19, 2, 7]]", "output_shape": "[[2, 19, 2, 7]]"}{"op_name": "fast_tanh", "c_code": "void default_function_kernel(float* T_fast_tanh, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 24; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 6; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 5; ++ax3) {\n        T_fast_tanh[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)] = ((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 30) + (ax2 * 5)) + ax3)]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ T_fast_tanh, float* __restrict__ data) {\n  T_fast_tanh[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 2, 6, 5), \"float32\"), T_fast_tanh: T.Buffer((12, 2, 6, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(24):\n            for ax2, ax3 in T.grid(6, 5):\n                cse_var_1: T.int32 = ax0_ax1_fused * 30 + ax2 * 5 + ax3\n                T_fast_tanh_1 = T.Buffer((720,), data=T_fast_tanh.data)\n                data_1 = T.Buffer((720,), data=data.data)\n                T_fast_tanh_1[cse_var_1] = T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(-2.76076847742355e-16) + T.float32(2.0001879048247699e-13)) + T.float32(-8.60467152213735e-11)) + T.float32(5.1222970903711401e-08)) + T.float32(1.4857223571797901e-05)) + T.float32(0.00063726192887543596)) + T.float32(0.0048935245589178597)) / (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(1.1982583946670199e-06) + T.float32(0.000118534705686654)) + T.float32(0.0022684346324390002)) + T.float32(0.0048935251855438504))", "op_args": [12, 2, 6, 5], "input_shape": "[[12, 2, 6, 5]]", "output_shape": "[[12, 2, 6, 5]]"}{"op_name": "fast_tanh", "c_code": "void default_function_kernel(float* T_fast_tanh, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 6; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 17; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 16; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 17; ++ax3) {\n          T_fast_tanh[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((ax0 * 4624) + (ax1 * 272)) + (ax2 * 17)) + ax3)]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ T_fast_tanh, float* __restrict__ data) {\n  T_fast_tanh[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 17, 16, 17), \"float32\"), T_fast_tanh: T.Buffer((6, 17, 16, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(6):\n            for ax1, ax2, ax3 in T.grid(17, 16, 17):\n                cse_var_1: T.int32 = ax0 * 4624 + ax1 * 272 + ax2 * 17 + ax3\n                T_fast_tanh_1 = T.Buffer((27744,), data=T_fast_tanh.data)\n                data_1 = T.Buffer((27744,), data=data.data)\n                T_fast_tanh_1[cse_var_1] = T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(-2.76076847742355e-16) + T.float32(2.0001879048247699e-13)) + T.float32(-8.60467152213735e-11)) + T.float32(5.1222970903711401e-08)) + T.float32(1.4857223571797901e-05)) + T.float32(0.00063726192887543596)) + T.float32(0.0048935245589178597)) / (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(1.1982583946670199e-06) + T.float32(0.000118534705686654)) + T.float32(0.0022684346324390002)) + T.float32(0.0048935251855438504))", "op_args": [6, 17, 16, 17], "input_shape": "[[6, 17, 16, 17]]", "output_shape": "[[6, 17, 16, 17]]"}{"op_name": "fast_tanh", "c_code": "void default_function_kernel(float* T_fast_tanh, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 1632; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_fast_tanh[ax0_ax1_fused_ax2_fused_ax3_fused] = ((max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused])) * max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused])) * max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused])) * max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused])) * max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused])) * max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused])) * max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused])) * max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused])) * max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused])) * max(-9.000000e+00f, min(9.000000e+00f, data[ax0_ax1_fused_ax2_fused_ax3_fused]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ T_fast_tanh, float* __restrict__ data) {\n  T_fast_tanh[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 6, 17, 2), \"float32\"), T_fast_tanh: T.Buffer((8, 6, 17, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(1632):\n            T_fast_tanh_1 = T.Buffer((1632,), data=T_fast_tanh.data)\n            data_1 = T.Buffer((1632,), data=data.data)\n            T_fast_tanh_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.float32(-2.76076847742355e-16) + T.float32(2.0001879048247699e-13)) + T.float32(-8.60467152213735e-11)) + T.float32(5.1222970903711401e-08)) + T.float32(1.4857223571797901e-05)) + T.float32(0.00063726192887543596)) + T.float32(0.0048935245589178597)) / (T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[ax0_ax1_fused_ax2_fused_ax3_fused])) * T.float32(1.1982583946670199e-06) + T.float32(0.000118534705686654)) + T.float32(0.0022684346324390002)) + T.float32(0.0048935251855438504))", "op_args": [8, 6, 17, 2], "input_shape": "[[8, 6, 17, 2]]", "output_shape": "[[8, 6, 17, 2]]"}{"op_name": "fast_tanh", "c_code": "void default_function_kernel(float* T_fast_tanh, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 252; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 12; ++ax3) {\n        T_fast_tanh[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)] = ((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_fast_tanh, float* __restrict__ data) {\n  T_fast_tanh[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 14, 2, 12), \"float32\"), T_fast_tanh: T.Buffer((18, 14, 2, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(252):\n            for ax2, ax3 in T.grid(2, 12):\n                cse_var_1: T.int32 = ax0_ax1_fused * 24 + ax2 * 12 + ax3\n                T_fast_tanh_1 = T.Buffer((6048,), data=T_fast_tanh.data)\n                data_1 = T.Buffer((6048,), data=data.data)\n                T_fast_tanh_1[cse_var_1] = T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(-2.76076847742355e-16) + T.float32(2.0001879048247699e-13)) + T.float32(-8.60467152213735e-11)) + T.float32(5.1222970903711401e-08)) + T.float32(1.4857223571797901e-05)) + T.float32(0.00063726192887543596)) + T.float32(0.0048935245589178597)) / (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(1.1982583946670199e-06) + T.float32(0.000118534705686654)) + T.float32(0.0022684346324390002)) + T.float32(0.0048935251855438504))", "op_args": [18, 14, 2, 12], "input_shape": "[[18, 14, 2, 12]]", "output_shape": "[[18, 14, 2, 12]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 728; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 2; ++ax3) {\n      T_reverse_sequence[((ax0_ax1_fused_ax2_fused * 2) + ax3)] = data[(((((ax0_ax1_fused_ax2_fused % 91) * 2) + ax3) + 1274) - ((ax0_ax1_fused_ax2_fused / 91) * 182))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) % 91) * 2) + (((int)threadIdx.x) & 1)) + 1274) - ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) / 91) * 182))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 13, 7, 2), \"float32\"), T_reverse_sequence: T.Buffer((8, 13, 7, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(728):\n            for ax3 in range(2):\n                T_reverse_sequence_1 = T.Buffer((1456,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((1456,), data=data.data)\n                T_reverse_sequence_1[ax0_ax1_fused_ax2_fused * 2 + ax3] = data_1[ax0_ax1_fused_ax2_fused % 91 * 2 + ax3 + 1274 - ax0_ax1_fused_ax2_fused // 91 * 182]", "op_args": [8, 13, 7, 2], "input_shape": "[[8, 13, 7, 2]]", "output_shape": "[[8, 13, 7, 2]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 4; ++i1) {\n      for (int32_t i2 = 0; i2 < 4; ++i2) {\n        for (int32_t i3 = 0; i3 < 24; ++i3) {\n          depth_to_space[((((i0 * 384) + (i1 * 96)) + (i2 * 24)) + i3)] = data[((((((i0 * 456) + ((i2 % 2) * 192)) + ((i3 % 2) * 96)) + (i1 * 24)) + ((i2 / 2) * 12)) + (i3 / 2))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) / 24) * 456) + ((((((((int)blockIdx.x) % 6) * 2) + (((int)threadIdx.x) >> 3)) / 3) % 2) * 192)) + (((((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) % 24) % 2) * 96)) + (((((int)blockIdx.x) % 24) / 6) * 24)) + ((((((((int)blockIdx.x) % 6) * 2) + (((int)threadIdx.x) >> 3)) / 3) / 2) * 12)) + ((((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) % 24) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 19, 2, 12), \"float32\"), depth_to_space: T.Buffer((4, 4, 4, 24), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(4, 4, 24):\n                depth_to_space_1 = T.Buffer((1536,), data=depth_to_space.data)\n                data_1 = T.Buffer((1824,), data=data.data)\n                depth_to_space_1[i0 * 384 + i1 * 96 + i2 * 24 + i3] = data_1[i0 * 456 + T.truncmod(i2, 2) * 192 + T.truncmod(i3, 2) * 96 + i1 * 24 + T.Div(i2, 2) * 12 + T.Div(i3, 2)]", "op_args": [4, 19, 2, 12], "input_shape": "[[4, 19, 2, 12]]", "output_shape": "[[4, 4, 4, 24]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 15; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 16; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 5; ++ax3) {\n        T_reverse_sequence[(((ax0_ax1_fused * 80) + (ax2 * 5)) + ax3)] = data[((((ax2 * 5) + ax3) + 1120) - (ax0_ax1_fused * 80))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) % 10) * 8) + ((int)threadIdx.x)) + 1120) - ((((int)blockIdx.x) / 10) * 80))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 1, 16, 5), \"float32\"), T_reverse_sequence: T.Buffer((15, 1, 16, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(15):\n            for ax2, ax3 in T.grid(16, 5):\n                cse_var_2: T.int32 = ax2 * 5\n                cse_var_1: T.int32 = ax0_ax1_fused * 80\n                T_reverse_sequence_1 = T.Buffer((1200,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((1200,), data=data.data)\n                T_reverse_sequence_1[cse_var_1 + cse_var_2 + ax3] = data_1[cse_var_2 + ax3 + 1120 - cse_var_1]", "op_args": [15, 1, 16, 5], "input_shape": "[[15, 1, 16, 5]]", "output_shape": "[[15, 1, 16, 5]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 4; ++i1) {\n      for (int32_t i2 = 0; i2 < 32; ++i2) {\n        for (int32_t i3 = 0; i3 < 6; ++i3) {\n          depth_to_space[((((i0 * 768) + (i1 * 192)) + (i2 * 6)) + i3)] = data[((((((i0 * 768) + ((i2 % 2) * 384)) + ((i3 % 2) * 192)) + (i1 * 48)) + ((i2 / 2) * 3)) + (i3 / 2))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) / 12) * 768) + ((((((((int)blockIdx.x) % 3) * 32) + (((int)threadIdx.x) >> 1)) / 3) % 2) * 384)) + (((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 6) % 2) * 192)) + (((((int)blockIdx.x) % 12) / 3) * 48)) + ((((((((int)blockIdx.x) % 3) * 32) + (((int)threadIdx.x) >> 1)) / 3) / 2) * 3)) + ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 6) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 16, 16, 3), \"float32\"), depth_to_space: T.Buffer((4, 4, 32, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(4, 32, 6):\n                cse_var_1: T.int32 = i0 * 768\n                depth_to_space_1 = T.Buffer((3072,), data=depth_to_space.data)\n                data_1 = T.Buffer((3072,), data=data.data)\n                depth_to_space_1[cse_var_1 + i1 * 192 + i2 * 6 + i3] = data_1[cse_var_1 + T.truncmod(i2, 2) * 384 + T.truncmod(i3, 2) * 192 + i1 * 48 + T.Div(i2, 2) * 3 + T.Div(i3, 2)]", "op_args": [4, 16, 16, 3], "input_shape": "[[4, 16, 16, 3]]", "output_shape": "[[4, 4, 32, 6]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 114; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 3; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 10; ++ax3) {\n        T_reverse_sequence[(((ax0_ax1_fused * 30) + (ax2 * 10)) + ax3)] = data[((((((ax0_ax1_fused % 6) * 30) + (ax2 * 10)) + ax3) + 3240) - ((ax0_ax1_fused / 6) * 180))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) & 3) * 45) + ((int)threadIdx.x)) + 3240) - ((((int)blockIdx.x) >> 2) * 180))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 6, 3, 10), \"float32\"), T_reverse_sequence: T.Buffer((19, 6, 3, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(114):\n            for ax2, ax3 in T.grid(3, 10):\n                cse_var_1: T.int32 = ax2 * 10\n                T_reverse_sequence_1 = T.Buffer((3420,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((3420,), data=data.data)\n                T_reverse_sequence_1[ax0_ax1_fused * 30 + cse_var_1 + ax3] = data_1[ax0_ax1_fused % 6 * 30 + cse_var_1 + ax3 + 3240 - ax0_ax1_fused // 6 * 180]", "op_args": [19, 6, 3, 10], "input_shape": "[[19, 6, 3, 10]]", "output_shape": "[[19, 6, 3, 10]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 384; ++i0_i1_fused_i2_fused_i3_fused) {\n    depth_to_space[i0_i1_fused_i2_fused_i3_fused] = data[((((((i0_i1_fused_i2_fused_i3_fused >> 7) * 152) + ((((i0_i1_fused_i2_fused_i3_fused & 31) >> 1) % 2) * 64)) + ((i0_i1_fused_i2_fused_i3_fused & 1) * 32)) + (((i0_i1_fused_i2_fused_i3_fused & 127) >> 5) * 8)) + (((i0_i1_fused_i2_fused_i3_fused & 31) >> 1) / 2))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) >> 3) * 152) + (((((int)threadIdx.x) >> 1) % 2) * 64)) + ((((int)threadIdx.x) & 1) * 32)) + ((((int)blockIdx.x) & 7) * 4)) + ((((int)threadIdx.x) >> 1) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 19, 8, 1), \"float32\"), depth_to_space: T.Buffer((3, 4, 16, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(384):\n            cse_var_1: T.int32 = i0_i1_fused_i2_fused_i3_fused % 32 // 2\n            depth_to_space_1 = T.Buffer((384,), data=depth_to_space.data)\n            data_1 = T.Buffer((456,), data=data.data)\n            depth_to_space_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 128 * 152 + T.truncmod(cse_var_1, 2) * 64 + i0_i1_fused_i2_fused_i3_fused % 2 * 32 + i0_i1_fused_i2_fused_i3_fused % 128 // 32 * 8 + T.Div(cse_var_1, 2)]", "op_args": [3, 19, 8, 1], "input_shape": "[[3, 19, 8, 1]]", "output_shape": "[[3, 4, 16, 2]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 10080; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_reverse_sequence[ax0_ax1_fused_ax2_fused_ax3_fused] = data[(((ax0_ax1_fused_ax2_fused_ax3_fused % 1680) + 8400) - ((ax0_ax1_fused_ax2_fused_ax3_fused / 1680) * 1680))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) % 60) * 28) + ((int)threadIdx.x)) + 8400) - ((((int)blockIdx.x) / 60) * 1680))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 10, 14, 12), \"float32\"), T_reverse_sequence: T.Buffer((6, 10, 14, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(10080):\n            T_reverse_sequence_1 = T.Buffer((10080,), data=T_reverse_sequence.data)\n            data_1 = T.Buffer((10080,), data=data.data)\n            T_reverse_sequence_1[ax0_ax1_fused_ax2_fused_ax3_fused] = data_1[ax0_ax1_fused_ax2_fused_ax3_fused % 1680 + 8400 - ax0_ax1_fused_ax2_fused_ax3_fused // 1680 * 1680]", "op_args": [6, 10, 14, 12], "input_shape": "[[6, 10, 14, 12]]", "output_shape": "[[6, 10, 14, 12]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 13; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 4; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 4; ++ax3) {\n          T_reverse_sequence[((((ax0 * 112) + (ax1 * 28)) + (ax2 * 4)) + ax3)] = data[(((((ax1 * 28) + (ax2 * 4)) + ax3) + 1344) - (ax0 * 112))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) * 26) + ((int)threadIdx.x)) % 112) + 1344) - ((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 1)) / 56) * 112))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 4, 7, 4), \"float32\"), T_reverse_sequence: T.Buffer((13, 4, 7, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(13):\n            for ax1, ax2, ax3 in T.grid(4, 7, 4):\n                cse_var_3: T.int32 = ax1 * 28\n                cse_var_2: T.int32 = ax2 * 4\n                cse_var_1: T.int32 = ax0 * 112\n                T_reverse_sequence_1 = T.Buffer((1456,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((1456,), data=data.data)\n                T_reverse_sequence_1[cse_var_1 + cse_var_3 + cse_var_2 + ax3] = data_1[cse_var_3 + cse_var_2 + ax3 + 1344 - cse_var_1]", "op_args": [13, 4, 7, 4], "input_shape": "[[13, 4, 7, 4]]", "output_shape": "[[13, 4, 7, 4]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 210; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 8; ++i3) {\n      depth_to_space[((i0_i1_fused_i2_fused * 8) + i3)] = data[(((((((i0_i1_fused_i2_fused / 42) * 364) + (((i0_i1_fused_i2_fused % 14) % 2) * 168)) + ((i3 % 2) * 84)) + (((i0_i1_fused_i2_fused % 42) / 14) * 28)) + (((i0_i1_fused_i2_fused % 14) / 2) * 4)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 7)) / 48) * 364) + ((((((((int)blockIdx.x) * 35) + ((int)threadIdx.x)) % 112) >> 3) % 2) * 168)) + (((((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) & 7) % 2) * 84)) + (((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 7)) % 48) >> 4) * 28)) + ((((((((int)blockIdx.x) * 35) + ((int)threadIdx.x)) % 112) >> 3) / 2) * 4)) + ((((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) & 7) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 13, 7, 4), \"float32\"), depth_to_space: T.Buffer((5, 3, 14, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(210):\n            for i3 in range(8):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused % 14\n                depth_to_space_1 = T.Buffer((1680,), data=depth_to_space.data)\n                data_1 = T.Buffer((1820,), data=data.data)\n                depth_to_space_1[i0_i1_fused_i2_fused * 8 + i3] = data_1[i0_i1_fused_i2_fused // 42 * 364 + T.truncmod(cse_var_1, 2) * 168 + T.truncmod(i3, 2) * 84 + i0_i1_fused_i2_fused % 42 // 14 * 28 + T.Div(cse_var_1, 2) * 4 + T.Div(i3, 2)]", "op_args": [5, 13, 7, 4], "input_shape": "[[5, 13, 7, 4]]", "output_shape": "[[5, 3, 14, 8]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 280; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 16; ++ax2) {\n      T_reverse_sequence[((ax0_ax1_fused * 16) + ax2)] = data[(((((ax0_ax1_fused % 14) * 16) + ax2) + 4256) - ((ax0_ax1_fused / 14) * 224))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) * 40) + ((int)threadIdx.x)) % 224) + 4256) - ((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) / 28) * 224))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 14, 16, 1), \"float32\"), T_reverse_sequence: T.Buffer((20, 14, 16, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(280):\n            for ax2 in range(16):\n                T_reverse_sequence_1 = T.Buffer((4480,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((4480,), data=data.data)\n                T_reverse_sequence_1[ax0_ax1_fused * 16 + ax2] = data_1[ax0_ax1_fused % 14 * 16 + ax2 + 4256 - ax0_ax1_fused // 14 * 224]", "op_args": [20, 14, 16, 1], "input_shape": "[[20, 14, 16, 1]]", "output_shape": "[[20, 14, 16, 1]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 7; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 6; ++i2) {\n      for (int32_t i3 = 0; i3 < 34; ++i3) {\n        depth_to_space[(((i0_i1_fused * 204) + (i2 * 34)) + i3)] = data[(((((i0_i1_fused * 357) + ((i2 % 2) * 102)) + ((i3 % 2) * 51)) + ((i2 / 2) * 17)) + (i3 / 2))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(14) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] = data[((((((((((int)blockIdx.x) * 7) + (((int)threadIdx.x) >> 1)) / 102) * 357) + ((((((((int)blockIdx.x) * 7) + (((int)threadIdx.x) >> 1)) % 102) / 17) % 2) * 102)) + (((((((int)blockIdx.x) * 14) + ((int)threadIdx.x)) % 34) % 2) * 51)) + ((((((((int)blockIdx.x) * 7) + (((int)threadIdx.x) >> 1)) % 102) / 17) / 2) * 17)) + ((((((int)blockIdx.x) * 14) + ((int)threadIdx.x)) % 34) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 7, 3, 17), \"float32\"), depth_to_space: T.Buffer((7, 1, 6, 34), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(7):\n            for i2, i3 in T.grid(6, 34):\n                depth_to_space_1 = T.Buffer((1428,), data=depth_to_space.data)\n                data_1 = T.Buffer((2499,), data=data.data)\n                depth_to_space_1[i0_i1_fused * 204 + i2 * 34 + i3] = data_1[i0_i1_fused * 357 + T.truncmod(i2, 2) * 102 + T.truncmod(i3, 2) * 51 + T.Div(i2, 2) * 17 + T.Div(i3, 2)]", "op_args": [7, 7, 3, 17], "input_shape": "[[7, 7, 3, 17]]", "output_shape": "[[7, 1, 6, 34]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 13; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 12; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 13; ++ax3) {\n          T_reverse_sequence[((((ax0 * 2028) + (ax1 * 156)) + (ax2 * 13)) + ax3)] = data[(((((ax1 * 156) + (ax2 * 13)) + ax3) + 6084) - (ax0 * 2028))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 507) {\n    T_reverse_sequence[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 2028) + 6084) - ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) / 507) * 2028))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 13, 12, 13), \"float32\"), T_reverse_sequence: T.Buffer((4, 13, 12, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            for ax1, ax2, ax3 in T.grid(13, 12, 13):\n                cse_var_3: T.int32 = ax1 * 156\n                cse_var_2: T.int32 = ax2 * 13\n                cse_var_1: T.int32 = ax0 * 2028\n                T_reverse_sequence_1 = T.Buffer((8112,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((8112,), data=data.data)\n                T_reverse_sequence_1[cse_var_1 + cse_var_3 + cse_var_2 + ax3] = data_1[cse_var_3 + cse_var_2 + ax3 + 6084 - cse_var_1]", "op_args": [4, 13, 12, 13], "input_shape": "[[4, 13, 12, 13]]", "output_shape": "[[4, 13, 12, 13]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 2016; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n      T_reverse_sequence[((ax0_ax1_fused_ax2_fused * 18) + ax3)] = data[(((((ax0_ax1_fused_ax2_fused % 144) * 18) + ax3) + 33696) - ((ax0_ax1_fused_ax2_fused / 144) * 2592))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) % 54) * 48) + ((int)threadIdx.x)) + 33696) - ((((int)blockIdx.x) / 54) * 2592))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 9, 16, 18), \"float32\"), T_reverse_sequence: T.Buffer((14, 9, 16, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(2016):\n            for ax3 in range(18):\n                T_reverse_sequence_1 = T.Buffer((36288,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((36288,), data=data.data)\n                T_reverse_sequence_1[ax0_ax1_fused_ax2_fused * 18 + ax3] = data_1[ax0_ax1_fused_ax2_fused % 144 * 18 + ax3 + 33696 - ax0_ax1_fused_ax2_fused // 144 * 2592]", "op_args": [14, 9, 16, 18], "input_shape": "[[14, 9, 16, 18]]", "output_shape": "[[14, 9, 16, 18]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 8; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 13; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 4; ++ax3) {\n        T_reverse_sequence[(((ax0_ax1_fused * 52) + (ax2 * 4)) + ax3)] = data[((((((ax0_ax1_fused & 1) * 52) + (ax2 * 4)) + ax3) + 312) - ((ax0_ax1_fused >> 1) * 104))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(13) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) & 7) * 13) + ((int)threadIdx.x)) + 312) - ((((int)blockIdx.x) >> 3) * 104))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 2, 13, 4), \"float32\"), T_reverse_sequence: T.Buffer((4, 2, 13, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(8):\n            for ax2, ax3 in T.grid(13, 4):\n                cse_var_1: T.int32 = ax2 * 4\n                T_reverse_sequence_1 = T.Buffer((416,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((416,), data=data.data)\n                T_reverse_sequence_1[ax0_ax1_fused * 52 + cse_var_1 + ax3] = data_1[ax0_ax1_fused % 2 * 52 + cse_var_1 + ax3 + 312 - ax0_ax1_fused // 2 * 104]", "op_args": [4, 2, 13, 4], "input_shape": "[[4, 2, 13, 4]]", "output_shape": "[[4, 2, 13, 4]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 672; ++ax0_ax1_fused_ax2_fused) {\n    T_reverse_sequence[ax0_ax1_fused_ax2_fused] = data[(((ax0_ax1_fused_ax2_fused % 84) + 588) - ((ax0_ax1_fused_ax2_fused / 84) * 84))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 84) + 588) - ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) / 21) * 84))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 14, 6, 1), \"float32\"), T_reverse_sequence: T.Buffer((8, 14, 6, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(672):\n            T_reverse_sequence_1 = T.Buffer((672,), data=T_reverse_sequence.data)\n            data_1 = T.Buffer((672,), data=data.data)\n            T_reverse_sequence_1[ax0_ax1_fused_ax2_fused] = data_1[ax0_ax1_fused_ax2_fused % 84 + 588 - ax0_ax1_fused_ax2_fused // 84 * 84]", "op_args": [8, 14, 6, 1], "input_shape": "[[8, 14, 6, 1]]", "output_shape": "[[8, 14, 6, 1]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 13; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 17; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 17; ++ax3) {\n          T_reverse_sequence[((((ax0 * 2890) + (ax1 * 289)) + (ax2 * 17)) + ax3)] = data[(((((ax1 * 289) + (ax2 * 17)) + ax3) + 34680) - (ax0 * 2890))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 18785) {\n    T_reverse_sequence[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 2890) + 34680) - ((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 1445) * 2890))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 10, 17, 17), \"float32\"), T_reverse_sequence: T.Buffer((13, 10, 17, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(13):\n            for ax1, ax2, ax3 in T.grid(10, 17, 17):\n                cse_var_3: T.int32 = ax1 * 289\n                cse_var_2: T.int32 = ax2 * 17\n                cse_var_1: T.int32 = ax0 * 2890\n                T_reverse_sequence_1 = T.Buffer((37570,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((37570,), data=data.data)\n                T_reverse_sequence_1[cse_var_1 + cse_var_3 + cse_var_2 + ax3] = data_1[cse_var_3 + cse_var_2 + ax3 + 34680 - cse_var_1]", "op_args": [13, 10, 17, 17], "input_shape": "[[13, 10, 17, 17]]", "output_shape": "[[13, 10, 17, 17]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 380; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 20; ++ax3) {\n      T_reverse_sequence[((ax0_ax1_fused_ax2_fused * 20) + ax3)] = data[(((((ax0_ax1_fused_ax2_fused % 95) * 20) + ax3) + 5700) - ((ax0_ax1_fused_ax2_fused / 95) * 1900))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) % 38) * 50) + ((int)threadIdx.x)) + 5700) - ((((int)blockIdx.x) / 38) * 1900))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 5, 19, 20), \"float32\"), T_reverse_sequence: T.Buffer((4, 5, 19, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(380):\n            for ax3 in range(20):\n                T_reverse_sequence_1 = T.Buffer((7600,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((7600,), data=data.data)\n                T_reverse_sequence_1[ax0_ax1_fused_ax2_fused * 20 + ax3] = data_1[ax0_ax1_fused_ax2_fused % 95 * 20 + ax3 + 5700 - ax0_ax1_fused_ax2_fused // 95 * 1900]", "op_args": [4, 5, 19, 20], "input_shape": "[[4, 5, 19, 20]]", "output_shape": "[[4, 5, 19, 20]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  for (int32_t ax1 = 0; ax1 < 18; ++ax1) {\n    for (int32_t ax2 = 0; ax2 < 16; ++ax2) {\n      T_reverse_sequence[((ax1 * 16) + ax2)] = data[((ax1 * 16) + ax2)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 18, 16, 1), \"float32\"), T_reverse_sequence: T.Buffer((1, 18, 16, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax1, ax2 in T.grid(18, 16):\n            cse_var_1: T.int32 = ax1 * 16 + ax2\n            T_reverse_sequence_1 = T.Buffer((288,), data=T_reverse_sequence.data)\n            data_1 = T.Buffer((288,), data=data.data)\n            T_reverse_sequence_1[cse_var_1] = data_1[cse_var_1]", "op_args": [1, 18, 16, 1], "input_shape": "[[1, 18, 16, 1]]", "output_shape": "[[1, 18, 16, 1]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 240; ++ax0_ax1_fused) {\n    for (int32_t ax3 = 0; ax3 < 3; ++ax3) {\n      T_reverse_sequence[((ax0_ax1_fused * 3) + ax3)] = data[(((((ax0_ax1_fused % 12) * 3) + ax3) + 684) - ((ax0_ax1_fused / 12) * 36))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 45) {\n    T_reverse_sequence[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 36) + 684) - ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) / 9) * 36))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 12, 1, 3), \"float32\"), T_reverse_sequence: T.Buffer((20, 12, 1, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(240):\n            for ax3 in range(3):\n                T_reverse_sequence_1 = T.Buffer((720,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((720,), data=data.data)\n                T_reverse_sequence_1[ax0_ax1_fused * 3 + ax3] = data_1[ax0_ax1_fused % 12 * 3 + ax3 + 684 - ax0_ax1_fused // 12 * 36]", "op_args": [20, 12, 1, 3], "input_shape": "[[20, 12, 1, 3]]", "output_shape": "[[20, 12, 1, 3]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 21; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 14; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 11; ++ax3) {\n        T_reverse_sequence[(((ax0_ax1_fused * 154) + (ax2 * 11)) + ax3)] = data[((((((ax0_ax1_fused % 7) * 154) + (ax2 * 11)) + ax3) + 2156) - ((ax0_ax1_fused / 7) * 1078))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(49) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) % 22) * 49) + ((int)threadIdx.x)) + 2156) - ((((int)blockIdx.x) / 22) * 1078))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 7, 14, 11), \"float32\"), T_reverse_sequence: T.Buffer((3, 7, 14, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(21):\n            for ax2, ax3 in T.grid(14, 11):\n                cse_var_1: T.int32 = ax2 * 11\n                T_reverse_sequence_1 = T.Buffer((3234,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((3234,), data=data.data)\n                T_reverse_sequence_1[ax0_ax1_fused * 154 + cse_var_1 + ax3] = data_1[ax0_ax1_fused % 7 * 154 + cse_var_1 + ax3 + 2156 - ax0_ax1_fused // 7 * 1078]", "op_args": [3, 7, 14, 11], "input_shape": "[[3, 7, 14, 11]]", "output_shape": "[[3, 7, 14, 11]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 2100; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_reverse_sequence[ax0_ax1_fused_ax2_fused_ax3_fused] = data[(((ax0_ax1_fused_ax2_fused_ax3_fused % 140) + 1960) - ((ax0_ax1_fused_ax2_fused_ax3_fused / 140) * 140))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) / 5)) % 28) * 5) + (((int)threadIdx.x) % 5)) + 1960) - ((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 10)) / 14) * 140))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 4, 7, 5), \"float32\"), T_reverse_sequence: T.Buffer((15, 4, 7, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(2100):\n            T_reverse_sequence_1 = T.Buffer((2100,), data=T_reverse_sequence.data)\n            data_1 = T.Buffer((2100,), data=data.data)\n            T_reverse_sequence_1[ax0_ax1_fused_ax2_fused_ax3_fused] = data_1[ax0_ax1_fused_ax2_fused_ax3_fused % 140 + 1960 - ax0_ax1_fused_ax2_fused_ax3_fused // 140 * 140]", "op_args": [15, 4, 7, 5], "input_shape": "[[15, 4, 7, 5]]", "output_shape": "[[15, 4, 7, 5]]"}{"op_name": "flip", "c_code": "void default_function_kernel(float* T_reverse_sequence, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 18; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 5; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 14; ++ax3) {\n          T_reverse_sequence[((((ax0 * 280) + (ax1 * 56)) + (ax2 * 14)) + ax3)] = data[(((((ax1 * 56) + (ax2 * 14)) + ax3) + 4760) - (ax0 * 280))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ T_reverse_sequence, float* __restrict__ data) {\n  T_reverse_sequence[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = data[(((((((int)blockIdx.x) * 60) + ((int)threadIdx.x)) % 280) + 4760) - ((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20)) / 14) * 280))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 5, 4, 14), \"float32\"), T_reverse_sequence: T.Buffer((18, 5, 4, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(18):\n            for ax1, ax2, ax3 in T.grid(5, 4, 14):\n                cse_var_3: T.int32 = ax1 * 56\n                cse_var_2: T.int32 = ax2 * 14\n                cse_var_1: T.int32 = ax0 * 280\n                T_reverse_sequence_1 = T.Buffer((5040,), data=T_reverse_sequence.data)\n                data_1 = T.Buffer((5040,), data=data.data)\n                T_reverse_sequence_1[cse_var_1 + cse_var_3 + cse_var_2 + ax3] = data_1[cse_var_3 + cse_var_2 + ax3 + 4760 - cse_var_1]", "op_args": [18, 5, 4, 14], "input_shape": "[[18, 5, 4, 14]]", "output_shape": "[[18, 5, 4, 14]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 187; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 11; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 11) + i3)] = floorf(data[((i0_i1_fused_i2_fused * 11) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) < 2057) {\n    compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 1, 17, 11), \"float32\"), compute: T.Buffer((11, 1, 17, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(187):\n            for i3 in range(11):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 11 + i3\n                compute_1 = T.Buffer((2057,), data=compute.data)\n                data_1 = T.Buffer((2057,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [11, 1, 17, 11], "input_shape": "[[11, 1, 17, 11]]", "output_shape": "[[11, 1, 17, 11]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 2; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 10; ++i2) {\n      for (int32_t i3 = 0; i3 < 15; ++i3) {\n        compute[(((i0_i1_fused * 150) + (i2 * 15)) + i3)] = floorf(data[(((i0_i1_fused * 150) + (i2 * 15)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 1, 10, 15), \"float32\"), compute: T.Buffer((2, 1, 10, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(2):\n            for i2, i3 in T.grid(10, 15):\n                cse_var_1: T.int32 = i0_i1_fused * 150 + i2 * 15 + i3\n                compute_1 = T.Buffer((300,), data=compute.data)\n                data_1 = T.Buffer((300,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [2, 1, 10, 15], "input_shape": "[[2, 1, 10, 15]]", "output_shape": "[[2, 1, 10, 15]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 12; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 18; ++i3) {\n          compute[((((i0 * 972) + (i1 * 108)) + (i2 * 18)) + i3)] = floorf(data[((((i0 * 972) + (i1 * 108)) + (i2 * 18)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 9, 6, 18), \"float32\"), compute: T.Buffer((12, 9, 6, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(12):\n            for i1, i2, i3 in T.grid(9, 6, 18):\n                cse_var_1: T.int32 = i0 * 972 + i1 * 108 + i2 * 18 + i3\n                compute_1 = T.Buffer((11664,), data=compute.data)\n                data_1 = T.Buffer((11664,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [12, 9, 6, 18], "input_shape": "[[12, 9, 6, 18]]", "output_shape": "[[12, 9, 6, 18]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1900; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = floorf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 475) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 2, 5, 10), \"float32\"), compute: T.Buffer((19, 2, 5, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1900):\n            compute_1 = T.Buffer((1900,), data=compute.data)\n            data_1 = T.Buffer((1900,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.floor(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [19, 2, 5, 10], "input_shape": "[[19, 2, 5, 10]]", "output_shape": "[[19, 2, 5, 10]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 39; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 17; ++i2) {\n      compute[((i0_i1_fused * 17) + i2)] = floorf(data[((i0_i1_fused * 17) + i2)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(51) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 13, 17, 1), \"float32\"), compute: T.Buffer((3, 13, 17, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(39):\n            for i2 in range(17):\n                cse_var_1: T.int32 = i0_i1_fused * 17 + i2\n                compute_1 = T.Buffer((663,), data=compute.data)\n                data_1 = T.Buffer((663,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [3, 13, 17, 1], "input_shape": "[[3, 13, 17, 1]]", "output_shape": "[[3, 13, 17, 1]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 594; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 10; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 10) + i3)] = floorf(data[((i0_i1_fused_i2_fused * 10) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(15) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 18, 11, 10), \"float32\"), compute: T.Buffer((3, 18, 11, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(594):\n            for i3 in range(10):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 10 + i3\n                compute_1 = T.Buffer((5940,), data=compute.data)\n                data_1 = T.Buffer((5940,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [3, 18, 11, 10], "input_shape": "[[3, 18, 11, 10]]", "output_shape": "[[3, 18, 11, 10]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 6; ++i0) {\n    for (int32_t i1 = 0; i1 < 3; ++i1) {\n      for (int32_t i3 = 0; i3 < 6; ++i3) {\n        compute[(((i0 * 18) + (i1 * 6)) + i3)] = floorf(data[(((i0 * 18) + (i1 * 6)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 3, 1, 6), \"float32\"), compute: T.Buffer((6, 3, 1, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(6):\n            for i1, i3 in T.grid(3, 6):\n                cse_var_1: T.int32 = i0 * 18 + i1 * 6 + i3\n                compute_1 = T.Buffer((108,), data=compute.data)\n                data_1 = T.Buffer((108,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [6, 3, 1, 6], "input_shape": "[[6, 3, 1, 6]]", "output_shape": "[[6, 3, 1, 6]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 204; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 20; ++i2) {\n      for (int32_t i3 = 0; i3 < 17; ++i3) {\n        compute[(((i0_i1_fused * 340) + (i2 * 17)) + i3)] = floorf(data[(((i0_i1_fused * 340) + (i2 * 17)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 17, 20, 17), \"float32\"), compute: T.Buffer((12, 17, 20, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(204):\n            for i2, i3 in T.grid(20, 17):\n                cse_var_1: T.int32 = i0_i1_fused * 340 + i2 * 17 + i3\n                compute_1 = T.Buffer((69360,), data=compute.data)\n                data_1 = T.Buffer((69360,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [12, 17, 20, 17], "input_shape": "[[12, 17, 20, 17]]", "output_shape": "[[12, 17, 20, 17]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 16; ++i1) {\n    for (int32_t i2 = 0; i2 < 13; ++i2) {\n      for (int32_t i3 = 0; i3 < 5; ++i3) {\n        compute[(((i1 * 65) + (i2 * 5)) + i3)] = floorf(data[(((i1 * 65) + (i2 * 5)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 65) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 16, 13, 5), \"float32\"), compute: T.Buffer((1, 16, 13, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(16, 13, 5):\n            cse_var_1: T.int32 = i1 * 65 + i2 * 5 + i3\n            compute_1 = T.Buffer((1040,), data=compute.data)\n            data_1 = T.Buffer((1040,), data=data.data)\n            compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [1, 16, 13, 5], "input_shape": "[[1, 16, 13, 5]]", "output_shape": "[[1, 16, 13, 5]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 255; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 11; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 11) + i3)] = floorf(data[((i0_i1_fused_i2_fused * 11) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(55) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 1, 15, 11), \"float32\"), compute: T.Buffer((17, 1, 15, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(255):\n            for i3 in range(11):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 11 + i3\n                compute_1 = T.Buffer((2805,), data=compute.data)\n                data_1 = T.Buffer((2805,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [17, 1, 15, 11], "input_shape": "[[17, 1, 15, 11]]", "output_shape": "[[17, 1, 15, 11]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 684; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 15; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 15) + i3)] = floorf(data[((i0_i1_fused_i2_fused * 15) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(27) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 27) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 27) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 19, 12, 15), \"float32\"), compute: T.Buffer((3, 19, 12, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(684):\n            for i3 in range(15):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 15 + i3\n                compute_1 = T.Buffer((10260,), data=compute.data)\n                data_1 = T.Buffer((10260,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [3, 19, 12, 15], "input_shape": "[[3, 19, 12, 15]]", "output_shape": "[[3, 19, 12, 15]]"}{"op_name": "floor", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 8; ++i2) {\n        for (int32_t i3 = 0; i3 < 8; ++i3) {\n          compute[((((i0 * 128) + (i1 * 64)) + (i2 * 8)) + i3)] = floorf(data[((((i0 * 128) + (i1 * 64)) + (i2 * 8)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 8, 8), \"float32\"), compute: T.Buffer((17, 2, 8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(17):\n            for i1, i2, i3 in T.grid(2, 8, 8):\n                cse_var_1: T.int32 = i0 * 128 + i1 * 64 + i2 * 8 + i3\n                compute_1 = T.Buffer((2176,), data=compute.data)\n                data_1 = T.Buffer((2176,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])", "op_args": [17, 2, 8, 8], "input_shape": "[[17, 2, 8, 8]]", "output_shape": "[[17, 2, 8, 8]]"}{"op_name": "isnan", "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5814; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((int8_t)(data[i0_i1_fused_i2_fused_i3_fused] != data[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(51) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 18, 1, 19), \"float32\"), compute: T.Buffer((17, 18, 1, 19), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(5814):\n            compute_1 = T.Buffer((5814,), \"int8\", data=compute.data)\n            data_1 = T.Buffer((5814,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.Cast(\"int8\", T.isnan(data_1[i0_i1_fused_i2_fused_i3_fused]))", "op_args": [17, 18, 1, 19], "input_shape": "[[17, 18, 1, 19]]", "output_shape": "[[17, 18, 1, 19]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 120; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 8; ++i3) {\n      depth_to_space[((i0_i1_fused_i2_fused * 8) + i3)] = data[(((((((i0_i1_fused_i2_fused / 40) * 360) + (((i0_i1_fused_i2_fused % 20) % 2) * 160)) + ((i3 % 2) * 80)) + (((i0_i1_fused_i2_fused % 40) / 20) * 40)) + (((i0_i1_fused_i2_fused % 20) / 2) * 4)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) / 40) * 360) + (((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) % 20) % 2) * 160)) + (((((int)threadIdx.x) & 7) % 2) * 80)) + (((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) % 40) / 20) * 40)) + (((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) % 20) / 2) * 4)) + ((((int)threadIdx.x) & 7) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 9, 10, 4), \"float32\"), depth_to_space: T.Buffer((3, 2, 20, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(120):\n            for i3 in range(8):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused % 20\n                depth_to_space_1 = T.Buffer((960,), data=depth_to_space.data)\n                data_1 = T.Buffer((1080,), data=data.data)\n                depth_to_space_1[i0_i1_fused_i2_fused * 8 + i3] = data_1[i0_i1_fused_i2_fused // 40 * 360 + T.truncmod(cse_var_1, 2) * 160 + T.truncmod(i3, 2) * 80 + i0_i1_fused_i2_fused % 40 // 20 * 40 + T.Div(cse_var_1, 2) * 4 + T.Div(i3, 2)]", "op_args": [3, 9, 10, 4], "input_shape": "[[3, 9, 10, 4]]", "output_shape": "[[3, 2, 20, 8]]"}{"op_name": "isnan", "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 4199; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 2; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 2) + i3_s)] = ((int8_t)(data[((i0_i1_fused_i2_fused * 2) + i3_s)] != data[((i0_i1_fused_i2_fused * 2) + i3_s)]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 4199) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 19, 17, 2), \"float32\"), compute: T.Buffer((13, 19, 17, 2), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(4199):\n            for i3_s in range(2):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 2 + i3_s\n                compute_1 = T.Buffer((8398,), \"int8\", data=compute.data)\n                data_1 = T.Buffer((8398,), data=data.data)\n                compute_1[cse_var_1] = T.Cast(\"int8\", T.isnan(data_1[cse_var_1]))", "op_args": [13, 19, 17, 2], "input_shape": "[[13, 19, 17, 2]]", "output_shape": "[[13, 19, 17, 2]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 8; ++i2) {\n        for (int32_t i3 = 0; i3 < 40; ++i3) {\n          depth_to_space[((((i0 * 640) + (i1 * 320)) + (i2 * 40)) + i3)] = data[((((((i0 * 640) + ((i2 % 2) * 320)) + ((i3 % 2) * 160)) + (i1 * 80)) + ((i2 / 2) * 20)) + (i3 / 2))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(52) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 2)) / 160) * 640) + ((((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 2)) % 80) / 10) % 2) * 320)) + (((((((int)blockIdx.x) * 12) + ((int)threadIdx.x)) % 40) % 2) * 160)) + (((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 2)) % 160) / 80) * 80)) + ((((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 2)) % 80) / 10) / 2) * 20)) + ((((((int)blockIdx.x) * 12) + ((int)threadIdx.x)) % 40) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 8, 4, 20), \"float32\"), depth_to_space: T.Buffer((13, 2, 8, 40), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3 in T.grid(2, 8, 40):\n                cse_var_1: T.int32 = i0 * 640\n                depth_to_space_1 = T.Buffer((8320,), data=depth_to_space.data)\n                data_1 = T.Buffer((8320,), data=data.data)\n                depth_to_space_1[cse_var_1 + i1 * 320 + i2 * 40 + i3] = data_1[cse_var_1 + T.truncmod(i2, 2) * 320 + T.truncmod(i3, 2) * 160 + i1 * 80 + T.Div(i2, 2) * 20 + T.Div(i3, 2)]", "op_args": [13, 8, 4, 20], "input_shape": "[[13, 8, 4, 20]]", "output_shape": "[[13, 2, 8, 40]]"}{"op_name": "isnan", "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 924; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 7; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 7) + i3_s)] = ((int8_t)(data[((i0_i1_fused_i2_fused * 7) + i3_s)] != data[((i0_i1_fused_i2_fused * 7) + i3_s)]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 1617) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 11, 6, 7), \"float32\"), compute: T.Buffer((14, 11, 6, 7), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(924):\n            for i3_s in range(7):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 7 + i3_s\n                compute_1 = T.Buffer((6468,), \"int8\", data=compute.data)\n                data_1 = T.Buffer((6468,), data=data.data)\n                compute_1[cse_var_1] = T.Cast(\"int8\", T.isnan(data_1[cse_var_1]))", "op_args": [14, 11, 6, 7], "input_shape": "[[14, 11, 6, 7]]", "output_shape": "[[14, 11, 6, 7]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 280; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 40; ++i3) {\n      depth_to_space[((i0_i1_fused_i2_fused * 40) + i3)] = data[(((((((i0_i1_fused_i2_fused / 28) * 1400) + (((i0_i1_fused_i2_fused % 14) % 2) * 560)) + ((i3 % 2) * 280)) + (((i0_i1_fused_i2_fused % 28) / 14) * 140)) + (((i0_i1_fused_i2_fused % 14) / 2) * 20)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10)) / 112) * 1400) + ((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10)) % 56) >> 2) % 2) * 560)) + (((((((int)blockIdx.x) * 10) + ((int)threadIdx.x)) % 40) % 2) * 280)) + (((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10)) % 112) / 56) * 140)) + ((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10)) % 56) >> 2) / 2) * 20)) + ((((((int)blockIdx.x) * 10) + ((int)threadIdx.x)) % 40) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 10, 7, 20), \"float32\"), depth_to_space: T.Buffer((10, 2, 14, 40), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(280):\n            for i3 in range(40):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused % 14\n                depth_to_space_1 = T.Buffer((11200,), data=depth_to_space.data)\n                data_1 = T.Buffer((14000,), data=data.data)\n                depth_to_space_1[i0_i1_fused_i2_fused * 40 + i3] = data_1[i0_i1_fused_i2_fused // 28 * 1400 + T.truncmod(cse_var_1, 2) * 560 + T.truncmod(i3, 2) * 280 + i0_i1_fused_i2_fused % 28 // 14 * 140 + T.Div(cse_var_1, 2) * 20 + T.Div(i3, 2)]", "op_args": [10, 10, 7, 20], "input_shape": "[[10, 10, 7, 20]]", "output_shape": "[[10, 2, 14, 40]]"}{"op_name": "isnan", "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2304; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((int8_t)(data[i0_i1_fused_i2_fused_i3_fused] != data[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 3, 16, 6), \"float32\"), compute: T.Buffer((8, 3, 16, 6), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2304):\n            compute_1 = T.Buffer((2304,), \"int8\", data=compute.data)\n            data_1 = T.Buffer((2304,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.Cast(\"int8\", T.isnan(data_1[i0_i1_fused_i2_fused_i3_fused]))", "op_args": [8, 3, 16, 6], "input_shape": "[[8, 3, 16, 6]]", "output_shape": "[[8, 3, 16, 6]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 200; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 22; ++i3) {\n      depth_to_space[((i0_i1_fused_i2_fused * 22) + i3)] = data[(((((((i0_i1_fused_i2_fused / 40) * 935) + (((i0_i1_fused_i2_fused % 10) % 2) * 440)) + ((i3 % 2) * 220)) + (((i0_i1_fused_i2_fused % 40) / 10) * 55)) + (((i0_i1_fused_i2_fused % 10) / 2) * 11)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10)) / 88) * 935) + ((((((((int)blockIdx.x) * 25) + (((int)threadIdx.x) >> 1)) % 110) / 11) % 2) * 440)) + (((((((int)blockIdx.x) * 6) + ((int)threadIdx.x)) % 22) % 2) * 220)) + (((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10)) % 88) / 22) * 55)) + ((((((((int)blockIdx.x) * 25) + (((int)threadIdx.x) >> 1)) % 110) / 11) / 2) * 11)) + ((((((int)blockIdx.x) * 6) + ((int)threadIdx.x)) % 22) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 17, 5, 11), \"float32\"), depth_to_space: T.Buffer((5, 4, 10, 22), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(200):\n            for i3 in range(22):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused % 10\n                depth_to_space_1 = T.Buffer((4400,), data=depth_to_space.data)\n                data_1 = T.Buffer((4675,), data=data.data)\n                depth_to_space_1[i0_i1_fused_i2_fused * 22 + i3] = data_1[i0_i1_fused_i2_fused // 40 * 935 + T.truncmod(cse_var_1, 2) * 440 + T.truncmod(i3, 2) * 220 + i0_i1_fused_i2_fused % 40 // 10 * 55 + T.Div(cse_var_1, 2) * 11 + T.Div(i3, 2)]", "op_args": [5, 17, 5, 11], "input_shape": "[[5, 17, 5, 11]]", "output_shape": "[[5, 4, 10, 22]]"}{"op_name": "isnan", "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 30; ++i0_i1_fused) {\n    for (int32_t i3 = 0; i3 < 19; ++i3) {\n      compute[((i0_i1_fused * 19) + i3)] = ((int8_t)(data[((i0_i1_fused * 19) + i3)] != data[((i0_i1_fused * 19) + i3)]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 2, 1, 19), \"float32\"), compute: T.Buffer((15, 2, 1, 19), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(30):\n            for i3 in range(19):\n                cse_var_1: T.int32 = i0_i1_fused * 19 + i3\n                compute_1 = T.Buffer((570,), \"int8\", data=compute.data)\n                data_1 = T.Buffer((570,), data=data.data)\n                compute_1[cse_var_1] = T.Cast(\"int8\", T.isnan(data_1[cse_var_1]))", "op_args": [15, 2, 1, 19], "input_shape": "[[15, 2, 1, 19]]", "output_shape": "[[15, 2, 1, 19]]"}{"op_name": "isnan", "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 42; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 15; ++i2) {\n      for (int32_t i3 = 0; i3 < 3; ++i3) {\n        compute[(((i0_i1_fused * 45) + (i2 * 3)) + i3)] = ((int8_t)(data[(((i0_i1_fused * 45) + (i2 * 3)) + i3)] != data[(((i0_i1_fused * 45) + (i2 * 3)) + i3)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(14) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 3, 15, 3), \"float32\"), compute: T.Buffer((14, 3, 15, 3), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(42):\n            for i2, i3 in T.grid(15, 3):\n                cse_var_1: T.int32 = i0_i1_fused * 45 + i2 * 3 + i3\n                compute_1 = T.Buffer((1890,), \"int8\", data=compute.data)\n                data_1 = T.Buffer((1890,), data=data.data)\n                compute_1[cse_var_1] = T.Cast(\"int8\", T.isnan(data_1[cse_var_1]))", "op_args": [14, 3, 15, 3], "input_shape": "[[14, 3, 15, 3]]", "output_shape": "[[14, 3, 15, 3]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  for (int32_t i1 = 0; i1 < 4; ++i1) {\n    for (int32_t i2 = 0; i2 < 26; ++i2) {\n      for (int32_t i3 = 0; i3 < 28; ++i3) {\n        depth_to_space[(((i1 * 728) + (i2 * 28)) + i3)] = data[((((((i2 % 2) * 1456) + ((i3 % 2) * 728)) + (i1 * 182)) + ((i2 / 2) * 14)) + (i3 / 2))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[((((((((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) % 182) / 7) % 2) * 1456) + (((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 28) % 2) * 728)) + ((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) / 91) * 182)) + ((((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) % 182) / 7) / 2) * 14)) + ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 28) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 18, 13, 14), \"float32\"), depth_to_space: T.Buffer((1, 4, 26, 28), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(4, 26, 28):\n            depth_to_space_1 = T.Buffer((2912,), data=depth_to_space.data)\n            data_1 = T.Buffer((3276,), data=data.data)\n            depth_to_space_1[i1 * 728 + i2 * 28 + i3] = data_1[T.truncmod(i2, 2) * 1456 + T.truncmod(i3, 2) * 728 + i1 * 182 + T.Div(i2, 2) * 14 + T.Div(i3, 2)]", "op_args": [1, 18, 13, 14], "input_shape": "[[1, 18, 13, 14]]", "output_shape": "[[1, 4, 26, 28]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 14; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 12; ++i3) {\n        depth_to_space[(((i0_i1_fused * 168) + (i2 * 12)) + i3)] = data[(((((i0_i1_fused * 294) + ((i2 % 2) * 84)) + ((i3 % 2) * 42)) + ((i2 / 2) * 6)) + (i3 / 2))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(49) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))] = data[((((((((((int)blockIdx.x) * 7) + (((int)threadIdx.x) / 7)) / 24) * 294) + ((((((((int)blockIdx.x) * 49) + ((int)threadIdx.x)) % 168) / 12) % 2) * 84)) + ((((((int)blockIdx.x) + ((int)threadIdx.x)) % 12) % 2) * 42)) + ((((((((int)blockIdx.x) * 49) + ((int)threadIdx.x)) % 168) / 12) / 2) * 6)) + (((((int)blockIdx.x) + ((int)threadIdx.x)) % 12) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 7, 7, 6), \"float32\"), depth_to_space: T.Buffer((14, 1, 14, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(14):\n            for i2, i3 in T.grid(14, 12):\n                depth_to_space_1 = T.Buffer((2352,), data=depth_to_space.data)\n                data_1 = T.Buffer((4116,), data=data.data)\n                depth_to_space_1[i0_i1_fused * 168 + i2 * 12 + i3] = data_1[i0_i1_fused * 294 + T.truncmod(i2, 2) * 84 + T.truncmod(i3, 2) * 42 + T.Div(i2, 2) * 6 + T.Div(i3, 2)]", "op_args": [14, 7, 7, 6], "input_shape": "[[14, 7, 7, 6]]", "output_shape": "[[14, 1, 14, 12]]"}{"op_name": "isnan", "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1080; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 15; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 15) + i3_s)] = ((int8_t)(data[((i0_i1_fused_i2_fused * 15) + i3_s)] != data[((i0_i1_fused_i2_fused * 15) + i3_s)]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 2025) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 12, 15, 15), \"float32\"), compute: T.Buffer((6, 12, 15, 15), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1080):\n            for i3_s in range(15):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 15 + i3_s\n                compute_1 = T.Buffer((16200,), \"int8\", data=compute.data)\n                data_1 = T.Buffer((16200,), data=data.data)\n                compute_1[cse_var_1] = T.Cast(\"int8\", T.isnan(data_1[cse_var_1]))", "op_args": [6, 12, 15, 15], "input_shape": "[[6, 12, 15, 15]]", "output_shape": "[[6, 12, 15, 15]]"}{"op_name": "isnan", "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 112; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 19; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 5; ++i3_s) {\n        compute[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)] = ((int8_t)(data[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)] != data[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 665) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 8, 19, 5), \"float32\"), compute: T.Buffer((14, 8, 19, 5), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(112):\n            for i2, i3_s in T.grid(19, 5):\n                cse_var_1: T.int32 = i0_i1_fused * 95 + i2 * 5 + i3_s\n                compute_1 = T.Buffer((10640,), \"int8\", data=compute.data)\n                data_1 = T.Buffer((10640,), data=data.data)\n                compute_1[cse_var_1] = T.Cast(\"int8\", T.isnan(data_1[cse_var_1]))", "op_args": [14, 8, 19, 5], "input_shape": "[[14, 8, 19, 5]]", "output_shape": "[[14, 8, 19, 5]]"}{"op_name": "isnan", "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 11088; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((int8_t)(data[i0_i1_fused_i2_fused_i3_fused] != data[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 9, 7, 16), \"float32\"), compute: T.Buffer((11, 9, 7, 16), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(11088):\n            compute_1 = T.Buffer((11088,), \"int8\", data=compute.data)\n            data_1 = T.Buffer((11088,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.Cast(\"int8\", T.isnan(data_1[i0_i1_fused_i2_fused_i3_fused]))", "op_args": [11, 9, 7, 16], "input_shape": "[[11, 9, 7, 16]]", "output_shape": "[[11, 9, 7, 16]]"}{"op_name": "isnan", "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 19; ++i1) {\n      for (int32_t i2 = 0; i2 < 18; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 14; ++i3_s) {\n          compute[((((i0 * 4788) + (i1 * 252)) + (i2 * 14)) + i3_s)] = ((int8_t)(data[((((i0 * 4788) + (i1 * 252)) + (i2 * 14)) + i3_s)] != data[((((i0 * 4788) + (i1 * 252)) + (i2 * 14)) + i3_s)]));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 19, 18, 14), \"float32\"), compute: T.Buffer((15, 19, 18, 14), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(15):\n            for i1, i2, i3_s in T.grid(19, 18, 14):\n                cse_var_1: T.int32 = i0 * 4788 + i1 * 252 + i2 * 14 + i3_s\n                compute_1 = T.Buffer((71820,), \"int8\", data=compute.data)\n                data_1 = T.Buffer((71820,), data=data.data)\n                compute_1[cse_var_1] = T.Cast(\"int8\", T.isnan(data_1[cse_var_1]))", "op_args": [15, 19, 18, 14], "input_shape": "[[15, 19, 18, 14]]", "output_shape": "[[15, 19, 18, 14]]"}{"op_name": "log", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 120; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 20; ++i2) {\n      for (int32_t i3 = 0; i3 < 18; ++i3) {\n        compute[(((i0_i1_fused * 360) + (i2 * 18)) + i3)] = logf(data[(((i0_i1_fused * 360) + (i2 * 18)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = __logf(data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 20, 20, 18), \"float32\"), compute: T.Buffer((6, 20, 20, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(120):\n            for i2, i3 in T.grid(20, 18):\n                cse_var_1: T.int32 = i0_i1_fused * 360 + i2 * 18 + i3\n                compute_1 = T.Buffer((43200,), data=compute.data)\n                data_1 = T.Buffer((43200,), data=data.data)\n                compute_1[cse_var_1] = T.log(data_1[cse_var_1])", "op_args": [6, 20, 20, 18], "input_shape": "[[6, 20, 20, 18]]", "output_shape": "[[6, 20, 20, 18]]"}{"op_name": "log", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 560; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 7; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 7) + i3)] = logf(data[((i0_i1_fused_i2_fused * 7) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = __logf(data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 5, 8, 7), \"float32\"), compute: T.Buffer((14, 5, 8, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(560):\n            for i3 in range(7):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 7 + i3\n                compute_1 = T.Buffer((3920,), data=compute.data)\n                data_1 = T.Buffer((3920,), data=data.data)\n                compute_1[cse_var_1] = T.log(data_1[cse_var_1])", "op_args": [14, 5, 8, 7], "input_shape": "[[14, 5, 8, 7]]", "output_shape": "[[14, 5, 8, 7]]"}{"op_name": "log", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 8; ++i0) {\n    for (int32_t i1 = 0; i1 < 7; ++i1) {\n      for (int32_t i2 = 0; i2 < 7; ++i2) {\n        for (int32_t i3 = 0; i3 < 16; ++i3) {\n          compute[((((i0 * 784) + (i1 * 112)) + (i2 * 16)) + i3)] = logf(data[((((i0 * 784) + (i1 * 112)) + (i2 * 16)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = __logf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 7, 7, 16), \"float32\"), compute: T.Buffer((8, 7, 7, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(8):\n            for i1, i2, i3 in T.grid(7, 7, 16):\n                cse_var_1: T.int32 = i0 * 784 + i1 * 112 + i2 * 16 + i3\n                compute_1 = T.Buffer((6272,), data=compute.data)\n                data_1 = T.Buffer((6272,), data=data.data)\n                compute_1[cse_var_1] = T.log(data_1[cse_var_1])", "op_args": [8, 7, 7, 16], "input_shape": "[[8, 7, 7, 16]]", "output_shape": "[[8, 7, 7, 16]]"}{"op_name": "log", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 12; ++i0) {\n    for (int32_t i1 = 0; i1 < 5; ++i1) {\n      for (int32_t i2 = 0; i2 < 9; ++i2) {\n        for (int32_t i3 = 0; i3 < 16; ++i3) {\n          compute[((((i0 * 720) + (i1 * 144)) + (i2 * 16)) + i3)] = logf(data[((((i0 * 720) + (i1 * 144)) + (i2 * 16)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = __logf(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 5, 9, 16), \"float32\"), compute: T.Buffer((12, 5, 9, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(12):\n            for i1, i2, i3 in T.grid(5, 9, 16):\n                cse_var_1: T.int32 = i0 * 720 + i1 * 144 + i2 * 16 + i3\n                compute_1 = T.Buffer((8640,), data=compute.data)\n                data_1 = T.Buffer((8640,), data=data.data)\n                compute_1[cse_var_1] = T.log(data_1[cse_var_1])", "op_args": [12, 5, 9, 16], "input_shape": "[[12, 5, 9, 16]]", "output_shape": "[[12, 5, 9, 16]]"}{"op_name": "log", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 3; ++i0) {\n    for (int32_t i1 = 0; i1 < 18; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 1836) + (i1 * 102)) + (i2 * 17)) + i3)] = logf(data[((((i0 * 1836) + (i1 * 102)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(51) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = __logf(data[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 18, 6, 17), \"float32\"), compute: T.Buffer((3, 18, 6, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(3):\n            for i1, i2, i3 in T.grid(18, 6, 17):\n                cse_var_1: T.int32 = i0 * 1836 + i1 * 102 + i2 * 17 + i3\n                compute_1 = T.Buffer((5508,), data=compute.data)\n                data_1 = T.Buffer((5508,), data=data.data)\n                compute_1[cse_var_1] = T.log(data_1[cse_var_1])", "op_args": [3, 18, 6, 17], "input_shape": "[[3, 18, 6, 17]]", "output_shape": "[[3, 18, 6, 17]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 200; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 2; ++i2) {\n      for (int32_t i3 = 0; i3 < 12; ++i3) {\n        compute[(((i0_i1_fused * 24) + (i2 * 12)) + i3)] = log10f(data[(((i0_i1_fused * 24) + (i2 * 12)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 10, 2, 12), \"float32\"), compute: T.Buffer((20, 10, 2, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(200):\n            for i2, i3 in T.grid(2, 12):\n                cse_var_1: T.int32 = i0_i1_fused * 24 + i2 * 12 + i3\n                compute_1 = T.Buffer((4800,), data=compute.data)\n                data_1 = T.Buffer((4800,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [20, 10, 2, 12], "input_shape": "[[20, 10, 2, 12]]", "output_shape": "[[20, 10, 2, 12]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 42; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      for (int32_t i3 = 0; i3 < 6; ++i3) {\n        compute[(((i0_i1_fused * 18) + (i2 * 6)) + i3)] = log10f(data[(((i0_i1_fused * 18) + (i2 * 6)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 6, 3, 6), \"float32\"), compute: T.Buffer((7, 6, 3, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(42):\n            for i2, i3 in T.grid(3, 6):\n                cse_var_1: T.int32 = i0_i1_fused * 18 + i2 * 6 + i3\n                compute_1 = T.Buffer((756,), data=compute.data)\n                data_1 = T.Buffer((756,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [7, 6, 3, 6], "input_shape": "[[7, 6, 3, 6]]", "output_shape": "[[7, 6, 3, 6]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 10; ++i1) {\n      for (int32_t i2 = 0; i2 < 20; ++i2) {\n        for (int32_t i3 = 0; i3 < 4; ++i3) {\n          compute[((((i0 * 800) + (i1 * 80)) + (i2 * 4)) + i3)] = log10f(data[((((i0 * 800) + (i1 * 80)) + (i2 * 4)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 10, 20, 4), \"float32\"), compute: T.Buffer((4, 10, 20, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(10, 20, 4):\n                cse_var_1: T.int32 = i0 * 800 + i1 * 80 + i2 * 4 + i3\n                compute_1 = T.Buffer((3200,), data=compute.data)\n                data_1 = T.Buffer((3200,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [4, 10, 20, 4], "input_shape": "[[4, 10, 20, 4]]", "output_shape": "[[4, 10, 20, 4]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 32; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 11; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 11) + i3)] = log10f(data[((i0_i1_fused_i2_fused * 11) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 4, 2, 11), \"float32\"), compute: T.Buffer((4, 4, 2, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(32):\n            for i3 in range(11):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 11 + i3\n                compute_1 = T.Buffer((352,), data=compute.data)\n                data_1 = T.Buffer((352,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [4, 4, 2, 11], "input_shape": "[[4, 4, 2, 11]]", "output_shape": "[[4, 4, 2, 11]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 12; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      for (int32_t i3 = 0; i3 < 16; ++i3) {\n        compute[(((i0_i1_fused * 48) + (i2 * 16)) + i3)] = log10f(data[(((i0_i1_fused * 48) + (i2 * 16)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 4, 3, 16), \"float32\"), compute: T.Buffer((3, 4, 3, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(12):\n            for i2, i3 in T.grid(3, 16):\n                cse_var_1: T.int32 = i0_i1_fused * 48 + i2 * 16 + i3\n                compute_1 = T.Buffer((576,), data=compute.data)\n                data_1 = T.Buffer((576,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [3, 4, 3, 16], "input_shape": "[[3, 4, 3, 16]]", "output_shape": "[[3, 4, 3, 16]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 78; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 10; ++i2) {\n      for (int32_t i3 = 0; i3 < 7; ++i3) {\n        compute[(((i0_i1_fused * 70) + (i2 * 7)) + i3)] = log10f(data[(((i0_i1_fused * 70) + (i2 * 7)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 13, 10, 7), \"float32\"), compute: T.Buffer((6, 13, 10, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(78):\n            for i2, i3 in T.grid(10, 7):\n                cse_var_1: T.int32 = i0_i1_fused * 70 + i2 * 7 + i3\n                compute_1 = T.Buffer((5460,), data=compute.data)\n                data_1 = T.Buffer((5460,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [6, 13, 10, 7], "input_shape": "[[6, 13, 10, 7]]", "output_shape": "[[6, 13, 10, 7]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 240; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 7; ++i2) {\n      for (int32_t i3 = 0; i3 < 19; ++i3) {\n        compute[(((i0_i1_fused * 133) + (i2 * 19)) + i3)] = log10f(data[(((i0_i1_fused * 133) + (i2 * 19)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 12, 7, 19), \"float32\"), compute: T.Buffer((20, 12, 7, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(240):\n            for i2, i3 in T.grid(7, 19):\n                cse_var_1: T.int32 = i0_i1_fused * 133 + i2 * 19 + i3\n                compute_1 = T.Buffer((31920,), data=compute.data)\n                data_1 = T.Buffer((31920,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [20, 12, 7, 19], "input_shape": "[[20, 12, 7, 19]]", "output_shape": "[[20, 12, 7, 19]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1530; ++i0_i1_fused_i2_fused) {\n    compute[i0_i1_fused_i2_fused] = log10f(data[i0_i1_fused_i2_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(51) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 5, 18, 1), \"float32\"), compute: T.Buffer((17, 5, 18, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1530):\n            compute_1 = T.Buffer((1530,), data=compute.data)\n            data_1 = T.Buffer((1530,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused] = T.log10(data_1[i0_i1_fused_i2_fused])", "op_args": [17, 5, 18, 1], "input_shape": "[[17, 5, 18, 1]]", "output_shape": "[[17, 5, 18, 1]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3640; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = log10f(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 20, 13, 7), \"float32\"), compute: T.Buffer((2, 20, 13, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3640):\n            compute_1 = T.Buffer((3640,), data=compute.data)\n            data_1 = T.Buffer((3640,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.log10(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [2, 20, 13, 7], "input_shape": "[[2, 20, 13, 7]]", "output_shape": "[[2, 20, 13, 7]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 6; ++i1) {\n    for (int32_t i2 = 0; i2 < 7; ++i2) {\n      for (int32_t i3 = 0; i3 < 11; ++i3) {\n        compute[(((i1 * 77) + (i2 * 11)) + i3)] = log10f(data[(((i1 * 77) + (i2 * 11)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(21) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 6, 7, 11), \"float32\"), compute: T.Buffer((1, 6, 7, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(6, 7, 11):\n            cse_var_1: T.int32 = i1 * 77 + i2 * 11 + i3\n            compute_1 = T.Buffer((462,), data=compute.data)\n            data_1 = T.Buffer((462,), data=data.data)\n            compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [1, 6, 7, 11], "input_shape": "[[1, 6, 7, 11]]", "output_shape": "[[1, 6, 7, 11]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 26; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 2; ++i2) {\n      for (int32_t i3 = 0; i3 < 5; ++i3) {\n        compute[(((i0_i1_fused * 10) + (i2 * 5)) + i3)] = log10f(data[(((i0_i1_fused * 10) + (i2 * 5)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 13, 2, 5), \"float32\"), compute: T.Buffer((2, 13, 2, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(26):\n            for i2, i3 in T.grid(2, 5):\n                cse_var_1: T.int32 = i0_i1_fused * 10 + i2 * 5 + i3\n                compute_1 = T.Buffer((260,), data=compute.data)\n                data_1 = T.Buffer((260,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [2, 13, 2, 5], "input_shape": "[[2, 13, 2, 5]]", "output_shape": "[[2, 13, 2, 5]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 2; ++i0) {\n    for (int32_t i1 = 0; i1 < 3; ++i1) {\n      for (int32_t i3 = 0; i3 < 17; ++i3) {\n        compute[(((i0 * 51) + (i1 * 17)) + i3)] = log10f(data[(((i0 * 51) + (i1 * 17)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(3) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 3, 1, 17), \"float32\"), compute: T.Buffer((2, 3, 1, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(2):\n            for i1, i3 in T.grid(3, 17):\n                cse_var_1: T.int32 = i0 * 51 + i1 * 17 + i3\n                compute_1 = T.Buffer((102,), data=compute.data)\n                data_1 = T.Buffer((102,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [2, 3, 1, 17], "input_shape": "[[2, 3, 1, 17]]", "output_shape": "[[2, 3, 1, 17]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1710; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 18; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 18) + i3)] = log10f(data[((i0_i1_fused_i2_fused * 18) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) / 12)) < 2565) {\n    compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 19, 5, 18), \"float32\"), compute: T.Buffer((18, 19, 5, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1710):\n            for i3 in range(18):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 18 + i3\n                compute_1 = T.Buffer((30780,), data=compute.data)\n                data_1 = T.Buffer((30780,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [18, 19, 5, 18], "input_shape": "[[18, 19, 5, 18]]", "output_shape": "[[18, 19, 5, 18]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 14; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 102) + (i1 * 51)) + (i2 * 17)) + i3)] = log10f(data[((((i0 * 102) + (i1 * 51)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(51) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 2, 3, 17), \"float32\"), compute: T.Buffer((14, 2, 3, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(14):\n            for i1, i2, i3 in T.grid(2, 3, 17):\n                cse_var_1: T.int32 = i0 * 102 + i1 * 51 + i2 * 17 + i3\n                compute_1 = T.Buffer((1428,), data=compute.data)\n                data_1 = T.Buffer((1428,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [14, 2, 3, 17], "input_shape": "[[14, 2, 3, 17]]", "output_shape": "[[14, 2, 3, 17]]"}{"op_name": "log10", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 19; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 7; ++i2) {\n        for (int32_t i3 = 0; i3 < 19; ++i3) {\n          compute[((((i0 * 1463) + (i1 * 133)) + (i2 * 19)) + i3)] = log10f(data[((((i0 * 1463) + (i1 * 133)) + (i2 * 19)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) < 27797) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 11, 7, 19), \"float32\"), compute: T.Buffer((19, 11, 7, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(19):\n            for i1, i2, i3 in T.grid(11, 7, 19):\n                cse_var_1: T.int32 = i0 * 1463 + i1 * 133 + i2 * 19 + i3\n                compute_1 = T.Buffer((27797,), data=compute.data)\n                data_1 = T.Buffer((27797,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])", "op_args": [19, 11, 7, 19], "input_shape": "[[19, 11, 7, 19]]", "output_shape": "[[19, 11, 7, 19]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 60192; ++i0_i1_fused_i2_fused_i3_fused) {\n    depth_to_space[i0_i1_fused_i2_fused_i3_fused] = data[(((((((i0_i1_fused_i2_fused_i3_fused / 5472) * 6156) + ((((i0_i1_fused_i2_fused_i3_fused % 1368) / 36) % 2) * 2736)) + (((i0_i1_fused_i2_fused_i3_fused % 36) % 2) * 1368)) + (((i0_i1_fused_i2_fused_i3_fused % 5472) / 1368) * 342)) + ((((i0_i1_fused_i2_fused_i3_fused % 1368) / 36) / 2) * 18)) + ((i0_i1_fused_i2_fused_i3_fused % 36) / 2))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) / 144) * 6156) + ((((((((int)blockIdx.x) % 36) * 19) + (((int)threadIdx.x) >> 1)) / 18) % 2) * 2736)) + (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 36) % 2) * 1368)) + (((((int)blockIdx.x) % 144) / 36) * 342)) + ((((((((int)blockIdx.x) % 36) * 19) + (((int)threadIdx.x) >> 1)) / 18) / 2) * 18)) + ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 36) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 18, 19, 18), \"float32\"), depth_to_space: T.Buffer((11, 4, 38, 36), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(60192):\n            cse_var_2: T.int32 = i0_i1_fused_i2_fused_i3_fused % 36\n            cse_var_1: T.int32 = i0_i1_fused_i2_fused_i3_fused % 1368 // 36\n            depth_to_space_1 = T.Buffer((60192,), data=depth_to_space.data)\n            data_1 = T.Buffer((67716,), data=data.data)\n            depth_to_space_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 5472 * 6156 + T.truncmod(cse_var_1, 2) * 2736 + T.truncmod(cse_var_2, 2) * 1368 + i0_i1_fused_i2_fused_i3_fused % 5472 // 1368 * 342 + T.Div(cse_var_1, 2) * 18 + T.Div(cse_var_2, 2)]", "op_args": [11, 18, 19, 18], "input_shape": "[[11, 18, 19, 18]]", "output_shape": "[[11, 4, 38, 36]]"}{"op_name": "log2", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 240; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = log2f(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 20, 2, 2), \"float32\"), compute: T.Buffer((3, 20, 2, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(240):\n            compute_1 = T.Buffer((240,), data=compute.data)\n            data_1 = T.Buffer((240,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.log2(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [3, 20, 2, 2], "input_shape": "[[3, 20, 2, 2]]", "output_shape": "[[3, 20, 2, 2]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5760; ++i0_i1_fused_i2_fused_i3_fused) {\n    depth_to_space[i0_i1_fused_i2_fused_i3_fused] = data[(((((((i0_i1_fused_i2_fused_i3_fused / 480) * 480) + ((((i0_i1_fused_i2_fused_i3_fused % 120) / 30) % 2) * 240)) + (((i0_i1_fused_i2_fused_i3_fused % 30) % 2) * 120)) + (((i0_i1_fused_i2_fused_i3_fused % 480) / 120) * 30)) + ((((i0_i1_fused_i2_fused_i3_fused % 120) / 30) / 2) * 15)) + ((i0_i1_fused_i2_fused_i3_fused % 30) / 2))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) >> 3) * 480) + ((((int)threadIdx.x) / 30) * 240)) + (((((int)threadIdx.x) % 30) % 2) * 120)) + ((((int)blockIdx.x) & 7) * 15)) + ((((int)threadIdx.x) % 30) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 16, 2, 15), \"float32\"), depth_to_space: T.Buffer((12, 4, 4, 30), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(5760):\n            cse_var_2: T.int32 = i0_i1_fused_i2_fused_i3_fused % 30\n            cse_var_1: T.int32 = i0_i1_fused_i2_fused_i3_fused % 120 // 30\n            depth_to_space_1 = T.Buffer((5760,), data=depth_to_space.data)\n            data_1 = T.Buffer((5760,), data=data.data)\n            depth_to_space_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 480 * 480 + T.truncmod(cse_var_1, 2) * 240 + T.truncmod(cse_var_2, 2) * 120 + i0_i1_fused_i2_fused_i3_fused % 480 // 120 * 30 + T.Div(cse_var_1, 2) * 15 + T.Div(cse_var_2, 2)]", "op_args": [12, 16, 2, 15], "input_shape": "[[12, 16, 2, 15]]", "output_shape": "[[12, 4, 4, 30]]"}{"op_name": "log2", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i3 = 0; i3 < 13; ++i3) {\n        compute[(((i0 * 104) + (i1 * 13)) + i3)] = log2f(data[(((i0 * 104) + (i1 * 13)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 143) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 8, 1, 13), \"float32\"), compute: T.Buffer((11, 8, 1, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i3 in T.grid(8, 13):\n                cse_var_1: T.int32 = i0 * 104 + i1 * 13 + i3\n                compute_1 = T.Buffer((1144,), data=compute.data)\n                data_1 = T.Buffer((1144,), data=data.data)\n                compute_1[cse_var_1] = T.log2(data_1[cse_var_1])", "op_args": [11, 8, 1, 13], "input_shape": "[[11, 8, 1, 13]]", "output_shape": "[[11, 8, 1, 13]]"}{"op_name": "log2", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 26; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 20; ++i2) {\n      for (int32_t i3 = 0; i3 < 4; ++i3) {\n        compute[(((i0_i1_fused * 80) + (i2 * 4)) + i3)] = log2f(data[(((i0_i1_fused * 80) + (i2 * 4)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 2, 20, 4), \"float32\"), compute: T.Buffer((13, 2, 20, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(26):\n            for i2, i3 in T.grid(20, 4):\n                cse_var_1: T.int32 = i0_i1_fused * 80 + i2 * 4 + i3\n                compute_1 = T.Buffer((2080,), data=compute.data)\n                data_1 = T.Buffer((2080,), data=data.data)\n                compute_1[cse_var_1] = T.log2(data_1[cse_var_1])", "op_args": [13, 2, 20, 4], "input_shape": "[[13, 2, 20, 4]]", "output_shape": "[[13, 2, 20, 4]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 3; ++i1) {\n      for (int32_t i2 = 0; i2 < 26; ++i2) {\n        for (int32_t i3 = 0; i3 < 18; ++i3) {\n          depth_to_space[((((i0 * 1404) + (i1 * 468)) + (i2 * 18)) + i3)] = data[((((((i0 * 1755) + ((i2 % 2) * 702)) + ((i3 % 2) * 351)) + (i1 * 117)) + ((i2 / 2) * 9)) + (i3 / 2))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 12)) / 117) * 1755) + ((((((((int)blockIdx.x) * 10) + (((int)threadIdx.x) / 6)) % 78) / 3) % 2) * 702)) + (((((((int)blockIdx.x) * 6) + ((int)threadIdx.x)) % 18) % 2) * 351)) + (((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 12)) % 117) / 39) * 117)) + ((((((((int)blockIdx.x) * 10) + (((int)threadIdx.x) / 6)) % 78) / 3) / 2) * 9)) + ((((((int)blockIdx.x) * 6) + ((int)threadIdx.x)) % 18) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 15, 13, 9), \"float32\"), depth_to_space: T.Buffer((15, 3, 26, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(15):\n            for i1, i2, i3 in T.grid(3, 26, 18):\n                depth_to_space_1 = T.Buffer((21060,), data=depth_to_space.data)\n                data_1 = T.Buffer((26325,), data=data.data)\n                depth_to_space_1[i0 * 1404 + i1 * 468 + i2 * 18 + i3] = data_1[i0 * 1755 + T.truncmod(i2, 2) * 702 + T.truncmod(i3, 2) * 351 + i1 * 117 + T.Div(i2, 2) * 9 + T.Div(i3, 2)]", "op_args": [15, 15, 13, 9], "input_shape": "[[15, 15, 13, 9]]", "output_shape": "[[15, 3, 26, 18]]"}{"op_name": "log2", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 34; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 12; ++i2) {\n      compute[((i0_i1_fused * 12) + i2)] = log2f(data[((i0_i1_fused * 12) + i2)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 51) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 17, 12, 1), \"float32\"), compute: T.Buffer((2, 17, 12, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(34):\n            for i2 in range(12):\n                cse_var_1: T.int32 = i0_i1_fused * 12 + i2\n                compute_1 = T.Buffer((408,), data=compute.data)\n                data_1 = T.Buffer((408,), data=data.data)\n                compute_1[cse_var_1] = T.log2(data_1[cse_var_1])", "op_args": [2, 17, 12, 1], "input_shape": "[[2, 17, 12, 1]]", "output_shape": "[[2, 17, 12, 1]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  for (int32_t i1 = 0; i1 < 2; ++i1) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 16; ++i3) {\n        depth_to_space[(((i1 * 224) + (i2 * 16)) + i3)] = data[((((((i2 % 2) * 224) + ((i3 % 2) * 112)) + (i1 * 56)) + ((i2 / 2) * 8)) + (i3 / 2))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = data[(((((((((((int)blockIdx.x) % 28) >> 1) % 2) * 224) + ((((int)threadIdx.x) % 2) * 112)) + ((((int)blockIdx.x) / 28) * 56)) + ((((((int)blockIdx.x) % 28) >> 1) / 2) * 8)) + ((((int)blockIdx.x) & 1) * 4)) + (((int)threadIdx.x) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 9, 7, 8), \"float32\"), depth_to_space: T.Buffer((1, 2, 14, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(2, 14, 16):\n            depth_to_space_1 = T.Buffer((448,), data=depth_to_space.data)\n            data_1 = T.Buffer((504,), data=data.data)\n            depth_to_space_1[i1 * 224 + i2 * 16 + i3] = data_1[T.truncmod(i2, 2) * 224 + T.truncmod(i3, 2) * 112 + i1 * 56 + T.Div(i2, 2) * 8 + T.Div(i3, 2)]", "op_args": [1, 9, 7, 8], "input_shape": "[[1, 9, 7, 8]]", "output_shape": "[[1, 2, 14, 16]]"}{"op_name": "depth_to_space", "c_code": "void default_function_kernel(float* data, float* depth_to_space) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 5; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 24; ++i2) {\n        for (int32_t i3 = 0; i3 < 12; ++i3) {\n          depth_to_space[((((i0 * 576) + (i1 * 288)) + (i2 * 12)) + i3)] = data[((((((i0 * 576) + ((i2 % 2) * 288)) + ((i3 % 2) * 144)) + (i1 * 72)) + ((i2 / 2) * 6)) + (i3 / 2))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ data, float* __restrict__ depth_to_space) {\n  depth_to_space[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) / 12) * 576) + (((((int)threadIdx.x) / 12) % 2) * 288)) + (((((int)threadIdx.x) % 12) % 2) * 144)) + ((((int)blockIdx.x) % 12) * 12)) + (((((int)threadIdx.x) / 12) / 2) * 6)) + ((((int)threadIdx.x) % 12) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 8, 12, 6), \"float32\"), depth_to_space: T.Buffer((5, 2, 24, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(5):\n            for i1, i2, i3 in T.grid(2, 24, 12):\n                cse_var_1: T.int32 = i0 * 576\n                depth_to_space_1 = T.Buffer((2880,), data=depth_to_space.data)\n                data_1 = T.Buffer((2880,), data=data.data)\n                depth_to_space_1[cse_var_1 + i1 * 288 + i2 * 12 + i3] = data_1[cse_var_1 + T.truncmod(i2, 2) * 288 + T.truncmod(i3, 2) * 144 + i1 * 72 + T.Div(i2, 2) * 6 + T.Div(i3, 2)]", "op_args": [5, 8, 12, 6], "input_shape": "[[5, 8, 12, 6]]", "output_shape": "[[5, 2, 24, 12]]"}{"op_name": "log2", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 26244; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = log2f(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 18, 9, 18), \"float32\"), compute: T.Buffer((9, 18, 9, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(26244):\n            compute_1 = T.Buffer((26244,), data=compute.data)\n            data_1 = T.Buffer((26244,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.log2(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [9, 18, 9, 18], "input_shape": "[[9, 18, 9, 18]]", "output_shape": "[[9, 18, 9, 18]]"}{"op_name": "log2", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 140; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 12; ++i2) {\n      compute[((i0_i1_fused * 12) + i2)] = log2f(data[((i0_i1_fused * 12) + i2)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 14, 12, 1), \"float32\"), compute: T.Buffer((10, 14, 12, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(140):\n            for i2 in range(12):\n                cse_var_1: T.int32 = i0_i1_fused * 12 + i2\n                compute_1 = T.Buffer((1680,), data=compute.data)\n                data_1 = T.Buffer((1680,), data=data.data)\n                compute_1[cse_var_1] = T.log2(data_1[cse_var_1])", "op_args": [10, 14, 12, 1], "input_shape": "[[10, 14, 12, 1]]", "output_shape": "[[10, 14, 12, 1]]"}{"op_name": "log2", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 144; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 15; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 15) + i3)] = log2f(data[((i0_i1_fused_i2_fused * 15) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 18, 1, 15), \"float32\"), compute: T.Buffer((8, 18, 1, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(144):\n            for i3 in range(15):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 15 + i3\n                compute_1 = T.Buffer((2160,), data=compute.data)\n                data_1 = T.Buffer((2160,), data=data.data)\n                compute_1[cse_var_1] = T.log2(data_1[cse_var_1])", "op_args": [8, 18, 1, 15], "input_shape": "[[8, 18, 1, 15]]", "output_shape": "[[8, 18, 1, 15]]"}{"op_name": "log2", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 46656; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = log2f(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 8, 18, 18), \"float32\"), compute: T.Buffer((18, 8, 18, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(46656):\n            compute_1 = T.Buffer((46656,), data=compute.data)\n            data_1 = T.Buffer((46656,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.log2(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [18, 8, 18, 18], "input_shape": "[[18, 8, 18, 18]]", "output_shape": "[[18, 8, 18, 18]]"}{"op_name": "log2", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 12; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      for (int32_t i3 = 0; i3 < 10; ++i3) {\n        compute[(((i0_i1_fused * 30) + (i2 * 10)) + i3)] = log2f(data[(((i0_i1_fused * 30) + (i2 * 10)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 4, 3, 10), \"float32\"), compute: T.Buffer((3, 4, 3, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(12):\n            for i2, i3 in T.grid(3, 10):\n                cse_var_1: T.int32 = i0_i1_fused * 30 + i2 * 10 + i3\n                compute_1 = T.Buffer((360,), data=compute.data)\n                data_1 = T.Buffer((360,), data=data.data)\n                compute_1[cse_var_1] = T.log2(data_1[cse_var_1])", "op_args": [3, 4, 3, 10], "input_shape": "[[3, 4, 3, 10]]", "output_shape": "[[3, 4, 3, 10]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[21];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 21; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 272; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 21; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 21) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 21; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 14; ++k0) {\n    for (int k1 = 0; k1 < 6; ++k1) {\n      for (int k2 = 0; k2 < 4; ++k2) {\n        for (int k3 = 0; k3 < 17; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 408) + (k1 * 68)) + (k2 * 17)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 6, 4, 17), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([21], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((21,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(21):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(272, 21):\n            data_1 = T.Buffer((5712,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 21 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(21):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [14, 6, 4, 17], "input_shape": "[[14, 6, 4, 17]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[20];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 20; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 400; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 20; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 20) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 20; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 5; ++k0) {\n    for (int k1 = 0; k1 < 5; ++k1) {\n      for (int k2 = 0; k2 < 20; ++k2) {\n        for (int k3 = 0; k3 < 16; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 1600) + (k1 * 320)) + (k2 * 16)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 5, 20, 16), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([20], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((20,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(20):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(400, 20):\n            data_1 = T.Buffer((8000,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 20 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(20):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [5, 5, 20, 16], "input_shape": "[[5, 5, 20, 16]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[24];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 24; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 130; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 24; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 24) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 24; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 13; ++k0) {\n    for (int k1 = 0; k1 < 15; ++k1) {\n      for (int k2 = 0; k2 < 2; ++k2) {\n        for (int k3 = 0; k3 < 8; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 240) + (k1 * 16)) + (k2 * 8)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 15, 2, 8), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([24], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((24,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(24):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(130, 24):\n            data_1 = T.Buffer((3120,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 24 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(24):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [13, 15, 2, 8], "input_shape": "[[13, 15, 2, 8]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[32];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 32; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 486; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 32; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 32; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 8; ++k0) {\n    for (int k1 = 0; k1 < 12; ++k1) {\n      for (int k2 = 0; k2 < 9; ++k2) {\n        for (int k3 = 0; k3 < 18; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 1944) + (k1 * 162)) + (k2 * 18)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 12, 9, 18), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([32], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((32,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(32):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(486, 32):\n            data_1 = T.Buffer((15552,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 32 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(32):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [8, 12, 9, 18], "input_shape": "[[8, 12, 9, 18]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[44];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 44; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 126; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 44; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 44) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 44; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 11; ++k0) {\n    for (int k1 = 0; k1 < 4; ++k1) {\n      for (int k2 = 0; k2 < 14; ++k2) {\n        for (int k3 = 0; k3 < 9; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 504) + (k1 * 126)) + (k2 * 9)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 4, 14, 9), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([44], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((44,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(44):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(126, 44):\n            data_1 = T.Buffer((5544,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 44 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(44):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [11, 4, 14, 9], "input_shape": "[[11, 4, 14, 9]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[49];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 49; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 144; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 49; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 49) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 49; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = -3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 221; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 2) + (((int)threadIdx.x) >> 4)) < 441) {\n      normal_reduce_temp0[0] = max(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 14, 4, 9), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([49], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((49,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(49):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(144, 49):\n            data_1 = T.Buffer((7056,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 49 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(49):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [14, 14, 4, 9], "input_shape": "[[14, 14, 4, 9]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[22];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 22; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 330; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 22; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 22) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 22; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 12; ++k0) {\n    for (int k1 = 0; k1 < 5; ++k1) {\n      for (int k2 = 0; k2 < 11; ++k2) {\n        for (int k3 = 0; k3 < 11; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 605) + (k1 * 121)) + (k2 * 11)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 5, 11, 11), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([22], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((22,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(22):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(330, 22):\n            data_1 = T.Buffer((7260,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 22 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(22):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [12, 5, 11, 11], "input_shape": "[[12, 5, 11, 11]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[20];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 20; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 459; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 20; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 20) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 20; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 17; ++k0) {\n    for (int k1 = 0; k1 < 18; ++k1) {\n      for (int k2 = 0; k2 < 10; ++k2) {\n        for (int k3 = 0; k3 < 3; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 540) + (k1 * 30)) + (k2 * 3)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 18, 10, 3), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([20], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((20,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(20):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(459, 20):\n            data_1 = T.Buffer((9180,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 20 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(20):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [17, 18, 10, 3], "input_shape": "[[17, 18, 10, 3]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[24];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 24; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 27; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 24; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 24) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 24; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = -3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 21; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 4) + (((int)threadIdx.x) >> 3)) < 81) {\n      normal_reduce_temp0[0] = max(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 18, 9, 4), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([24], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((24,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(24):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(27, 24):\n            data_1 = T.Buffer((648,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 24 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(24):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [1, 18, 9, 4], "input_shape": "[[1, 18, 9, 4]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[12];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 12; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 24; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 12; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 12) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 12; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k1 = 0; k1 < 3; ++k1) {\n    for (int k2 = 0; k2 < 8; ++k2) {\n      for (int k3 = 0; k3 < 12; ++k3) {\n        data_red[0] = max(data_red[0], data[(((k1 * 96) + (k2 * 12)) + k3)]);\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 3, 8, 12), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([12], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((12,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(12):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(24, 12):\n            data_1 = T.Buffer((288,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 12 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(12):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [1, 3, 8, 12], "input_shape": "[[1, 3, 8, 12]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[20];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 20; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 340; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 20; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 20) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 20; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = -3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 213; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 2) + (((int)threadIdx.x) >> 4)) < 425) {\n      normal_reduce_temp0[0] = max(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = max(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 5, 17, 5), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([20], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((20,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(20):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(340, 20):\n            data_1 = T.Buffer((6800,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 20 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(20):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [16, 5, 17, 5], "input_shape": "[[16, 5, 17, 5]]", "output_shape": "[[]]"}{"op_name": "max", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[28];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 28; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = -3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 156; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 28; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = max(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 28) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = -3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 28; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = max(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = -3.402823e+38f;\n  for (int k0 = 0; k0 < 14; ++k0) {\n    for (int k1 = 0; k1 < 12; ++k1) {\n      for (int k2 = 0; k2 < 2; ++k2) {\n        for (int k3 = 0; k3 < 13; ++k3) {\n          data_red[0] = max(data_red[0], data[((((k0 * 312) + (k1 * 26)) + (k2 * 13)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 12, 2, 13), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([28], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((28,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(28):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(156, 28):\n            data_1 = T.Buffer((4368,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.max(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 28 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(-3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(28):\n            data_red_1[0] = T.max(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [14, 12, 2, 13], "input_shape": "[[14, 12, 2, 13]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[10];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 10; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 9690; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 10; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 10) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 10; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 3029; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 8) + (((int)threadIdx.x) >> 2)) < 24225) {\n      normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 15, 19, 20), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([10], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((10,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(10):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(9690, 10):\n            data_1 = T.Buffer((96900,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 10 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(10):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [17, 15, 19, 20], "input_shape": "[[17, 15, 19, 20]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[21];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 21; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 48; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 21; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 21) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 21; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 32; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 2) + (((int)threadIdx.x) >> 4)) < 63) {\n      normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 12, 3, 2), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([21], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((21,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(21):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(48, 21):\n            data_1 = T.Buffer((1008,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 21 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(21):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [14, 12, 3, 2], "input_shape": "[[14, 12, 3, 2]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[28];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 28; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 867; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 28; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 28) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 28; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 3.402823e+38f;\n  for (int k0 = 0; k0 < 17; ++k0) {\n    for (int k1 = 0; k1 < 17; ++k1) {\n      for (int k2 = 0; k2 < 6; ++k2) {\n        for (int k3 = 0; k3 < 14; ++k3) {\n          data_red[0] = min(data_red[0], data[((((k0 * 1428) + (k1 * 84)) + (k2 * 14)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 17, 6, 14), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([28], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((28,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(28):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(867, 28):\n            data_1 = T.Buffer((24276,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 28 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(28):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [17, 17, 6, 14], "input_shape": "[[17, 17, 6, 14]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[20];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 20; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 1020; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 20; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 20) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 20; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 638; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 2) + (((int)threadIdx.x) >> 4)) < 1275) {\n      normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 12, 20, 17), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([20], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((20,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(20):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(1020, 20):\n            data_1 = T.Buffer((20400,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 20 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(20):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [5, 12, 20, 17], "input_shape": "[[5, 12, 20, 17]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[18];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 18; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 40; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 18; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 18) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 18; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 3.402823e+38f;\n  for (int k1 = 0; k1 < 8; ++k1) {\n    for (int k2 = 0; k2 < 6; ++k2) {\n      for (int k3 = 0; k3 < 15; ++k3) {\n        data_red[0] = min(data_red[0], data[(((k1 * 90) + (k2 * 15)) + k3)]);\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 8, 6, 15), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([18], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((18,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(18):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(40, 18):\n            data_1 = T.Buffer((720,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 18 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(18):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [1, 8, 6, 15], "input_shape": "[[1, 8, 6, 15]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[60];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 60; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 231; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 60; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 60) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 60; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 434; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 8) + (((int)threadIdx.x) >> 2)) < 3465) {\n      normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 15, 12, 11), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([60], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((60,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(60):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(231, 60):\n            data_1 = T.Buffer((13860,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 60 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(60):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [7, 15, 12, 11], "input_shape": "[[7, 15, 12, 11]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[55];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 55; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 456; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 55; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 55) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 55; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 3.402823e+38f;\n  for (int k0 = 0; k0 < 11; ++k0) {\n    for (int k1 = 0; k1 < 10; ++k1) {\n      for (int k2 = 0; k2 < 19; ++k2) {\n        for (int k3 = 0; k3 < 12; ++k3) {\n          data_red[0] = min(data_red[0], data[((((k0 * 2280) + (k1 * 228)) + (k2 * 12)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 10, 19, 12), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([55], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((55,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(55):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(456, 55):\n            data_1 = T.Buffer((25080,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 55 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(55):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [11, 10, 19, 12], "input_shape": "[[11, 10, 19, 12]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[48];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 48; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 24; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 48; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 48) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 48; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 3.402823e+38f;\n  for (int k0 = 0; k0 < 2; ++k0) {\n    for (int k1 = 0; k1 < 16; ++k1) {\n      for (int k2 = 0; k2 < 6; ++k2) {\n        for (int k3 = 0; k3 < 6; ++k3) {\n          data_red[0] = min(data_red[0], data[((((k0 * 576) + (k1 * 36)) + (k2 * 6)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 16, 6, 6), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([48], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((48,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(48):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(24, 48):\n            data_1 = T.Buffer((1152,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 48 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(48):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [2, 16, 6, 6], "input_shape": "[[2, 16, 6, 6]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[24];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 24; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 108; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 24; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 24) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 24; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 81; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 4, 8, 9), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([24], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((24,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(24):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(108, 24):\n            data_1 = T.Buffer((2592,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 24 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(24):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [9, 4, 8, 9], "input_shape": "[[9, 4, 8, 9]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[36];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 36; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 84; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 36; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 36) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 36; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 3.402823e+38f;\n  for (int k0 = 0; k0 < 2; ++k0) {\n    for (int k1 = 0; k1 < 18; ++k1) {\n      for (int k2 = 0; k2 < 12; ++k2) {\n        for (int k3 = 0; k3 < 7; ++k3) {\n          data_red[0] = min(data_red[0], data[((((k0 * 1512) + (k1 * 84)) + (k2 * 7)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 18, 12, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([36], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((36,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(36):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(84, 36):\n            data_1 = T.Buffer((3024,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 36 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(36):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [2, 18, 12, 7], "input_shape": "[[2, 18, 12, 7]]", "output_shape": "[[]]"}{"op_name": "leaky_relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 20; ++i1) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 7; ++i3) {\n        compute[(((i1 * 98) + (i2 * 7)) + i3)] = ((0.000000e+00f < data[(((i1 * 98) + (i2 * 7)) + i3)]) ? data[(((i1 * 98) + (i2 * 7)) + i3)] : (data[(((i1 * 98) + (i2 * 7)) + i3)] * 5.000000e-01f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) < 245) {\n    compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] * 5.000000e-01f));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 20, 14, 7), \"float32\"), compute: T.Buffer((1, 20, 14, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(20, 14, 7):\n            cse_var_1: T.int32 = i1 * 98 + i2 * 7 + i3\n            compute_1 = T.Buffer((1960,), data=compute.data)\n            data_1 = T.Buffer((1960,), data=data.data)\n            compute_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], data_1[cse_var_1], data_1[cse_var_1] * T.float32(0.5))", "op_args": [1, 20, 14, 7], "input_shape": "[[1, 20, 14, 7]]", "output_shape": "[[1, 20, 14, 7]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[14];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 14; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 144; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 14; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 14) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 14; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 3.402823e+38f;\n  for (int k0 = 0; k0 < 6; ++k0) {\n    for (int k1 = 0; k1 < 3; ++k1) {\n      for (int k2 = 0; k2 < 16; ++k2) {\n        for (int k3 = 0; k3 < 7; ++k3) {\n          data_red[0] = min(data_red[0], data[((((k0 * 336) + (k1 * 112)) + (k2 * 7)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 3, 16, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([14], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((14,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(14):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(144, 14):\n            data_1 = T.Buffer((2016,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 14 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(14):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [6, 3, 16, 7], "input_shape": "[[6, 3, 16, 7]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[57];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 57; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 80; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 57; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 57) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 57; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 143; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 2) + (((int)threadIdx.x) >> 4)) < 285) {\n      normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 4, 15, 4), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([57], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((57,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(57):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(80, 57):\n            data_1 = T.Buffer((4560,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 57 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(57):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [19, 4, 15, 4], "input_shape": "[[19, 4, 15, 4]]", "output_shape": "[[]]"}{"op_name": "leaky_relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 32; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 15; ++i2) {\n      for (int32_t i3 = 0; i3 < 7; ++i3) {\n        compute[(((i0_i1_fused * 105) + (i2 * 7)) + i3)] = ((0.000000e+00f < data[(((i0_i1_fused * 105) + (i2 * 7)) + i3)]) ? data[(((i0_i1_fused * 105) + (i2 * 7)) + i3)] : (data[(((i0_i1_fused * 105) + (i2 * 7)) + i3)] * 5.000000e-01f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] * 5.000000e-01f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 16, 15, 7), \"float32\"), compute: T.Buffer((2, 16, 15, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(32):\n            for i2, i3 in T.grid(15, 7):\n                cse_var_1: T.int32 = i0_i1_fused * 105 + i2 * 7 + i3\n                compute_1 = T.Buffer((3360,), data=compute.data)\n                data_1 = T.Buffer((3360,), data=data.data)\n                compute_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], data_1[cse_var_1], data_1[cse_var_1] * T.float32(0.5))", "op_args": [2, 16, 15, 7], "input_shape": "[[2, 16, 15, 7]]", "output_shape": "[[2, 16, 15, 7]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[36];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 36; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 95; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 36; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 36) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 36; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 107; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 8) + (((int)threadIdx.x) >> 2)) < 855) {\n      normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 10, 19, 1), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([36], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((36,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(36):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(95, 36):\n            data_1 = T.Buffer((3420,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 36 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(36):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [18, 10, 19, 1], "input_shape": "[[18, 10, 19, 1]]", "output_shape": "[[]]"}{"op_name": "leaky_relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2592; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused]) ? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * 5.000000e-01f));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] * 5.000000e-01f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 12, 18, 4), \"float32\"), compute: T.Buffer((3, 12, 18, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2592):\n            compute_1 = T.Buffer((2592,), data=compute.data)\n            data_1 = T.Buffer((2592,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.if_then_else(T.float32(0) < data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused] * T.float32(0.5))", "op_args": [3, 12, 18, 4], "input_shape": "[[3, 12, 18, 4]]", "output_shape": "[[3, 12, 18, 4]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[36];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 36; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 65; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 36; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 36) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 36; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 74; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 8) + (((int)threadIdx.x) >> 2)) < 585) {\n      normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 13, 2, 9), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([36], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((36,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(36):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(65, 36):\n            data_1 = T.Buffer((2340,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 36 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(36):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [10, 13, 2, 9], "input_shape": "[[10, 13, 2, 9]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[48];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 48; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 78; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 48; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 48) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 48; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 117; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 13, 6, 3), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([48], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((48,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(48):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(78, 48):\n            data_1 = T.Buffer((3744,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 48 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(48):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [16, 13, 6, 3], "input_shape": "[[16, 13, 6, 3]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[44];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 44; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 77; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 44; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 44) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 44; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 106; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 8) + (((int)threadIdx.x) >> 2)) < 847) {\n      normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 11, 7, 11), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([44], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((44,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(44):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(77, 44):\n            data_1 = T.Buffer((3388,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 44 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(44):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [4, 11, 7, 11], "input_shape": "[[4, 11, 7, 11]]", "output_shape": "[[]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[27];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 432; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 27; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 27) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 27; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 3.402823e+38f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 365; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 2) + (((int)threadIdx.x) >> 4)) < 729) {\n      normal_reduce_temp0[0] = min(normal_reduce_temp0[0], data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = min(red_buf0[0], t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 12, 18, 3), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([27], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((27,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(27):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(432, 27):\n            data_1 = T.Buffer((11664,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 27 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(27):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [18, 12, 18, 3], "input_shape": "[[18, 12, 18, 3]]", "output_shape": "[[]]"}{"op_name": "log_softmax", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused = 0; i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused < 1190; ++i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused) {\n    float T_softmax_maxelem[2];\n    float compute_1[2];\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      T_softmax_maxelem[i1] = -3.402823e+38f;\n      for (int32_t k = 0; k < 17; ++k) {\n        T_softmax_maxelem[i1] = max(T_softmax_maxelem[i1], data[(((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused / 238) * 476) + (i1 * 238)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused % 14) * 17)) + k)]);\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 2; ++i1_1) {\n      compute_1[i1_1] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 17; ++k_1) {\n        compute_1[i1_1] = (compute_1[i1_1] + expf((data[(((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused / 238) * 476) + (i1_1 * 238)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused % 14) * 17)) + k_1)] - T_softmax_maxelem[i1_1])));\n      }\n    }\n    for (int32_t i1_inner = 0; i1_inner < 2; ++i1_inner) {\n      compute[(((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused / 238) * 476) + (i1_inner * 238)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused % 14) * 17)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused % 238) / 14))] = ((data[(((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused / 238) * 476) + (i1_inner * 238)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused % 14) * 17)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused % 238) / 14))] - T_softmax_maxelem[i1_inner]) - logf(compute_1[i1_inner]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 17))]) - __logf(compute_1[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 17))]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 35) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 17; ++k) {\n    if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 35) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 544) + (((int)threadIdx.x) * 17)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 35) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 17; ++k) {\n    if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 35) {\n      compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 544) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 10, 14, 17), \"float32\"), compute: T.Buffer((1, 10, 14, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused in T.parallel(1190):\n            T_softmax_maxelem = T.allocate([2], \"float32\", \"global\")\n            compute_1 = T.allocate([2], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((2,), data=T_softmax_maxelem, align=8)\n            data_1 = T.Buffer((2380,), data=data.data)\n            for i1 in range(2):\n                T_softmax_maxelem_1[i1] = T.float32(-3.4028234663852886e+38)\n                for k in range(17):\n                    T_softmax_maxelem_1[i1] = T.max(T_softmax_maxelem_1[i1], data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused // 238 * 476 + i1 * 238 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused % 14 * 17 + k])\n            compute_2 = T.Buffer((2,), data=compute_1, align=8)\n            for i1 in range(2):\n                compute_2[i1] = T.float32(0)\n                for k in range(17):\n                    compute_2[i1] = compute_2[i1] + T.exp(data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused // 238 * 476 + i1 * 238 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused % 14 * 17 + k] - T_softmax_maxelem_1[i1])\n            for i1_inner in range(2):\n                cse_var_1: T.int32 = i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused // 238 * 476 + i1_inner * 238 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused % 14 * 17 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused % 238 // 14\n                compute_3 = T.Buffer((2380,), data=compute.data)\n                compute_3[cse_var_1] = data_1[cse_var_1] - T_softmax_maxelem_1[i1_inner] - T.log(compute_2[i1_inner])", "op_args": [1, 10, 14, 17], "input_shape": "[[1, 10, 14, 17]]", "output_shape": "[[1, 10, 14, 17]]"}{"op_name": "min", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[24];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 24; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 3.402823e+38f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 3375; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 24; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = min(data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner], data[((k0_k1_fused_k2_fused_k3_fused_outer * 24) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 3.402823e+38f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 24; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = min(data_red[0], data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 3.402823e+38f;\n  for (int k0 = 0; k0 < 18; ++k0) {\n    for (int k1 = 0; k1 < 15; ++k1) {\n      for (int k2 = 0; k2 < 15; ++k2) {\n        for (int k3 = 0; k3 < 20; ++k3) {\n          data_red[0] = min(data_red[0], data[((((k0 * 4500) + (k1 * 300)) + (k2 * 20)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 15, 15, 20), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([24], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((24,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(24):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(3375, 24):\n            data_1 = T.Buffer((81000,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = T.min(data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner], data_1[k0_k1_fused_k2_fused_k3_fused_outer * 24 + k0_k1_fused_k2_fused_k3_fused_inner])\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(3.4028234663852886e+38)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(24):\n            data_red_1[0] = T.min(data_red_1[0], data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v])", "op_args": [18, 15, 15, 20], "input_shape": "[[18, 15, 15, 20]]", "output_shape": "[[]]"}{"op_name": "log_softmax", "c_code": "void default_function_kernel(float* compute, float* data) {\n  float T_softmax_maxelem[12];\n  float compute_1[1];\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      T_softmax_maxelem[((i0 * 3) + i2)] = -3.402823e+38f;\n      for (int32_t k = 0; k < 18; ++k) {\n        T_softmax_maxelem[((i0 * 3) + i2)] = max(T_softmax_maxelem[((i0 * 3) + i2)], data[(((i0 * 54) + (i2 * 18)) + k)]);\n      }\n    }\n  }\n  for (int32_t i3_outer_outer_outer = 0; i3_outer_outer_outer < 9; ++i3_outer_outer_outer) {\n    for (int32_t i0_outer_outer_inner = 0; i0_outer_outer_inner < 2; ++i0_outer_outer_inner) {\n      for (int32_t i2_outer_outer_inner = 0; i2_outer_outer_inner < 3; ++i2_outer_outer_inner) {\n        for (int32_t i3_outer_outer_inner = 0; i3_outer_outer_inner < 2; ++i3_outer_outer_inner) {\n          for (int32_t i0_outer_inner = 0; i0_outer_inner < 2; ++i0_outer_inner) {\n            compute_1[0] = 0.000000e+00f;\n            for (int32_t k_1 = 0; k_1 < 18; ++k_1) {\n              compute_1[0] = (compute_1[0] + expf((data[((((i0_outer_outer_inner * 108) + (i0_outer_inner * 54)) + (i2_outer_outer_inner * 18)) + k_1)] - T_softmax_maxelem[(((i0_outer_outer_inner * 6) + (i0_outer_inner * 3)) + i2_outer_outer_inner)])));\n            }\n            compute[(((((i0_outer_outer_inner * 108) + (i0_outer_inner * 54)) + (i2_outer_outer_inner * 18)) + (i3_outer_outer_outer * 2)) + i3_outer_outer_inner)] = ((data[(((((i0_outer_outer_inner * 108) + (i0_outer_inner * 54)) + (i2_outer_outer_inner * 18)) + (i3_outer_outer_outer * 2)) + i3_outer_outer_inner)] - T_softmax_maxelem[(((i0_outer_outer_inner * 6) + (i0_outer_inner * 3)) + i2_outer_outer_inner)]) - logf(compute_1[0]));\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((int)threadIdx.x)] = 0.000000e+00f;\n  for (int k = 0; k < 18; ++k) {\n    compute[((int)threadIdx.x)] = (compute[((int)threadIdx.x)] + __expf((data[((((int)threadIdx.x) * 18) + k)] - T_softmax_maxelem[((int)threadIdx.x)])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(18) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]) - __logf(compute_1[((int)blockIdx.x)]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int k = 0; k < 18; ++k) {\n    T_softmax_maxelem[((int)threadIdx.x)] = max(T_softmax_maxelem[((int)threadIdx.x)], data[((((int)threadIdx.x) * 18) + k)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 1, 3, 18), \"float32\"), compute: T.Buffer((4, 1, 3, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_softmax_maxelem = T.allocate([12], \"float32\", \"global\")\n        compute_1 = T.allocate([1], \"float32\", \"global\")\n        T_softmax_maxelem_1 = T.Buffer((12,), data=T_softmax_maxelem, align=32)\n        data_1 = T.Buffer((216,), data=data.data)\n        for i0, i2 in T.grid(4, 3):\n            T_softmax_maxelem_1[i0 * 3 + i2] = T.float32(-3.4028234663852886e+38)\n            for k in range(18):\n                cse_var_1: T.int32 = i0 * 3 + i2\n                T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 54 + i2 * 18 + k])\n        for i3_outer_outer_outer, i0_outer_outer_inner, i2_outer_outer_inner, i3_outer_outer_inner, i0_outer_inner in T.grid(9, 2, 3, 2, 2):\n            cse_var_2: T.int32 = i0_outer_outer_inner * 108 + i0_outer_inner * 54 + i2_outer_outer_inner * 18 + i3_outer_outer_outer * 2 + i3_outer_outer_inner\n            compute_2 = T.Buffer((1,), data=compute_1, align=4)\n            compute_2[0] = T.float32(0)\n            for k in range(18):\n                compute_2[0] = compute_2[0] + T.exp(data_1[i0_outer_outer_inner * 108 + i0_outer_inner * 54 + i2_outer_outer_inner * 18 + k] - T_softmax_maxelem_1[i0_outer_outer_inner * 6 + i0_outer_inner * 3 + i2_outer_outer_inner])\n            compute_3 = T.Buffer((216,), data=compute.data)\n            compute_3[cse_var_2] = data_1[cse_var_2] - T_softmax_maxelem_1[i0_outer_outer_inner * 6 + i0_outer_inner * 3 + i2_outer_outer_inner] - T.log(compute_2[0])", "op_args": [4, 1, 3, 18], "input_shape": "[[4, 1, 3, 18]]", "output_shape": "[[4, 1, 3, 18]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5940; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (data[i0_i1_fused_i2_fused_i3_fused] * -1.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 14) + (((int)threadIdx.x) >> 2)) < 1485) {\n    compute[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] * -1.000000e+00f);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 9, 5, 12), \"float32\"), compute: T.Buffer((11, 9, 5, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(5940):\n            compute_1 = T.Buffer((5940,), data=compute.data)\n            data_1 = T.Buffer((5940,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused] * T.float32(-1)", "op_args": [11, 9, 5, 12], "input_shape": "[[11, 9, 5, 12]]", "output_shape": "[[11, 9, 5, 12]]"}{"op_name": "log_softmax", "c_code": "void default_function_kernel(float* compute, float* data) {\n  float T_softmax_maxelem[60];\n  float compute_1[10];\n  for (int32_t i1 = 0; i1 < 6; ++i1) {\n    for (int32_t i2 = 0; i2 < 10; ++i2) {\n      T_softmax_maxelem[((i1 * 10) + i2)] = -3.402823e+38f;\n      for (int32_t k = 0; k < 20; ++k) {\n        T_softmax_maxelem[((i1 * 10) + i2)] = max(T_softmax_maxelem[((i1 * 10) + i2)], data[(((i1 * 200) + (i2 * 20)) + k)]);\n      }\n    }\n  }\n  for (int32_t i1_outer_outer_inner = 0; i1_outer_outer_inner < 6; ++i1_outer_outer_inner) {\n    for (int32_t i2_1 = 0; i2_1 < 10; ++i2_1) {\n      compute_1[i2_1] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 20; ++k_1) {\n        compute_1[i2_1] = (compute_1[i2_1] + expf((data[(((i1_outer_outer_inner * 200) + (i2_1 * 20)) + k_1)] - T_softmax_maxelem[((i1_outer_outer_inner * 10) + i2_1)])));\n      }\n    }\n    for (int32_t i3_outer_inner = 0; i3_outer_inner < 20; ++i3_outer_inner) {\n      for (int32_t i2_inner = 0; i2_inner < 10; ++i2_inner) {\n        compute[(((i1_outer_outer_inner * 200) + (i2_inner * 20)) + i3_outer_inner)] = ((data[(((i1_outer_outer_inner * 200) + (i2_inner * 20)) + i3_outer_inner)] - T_softmax_maxelem[((i1_outer_outer_inner * 10) + i2_inner)]) - logf(compute_1[i2_inner]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 20; ++k) {\n    compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 80) + (((int)threadIdx.x) * 20)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 20; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 80) + (((int)threadIdx.x) * 20)) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(60) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20))]) - __logf(compute_1[((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 6, 10, 20), \"float32\"), compute: T.Buffer((1, 6, 10, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_softmax_maxelem = T.allocate([60], \"float32\", \"global\")\n        compute_1 = T.allocate([10], \"float32\", \"global\")\n        T_softmax_maxelem_1 = T.Buffer((60,), data=T_softmax_maxelem)\n        data_1 = T.Buffer((1200,), data=data.data)\n        for i1, i2 in T.grid(6, 10):\n            T_softmax_maxelem_1[i1 * 10 + i2] = T.float32(-3.4028234663852886e+38)\n            for k in range(20):\n                cse_var_1: T.int32 = i1 * 10 + i2\n                T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i1 * 200 + i2 * 20 + k])\n        for i1_outer_outer_inner in range(6):\n            compute_2 = T.Buffer((10,), data=compute_1, align=32)\n            for i2 in range(10):\n                compute_2[i2] = T.float32(0)\n                for k in range(20):\n                    compute_2[i2] = compute_2[i2] + T.exp(data_1[i1_outer_outer_inner * 200 + i2 * 20 + k] - T_softmax_maxelem_1[i1_outer_outer_inner * 10 + i2])\n            for i3_outer_inner, i2_inner in T.grid(20, 10):\n                cse_var_2: T.int32 = i1_outer_outer_inner * 200 + i2_inner * 20 + i3_outer_inner\n                compute_3 = T.Buffer((1200,), data=compute.data)\n                compute_3[cse_var_2] = data_1[cse_var_2] - T_softmax_maxelem_1[i1_outer_outer_inner * 10 + i2_inner] - T.log(compute_2[i2_inner])", "op_args": [1, 6, 10, 20], "input_shape": "[[1, 6, 10, 20]]", "output_shape": "[[1, 6, 10, 20]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i2 = 0; i2 < 4; ++i2) {\n    for (int32_t i3 = 0; i3 < 10; ++i3) {\n      compute[((i2 * 10) + i3)] = (data[((i2 * 10) + i3)] * -1.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((int)blockIdx.x)] = (data[((int)blockIdx.x)] * -1.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 1, 4, 10), \"float32\"), compute: T.Buffer((1, 1, 4, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i2, i3 in T.grid(4, 10):\n            cse_var_1: T.int32 = i2 * 10 + i3\n            compute_1 = T.Buffer((40,), data=compute.data)\n            data_1 = T.Buffer((40,), data=data.data)\n            compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)", "op_args": [1, 1, 4, 10], "input_shape": "[[1, 1, 4, 10]]", "output_shape": "[[1, 1, 4, 10]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 204; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 5; ++i2) {\n      for (int32_t i3 = 0; i3 < 20; ++i3) {\n        compute[(((i0_i1_fused * 100) + (i2 * 20)) + i3)] = (data[(((i0_i1_fused * 100) + (i2 * 20)) + i3)] * -1.000000e+00f);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] * -1.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 17, 5, 20), \"float32\"), compute: T.Buffer((12, 17, 5, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(204):\n            for i2, i3 in T.grid(5, 20):\n                cse_var_1: T.int32 = i0_i1_fused * 100 + i2 * 20 + i3\n                compute_1 = T.Buffer((20400,), data=compute.data)\n                data_1 = T.Buffer((20400,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)", "op_args": [12, 17, 5, 20], "input_shape": "[[12, 17, 5, 20]]", "output_shape": "[[12, 17, 5, 20]]"}{"op_name": "log_softmax", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused = 0; i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused < 156; ++i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused) {\n    float T_softmax_maxelem[27];\n    float compute_1[27];\n    for (int32_t i0 = 0; i0 < 9; ++i0) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        T_softmax_maxelem[((i0 * 3) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 15; ++k) {\n          T_softmax_maxelem[((i0 * 3) + i2)] = max(T_softmax_maxelem[((i0 * 3) + i2)], data[((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused & 1) * 31590) + (i0 * 3510)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused >> 1) * 45)) + (i2 * 15)) + k)]);\n        }\n      }\n    }\n    for (int32_t i0_1 = 0; i0_1 < 9; ++i0_1) {\n      for (int32_t i2_1 = 0; i2_1 < 3; ++i2_1) {\n        compute_1[((i0_1 * 3) + i2_1)] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 15; ++k_1) {\n          compute_1[((i0_1 * 3) + i2_1)] = (compute_1[((i0_1 * 3) + i2_1)] + expf((data[((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused & 1) * 31590) + (i0_1 * 3510)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused >> 1) * 45)) + (i2_1 * 15)) + k_1)] - T_softmax_maxelem[((i0_1 * 3) + i2_1)])));\n        }\n      }\n    }\n    for (int32_t i3_outer_outer_inner = 0; i3_outer_outer_inner < 3; ++i3_outer_outer_inner) {\n      for (int32_t i0_outer_inner = 0; i0_outer_inner < 9; ++i0_outer_inner) {\n        for (int32_t i2_outer_inner = 0; i2_outer_inner < 3; ++i2_outer_inner) {\n          for (int32_t i3_outer_inner = 0; i3_outer_inner < 5; ++i3_outer_inner) {\n            compute[(((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused & 1) * 31590) + (i0_outer_inner * 3510)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused >> 1) * 45)) + (i2_outer_inner * 15)) + (i3_outer_outer_inner * 5)) + i3_outer_inner)] = ((data[(((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused & 1) * 31590) + (i0_outer_inner * 3510)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused >> 1) * 45)) + (i2_outer_inner * 15)) + (i3_outer_outer_inner * 5)) + i3_outer_inner)] - T_softmax_maxelem[((i0_outer_inner * 3) + i2_outer_inner)]) - logf(compute_1[((i0_outer_inner * 3) + i2_outer_inner)]));\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 1053) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 15; ++k) {\n    if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 1053) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 480) + (((int)threadIdx.x) * 15)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) < 15795) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) / 15)]) - __logf(compute_1[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) / 15)]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(52) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 15; ++k) {\n    compute[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = (compute[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 780) + (((int)threadIdx.x) * 15)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))])));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 13, 18, 15), \"float32\"), compute: T.Buffer((18, 13, 18, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused in T.parallel(156):\n            T_softmax_maxelem = T.allocate([27], \"float32\", \"global\")\n            compute_1 = T.allocate([27], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((27,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((63180,), data=data.data)\n            for i0, i2 in T.grid(9, 3):\n                T_softmax_maxelem_1[i0 * 3 + i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(15):\n                    cse_var_1: T.int32 = i0 * 3 + i2\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 2 * 31590 + i0 * 3510 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused // 2 * 45 + i2 * 15 + k])\n            compute_2 = T.Buffer((27,), data=compute_1)\n            for i0, i2 in T.grid(9, 3):\n                compute_2[i0 * 3 + i2] = T.float32(0)\n                for k in range(15):\n                    cse_var_2: T.int32 = i0 * 3 + i2\n                    compute_2[cse_var_2] = compute_2[cse_var_2] + T.exp(data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 2 * 31590 + i0 * 3510 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused // 2 * 45 + i2 * 15 + k] - T_softmax_maxelem_1[cse_var_2])\n            for i3_outer_outer_inner, i0_outer_inner, i2_outer_inner, i3_outer_inner in T.grid(3, 9, 3, 5):\n                cse_var_4: T.int32 = i0_outer_inner * 3 + i2_outer_inner\n                cse_var_3: T.int32 = i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 2 * 31590 + i0_outer_inner * 3510 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused // 2 * 45 + i2_outer_inner * 15 + i3_outer_outer_inner * 5 + i3_outer_inner\n                compute_3 = T.Buffer((63180,), data=compute.data)\n                compute_3[cse_var_3] = data_1[cse_var_3] - T_softmax_maxelem_1[cse_var_4] - T.log(compute_2[cse_var_4])", "op_args": [18, 13, 18, 15], "input_shape": "[[18, 13, 18, 15]]", "output_shape": "[[18, 13, 18, 15]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 42560; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (data[i0_i1_fused_i2_fused_i3_fused] * -1.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * -1.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 19, 14, 20), \"float32\"), compute: T.Buffer((8, 19, 14, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(42560):\n            compute_1 = T.Buffer((42560,), data=compute.data)\n            data_1 = T.Buffer((42560,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused] * T.float32(-1)", "op_args": [8, 19, 14, 20], "input_shape": "[[8, 19, 14, 20]]", "output_shape": "[[8, 19, 14, 20]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    for (int32_t i2 = 0; i2 < 17; ++i2) {\n      for (int32_t i3 = 0; i3 < 12; ++i3) {\n        compute[(((i0 * 204) + (i2 * 12)) + i3)] = (data[(((i0 * 204) + (i2 * 12)) + i3)] * -1.000000e+00f);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 459) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * -1.000000e+00f);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 1, 17, 12), \"float32\"), compute: T.Buffer((18, 1, 17, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(18):\n            for i2, i3 in T.grid(17, 12):\n                cse_var_1: T.int32 = i0 * 204 + i2 * 12 + i3\n                compute_1 = T.Buffer((3672,), data=compute.data)\n                data_1 = T.Buffer((3672,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)", "op_args": [18, 1, 17, 12], "input_shape": "[[18, 1, 17, 12]]", "output_shape": "[[18, 1, 17, 12]]"}{"op_name": "log_softmax", "c_code": "void default_function_kernel(float* compute, float* data) {\n  float T_softmax_maxelem[495];\n  float compute_1[1];\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        T_softmax_maxelem[(((i0 * 33) + (i1 * 3)) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 4; ++k) {\n          T_softmax_maxelem[(((i0 * 33) + (i1 * 3)) + i2)] = max(T_softmax_maxelem[(((i0 * 33) + (i1 * 3)) + i2)], data[((((i0 * 132) + (i1 * 12)) + (i2 * 4)) + k)]);\n        }\n      }\n    }\n  }\n  for (int32_t i0_outer_outer_inner = 0; i0_outer_outer_inner < 5; ++i0_outer_outer_inner) {\n    for (int32_t i3_outer_outer_inner = 0; i3_outer_outer_inner < 4; ++i3_outer_outer_inner) {\n      for (int32_t i0_outer_inner = 0; i0_outer_inner < 3; ++i0_outer_inner) {\n        for (int32_t i1_outer_inner = 0; i1_outer_inner < 11; ++i1_outer_inner) {\n          for (int32_t i2_outer_inner = 0; i2_outer_inner < 3; ++i2_outer_inner) {\n            compute_1[0] = 0.000000e+00f;\n            for (int32_t k_1 = 0; k_1 < 4; ++k_1) {\n              compute_1[0] = (compute_1[0] + expf((data[(((((i0_outer_outer_inner * 396) + (i0_outer_inner * 132)) + (i1_outer_inner * 12)) + (i2_outer_inner * 4)) + k_1)] - T_softmax_maxelem[((((i0_outer_outer_inner * 99) + (i0_outer_inner * 33)) + (i1_outer_inner * 3)) + i2_outer_inner)])));\n            }\n            compute[(((((i0_outer_outer_inner * 396) + (i0_outer_inner * 132)) + (i1_outer_inner * 12)) + (i2_outer_inner * 4)) + i3_outer_outer_inner)] = ((data[(((((i0_outer_outer_inner * 396) + (i0_outer_inner * 132)) + (i1_outer_inner * 12)) + (i2_outer_inner * 4)) + i3_outer_outer_inner)] - T_softmax_maxelem[((((i0_outer_outer_inner * 99) + (i0_outer_inner * 33)) + (i1_outer_inner * 3)) + i2_outer_inner)]) - logf(compute_1[0]));\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) < 495) {\n    compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 4; ++k) {\n    if (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) < 495) {\n      compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 495) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2))]) - __logf(compute_1[((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2))]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 495) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 4; ++k) {\n    if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 495) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) * 4)) + k)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 11, 3, 4), \"float32\"), compute: T.Buffer((15, 11, 3, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_softmax_maxelem = T.allocate([495], \"float32\", \"global\")\n        compute_1 = T.allocate([1], \"float32\", \"global\")\n        T_softmax_maxelem_1 = T.Buffer((495,), data=T_softmax_maxelem)\n        data_1 = T.Buffer((1980,), data=data.data)\n        for i0, i1, i2 in T.grid(15, 11, 3):\n            T_softmax_maxelem_1[i0 * 33 + i1 * 3 + i2] = T.float32(-3.4028234663852886e+38)\n            for k in range(4):\n                cse_var_1: T.int32 = i0 * 33 + i1 * 3 + i2\n                T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 132 + i1 * 12 + i2 * 4 + k])\n        for i0_outer_outer_inner, i3_outer_outer_inner, i0_outer_inner, i1_outer_inner, i2_outer_inner in T.grid(5, 4, 3, 11, 3):\n            cse_var_2: T.int32 = i0_outer_outer_inner * 396 + i0_outer_inner * 132 + i1_outer_inner * 12 + i2_outer_inner * 4 + i3_outer_outer_inner\n            compute_2 = T.Buffer((1,), data=compute_1, align=4)\n            compute_2[0] = T.float32(0)\n            for k in range(4):\n                compute_2[0] = compute_2[0] + T.exp(data_1[i0_outer_outer_inner * 396 + i0_outer_inner * 132 + i1_outer_inner * 12 + i2_outer_inner * 4 + k] - T_softmax_maxelem_1[i0_outer_outer_inner * 99 + i0_outer_inner * 33 + i1_outer_inner * 3 + i2_outer_inner])\n            compute_3 = T.Buffer((1980,), data=compute.data)\n            compute_3[cse_var_2] = data_1[cse_var_2] - T_softmax_maxelem_1[i0_outer_outer_inner * 99 + i0_outer_inner * 33 + i1_outer_inner * 3 + i2_outer_inner] - T.log(compute_2[0])", "op_args": [15, 11, 3, 4], "input_shape": "[[15, 11, 3, 4]]", "output_shape": "[[15, 11, 3, 4]]"}{"op_name": "log_softmax", "c_code": "void default_function_kernel(float* compute, float* data) {\n  float T_softmax_maxelem[30];\n  float compute_1[1];\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      T_softmax_maxelem[((i0 * 2) + i1)] = -3.402823e+38f;\n      for (int32_t k = 0; k < 17; ++k) {\n        T_softmax_maxelem[((i0 * 2) + i1)] = max(T_softmax_maxelem[((i0 * 2) + i1)], data[(((i0 * 34) + (i1 * 17)) + k)]);\n      }\n    }\n  }\n  for (int32_t i3_outer_outer_inner = 0; i3_outer_outer_inner < 17; ++i3_outer_outer_inner) {\n    for (int32_t i0_outer_inner = 0; i0_outer_inner < 15; ++i0_outer_inner) {\n      for (int32_t i1_outer_inner = 0; i1_outer_inner < 2; ++i1_outer_inner) {\n        compute_1[0] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 17; ++k_1) {\n          compute_1[0] = (compute_1[0] + expf((data[(((i0_outer_inner * 34) + (i1_outer_inner * 17)) + k_1)] - T_softmax_maxelem[((i0_outer_inner * 2) + i1_outer_inner)])));\n        }\n        compute[(((i0_outer_inner * 34) + (i1_outer_inner * 17)) + i3_outer_outer_inner)] = ((data[(((i0_outer_inner * 34) + (i1_outer_inner * 17)) + i3_outer_outer_inner)] - T_softmax_maxelem[((i0_outer_inner * 2) + i1_outer_inner)]) - logf(compute_1[0]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((int)threadIdx.x)] = -3.402823e+38f;\n  for (int k = 0; k < 17; ++k) {\n    T_softmax_maxelem[((int)threadIdx.x)] = max(T_softmax_maxelem[((int)threadIdx.x)], data[((((int)threadIdx.x) * 17) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(24) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) / 6)) < 85) {\n    compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) / 17)]) - __logf(compute_1[(((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) / 17)]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(30) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((int)threadIdx.x)] = 0.000000e+00f;\n  for (int k = 0; k < 17; ++k) {\n    compute[((int)threadIdx.x)] = (compute[((int)threadIdx.x)] + __expf((data[((((int)threadIdx.x) * 17) + k)] - T_softmax_maxelem[((int)threadIdx.x)])));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 2, 1, 17), \"float32\"), compute: T.Buffer((15, 2, 1, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_softmax_maxelem = T.allocate([30], \"float32\", \"global\")\n        compute_1 = T.allocate([1], \"float32\", \"global\")\n        T_softmax_maxelem_1 = T.Buffer((30,), data=T_softmax_maxelem)\n        data_1 = T.Buffer((510,), data=data.data)\n        for i0, i1 in T.grid(15, 2):\n            T_softmax_maxelem_1[i0 * 2 + i1] = T.float32(-3.4028234663852886e+38)\n            for k in range(17):\n                cse_var_1: T.int32 = i0 * 2 + i1\n                T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 34 + i1 * 17 + k])\n        for i3_outer_outer_inner, i0_outer_inner, i1_outer_inner in T.grid(17, 15, 2):\n            cse_var_2: T.int32 = i0_outer_inner * 34 + i1_outer_inner * 17 + i3_outer_outer_inner\n            compute_2 = T.Buffer((1,), data=compute_1, align=4)\n            compute_2[0] = T.float32(0)\n            for k in range(17):\n                compute_2[0] = compute_2[0] + T.exp(data_1[i0_outer_inner * 34 + i1_outer_inner * 17 + k] - T_softmax_maxelem_1[i0_outer_inner * 2 + i1_outer_inner])\n            compute_3 = T.Buffer((510,), data=compute.data)\n            compute_3[cse_var_2] = data_1[cse_var_2] - T_softmax_maxelem_1[i0_outer_inner * 2 + i1_outer_inner] - T.log(compute_2[0])", "op_args": [15, 2, 1, 17], "input_shape": "[[15, 2, 1, 17]]", "output_shape": "[[15, 2, 1, 17]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 4480; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (data[i0_i1_fused_i2_fused_i3_fused] * -1.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * -1.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 8, 4, 7), \"float32\"), compute: T.Buffer((20, 8, 4, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(4480):\n            compute_1 = T.Buffer((4480,), data=compute.data)\n            data_1 = T.Buffer((4480,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused] * T.float32(-1)", "op_args": [20, 8, 4, 7], "input_shape": "[[20, 8, 4, 7]]", "output_shape": "[[20, 8, 4, 7]]"}{"op_name": "log_softmax", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused = 0; i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused < 1296; ++i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused) {\n    float T_softmax_maxelem[2];\n    float compute_1[2];\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      T_softmax_maxelem[i1] = -3.402823e+38f;\n      for (int32_t k = 0; k < 5; ++k) {\n        T_softmax_maxelem[i1] = max(T_softmax_maxelem[i1], data[((((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 144) / 48) * 4320) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 6) * 720)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused / 144) * 80)) + (i1 * 40)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 48) / 6) * 5)) + k)]);\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 2; ++i1_1) {\n      compute_1[i1_1] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 5; ++k_1) {\n        compute_1[i1_1] = (compute_1[i1_1] + expf((data[((((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 144) / 48) * 4320) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 6) * 720)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused / 144) * 80)) + (i1_1 * 40)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 48) / 6) * 5)) + k_1)] - T_softmax_maxelem[i1_1])));\n      }\n    }\n    for (int32_t i3_outer_inner = 0; i3_outer_inner < 5; ++i3_outer_inner) {\n      for (int32_t i1_inner = 0; i1_inner < 2; ++i1_inner) {\n        compute[((((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 144) / 48) * 4320) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 6) * 720)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused / 144) * 80)) + (i1_inner * 40)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 48) / 6) * 5)) + i3_outer_inner)] = ((data[((((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 144) / 48) * 4320) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 6) * 720)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused / 144) * 80)) + (i1_inner * 40)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 48) / 6) * 5)) + i3_outer_inner)] - T_softmax_maxelem[i1_inner]) - logf(compute_1[i1_inner]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 5; ++k) {\n    compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = (compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 120) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]) - __logf(compute_1[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 5; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 80) + (((int)threadIdx.x) * 5)) + k)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 18, 8, 5), \"float32\"), compute: T.Buffer((18, 18, 8, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused in T.parallel(1296):\n            T_softmax_maxelem = T.allocate([2], \"float32\", \"global\")\n            compute_1 = T.allocate([2], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((2,), data=T_softmax_maxelem, align=8)\n            data_1 = T.Buffer((12960,), data=data.data)\n            for i1 in range(2):\n                T_softmax_maxelem_1[i1] = T.float32(-3.4028234663852886e+38)\n                for k in range(5):\n                    T_softmax_maxelem_1[i1] = T.max(T_softmax_maxelem_1[i1], data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 144 // 48 * 4320 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 6 * 720 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused // 144 * 80 + i1 * 40 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 48 // 6 * 5 + k])\n            compute_2 = T.Buffer((2,), data=compute_1, align=8)\n            for i1 in range(2):\n                compute_2[i1] = T.float32(0)\n                for k in range(5):\n                    compute_2[i1] = compute_2[i1] + T.exp(data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 144 // 48 * 4320 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 6 * 720 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused // 144 * 80 + i1 * 40 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 48 // 6 * 5 + k] - T_softmax_maxelem_1[i1])\n            for i3_outer_inner, i1_inner in T.grid(5, 2):\n                cse_var_1: T.int32 = i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 144 // 48 * 4320 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 6 * 720 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused // 144 * 80 + i1_inner * 40 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused % 48 // 6 * 5 + i3_outer_inner\n                compute_3 = T.Buffer((12960,), data=compute.data)\n                compute_3[cse_var_1] = data_1[cse_var_1] - T_softmax_maxelem_1[i1_inner] - T.log(compute_2[i1_inner])", "op_args": [18, 18, 8, 5], "input_shape": "[[18, 18, 8, 5]]", "output_shape": "[[18, 18, 8, 5]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 126; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 11; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 11) + i3)] = (data[((i0_i1_fused_i2_fused * 11) + i3)] * -1.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] * -1.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 9, 2, 11), \"float32\"), compute: T.Buffer((7, 9, 2, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(126):\n            for i3 in range(11):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 11 + i3\n                compute_1 = T.Buffer((1386,), data=compute.data)\n                data_1 = T.Buffer((1386,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)", "op_args": [7, 9, 2, 11], "input_shape": "[[7, 9, 2, 11]]", "output_shape": "[[7, 9, 2, 11]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 3; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3 = 0; i3 < 12; ++i3) {\n          compute[((((i0 * 396) + (i1 * 132)) + (i2 * 12)) + i3)] = (data[((((i0 * 396) + (i1 * 132)) + (i2 * 12)) + i3)] * -1.000000e+00f);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 1089) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * -1.000000e+00f);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 3, 11, 12), \"float32\"), compute: T.Buffer((11, 3, 11, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i2, i3 in T.grid(3, 11, 12):\n                cse_var_1: T.int32 = i0 * 396 + i1 * 132 + i2 * 12 + i3\n                compute_1 = T.Buffer((4356,), data=compute.data)\n                data_1 = T.Buffer((4356,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)", "op_args": [11, 3, 11, 12], "input_shape": "[[11, 3, 11, 12]]", "output_shape": "[[11, 3, 11, 12]]"}{"op_name": "log_softmax", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused = 0; i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused < 72; ++i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused) {\n    float T_softmax_maxelem[210];\n    float compute_1[210];\n    for (int32_t i1 = 0; i1 < 14; ++i1) {\n      for (int32_t i2 = 0; i2 < 15; ++i2) {\n        T_softmax_maxelem[((i1 * 15) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 9; ++k) {\n          T_softmax_maxelem[((i1 * 15) + i2)] = max(T_softmax_maxelem[((i1 * 15) + i2)], data[(((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused / 9) * 1890) + (i1 * 135)) + (i2 * 9)) + k)]);\n        }\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 14; ++i1_1) {\n      for (int32_t i2_1 = 0; i2_1 < 15; ++i2_1) {\n        compute_1[((i1_1 * 15) + i2_1)] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 9; ++k_1) {\n          compute_1[((i1_1 * 15) + i2_1)] = (compute_1[((i1_1 * 15) + i2_1)] + expf((data[(((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused / 9) * 1890) + (i1_1 * 135)) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)])));\n        }\n      }\n    }\n    for (int32_t i2_outer_inner = 0; i2_outer_inner < 15; ++i2_outer_inner) {\n      for (int32_t i1_inner = 0; i1_inner < 14; ++i1_inner) {\n        compute[(((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused / 9) * 1890) + (i1_inner * 135)) + (i2_outer_inner * 9)) + (i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 9))] = ((data[(((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused / 9) * 1890) + (i1_inner * 135)) + (i2_outer_inner * 9)) + (i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 9))] - T_softmax_maxelem[((i1_inner * 15) + i2_outer_inner)]) - logf(compute_1[((i1_inner * 15) + i2_outer_inner)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 105) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 9; ++k) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 105) {\n      compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 288) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(14) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 9; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 126) + (((int)threadIdx.x) * 9)) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 945) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]) - __logf(compute_1[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 14, 15, 9), \"float32\"), compute: T.Buffer((8, 14, 15, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused in T.parallel(72):\n            T_softmax_maxelem = T.allocate([210], \"float32\", \"global\")\n            compute_1 = T.allocate([210], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((210,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((15120,), data=data.data)\n            for i1, i2 in T.grid(14, 15):\n                T_softmax_maxelem_1[i1 * 15 + i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(9):\n                    cse_var_1: T.int32 = i1 * 15 + i2\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused // 9 * 1890 + i1 * 135 + i2 * 9 + k])\n            compute_2 = T.Buffer((210,), data=compute_1)\n            for i1, i2 in T.grid(14, 15):\n                compute_2[i1 * 15 + i2] = T.float32(0)\n                for k in range(9):\n                    cse_var_2: T.int32 = i1 * 15 + i2\n                    compute_2[cse_var_2] = compute_2[cse_var_2] + T.exp(data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused // 9 * 1890 + i1 * 135 + i2 * 9 + k] - T_softmax_maxelem_1[cse_var_2])\n            for i2_outer_inner, i1_inner in T.grid(15, 14):\n                cse_var_4: T.int32 = i1_inner * 15 + i2_outer_inner\n                cse_var_3: T.int32 = i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused // 9 * 1890 + i1_inner * 135 + i2_outer_inner * 9 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 9\n                compute_3 = T.Buffer((15120,), data=compute.data)\n                compute_3[cse_var_3] = data_1[cse_var_3] - T_softmax_maxelem_1[cse_var_4] - T.log(compute_2[cse_var_4])", "op_args": [8, 14, 15, 9], "input_shape": "[[8, 14, 15, 9]]", "output_shape": "[[8, 14, 15, 9]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 16; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 7; ++i2) {\n      for (int32_t i3 = 0; i3 < 15; ++i3) {\n        compute[(((i0_i1_fused * 105) + (i2 * 15)) + i3)] = (data[(((i0_i1_fused * 105) + (i2 * 15)) + i3)] * -1.000000e+00f);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) < 105) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * -1.000000e+00f);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 8, 7, 15), \"float32\"), compute: T.Buffer((2, 8, 7, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(16):\n            for i2, i3 in T.grid(7, 15):\n                cse_var_1: T.int32 = i0_i1_fused * 105 + i2 * 15 + i3\n                compute_1 = T.Buffer((1680,), data=compute.data)\n                data_1 = T.Buffer((1680,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)", "op_args": [2, 8, 7, 15], "input_shape": "[[2, 8, 7, 15]]", "output_shape": "[[2, 8, 7, 15]]"}{"op_name": "log_softmax", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused = 0; i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused < 2090; ++i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused) {\n    float T_softmax_maxelem[17];\n    float compute_1[17];\n    for (int32_t i2 = 0; i2 < 17; ++i2) {\n      T_softmax_maxelem[i2] = -3.402823e+38f;\n      for (int32_t k = 0; k < 19; ++k) {\n        T_softmax_maxelem[i2] = max(T_softmax_maxelem[i2], data[((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused / 418) * 7106) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused & 1) * 3553)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 22) >> 1) * 323)) + (i2 * 19)) + k)]);\n      }\n    }\n    for (int32_t i2_1 = 0; i2_1 < 17; ++i2_1) {\n      compute_1[i2_1] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 19; ++k_1) {\n        compute_1[i2_1] = (compute_1[i2_1] + expf((data[((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused / 418) * 7106) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused & 1) * 3553)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 22) >> 1) * 323)) + (i2_1 * 19)) + k_1)] - T_softmax_maxelem[i2_1])));\n      }\n    }\n    for (int32_t i2_inner = 0; i2_inner < 17; ++i2_inner) {\n      compute[((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused / 418) * 7106) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused & 1) * 3553)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 22) >> 1) * 323)) + (i2_inner * 19)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 418) / 22))] = ((data[((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused / 418) * 7106) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused & 1) * 3553)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 22) >> 1) * 323)) + (i2_inner * 19)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 418) / 22))] - T_softmax_maxelem[i2_inner]) - logf(compute_1[i2_inner]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) < 17765) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) / 19)]) - __logf(compute_1[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) / 19)]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) < 935) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 19; ++k) {\n    if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) < 935) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 304) + (((int)threadIdx.x) * 19)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 935) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 19; ++k) {\n    if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 935) {\n      compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 608) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 11, 17, 19), \"float32\"), compute: T.Buffer((10, 11, 17, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused in T.parallel(2090):\n            T_softmax_maxelem = T.allocate([17], \"float32\", \"global\")\n            compute_1 = T.allocate([17], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((17,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((35530,), data=data.data)\n            for i2 in range(17):\n                T_softmax_maxelem_1[i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(19):\n                    T_softmax_maxelem_1[i2] = T.max(T_softmax_maxelem_1[i2], data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused // 418 * 7106 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 2 * 3553 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 22 // 2 * 323 + i2 * 19 + k])\n            compute_2 = T.Buffer((17,), data=compute_1)\n            for i2 in range(17):\n                compute_2[i2] = T.float32(0)\n                for k in range(19):\n                    compute_2[i2] = compute_2[i2] + T.exp(data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused // 418 * 7106 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 2 * 3553 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 22 // 2 * 323 + i2 * 19 + k] - T_softmax_maxelem_1[i2])\n            for i2_inner in range(17):\n                cse_var_1: T.int32 = i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused // 418 * 7106 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 2 * 3553 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 22 // 2 * 323 + i2_inner * 19 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused_i2_outer_outer_inner_fused_i3_outer_outer_inner_fused_i0_outer_inner_fused_i1_outer_inner_fused_i2_outer_inner_fused_i3_outer_inner_fused % 418 // 22\n                compute_3 = T.Buffer((35530,), data=compute.data)\n                compute_3[cse_var_1] = data_1[cse_var_1] - T_softmax_maxelem_1[i2_inner] - T.log(compute_2[i2_inner])", "op_args": [10, 11, 17, 19], "input_shape": "[[10, 11, 17, 19]]", "output_shape": "[[10, 11, 17, 19]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 19; ++i0) {\n    for (int32_t i1 = 0; i1 < 14; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 3; ++i3) {\n          compute[((((i0 * 126) + (i1 * 9)) + (i2 * 3)) + i3)] = (data[((((i0 * 126) + (i1 * 9)) + (i2 * 3)) + i3)] * -1.000000e+00f);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(52) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 26) + (((int)threadIdx.x) >> 1)) < 1197) {\n    compute[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] * -1.000000e+00f);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 14, 3, 3), \"float32\"), compute: T.Buffer((19, 14, 3, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(19):\n            for i1, i2, i3 in T.grid(14, 3, 3):\n                cse_var_1: T.int32 = i0 * 126 + i1 * 9 + i2 * 3 + i3\n                compute_1 = T.Buffer((2394,), data=compute.data)\n                data_1 = T.Buffer((2394,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)", "op_args": [19, 14, 3, 3], "input_shape": "[[19, 14, 3, 3]]", "output_shape": "[[19, 14, 3, 3]]"}{"op_name": "log_softmax", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused = 0; i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused < 117; ++i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused) {\n    float T_softmax_maxelem[9];\n    float compute_1[3];\n    for (int32_t i0 = 0; i0 < 3; ++i0) {\n      for (int32_t i1 = 0; i1 < 3; ++i1) {\n        T_softmax_maxelem[((i0 * 3) + i1)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 19; ++k) {\n          T_softmax_maxelem[((i0 * 3) + i1)] = max(T_softmax_maxelem[((i0 * 3) + i1)], data[(((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused / 39) * 6669) + (i0 * 2223)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 3) * 741)) + (i1 * 247)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 39) / 3) * 19)) + k)]);\n        }\n      }\n    }\n    for (int32_t i1_outer_inner = 0; i1_outer_inner < 3; ++i1_outer_inner) {\n      for (int32_t i0_1 = 0; i0_1 < 3; ++i0_1) {\n        compute_1[i0_1] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 19; ++k_1) {\n          compute_1[i0_1] = (compute_1[i0_1] + expf((data[(((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused / 39) * 6669) + (i0_1 * 2223)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 3) * 741)) + (i1_outer_inner * 247)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 39) / 3) * 19)) + k_1)] - T_softmax_maxelem[((i0_1 * 3) + i1_outer_inner)])));\n        }\n      }\n      for (int32_t i3_outer_inner = 0; i3_outer_inner < 19; ++i3_outer_inner) {\n        for (int32_t i0_inner = 0; i0_inner < 3; ++i0_inner) {\n          compute[(((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused / 39) * 6669) + (i0_inner * 2223)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 3) * 741)) + (i1_outer_inner * 247)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 39) / 3) * 19)) + i3_outer_inner)] = ((data[(((((((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused / 39) * 6669) + (i0_inner * 2223)) + ((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 3) * 741)) + (i1_outer_inner * 247)) + (((i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 39) / 3) * 19)) + i3_outer_inner)] - T_softmax_maxelem[((i0_inner * 3) + i1_outer_inner)]) - logf(compute_1[i0_inner]));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 1053) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 19; ++k) {\n    if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 1053) {\n      compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 608) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 1053) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 19; ++k) {\n    if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 1053) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 152) + (((int)threadIdx.x) * 19)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(40) default_function_kernel_2(float* __restrict__ T_softmax_maxelem, float* __restrict__ compute, float* __restrict__ compute_1, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 40) + ((int)threadIdx.x)) < 20007) {\n    compute[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 40) + ((int)threadIdx.x)) / 19)]) - __logf(compute_1[(((((int)blockIdx.x) * 40) + ((int)threadIdx.x)) / 19)]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 9, 13, 19), \"float32\"), compute: T.Buffer((9, 9, 13, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused in T.parallel(117):\n            T_softmax_maxelem = T.allocate([9], \"float32\", \"global\")\n            compute_1 = T.allocate([3], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((9,), data=T_softmax_maxelem, align=32)\n            data_1 = T.Buffer((20007,), data=data.data)\n            for i0, i1 in T.grid(3, 3):\n                T_softmax_maxelem_1[i0 * 3 + i1] = T.float32(-3.4028234663852886e+38)\n                for k in range(19):\n                    cse_var_1: T.int32 = i0 * 3 + i1\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused // 39 * 6669 + i0 * 2223 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 3 * 741 + i1 * 247 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 39 // 3 * 19 + k])\n            for i1_outer_inner in range(3):\n                compute_2 = T.Buffer((3,), data=compute_1, align=8)\n                for i0 in range(3):\n                    compute_2[i0] = T.float32(0)\n                    for k in range(19):\n                        compute_2[i0] = compute_2[i0] + T.exp(data_1[i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused // 39 * 6669 + i0 * 2223 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 3 * 741 + i1_outer_inner * 247 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 39 // 3 * 19 + k] - T_softmax_maxelem_1[i0 * 3 + i1_outer_inner])\n                for i3_outer_inner, i0_inner in T.grid(19, 3):\n                    cse_var_2: T.int32 = i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused // 39 * 6669 + i0_inner * 2223 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 3 * 741 + i1_outer_inner * 247 + i0_outer_outer_outer_i1_outer_outer_outer_fused_i2_outer_outer_outer_fused_i3_outer_outer_outer_fused_i0_outer_outer_inner_fused_i1_outer_outer_inner_fused % 39 // 3 * 19 + i3_outer_inner\n                    compute_3 = T.Buffer((20007,), data=compute.data)\n                    compute_3[cse_var_2] = data_1[cse_var_2] - T_softmax_maxelem_1[i0_inner * 3 + i1_outer_inner] - T.log(compute_2[i0_inner])", "op_args": [9, 9, 13, 19], "input_shape": "[[9, 9, 13, 19]]", "output_shape": "[[9, 9, 13, 19]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 75; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 17; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 17) + i3)] = (data[((i0_i1_fused_i2_fused * 17) + i3)] * -1.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(51) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] * -1.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 5, 3, 17), \"float32\"), compute: T.Buffer((5, 5, 3, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(75):\n            for i3 in range(17):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 17 + i3\n                compute_1 = T.Buffer((1275,), data=compute.data)\n                data_1 = T.Buffer((1275,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)", "op_args": [5, 5, 3, 17], "input_shape": "[[5, 5, 3, 17]]", "output_shape": "[[5, 5, 3, 17]]"}{"op_name": "negative", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 10; ++i3) {\n          compute[((((i0 * 540) + (i1 * 60)) + (i2 * 10)) + i3)] = (data[((((i0 * 540) + (i1 * 60)) + (i2 * 10)) + i3)] * -1.000000e+00f);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * -1.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 9, 6, 10), \"float32\"), compute: T.Buffer((4, 9, 6, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(9, 6, 10):\n                cse_var_1: T.int32 = i0 * 540 + i1 * 60 + i2 * 10 + i3\n                compute_1 = T.Buffer((2160,), data=compute.data)\n                data_1 = T.Buffer((2160,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)", "op_args": [4, 9, 6, 10], "input_shape": "[[4, 9, 6, 10]]", "output_shape": "[[4, 9, 6, 10]]"}{"op_name": "lrn", "c_code": "void default_function_kernel(float* T_divide, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 1560; ++ax0_ax1_fused_ax2_fused) {\n    float tensor[1];\n    for (int32_t ax3 = 0; ax3 < 9; ++ax3) {\n      tensor[0] = 0.000000e+00f;\n      tensor[0] = (tensor[0] + (data[((ax0_ax1_fused_ax2_fused * 9) + ax3)] * data[((ax0_ax1_fused_ax2_fused * 9) + ax3)]));\n      T_divide[((ax0_ax1_fused_ax2_fused * 9) + ax3)] = (data[((ax0_ax1_fused_ax2_fused * 9) + ax3)] / powf((2.000000e+00f + (1.000000e-04f * tensor[0])), 7.500000e-01f));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel_1(float* __restrict__ T_divide, float* __restrict__ data, float* __restrict__ tensor) {\n  T_divide[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] / powf((2.000000e+00f + (1.000000e-04f * tensor[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))])), 7.500000e-01f));\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ tensor) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 1755) {\n    tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 1755) {\n    tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (tensor[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + (data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 10, 13, 9), \"float32\"), T_divide: T.Buffer((12, 10, 13, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(1560):\n            tensor = T.allocate([1], \"float32\", \"global\")\n            for ax3 in range(9):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 9 + ax3\n                tensor_1 = T.Buffer((1,), data=tensor, align=4)\n                tensor_1[0] = T.float32(0)\n                data_1 = T.Buffer((14040,), data=data.data)\n                tensor_1[0] = tensor_1[0] + data_1[cse_var_1] * data_1[cse_var_1]\n                T_divide_1 = T.Buffer((14040,), data=T_divide.data)\n                T_divide_1[cse_var_1] = data_1[cse_var_1] / T.pow(T.float32(2) + T.float32(9.9999997473787516e-05) * tensor_1[0], T.float32(0.75))", "op_args": [12, 10, 13, 9], "input_shape": "[[12, 10, 13, 9]]", "output_shape": "[[12, 10, 13, 9]]"}{"op_name": "lrn", "c_code": "void default_function_kernel(float* T_divide, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 2; ++ax0) {\n    float tensor[1];\n    for (int32_t ax2 = 0; ax2 < 20; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 10; ++ax3) {\n        tensor[0] = 0.000000e+00f;\n        tensor[0] = (tensor[0] + (data[(((ax0 * 200) + (ax2 * 10)) + ax3)] * data[(((ax0 * 200) + (ax2 * 10)) + ax3)]));\n        T_divide[(((ax0 * 200) + (ax2 * 10)) + ax3)] = (data[(((ax0 * 200) + (ax2 * 10)) + ax3)] / powf((2.000000e+00f + (1.000000e-04f * tensor[0])), 7.500000e-01f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_divide, float* __restrict__ data, float* __restrict__ tensor) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 25) {\n    T_divide[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] / powf((2.000000e+00f + (1.000000e-04f * tensor[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])), 7.500000e-01f));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ tensor) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 25) {\n    tensor[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 25) {\n    tensor[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (tensor[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 1, 20, 10), \"float32\"), T_divide: T.Buffer((2, 1, 20, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(2):\n            tensor = T.allocate([1], \"float32\", \"global\")\n            for ax2, ax3 in T.grid(20, 10):\n                cse_var_1: T.int32 = ax0 * 200 + ax2 * 10 + ax3\n                tensor_1 = T.Buffer((1,), data=tensor, align=4)\n                tensor_1[0] = T.float32(0)\n                data_1 = T.Buffer((400,), data=data.data)\n                tensor_1[0] = tensor_1[0] + data_1[cse_var_1] * data_1[cse_var_1]\n                T_divide_1 = T.Buffer((400,), data=T_divide.data)\n                T_divide_1[cse_var_1] = data_1[cse_var_1] / T.pow(T.float32(2) + T.float32(9.9999997473787516e-05) * tensor_1[0], T.float32(0.75))", "op_args": [2, 1, 20, 10], "input_shape": "[[2, 1, 20, 10]]", "output_shape": "[[2, 1, 20, 10]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[16];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 16; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 225; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 16; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 16) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 16; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 4; ++k0) {\n    for (int k1 = 0; k1 < 15; ++k1) {\n      for (int k2 = 0; k2 < 15; ++k2) {\n        for (int k3 = 0; k3 < 4; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 900) + (k1 * 60)) + (k2 * 4)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 15, 15, 4), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([16], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((16,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(16):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(225, 16):\n            data_1 = T.Buffer((3600,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 16 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(16):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [4, 15, 15, 4], "input_shape": "[[4, 15, 15, 4]]", "output_shape": "[[]]"}{"op_name": "lrn", "c_code": "void default_function_kernel(float* T_divide, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 7; ++ax0) {\n    float tensor[170];\n    for (int32_t ax2 = 0; ax2 < 17; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 10; ++ax3) {\n        tensor[((ax2 * 10) + ax3)] = 0.000000e+00f;\n        tensor[((ax2 * 10) + ax3)] = (tensor[((ax2 * 10) + ax3)] + (data[(((ax0 * 170) + (ax2 * 10)) + ax3)] * data[(((ax0 * 170) + (ax2 * 10)) + ax3)]));\n      }\n    }\n    for (int32_t ax2_1 = 0; ax2_1 < 17; ++ax2_1) {\n      for (int32_t ax3_1 = 0; ax3_1 < 10; ++ax3_1) {\n        T_divide[(((ax0 * 170) + (ax2_1 * 10)) + ax3_1)] = (data[(((ax0 * 170) + (ax2_1 * 10)) + ax3_1)] / powf((2.000000e+00f + (1.000000e-04f * tensor[((ax2_1 * 10) + ax3_1)])), 7.500000e-01f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel_1(float* __restrict__ T_divide, float* __restrict__ data, float* __restrict__ tensor) {\n  T_divide[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] / powf((2.000000e+00f + (1.000000e-04f * tensor[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))])), 7.500000e-01f));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ tensor) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 595) {\n    tensor[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 595) {\n    tensor[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (tensor[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 1, 17, 10), \"float32\"), T_divide: T.Buffer((7, 1, 17, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(7):\n            tensor = T.allocate([170], \"float32\", \"global\")\n            tensor_1 = T.Buffer((170,), data=tensor)\n            data_1 = T.Buffer((1190,), data=data.data)\n            for ax2, ax3 in T.grid(17, 10):\n                cse_var_3: T.int32 = ax2 * 10\n                cse_var_2: T.int32 = cse_var_3 + ax3\n                cse_var_1: T.int32 = ax0 * 170 + cse_var_3 + ax3\n                tensor_1[cse_var_2] = T.float32(0)\n                tensor_1[cse_var_2] = tensor_1[cse_var_2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax2, ax3 in T.grid(17, 10):\n                cse_var_5: T.int32 = ax2 * 10\n                cse_var_4: T.int32 = ax0 * 170 + cse_var_5 + ax3\n                T_divide_1 = T.Buffer((1190,), data=T_divide.data)\n                T_divide_1[cse_var_4] = data_1[cse_var_4] / T.pow(T.float32(2) + T.float32(9.9999997473787516e-05) * tensor_1[cse_var_5 + ax3], T.float32(0.75))", "op_args": [7, 1, 17, 10], "input_shape": "[[7, 1, 17, 10]]", "output_shape": "[[7, 1, 17, 10]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[12];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 12; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 32; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 12; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 12) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 12; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 16; ++k0) {\n    for (int k2 = 0; k2 < 2; ++k2) {\n      for (int k3 = 0; k3 < 12; ++k3) {\n        data_red[0] = (data_red[0] * data[(((k0 * 24) + (k2 * 12)) + k3)]);\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 1, 2, 12), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([12], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((12,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(12):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(32, 12):\n            data_1 = T.Buffer((384,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 12 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(12):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [16, 1, 2, 12], "input_shape": "[[16, 1, 2, 12]]", "output_shape": "[[]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[35];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 35; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 76; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 35; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 35) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 35; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 19; ++k0) {\n    for (int k1 = 0; k1 < 2; ++k1) {\n      for (int k2 = 0; k2 < 14; ++k2) {\n        for (int k3 = 0; k3 < 5; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 140) + (k1 * 70)) + (k2 * 5)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 2, 14, 5), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([35], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((35,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(35):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(76, 35):\n            data_1 = T.Buffer((2660,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 35 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(35):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [19, 2, 14, 5], "input_shape": "[[19, 2, 14, 5]]", "output_shape": "[[]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[45];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 45; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 144; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 45; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 45) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 45; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 1.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 203; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 2) + (((int)threadIdx.x) >> 4)) < 405) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 18, 2, 10), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([45], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((45,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(45):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(144, 45):\n            data_1 = T.Buffer((6480,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 45 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(45):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [18, 18, 2, 10], "input_shape": "[[18, 18, 2, 10]]", "output_shape": "[[]]"}{"op_name": "mirror_pad", "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 77; ++i0_i1_fused) {\n    MirrorPadInput[i0_i1_fused] = data[((((55 <= i0_i1_fused) ? (8 - (i0_i1_fused / 11)) : ((i0_i1_fused < 11) ? 0 : ((i0_i1_fused / 11) - 1))) * 8) + (((i0_i1_fused % 11) == 10) ? 7 : (((i0_i1_fused % 11) < 2) ? (1 - (i0_i1_fused % 11)) : ((i0_i1_fused % 11) - 2))))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 77) {\n    MirrorPadInput[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = data[((((55 <= ((((int)blockIdx.x) * 32) + ((int)threadIdx.x))) ? (8 - (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)) : ((((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 11) ? 0 : ((((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11) - 1))) * 8) + (((((((int)blockIdx.x) * 10) + ((int)threadIdx.x)) % 11) == 10) ? (17 - (((((int)blockIdx.x) * 10) + ((int)threadIdx.x)) % 11)) : (((((((int)blockIdx.x) * 10) + ((int)threadIdx.x)) % 11) < 2) ? (1 - (((((int)blockIdx.x) * 10) + ((int)threadIdx.x)) % 11)) : ((((((int)blockIdx.x) * 10) + ((int)threadIdx.x)) % 11) - 2))))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 8), \"float32\"), MirrorPadInput: T.Buffer((7, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(77):\n            cse_var_2: T.int32 = i0_i1_fused // 11\n            cse_var_1: T.int32 = i0_i1_fused % 11\n            MirrorPadInput_1 = T.Buffer((77,), data=MirrorPadInput.data)\n            data_1 = T.Buffer((32,), data=data.data)\n            MirrorPadInput_1[i0_i1_fused] = data_1[T.if_then_else(55 <= i0_i1_fused, 8 - cse_var_2, T.if_then_else(i0_i1_fused < 11, 0, cse_var_2 - 1)) * 8 + T.if_then_else(cse_var_1 == 10, 7, T.if_then_else(cse_var_1 < 2, 1 - cse_var_1, cse_var_1 - 2))]", "op_args": [6, 6, 4, 8], "input_shape": "[[4, 8]]", "output_shape": "[[7, 11]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[64];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 64; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 54; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 64; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 64) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 64; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 6; ++k0) {\n    for (int k1 = 0; k1 < 18; ++k1) {\n      for (int k2 = 0; k2 < 2; ++k2) {\n        for (int k3 = 0; k3 < 16; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 576) + (k1 * 32)) + (k2 * 16)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 18, 2, 16), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([64], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((64,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(64):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(54, 64):\n            data_1 = T.Buffer((3456,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 64 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(64):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [6, 18, 2, 16], "input_shape": "[[6, 18, 2, 16]]", "output_shape": "[[]]"}{"op_name": "mirror_pad", "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 16; ++i1) {\n      MirrorPadInput[((i0 * 16) + i1)] = data[((((5 <= i0) ? (8 - i0) : ((i0 < 1) ? (0 - i0) : (i0 - 1))) * 13) + ((i1 == 15) ? (27 - i1) : ((i1 < 2) ? (1 - i1) : (i1 - 2))))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  MirrorPadInput[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = data[((((80 <= ((((int)blockIdx.x) * 7) + ((int)threadIdx.x))) ? (8 - (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) >> 4)) : ((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 16) ? 0 : ((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) >> 4) - 1))) * 13) + (((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) & 15) == 15) ? (27 - (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) & 15)) : (((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) & 15) < 2) ? (1 - (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) & 15)) : ((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) & 15) - 2))))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 13), \"float32\"), MirrorPadInput: T.Buffer((7, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i1 in range(16):\n                MirrorPadInput_1 = T.Buffer((112,), data=MirrorPadInput.data)\n                data_1 = T.Buffer((52,), data=data.data)\n                MirrorPadInput_1[i0 * 16 + i1] = data_1[T.if_then_else(5 <= i0, 8 - i0, T.if_then_else(i0 < 1, 0 - i0, i0 - 1)) * 13 + T.if_then_else(i1 == 15, 27 - i1, T.if_then_else(i1 < 2, 1 - i1, i1 - 2))]", "op_args": [2, 2, 4, 13], "input_shape": "[[4, 13]]", "output_shape": "[[7, 16]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[8];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 8; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 2793; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 8; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 8) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 8; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 12; ++k0) {\n    for (int k1 = 0; k1 < 14; ++k1) {\n      for (int k2 = 0; k2 < 19; ++k2) {\n        for (int k3 = 0; k3 < 7; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 1862) + (k1 * 133)) + (k2 * 7)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 14, 19, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([8], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((8,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(8):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(2793, 8):\n            data_1 = T.Buffer((22344,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 8 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(8):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [12, 14, 19, 7], "input_shape": "[[12, 14, 19, 7]]", "output_shape": "[[]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[16];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 16; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 132; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 16; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 16) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 16; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 6; ++k0) {\n    for (int k1 = 0; k1 < 8; ++k1) {\n      for (int k2 = 0; k2 < 11; ++k2) {\n        for (int k3 = 0; k3 < 4; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 352) + (k1 * 44)) + (k2 * 4)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 8, 11, 4), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([16], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((16,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(16):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(132, 16):\n            data_1 = T.Buffer((2112,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 16 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(16):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [6, 8, 11, 4], "input_shape": "[[6, 8, 11, 4]]", "output_shape": "[[]]"}{"op_name": "mirror_pad", "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 23; ++i1) {\n      MirrorPadInput[((i0 * 23) + i1)] = data[((((5 <= i0) ? (8 - i0) : ((i0 < 1) ? (0 - i0) : (i0 - 1))) * 20) + ((i1 == 22) ? (41 - i1) : ((i1 < 2) ? (1 - i1) : (i1 - 2))))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(5) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) < 161) {\n    MirrorPadInput[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))] = data[((((23 <= ((int)blockIdx.x)) ? (8 - (((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) / 23)) : ((((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) < 23) ? 0 : ((((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) / 23) - 1))) * 20) + (((((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) % 23) == 22) ? (41 - (((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) % 23)) : (((((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) % 23) < 2) ? (1 - (((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) % 23)) : ((((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) % 23) - 2))))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 20), \"float32\"), MirrorPadInput: T.Buffer((7, 23), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i1 in range(23):\n                MirrorPadInput_1 = T.Buffer((161,), data=MirrorPadInput.data)\n                data_1 = T.Buffer((80,), data=data.data)\n                MirrorPadInput_1[i0 * 23 + i1] = data_1[T.if_then_else(5 <= i0, 8 - i0, T.if_then_else(i0 < 1, 0 - i0, i0 - 1)) * 20 + T.if_then_else(i1 == 22, 41 - i1, T.if_then_else(i1 < 2, 1 - i1, i1 - 2))]", "op_args": [15, 17, 4, 20], "input_shape": "[[4, 20]]", "output_shape": "[[7, 23]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[34];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 34; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 336; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 34; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 34) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 34; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 4; ++k0) {\n    for (int k1 = 0; k1 < 17; ++k1) {\n      for (int k2 = 0; k2 < 14; ++k2) {\n        for (int k3 = 0; k3 < 12; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 2856) + (k1 * 168)) + (k2 * 12)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 17, 14, 12), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([34], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((34,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(34):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(336, 34):\n            data_1 = T.Buffer((11424,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 34 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(34):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [4, 17, 14, 12], "input_shape": "[[4, 17, 14, 12]]", "output_shape": "[[]]"}{"op_name": "mirror_pad", "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 10; ++i0) {\n    for (int32_t i1 = 0; i1 < 16; ++i1) {\n      MirrorPadInput[((i0 * 16) + i1)] = data[((((8 <= i0) ? (14 - i0) : ((i0 < 1) ? (0 - i0) : (i0 - 1))) * 13) + ((i1 == 15) ? (27 - i1) : ((i1 < 2) ? (1 - i1) : (i1 - 2))))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(5) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  MirrorPadInput[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))] = data[((((128 <= ((((int)blockIdx.x) * 5) + ((int)threadIdx.x))) ? (14 - (((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) >> 4)) : ((((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) < 16) ? 0 : ((((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) >> 4) - 1))) * 13) + (((((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) & 15) == 15) ? (27 - (((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) & 15)) : (((((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) & 15) < 2) ? (1 - (((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) & 15)) : ((((((int)blockIdx.x) * 5) + ((int)threadIdx.x)) & 15) - 2))))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 13), \"float32\"), MirrorPadInput: T.Buffer((10, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(10):\n            for i1 in range(16):\n                MirrorPadInput_1 = T.Buffer((160,), data=MirrorPadInput.data)\n                data_1 = T.Buffer((91,), data=data.data)\n                MirrorPadInput_1[i0 * 16 + i1] = data_1[T.if_then_else(8 <= i0, 14 - i0, T.if_then_else(i0 < 1, 0 - i0, i0 - 1)) * 13 + T.if_then_else(i1 == 15, 27 - i1, T.if_then_else(i1 < 2, 1 - i1, i1 - 2))]", "op_args": [15, 14, 7, 13], "input_shape": "[[7, 13]]", "output_shape": "[[10, 16]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[18];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 18; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 343; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 18; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 18) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 18; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 1.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 193; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 16) + (((int)threadIdx.x) >> 1)) < 3087) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 9, 14, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([18], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((18,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(18):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(343, 18):\n            data_1 = T.Buffer((6174,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 18 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(18):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [7, 9, 14, 7], "input_shape": "[[7, 9, 14, 7]]", "output_shape": "[[]]"}{"op_name": "mirror_pad", "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 135; ++i0_i1_fused) {\n    MirrorPadInput[i0_i1_fused] = data[((((117 <= i0_i1_fused) ? (24 - (i0_i1_fused / 9)) : ((i0_i1_fused < 9) ? 0 : ((i0_i1_fused / 9) - 1))) * 6) + (((i0_i1_fused % 9) == 8) ? 5 : (((i0_i1_fused % 9) < 2) ? (1 - (i0_i1_fused % 9)) : ((i0_i1_fused % 9) - 2))))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) < 135) {\n    MirrorPadInput[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = data[((((117 <= ((((int)blockIdx.x) * 64) + ((int)threadIdx.x))) ? (24 - (((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) / 9)) : ((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) < 9) ? 0 : ((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) / 9) - 1))) * 6) + ((((((int)blockIdx.x) + ((int)threadIdx.x)) % 9) == 8) ? (13 - ((((int)blockIdx.x) + ((int)threadIdx.x)) % 9)) : ((((((int)blockIdx.x) + ((int)threadIdx.x)) % 9) < 2) ? (1 - ((((int)blockIdx.x) + ((int)threadIdx.x)) % 9)) : (((((int)blockIdx.x) + ((int)threadIdx.x)) % 9) - 2))))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 6), \"float32\"), MirrorPadInput: T.Buffer((15, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(135):\n            cse_var_2: T.int32 = i0_i1_fused // 9\n            cse_var_1: T.int32 = i0_i1_fused % 9\n            MirrorPadInput_1 = T.Buffer((135,), data=MirrorPadInput.data)\n            data_1 = T.Buffer((72,), data=data.data)\n            MirrorPadInput_1[i0_i1_fused] = data_1[T.if_then_else(117 <= i0_i1_fused, 24 - cse_var_2, T.if_then_else(i0_i1_fused < 9, 0, cse_var_2 - 1)) * 6 + T.if_then_else(cse_var_1 == 8, 5, T.if_then_else(cse_var_1 < 2, 1 - cse_var_1, cse_var_1 - 2))]", "op_args": [17, 12, 12, 6], "input_shape": "[[12, 6]]", "output_shape": "[[15, 9]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[34];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 34; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 27; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 34; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 34) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 34; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 9; ++k0) {\n    for (int k1 = 0; k1 < 17; ++k1) {\n      for (int k2 = 0; k2 < 6; ++k2) {\n        data_red[0] = (data_red[0] * data[(((k0 * 102) + (k1 * 6)) + k2)]);\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 17, 6, 1), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([34], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((34,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(34):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(27, 34):\n            data_1 = T.Buffer((918,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 34 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(34):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [9, 17, 6, 1], "input_shape": "[[9, 17, 6, 1]]", "output_shape": "[[]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[18];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 18; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 845; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 18; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 18) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 18; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 13; ++k0) {\n    for (int k1 = 0; k1 < 10; ++k1) {\n      for (int k2 = 0; k2 < 9; ++k2) {\n        for (int k3 = 0; k3 < 13; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 1170) + (k1 * 117)) + (k2 * 13)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 10, 9, 13), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([18], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((18,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(18):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(845, 18):\n            data_1 = T.Buffer((15210,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 18 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(18):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [13, 10, 9, 13], "input_shape": "[[13, 10, 9, 13]]", "output_shape": "[[]]"}{"op_name": "mirror_pad", "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 22; ++i0) {\n    for (int32_t i1 = 0; i1 < 22; ++i1) {\n      MirrorPadInput[((i0 * 22) + i1)] = data[((((20 <= i0) ? (38 - i0) : ((i0 < 1) ? (0 - i0) : (i0 - 1))) * 19) + ((i1 == 21) ? (39 - i1) : ((i1 < 2) ? (1 - i1) : (i1 - 2))))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(15) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) < 484) {\n    MirrorPadInput[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))] = data[((((88 <= ((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 5))) ? (38 - (((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) / 22)) : ((((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) < 22) ? 0 : ((((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) / 22) - 1))) * 19) + (((((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) % 22) == 21) ? (39 - (((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) % 22)) : (((((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) % 22) < 2) ? (1 - (((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) % 22)) : ((((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) % 22) - 2))))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 19), \"float32\"), MirrorPadInput: T.Buffer((22, 22), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(22):\n            for i1 in range(22):\n                MirrorPadInput_1 = T.Buffer((484,), data=MirrorPadInput.data)\n                data_1 = T.Buffer((361,), data=data.data)\n                MirrorPadInput_1[i0 * 22 + i1] = data_1[T.if_then_else(20 <= i0, 38 - i0, T.if_then_else(i0 < 1, 0 - i0, i0 - 1)) * 19 + T.if_then_else(i1 == 21, 39 - i1, T.if_then_else(i1 < 2, 1 - i1, i1 - 2))]", "op_args": [18, 14, 19, 19], "input_shape": "[[19, 19]]", "output_shape": "[[22, 22]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[25];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 25; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 936; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 25; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 25) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 25; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 13; ++k0) {\n    for (int k1 = 0; k1 < 20; ++k1) {\n      for (int k2 = 0; k2 < 6; ++k2) {\n        for (int k3 = 0; k3 < 15; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 1800) + (k1 * 90)) + (k2 * 15)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 20, 6, 15), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([25], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((25,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(25):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(936, 25):\n            data_1 = T.Buffer((23400,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 25 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(25):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [13, 20, 6, 15], "input_shape": "[[13, 20, 6, 15]]", "output_shape": "[[]]"}{"op_name": "mirror_pad", "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 112; ++i0_i1_fused) {\n    MirrorPadInput[i0_i1_fused] = data[((((96 <= i0_i1_fused) ? (22 - (i0_i1_fused >> 3)) : ((i0_i1_fused < 8) ? 0 : ((i0_i1_fused >> 3) - 1))) * 5) + (((i0_i1_fused & 7) == 7) ? 4 : (((i0_i1_fused & 7) < 2) ? (1 - (i0_i1_fused & 7)) : ((i0_i1_fused & 7) - 2))))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  MirrorPadInput[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = data[((((96 <= ((((int)blockIdx.x) * 7) + ((int)threadIdx.x))) ? (22 - (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) >> 3)) : ((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 8) ? 0 : ((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) >> 3) - 1))) * 5) + (((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) & 7) == 7) ? (11 - (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) & 7)) : (((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) & 7) < 2) ? (1 - (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) & 7)) : ((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) & 7) - 2))))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 5), \"float32\"), MirrorPadInput: T.Buffer((14, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(112):\n            cse_var_2: T.int32 = i0_i1_fused // 8\n            cse_var_1: T.int32 = i0_i1_fused % 8\n            MirrorPadInput_1 = T.Buffer((112,), data=MirrorPadInput.data)\n            data_1 = T.Buffer((55,), data=data.data)\n            MirrorPadInput_1[i0_i1_fused] = data_1[T.if_then_else(96 <= i0_i1_fused, 22 - cse_var_2, T.if_then_else(i0_i1_fused < 8, 0, cse_var_2 - 1)) * 5 + T.if_then_else(cse_var_1 == 7, 4, T.if_then_else(cse_var_1 < 2, 1 - cse_var_1, cse_var_1 - 2))]", "op_args": [5, 14, 11, 5], "input_shape": "[[11, 5]]", "output_shape": "[[14, 8]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[21];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 21; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 300; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 21; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 21) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 21; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 15; ++k0) {\n    for (int k1 = 0; k1 < 20; ++k1) {\n      for (int k2 = 0; k2 < 3; ++k2) {\n        for (int k3 = 0; k3 < 7; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 420) + (k1 * 21)) + (k2 * 7)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 20, 3, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([21], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((21,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(21):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(300, 21):\n            data_1 = T.Buffer((6300,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 21 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(21):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [15, 20, 3, 7], "input_shape": "[[15, 20, 3, 7]]", "output_shape": "[[]]"}{"op_name": "mirror_pad", "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 98; ++i0_i1_fused) {\n    MirrorPadInput[i0_i1_fused] = data[((((70 <= i0_i1_fused) ? (8 - (i0_i1_fused / 14)) : ((i0_i1_fused < 14) ? 0 : ((i0_i1_fused / 14) - 1))) * 11) + (((i0_i1_fused % 14) == 13) ? 10 : (((i0_i1_fused % 14) < 2) ? (1 - (i0_i1_fused % 14)) : ((i0_i1_fused % 14) - 2))))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) < 49) {\n    MirrorPadInput[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = data[((((35 <= ((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1))) ? (8 - (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) / 7)) : ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) < 7) ? 0 : ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) / 7) - 1))) * 11) + (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 14) == 13) ? (23 - (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 14)) : (((((((int)threadIdx.x) >> 1) + ((int)blockIdx.x)) % 7) < 1) ? (1 - (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 14)) : ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 14) - 2))))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 11), \"float32\"), MirrorPadInput: T.Buffer((7, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(98):\n            cse_var_2: T.int32 = i0_i1_fused // 14\n            cse_var_1: T.int32 = i0_i1_fused % 14\n            MirrorPadInput_1 = T.Buffer((98,), data=MirrorPadInput.data)\n            data_1 = T.Buffer((44,), data=data.data)\n            MirrorPadInput_1[i0_i1_fused] = data_1[T.if_then_else(70 <= i0_i1_fused, 8 - cse_var_2, T.if_then_else(i0_i1_fused < 14, 0, cse_var_2 - 1)) * 11 + T.if_then_else(cse_var_1 == 13, 10, T.if_then_else(cse_var_1 < 2, 1 - cse_var_1, cse_var_1 - 2))]", "op_args": [8, 11, 4, 11], "input_shape": "[[4, 11]]", "output_shape": "[[7, 14]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[9];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 9; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 588; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 9; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 9) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 9; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 7; ++k0) {\n    for (int k1 = 0; k1 < 12; ++k1) {\n      for (int k2 = 0; k2 < 9; ++k2) {\n        for (int k3 = 0; k3 < 7; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 756) + (k1 * 63)) + (k2 * 7)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 12, 9, 7), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([9], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((9,), data=data_red_rf, align=32)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(9):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(588, 9):\n            data_1 = T.Buffer((5292,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 9 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(9):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [7, 12, 9, 7], "input_shape": "[[7, 12, 9, 7]]", "output_shape": "[[]]"}{"op_name": "mirror_pad", "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 21; ++i0) {\n    for (int32_t i1 = 0; i1 < 17; ++i1) {\n      MirrorPadInput[((i0 * 17) + i1)] = data[((((19 <= i0) ? (36 - i0) : ((i0 < 1) ? (0 - i0) : (i0 - 1))) * 14) + ((i1 == 16) ? (29 - i1) : ((i1 < 2) ? (1 - i1) : (i1 - 2))))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 357) {\n    MirrorPadInput[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = data[((((323 <= ((((int)blockIdx.x) * 8) + ((int)threadIdx.x))) ? (36 - (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17)) : ((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 17) ? 0 : ((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 17) - 1))) * 14) + (((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 17) == 16) ? (29 - (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 17)) : (((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 17) < 2) ? (1 - (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 17)) : ((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 17) - 2))))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 14), \"float32\"), MirrorPadInput: T.Buffer((21, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(21):\n            for i1 in range(17):\n                MirrorPadInput_1 = T.Buffer((357,), data=MirrorPadInput.data)\n                data_1 = T.Buffer((252,), data=data.data)\n                MirrorPadInput_1[i0 * 17 + i1] = data_1[T.if_then_else(19 <= i0, 36 - i0, T.if_then_else(i0 < 1, 0 - i0, i0 - 1)) * 14 + T.if_then_else(i1 == 16, 29 - i1, T.if_then_else(i1 < 2, 1 - i1, i1 - 2))]", "op_args": [13, 11, 18, 14], "input_shape": "[[18, 14]]", "output_shape": "[[21, 17]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[35];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 35; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 16; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 35; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 35) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 35; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 1.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 18; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 2) + (((int)threadIdx.x) >> 4)) < 35) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 1, 2, 14), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([35], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((35,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(35):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(16, 35):\n            data_1 = T.Buffer((560,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 35 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(35):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [20, 1, 2, 14], "input_shape": "[[20, 1, 2, 14]]", "output_shape": "[[]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[45];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 45; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 408; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 45; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 45) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 45; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  data_red[0] = 1.000000e+00f;\n  for (int k0 = 0; k0 < 20; ++k0) {\n    for (int k1 = 0; k1 < 17; ++k1) {\n      for (int k2 = 0; k2 < 6; ++k2) {\n        for (int k3 = 0; k3 < 9; ++k3) {\n          data_red[0] = (data_red[0] * data[((((k0 * 918) + (k1 * 54)) + (k2 * 9)) + k3)]);\n        }\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 17, 6, 9), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([45], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((45,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(45):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(408, 45):\n            data_1 = T.Buffer((18360,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 45 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(45):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [20, 17, 6, 9], "input_shape": "[[20, 17, 6, 9]]", "output_shape": "[[]]"}{"op_name": "mirror_pad", "c_code": "void default_function_kernel(float* MirrorPadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 5; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      MirrorPadInput[((i0 * 9) + i1)] = data[((((3 <= i0) ? (4 - i0) : ((i0 < 1) ? (0 - i0) : (i0 - 1))) * 6) + ((i1 == 8) ? (13 - i1) : ((i1 < 2) ? (1 - i1) : (i1 - 2))))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(11) default_function_kernel(float* __restrict__ MirrorPadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) < 45) {\n    MirrorPadInput[((((int)blockIdx.x) * 11) + ((int)threadIdx.x))] = data[((((27 <= ((((int)blockIdx.x) * 11) + ((int)threadIdx.x))) ? (4 - (((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) / 9)) : ((((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) < 9) ? 0 : ((((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) / 9) - 1))) * 6) + (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9) == 8) ? (13 - (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9)) : (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9) < 2) ? (1 - (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9)) : ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 9) - 2))))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 6), \"float32\"), MirrorPadInput: T.Buffer((5, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(5):\n            for i1 in range(9):\n                MirrorPadInput_1 = T.Buffer((45,), data=MirrorPadInput.data)\n                data_1 = T.Buffer((12,), data=data.data)\n                MirrorPadInput_1[i0 * 9 + i1] = data_1[T.if_then_else(3 <= i0, 4 - i0, T.if_then_else(i0 < 1, 0 - i0, i0 - 1)) * 6 + T.if_then_else(i1 == 8, 13 - i1, T.if_then_else(i1 < 2, 1 - i1, i1 - 2))]", "op_args": [14, 16, 2, 6], "input_shape": "[[2, 6]]", "output_shape": "[[5, 9]]"}{"op_name": "prod", "c_code": "void default_function_kernel(float* data, float* data_red) {\n  float data_red_rf[26];\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_init = 0; k0_k1_fused_k2_fused_k3_fused_inner_init < 26; ++k0_k1_fused_k2_fused_k3_fused_inner_init) {\n    data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_init] = 1.000000e+00f;\n  }\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 1320; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    for (int32_t k0_k1_fused_k2_fused_k3_fused_inner = 0; k0_k1_fused_k2_fused_k3_fused_inner < 26; ++k0_k1_fused_k2_fused_k3_fused_inner) {\n      data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] = (data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 26) + k0_k1_fused_k2_fused_k3_fused_inner)]);\n    }\n  }\n  data_red[0] = 1.000000e+00f;\n  for (int32_t k0_k1_fused_k2_fused_k3_fused_inner_v = 0; k0_k1_fused_k2_fused_k3_fused_inner_v < 26; ++k0_k1_fused_k2_fused_k3_fused_inner_v) {\n    data_red[0] = (data_red[0] * data_red_rf[k0_k1_fused_k2_fused_k3_fused_inner_v]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ data_red) {\n  float normal_reduce_temp0[1];\n  float red_buf0[1];\n  normal_reduce_temp0[0] = 1.000000e+00f;\n  for (int k0_k1_fused_k2_fused_k3_fused_outer = 0; k0_k1_fused_k2_fused_k3_fused_outer < 1073; ++k0_k1_fused_k2_fused_k3_fused_outer) {\n    if (((k0_k1_fused_k2_fused_k3_fused_outer * 2) + (((int)threadIdx.x) >> 4)) < 2145) {\n      normal_reduce_temp0[0] = (normal_reduce_temp0[0] * data[((k0_k1_fused_k2_fused_k3_fused_outer * 32) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = normal_reduce_temp0[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] * t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);\n  if (((int)threadIdx.x) == 0) {\n    data_red[0] = red_buf0[0];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 11, 13, 12), \"float32\"), data_red: T.Buffer((), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_red_rf = T.allocate([26], \"float32\", \"global\")\n        data_red_rf_1 = T.Buffer((26,), data=data_red_rf)\n        for k0_k1_fused_k2_fused_k3_fused_inner_init in range(26):\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_init] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_outer, k0_k1_fused_k2_fused_k3_fused_inner in T.grid(1320, 26):\n            data_1 = T.Buffer((34320,), data=data.data)\n            data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] = data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner] * data_1[k0_k1_fused_k2_fused_k3_fused_outer * 26 + k0_k1_fused_k2_fused_k3_fused_inner]\n        data_red_1 = T.Buffer((1,), data=data_red.data)\n        data_red_1[0] = T.float32(1)\n        for k0_k1_fused_k2_fused_k3_fused_inner_v in range(26):\n            data_red_1[0] = data_red_1[0] * data_red_rf_1[k0_k1_fused_k2_fused_k3_fused_inner_v]", "op_args": [20, 11, 13, 12], "input_shape": "[[20, 11, 13, 12]]", "output_shape": "[[]]"}{"op_name": "pad", "c_code": "void default_function_kernel(float* PadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 78; ++i0_i1_fused) {\n    PadInput[i0_i1_fused] = (((((13 <= i0_i1_fused) && (i0_i1_fused < 52)) && (2 <= (i0_i1_fused % 13))) && ((i0_i1_fused % 13) < 12)) ? data[((((i0_i1_fused / 13) * 10) + (i0_i1_fused % 13)) - 12)] : 0.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ PadInput, float* __restrict__ data) {\n  PadInput[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (((((13 <= ((((int)blockIdx.x) * 2) + ((int)threadIdx.x))) && (((int)blockIdx.x) < 26)) && (2 <= (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 13))) && ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 13) < 12)) ? data[((((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) / 13) * 10) + (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 13)) - 12)] : 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 10), \"float32\"), PadInput: T.Buffer((6, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(78):\n            cse_var_1: T.int32 = i0_i1_fused % 13\n            PadInput_1 = T.Buffer((78,), data=PadInput.data)\n            data_1 = T.Buffer((30,), data=data.data)\n            PadInput_1[i0_i1_fused] = T.if_then_else(13 <= i0_i1_fused and i0_i1_fused < 52 and 2 <= cse_var_1 and cse_var_1 < 12, data_1[i0_i1_fused // 13 * 10 + cse_var_1 - 12], T.float32(0))", "op_args": [10, 9, 3, 10], "input_shape": "[[3, 10]]", "output_shape": "[[6, 13]]"}{"op_name": "round", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 16; ++i1) {\n    for (int32_t i2 = 0; i2 < 13; ++i2) {\n      compute[((i1 * 13) + i2)] = roundf(data[((i1 * 13) + i2)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(52) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = roundf(data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 16, 13, 1), \"float32\"), compute: T.Buffer((1, 16, 13, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2 in T.grid(16, 13):\n            cse_var_1: T.int32 = i1 * 13 + i2\n            compute_1 = T.Buffer((208,), data=compute.data)\n            data_1 = T.Buffer((208,), data=data.data)\n            compute_1[cse_var_1] = T.round(data_1[cse_var_1])", "op_args": [1, 16, 13, 1], "input_shape": "[[1, 16, 13, 1]]", "output_shape": "[[1, 16, 13, 1]]"}{"op_name": "pad", "c_code": "void default_function_kernel(float* PadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 5; ++i0) {\n    for (int32_t i1 = 0; i1 < 7; ++i1) {\n      PadInput[((i0 * 7) + i1)] = (((((1 <= i0) && (i0 < 3)) && (2 <= i1)) && (i1 < 6)) ? data[(((i0 * 4) + i1) - 6)] : 0.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ PadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 35) {\n    PadInput[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (((((7 <= ((((int)blockIdx.x) * 8) + ((int)threadIdx.x))) && (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 21)) && (2 <= ((((int)blockIdx.x) + ((int)threadIdx.x)) % 7))) && (((((int)blockIdx.x) + ((int)threadIdx.x)) % 7) < 6)) ? data[((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 7) * 4) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 7)) - 6)] : 0.000000e+00f);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 4), \"float32\"), PadInput: T.Buffer((5, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(5):\n            for i1 in range(7):\n                PadInput_1 = T.Buffer((35,), data=PadInput.data)\n                data_1 = T.Buffer((8,), data=data.data)\n                PadInput_1[i0 * 7 + i1] = T.if_then_else(1 <= i0 and i0 < 3 and 2 <= i1 and i1 < 6, data_1[i0 * 4 + i1 - 6], T.float32(0))", "op_args": [1, 5, 2, 4], "input_shape": "[[2, 4]]", "output_shape": "[[5, 7]]"}{"op_name": "round", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 2432; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 18; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 18) + i3)] = roundf(data[((i0_i1_fused_i2_fused * 18) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = roundf(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 8, 16, 18), \"float32\"), compute: T.Buffer((19, 8, 16, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(2432):\n            for i3 in range(18):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 18 + i3\n                compute_1 = T.Buffer((43776,), data=compute.data)\n                data_1 = T.Buffer((43776,), data=data.data)\n                compute_1[cse_var_1] = T.round(data_1[cse_var_1])", "op_args": [19, 8, 16, 18], "input_shape": "[[19, 8, 16, 18]]", "output_shape": "[[19, 8, 16, 18]]"}{"op_name": "pad", "c_code": "void default_function_kernel(float* PadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 10; ++i0) {\n    for (int32_t i1 = 0; i1 < 15; ++i1) {\n      PadInput[((i0 * 15) + i1)] = (((((1 <= i0) && (i0 < 8)) && (2 <= i1)) && (i1 < 14)) ? data[(((i0 * 12) + i1) - 14)] : 0.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ PadInput, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) < 75) {\n    PadInput[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = (((((15 <= ((((int)blockIdx.x) * 16) + ((int)threadIdx.x))) && (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) < 15)) && (2 <= ((((int)blockIdx.x) + ((int)threadIdx.x)) % 15))) && (((((int)blockIdx.x) + ((int)threadIdx.x)) % 15) < 14)) ? data[((((((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 15) * 12) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 15)) - 14)] : 0.000000e+00f);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 12), \"float32\"), PadInput: T.Buffer((10, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(10):\n            for i1 in range(15):\n                PadInput_1 = T.Buffer((150,), data=PadInput.data)\n                data_1 = T.Buffer((84,), data=data.data)\n                PadInput_1[i0 * 15 + i1] = T.if_then_else(1 <= i0 and i0 < 8 and 2 <= i1 and i1 < 14, data_1[i0 * 12 + i1 - 14], T.float32(0))", "op_args": [6, 5, 7, 12], "input_shape": "[[7, 12]]", "output_shape": "[[10, 15]]"}{"op_name": "round", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 324; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 9; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 9) + i3)] = roundf(data[((i0_i1_fused_i2_fused * 9) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 729) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = roundf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 6, 6, 9), \"float32\"), compute: T.Buffer((9, 6, 6, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(324):\n            for i3 in range(9):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 9 + i3\n                compute_1 = T.Buffer((2916,), data=compute.data)\n                data_1 = T.Buffer((2916,), data=data.data)\n                compute_1[cse_var_1] = T.round(data_1[cse_var_1])", "op_args": [9, 6, 6, 9], "input_shape": "[[9, 6, 6, 9]]", "output_shape": "[[9, 6, 6, 9]]"}{"op_name": "pad", "c_code": "void default_function_kernel(float* PadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 22; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      PadInput[((i0 * 9) + i1)] = (((((1 <= i0) && (i0 < 20)) && (2 <= i1)) && (i1 < 8)) ? data[(((i0 * 6) + i1) - 8)] : 0.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(22) default_function_kernel(float* __restrict__ PadInput, float* __restrict__ data) {\n  PadInput[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))] = (((((9 <= ((((int)blockIdx.x) * 22) + ((int)threadIdx.x))) && (((((int)blockIdx.x) * 11) + (((int)threadIdx.x) >> 1)) < 90)) && (2 <= (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 9))) && ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 9) < 8)) ? data[((((((((int)blockIdx.x) * 22) + ((int)threadIdx.x)) / 9) * 6) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 9)) - 8)] : 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 6), \"float32\"), PadInput: T.Buffer((22, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(22):\n            for i1 in range(9):\n                PadInput_1 = T.Buffer((198,), data=PadInput.data)\n                data_1 = T.Buffer((114,), data=data.data)\n                PadInput_1[i0 * 9 + i1] = T.if_then_else(1 <= i0 and i0 < 20 and 2 <= i1 and i1 < 8, data_1[i0 * 6 + i1 - 8], T.float32(0))", "op_args": [16, 11, 19, 6], "input_shape": "[[19, 6]]", "output_shape": "[[22, 9]]"}{"op_name": "round", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 150; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = roundf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 75) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = roundf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 5, 2, 3), \"float32\"), compute: T.Buffer((5, 5, 2, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(150):\n            compute_1 = T.Buffer((150,), data=compute.data)\n            data_1 = T.Buffer((150,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.round(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [5, 5, 2, 3], "input_shape": "[[5, 5, 2, 3]]", "output_shape": "[[5, 5, 2, 3]]"}{"op_name": "pad", "c_code": "void default_function_kernel(float* PadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 6; ++i0) {\n    for (int32_t i1 = 0; i1 < 14; ++i1) {\n      PadInput[((i0 * 14) + i1)] = (((((1 <= i0) && (i0 < 4)) && (2 <= i1)) && (i1 < 13)) ? data[(((i0 * 11) + i1) - 13)] : 0.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(14) default_function_kernel(float* __restrict__ PadInput, float* __restrict__ data) {\n  PadInput[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] = (((((1 <= ((int)blockIdx.x)) && (((int)blockIdx.x) < 4)) && (2 <= ((int)threadIdx.x))) && (((int)threadIdx.x) < 13)) ? data[(((((int)blockIdx.x) * 11) + ((int)threadIdx.x)) - 13)] : 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 11), \"float32\"), PadInput: T.Buffer((6, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(6):\n            for i1 in range(14):\n                PadInput_1 = T.Buffer((84,), data=PadInput.data)\n                data_1 = T.Buffer((33,), data=data.data)\n                PadInput_1[i0 * 14 + i1] = T.if_then_else(1 <= i0 and i0 < 4 and 2 <= i1 and i1 < 13, data_1[i0 * 11 + i1 - 13], T.float32(0))", "op_args": [10, 5, 3, 11], "input_shape": "[[3, 11]]", "output_shape": "[[6, 14]]"}{"op_name": "round", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 810; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 4; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 4) + i3)] = roundf(data[((i0_i1_fused_i2_fused * 4) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = roundf(data[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 5, 18, 4), \"float32\"), compute: T.Buffer((9, 5, 18, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(810):\n            for i3 in range(4):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 4 + i3\n                compute_1 = T.Buffer((3240,), data=compute.data)\n                data_1 = T.Buffer((3240,), data=data.data)\n                compute_1[cse_var_1] = T.round(data_1[cse_var_1])", "op_args": [9, 5, 18, 4], "input_shape": "[[9, 5, 18, 4]]", "output_shape": "[[9, 5, 18, 4]]"}{"op_name": "pad", "c_code": "void default_function_kernel(float* PadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 108; ++i0_i1_fused) {\n    PadInput[i0_i1_fused] = (((((9 <= i0_i1_fused) && (i0_i1_fused < 90)) && (2 <= (i0_i1_fused % 9))) && ((i0_i1_fused % 9) < 8)) ? data[((((i0_i1_fused / 9) * 6) + (i0_i1_fused % 9)) - 8)] : 0.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ PadInput, float* __restrict__ data) {\n  PadInput[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = (((((1 <= ((((int)blockIdx.x) * 6) + (((int)threadIdx.x) / 9))) && (((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 18)) < 5)) && (2 <= (((int)threadIdx.x) % 9))) && ((((int)threadIdx.x) % 9) < 8)) ? data[((((((int)blockIdx.x) * 36) + ((((int)threadIdx.x) / 9) * 6)) + (((int)threadIdx.x) % 9)) - 8)] : 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 6), \"float32\"), PadInput: T.Buffer((12, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(108):\n            cse_var_1: T.int32 = i0_i1_fused % 9\n            PadInput_1 = T.Buffer((108,), data=PadInput.data)\n            data_1 = T.Buffer((54,), data=data.data)\n            PadInput_1[i0_i1_fused] = T.if_then_else(9 <= i0_i1_fused and i0_i1_fused < 90 and 2 <= cse_var_1 and cse_var_1 < 8, data_1[i0_i1_fused // 9 * 6 + cse_var_1 - 8], T.float32(0))", "op_args": [4, 1, 9, 6], "input_shape": "[[9, 6]]", "output_shape": "[[12, 9]]"}{"op_name": "round", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    for (int32_t i2 = 0; i2 < 2; ++i2) {\n      for (int32_t i3 = 0; i3 < 11; ++i3) {\n        compute[(((i0 * 22) + (i2 * 11)) + i3)] = roundf(data[(((i0 * 22) + (i2 * 11)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(3) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) < 374) {\n    compute[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))] = roundf(data[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 1, 2, 11), \"float32\"), compute: T.Buffer((17, 1, 2, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(17):\n            for i2, i3 in T.grid(2, 11):\n                cse_var_1: T.int32 = i0 * 22 + i2 * 11 + i3\n                compute_1 = T.Buffer((374,), data=compute.data)\n                data_1 = T.Buffer((374,), data=data.data)\n                compute_1[cse_var_1] = T.round(data_1[cse_var_1])", "op_args": [17, 1, 2, 11], "input_shape": "[[17, 1, 2, 11]]", "output_shape": "[[17, 1, 2, 11]]"}{"op_name": "pad", "c_code": "void default_function_kernel(float* PadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 16; ++i0) {\n    for (int32_t i1 = 0; i1 < 22; ++i1) {\n      PadInput[((i0 * 22) + i1)] = (((((1 <= i0) && (i0 < 14)) && (2 <= i1)) && (i1 < 21)) ? data[(((i0 * 19) + i1) - 21)] : 0.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ PadInput, float* __restrict__ data) {\n  PadInput[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (((((11 <= ((int)blockIdx.x)) && (((int)blockIdx.x) < 154)) && (1 <= (((int)blockIdx.x) % 11))) && ((((((int)blockIdx.x) % 11) * 2) + ((int)threadIdx.x)) < 21)) ? data[(((((((int)blockIdx.x) / 11) * 19) + ((((int)blockIdx.x) % 11) * 2)) + ((int)threadIdx.x)) - 21)] : 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 19), \"float32\"), PadInput: T.Buffer((16, 22), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(16):\n            for i1 in range(22):\n                PadInput_1 = T.Buffer((352,), data=PadInput.data)\n                data_1 = T.Buffer((247,), data=data.data)\n                PadInput_1[i0 * 22 + i1] = T.if_then_else(1 <= i0 and i0 < 14 and 2 <= i1 and i1 < 21, data_1[i0 * 19 + i1 - 21], T.float32(0))", "op_args": [7, 9, 13, 19], "input_shape": "[[13, 19]]", "output_shape": "[[16, 22]]"}{"op_name": "round", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 48; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3 = 0; i3 < 15; ++i3) {\n        compute[(((i0_i1_fused * 60) + (i2 * 15)) + i3)] = roundf(data[(((i0_i1_fused * 60) + (i2 * 15)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = roundf(data[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 16, 4, 15), \"float32\"), compute: T.Buffer((3, 16, 4, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(48):\n            for i2, i3 in T.grid(4, 15):\n                cse_var_1: T.int32 = i0_i1_fused * 60 + i2 * 15 + i3\n                compute_1 = T.Buffer((2880,), data=compute.data)\n                data_1 = T.Buffer((2880,), data=data.data)\n                compute_1[cse_var_1] = T.round(data_1[cse_var_1])", "op_args": [3, 16, 4, 15], "input_shape": "[[3, 16, 4, 15]]", "output_shape": "[[3, 16, 4, 15]]"}{"op_name": "pad", "c_code": "void default_function_kernel(float* PadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 14; ++i0) {\n    for (int32_t i1 = 0; i1 < 10; ++i1) {\n      PadInput[((i0 * 10) + i1)] = (((((1 <= i0) && (i0 < 12)) && (2 <= i1)) && (i1 < 9)) ? data[(((i0 * 7) + i1) - 9)] : 0.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ PadInput, float* __restrict__ data) {\n  PadInput[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = (((((5 <= ((((int)blockIdx.x) * 14) + (((int)threadIdx.x) >> 1))) && (((((int)blockIdx.x) * 7) + (((int)threadIdx.x) >> 2)) < 30)) && (1 <= (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 1)) % 5))) && ((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 10) < 9)) ? data[((((((((int)blockIdx.x) * 14) + (((int)threadIdx.x) >> 1)) / 5) * 7) + (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 10)) - 9)] : 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 7), \"float32\"), PadInput: T.Buffer((14, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(14):\n            for i1 in range(10):\n                PadInput_1 = T.Buffer((140,), data=PadInput.data)\n                data_1 = T.Buffer((77,), data=data.data)\n                PadInput_1[i0 * 10 + i1] = T.if_then_else(1 <= i0 and i0 < 12 and 2 <= i1 and i1 < 9, data_1[i0 * 7 + i1 - 9], T.float32(0))", "op_args": [4, 10, 11, 7], "input_shape": "[[11, 7]]", "output_shape": "[[14, 10]]"}{"op_name": "rsqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1890; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 19; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 19) + i3)] = (1.000000e+00f / sqrtf(data[((i0_i1_fused_i2_fused * 19) + i3)]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 9, 15, 19), \"float32\"), compute: T.Buffer((14, 9, 15, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1890):\n            for i3 in range(19):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 19 + i3\n                compute_1 = T.Buffer((35910,), data=compute.data)\n                data_1 = T.Buffer((35910,), data=data.data)\n                compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])", "op_args": [14, 9, 15, 19], "input_shape": "[[14, 9, 15, 19]]", "output_shape": "[[14, 9, 15, 19]]"}{"op_name": "rsqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    for (int32_t i1 = 0; i1 < 17; ++i1) {\n      for (int32_t i2 = 0; i2 < 18; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 2; ++i3_s) {\n          compute[((((i0 * 612) + (i1 * 36)) + (i2 * 2)) + i3_s)] = (1.000000e+00f / sqrtf(data[((((i0 * 612) + (i1 * 36)) + (i2 * 2)) + i3_s)]));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 25) + (((int)threadIdx.x) >> 1)) < 5202) {\n    compute[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 17, 18, 2), \"float32\"), compute: T.Buffer((17, 17, 18, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(17):\n            for i1, i2, i3_s in T.grid(17, 18, 2):\n                cse_var_1: T.int32 = i0 * 612 + i1 * 36 + i2 * 2 + i3_s\n                compute_1 = T.Buffer((10404,), data=compute.data)\n                data_1 = T.Buffer((10404,), data=data.data)\n                compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])", "op_args": [17, 17, 18, 2], "input_shape": "[[17, 17, 18, 2]]", "output_shape": "[[17, 17, 18, 2]]"}{"op_name": "pad", "c_code": "void default_function_kernel(float* PadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 7; ++i1) {\n      PadInput[((i0 * 7) + i1)] = (((((1 <= i0) && (i0 < 2)) && (2 <= i1)) && (i1 < 6)) ? data[(((i0 * 4) + i1) - 6)] : 0.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ PadInput, float* __restrict__ data) {\n  PadInput[((int)threadIdx.x)] = (((((7 <= ((int)threadIdx.x)) && (((int)threadIdx.x) < 14)) && (2 <= (((int)threadIdx.x) % 7))) && ((((int)threadIdx.x) % 7) < 6)) ? data[((((((int)threadIdx.x) / 7) * 4) + (((int)threadIdx.x) % 7)) - 6)] : 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 4), \"float32\"), PadInput: T.Buffer((4, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            for i1 in range(7):\n                PadInput_1 = T.Buffer((28,), data=PadInput.data)\n                data_1 = T.Buffer((4,), data=data.data)\n                PadInput_1[i0 * 7 + i1] = T.if_then_else(1 <= i0 and i0 < 2 and 2 <= i1 and i1 < 6, data_1[i0 * 4 + i1 - 6], T.float32(0))", "op_args": [11, 1, 1, 4], "input_shape": "[[1, 4]]", "output_shape": "[[4, 7]]"}{"op_name": "rsqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 18; ++i1) {\n    for (int32_t i2 = 0; i2 < 16; ++i2) {\n      for (int32_t i3 = 0; i3 < 19; ++i3) {\n        compute[(((i1 * 304) + (i2 * 19)) + i3)] = (1.000000e+00f / sqrtf(data[(((i1 * 304) + (i2 * 19)) + i3)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(57) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 57) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 57) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 18, 16, 19), \"float32\"), compute: T.Buffer((1, 18, 16, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(18, 16, 19):\n            cse_var_1: T.int32 = i1 * 304 + i2 * 19 + i3\n            compute_1 = T.Buffer((5472,), data=compute.data)\n            data_1 = T.Buffer((5472,), data=data.data)\n            compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])", "op_args": [1, 18, 16, 19], "input_shape": "[[1, 18, 16, 19]]", "output_shape": "[[1, 18, 16, 19]]"}{"op_name": "rsqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 16; ++i2) {\n        for (int32_t i3 = 0; i3 < 20; ++i3) {\n          compute[((((i0 * 3520) + (i1 * 320)) + (i2 * 20)) + i3)] = (1.000000e+00f / sqrtf(data[((((i0 * 3520) + (i1 * 320)) + (i2 * 20)) + i3)]));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 11, 16, 20), \"float32\"), compute: T.Buffer((15, 11, 16, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(15):\n            for i1, i2, i3 in T.grid(11, 16, 20):\n                cse_var_1: T.int32 = i0 * 3520 + i1 * 320 + i2 * 20 + i3\n                compute_1 = T.Buffer((52800,), data=compute.data)\n                data_1 = T.Buffer((52800,), data=data.data)\n                compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])", "op_args": [15, 11, 16, 20], "input_shape": "[[15, 11, 16, 20]]", "output_shape": "[[15, 11, 16, 20]]"}{"op_name": "pad", "c_code": "void default_function_kernel(float* PadInput, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 138; ++i0_i1_fused) {\n    PadInput[i0_i1_fused] = (((((23 <= i0_i1_fused) && (i0_i1_fused < 92)) && (2 <= (i0_i1_fused % 23))) && ((i0_i1_fused % 23) < 22)) ? data[((((i0_i1_fused / 23) * 20) + (i0_i1_fused % 23)) - 22)] : 0.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ PadInput, float* __restrict__ data) {\n  PadInput[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (((((23 <= ((((int)blockIdx.x) * 2) + ((int)threadIdx.x))) && (((int)blockIdx.x) < 46)) && (2 <= (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 23))) && ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 23) < 22)) ? data[((((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) / 23) * 20) + (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 23)) - 22)] : 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 20), \"float32\"), PadInput: T.Buffer((6, 23), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(138):\n            cse_var_1: T.int32 = i0_i1_fused % 23\n            PadInput_1 = T.Buffer((138,), data=PadInput.data)\n            data_1 = T.Buffer((60,), data=data.data)\n            PadInput_1[i0_i1_fused] = T.if_then_else(23 <= i0_i1_fused and i0_i1_fused < 92 and 2 <= cse_var_1 and cse_var_1 < 22, data_1[i0_i1_fused // 23 * 20 + cse_var_1 - 22], T.float32(0))", "op_args": [17, 12, 3, 20], "input_shape": "[[3, 20]]", "output_shape": "[[6, 23]]"}{"op_name": "rsqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 306; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 5; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 11; ++i3_s) {\n        compute[(((i0_i1_fused * 55) + (i2 * 11)) + i3_s)] = (1.000000e+00f / sqrtf(data[(((i0_i1_fused * 55) + (i2 * 11)) + i3_s)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 18, 5, 11), \"float32\"), compute: T.Buffer((17, 18, 5, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(306):\n            for i2, i3_s in T.grid(5, 11):\n                cse_var_1: T.int32 = i0_i1_fused * 55 + i2 * 11 + i3_s\n                compute_1 = T.Buffer((16830,), data=compute.data)\n                data_1 = T.Buffer((16830,), data=data.data)\n                compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])", "op_args": [17, 18, 5, 11], "input_shape": "[[17, 18, 5, 11]]", "output_shape": "[[17, 18, 5, 11]]"}{"op_name": "pool1d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 20; ++ax0) {\n    float pad_temp[285];\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2_s = 0; ax2_s < 15; ++ax2_s) {\n        pad_temp[((ax1 * 15) + ax2_s)] = (((1 <= ax2_s) && (ax2_s < 14)) ? data[((((ax0 * 247) + (ax1 * 13)) + ax2_s) - 1)] : -3.402823e+38f);\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 19; ++ax1_1) {\n      for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n        pool_max[(((ax0 * 133) + (ax1_1 * 7)) + ax2)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          pool_max[(((ax0 * 133) + (ax1_1 * 7)) + ax2)] = max(pool_max[(((ax0 * 133) + (ax1_1 * 7)) + ax2)], pad_temp[(((ax1_1 * 15) + (ax2 * 2)) + rv0)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    pool_max[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))], (((1 <= (((((int)threadIdx.x) % 7) * 2) + rv0)) && (((rv0 >> 1) + (((int)threadIdx.x) % 7)) < 7)) ? data[(((((((int)blockIdx.x) * 52) + ((((int)threadIdx.x) / 7) * 13)) + ((((int)threadIdx.x) % 7) * 2)) + rv0) - 1)] : -3.402823e+38f));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 19, 13), \"float32\"), pool_max: T.Buffer((20, 19, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(20):\n            pad_temp = T.allocate([285], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((285,), data=pad_temp)\n            for ax1, ax2_s in T.grid(19, 15):\n                data_1 = T.Buffer((4940,), data=data.data)\n                pad_temp_1[ax1 * 15 + ax2_s] = T.if_then_else(1 <= ax2_s and ax2_s < 14, data_1[ax0 * 247 + ax1 * 13 + ax2_s - 1], T.float32(-3.4028234663852886e+38))\n            for ax1, ax2 in T.grid(19, 7):\n                pool_max_1 = T.Buffer((2660,), data=pool_max.data)\n                pool_max_1[ax0 * 133 + ax1 * 7 + ax2] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_1: T.int32 = ax0 * 133 + ax1 * 7 + ax2\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax1 * 15 + ax2 * 2 + rv0])", "op_args": [20, 19, 20, 13], "input_shape": "[[20, 19, 13]]", "output_shape": "[[20, 19, 7]]"}{"op_name": "rsqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    for (int32_t i1 = 0; i1 < 14; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        compute[(((i0 * 196) + (i1 * 14)) + i2)] = (1.000000e+00f / sqrtf(data[(((i0 * 196) + (i1 * 14)) + i2)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 14, 14, 1), \"float32\"), compute: T.Buffer((18, 14, 14, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(18):\n            for i1, i2 in T.grid(14, 14):\n                cse_var_1: T.int32 = i0 * 196 + i1 * 14 + i2\n                compute_1 = T.Buffer((3528,), data=compute.data)\n                data_1 = T.Buffer((3528,), data=data.data)\n                compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])", "op_args": [18, 14, 14, 1], "input_shape": "[[18, 14, 14, 1]]", "output_shape": "[[18, 14, 14, 1]]"}{"op_name": "pool1d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 10; ++ax0) {\n    float pad_temp[3];\n    for (int32_t ax1 = 0; ax1 < 18; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 3; ++ax2) {\n        for (int32_t ax1_ax2_fused_s = 0; ax1_ax2_fused_s < 3; ++ax1_ax2_fused_s) {\n          pad_temp[ax1_ax2_fused_s] = (((1 <= ((ax2 * 2) + ax1_ax2_fused_s)) && (((ax1_ax2_fused_s >> 1) + ax2) < 3)) ? data[(((((ax0 * 90) + (ax1 * 5)) + (ax2 * 2)) + ax1_ax2_fused_s) - 1)] : -3.402823e+38f);\n        }\n        pool_max[(((ax0 * 54) + (ax1 * 3)) + ax2)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          pool_max[(((ax0 * 54) + (ax1 * 3)) + ax2)] = max(pool_max[(((ax0 * 54) + (ax1 * 3)) + ax2)], pad_temp[rv0]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 2)) < 135) {\n    pool_max[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 2)) < 135) {\n      pool_max[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))], (((1 <= (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 3) * 2) + rv0)) && (((rv0 >> 1) + (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 3)) < 3)) ? data[(((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 3) * 5) + ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 3) * 2)) + rv0) - 1)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 18, 5), \"float32\"), pool_max: T.Buffer((10, 18, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(10):\n            pad_temp = T.allocate([3], \"float32\", \"global\")\n            for ax1, ax2 in T.grid(18, 3):\n                pad_temp_1 = T.Buffer((3,), data=pad_temp, align=8)\n                for ax1_ax2_fused_s in range(3):\n                    cse_var_1: T.int32 = ax2 * 2\n                    data_1 = T.Buffer((900,), data=data.data)\n                    pad_temp_1[ax1_ax2_fused_s] = T.if_then_else(1 <= cse_var_1 + ax1_ax2_fused_s and ax1_ax2_fused_s // 2 + ax2 < 3, data_1[ax0 * 90 + ax1 * 5 + cse_var_1 + ax1_ax2_fused_s - 1], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((540,), data=pool_max.data)\n                pool_max_1[ax0 * 54 + ax1 * 3 + ax2] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_2: T.int32 = ax0 * 54 + ax1 * 3 + ax2\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0])", "op_args": [10, 18, 3, 5], "input_shape": "[[10, 18, 5]]", "output_shape": "[[10, 18, 3]]"}{"op_name": "rsqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 73440; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (1.000000e+00f / sqrtf(data[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 15, 18, 17), \"float32\"), compute: T.Buffer((16, 15, 18, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(73440):\n            compute_1 = T.Buffer((73440,), data=compute.data)\n            data_1 = T.Buffer((73440,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.rsqrt(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [16, 15, 18, 17], "input_shape": "[[16, 15, 18, 17]]", "output_shape": "[[16, 15, 18, 17]]"}{"op_name": "pool1d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 5; ++ax0) {\n    float pad_temp[323];\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 17; ++ax2) {\n        pad_temp[((ax1 * 17) + ax2)] = (((1 <= ax2) && (ax2 < 16)) ? data[((((ax0 * 285) + (ax1 * 15)) + ax2) - 1)] : -3.402823e+38f);\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 19; ++ax1_1) {\n      for (int32_t ax2_1 = 0; ax2_1 < 8; ++ax2_1) {\n        pool_max[(((ax0 * 152) + (ax1_1 * 8)) + ax2_1)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          pool_max[(((ax0 * 152) + (ax1_1 * 8)) + ax2_1)] = max(pool_max[(((ax0 * 152) + (ax1_1 * 8)) + ax2_1)], pad_temp[(((ax1_1 * 17) + (ax2_1 * 2)) + rv0)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))], (((1 <= (((((int)threadIdx.x) & 7) * 2) + rv0)) && (((rv0 >> 1) + (((int)threadIdx.x) & 7)) < 8)) ? data[(((((((int)blockIdx.x) * 75) + ((((int)threadIdx.x) >> 3) * 15)) + ((((int)threadIdx.x) & 7) * 2)) + rv0) - 1)] : -3.402823e+38f));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 19, 15), \"float32\"), pool_max: T.Buffer((5, 19, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(5):\n            pad_temp = T.allocate([323], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((323,), data=pad_temp)\n            for ax1, ax2 in T.grid(19, 17):\n                data_1 = T.Buffer((1425,), data=data.data)\n                pad_temp_1[ax1 * 17 + ax2] = T.if_then_else(1 <= ax2 and ax2 < 16, data_1[ax0 * 285 + ax1 * 15 + ax2 - 1], T.float32(-3.4028234663852886e+38))\n            for ax1, ax2 in T.grid(19, 8):\n                pool_max_1 = T.Buffer((760,), data=pool_max.data)\n                pool_max_1[ax0 * 152 + ax1 * 8 + ax2] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_1: T.int32 = ax0 * 152 + ax1 * 8 + ax2\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax1 * 17 + ax2 * 2 + rv0])", "op_args": [5, 19, 20, 15], "input_shape": "[[5, 19, 15]]", "output_shape": "[[5, 19, 8]]"}{"op_name": "rsqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 144; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 16; ++i2) {\n      for (int32_t i3 = 0; i3 < 19; ++i3) {\n        compute[(((i0_i1_fused * 304) + (i2 * 19)) + i3)] = (1.000000e+00f / sqrtf(data[(((i0_i1_fused * 304) + (i2 * 19)) + i3)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 12, 16, 19), \"float32\"), compute: T.Buffer((12, 12, 16, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(144):\n            for i2, i3 in T.grid(16, 19):\n                cse_var_1: T.int32 = i0_i1_fused * 304 + i2 * 19 + i3\n                compute_1 = T.Buffer((43776,), data=compute.data)\n                data_1 = T.Buffer((43776,), data=data.data)\n                compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])", "op_args": [12, 12, 16, 19], "input_shape": "[[12, 12, 16, 19]]", "output_shape": "[[12, 12, 16, 19]]"}{"op_name": "rsqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 36; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 12; ++i2) {\n      for (int32_t i3 = 0; i3 < 6; ++i3) {\n        compute[(((i0_i1_fused * 72) + (i2 * 6)) + i3)] = (1.000000e+00f / sqrtf(data[(((i0_i1_fused * 72) + (i2 * 6)) + i3)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 18, 12, 6), \"float32\"), compute: T.Buffer((2, 18, 12, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(36):\n            for i2, i3 in T.grid(12, 6):\n                cse_var_1: T.int32 = i0_i1_fused * 72 + i2 * 6 + i3\n                compute_1 = T.Buffer((2592,), data=compute.data)\n                data_1 = T.Buffer((2592,), data=data.data)\n                compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])", "op_args": [2, 18, 12, 6], "input_shape": "[[2, 18, 12, 6]]", "output_shape": "[[2, 18, 12, 6]]"}{"op_name": "pool1d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 16; ++ax0) {\n    float pad_temp[72];\n    for (int32_t ax1 = 0; ax1 < 8; ++ax1) {\n      for (int32_t ax2_s = 0; ax2_s < 9; ++ax2_s) {\n        pad_temp[((ax1 * 9) + ax2_s)] = (((1 <= ax2_s) && (ax2_s < 8)) ? data[((((ax0 * 56) + (ax1 * 7)) + ax2_s) - 1)] : -3.402823e+38f);\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 8; ++ax1_1) {\n      for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n        pool_max[(((ax0 * 32) + (ax1_1 * 4)) + ax2)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          pool_max[(((ax0 * 32) + (ax1_1 * 4)) + ax2)] = max(pool_max[(((ax0 * 32) + (ax1_1 * 4)) + ax2)], pad_temp[(((ax1_1 * 9) + (ax2 * 2)) + rv0)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    pool_max[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], (((1 <= (((((int)threadIdx.x) & 3) * 2) + rv0)) && (((rv0 >> 1) + (((int)threadIdx.x) & 3)) < 4)) ? data[(((((((int)blockIdx.x) * 56) + ((((int)threadIdx.x) >> 2) * 7)) + ((((int)threadIdx.x) & 3) * 2)) + rv0) - 1)] : -3.402823e+38f));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 8, 7), \"float32\"), pool_max: T.Buffer((16, 8, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(16):\n            pad_temp = T.allocate([72], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((72,), data=pad_temp)\n            for ax1, ax2_s in T.grid(8, 9):\n                data_1 = T.Buffer((896,), data=data.data)\n                pad_temp_1[ax1 * 9 + ax2_s] = T.if_then_else(1 <= ax2_s and ax2_s < 8, data_1[ax0 * 56 + ax1 * 7 + ax2_s - 1], T.float32(-3.4028234663852886e+38))\n            for ax1, ax2 in T.grid(8, 4):\n                pool_max_1 = T.Buffer((512,), data=pool_max.data)\n                pool_max_1[ax0 * 32 + ax1 * 4 + ax2] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_1: T.int32 = ax0 * 32 + ax1 * 4 + ax2\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax1 * 9 + ax2 * 2 + rv0])", "op_args": [16, 8, 19, 7], "input_shape": "[[16, 8, 7]]", "output_shape": "[[16, 8, 4]]"}{"op_name": "rsqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 20; ++i0) {\n    for (int32_t i1 = 0; i1 < 17; ++i1) {\n      for (int32_t i2 = 0; i2 < 16; ++i2) {\n        compute[(((i0 * 272) + (i1 * 16)) + i2)] = (1.000000e+00f / sqrtf(data[(((i0 * 272) + (i1 * 16)) + i2)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 17, 16, 1), \"float32\"), compute: T.Buffer((20, 17, 16, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(20):\n            for i1, i2 in T.grid(17, 16):\n                cse_var_1: T.int32 = i0 * 272 + i1 * 16 + i2\n                compute_1 = T.Buffer((5440,), data=compute.data)\n                data_1 = T.Buffer((5440,), data=data.data)\n                compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])", "op_args": [20, 17, 16, 1], "input_shape": "[[20, 17, 16, 1]]", "output_shape": "[[20, 17, 16, 1]]"}{"op_name": "pool1d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 13; ++ax0) {\n    float pad_temp[3];\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      for (int32_t ax2_s = 0; ax2_s < 3; ++ax2_s) {\n        pad_temp[ax2_s] = (((1 <= ax2_s) && (ax2_s < 2)) ? data[((((ax0 * 10) + ax1) + ax2_s) - 1)] : -3.402823e+38f);\n      }\n      pool_max[((ax0 * 10) + ax1)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n        pool_max[((ax0 * 10) + ax1)] = max(pool_max[((ax0 * 10) + ax1)], pad_temp[rv0]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 1)) < 65) {\n    pool_max[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 1)) < 65) {\n      pool_max[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))], (((1 <= rv0) && (rv0 < 2)) ? data[((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) + rv0) - 1)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 10, 1), \"float32\"), pool_max: T.Buffer((13, 10, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(13):\n            pad_temp = T.allocate([3], \"float32\", \"global\")\n            for ax1 in range(10):\n                pad_temp_1 = T.Buffer((3,), data=pad_temp, align=8)\n                for ax2_s in range(3):\n                    data_1 = T.Buffer((130,), data=data.data)\n                    pad_temp_1[ax2_s] = T.if_then_else(1 <= ax2_s and ax2_s < 2, data_1[ax0 * 10 + ax1 + ax2_s - 1], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((130,), data=pool_max.data)\n                pool_max_1[ax0 * 10 + ax1] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_1: T.int32 = ax0 * 10 + ax1\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[rv0])", "op_args": [13, 10, 7, 1], "input_shape": "[[13, 10, 1]]", "output_shape": "[[13, 10, 1]]"}{"op_name": "pool1d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 19; ++ax0) {\n    float pad_temp[13];\n    for (int32_t ax2_s = 0; ax2_s < 13; ++ax2_s) {\n      pad_temp[ax2_s] = (((1 <= ax2_s) && (ax2_s < 12)) ? data[(((ax0 * 11) + ax2_s) - 1)] : -3.402823e+38f);\n    }\n    for (int32_t ax2 = 0; ax2 < 6; ++ax2) {\n      pool_max[((ax0 * 6) + ax2)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n        pool_max[((ax0 * 6) + ax2)] = max(pool_max[((ax0 * 6) + ax2)], pad_temp[((ax2 * 2) + rv0)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  if (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 114) {\n    pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    if (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) < 114) {\n      pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))], (((1 <= ((((((int)blockIdx.x) + ((int)threadIdx.x)) % 6) * 2) + rv0)) && (((rv0 >> 1) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 6)) < 6)) ? data[(((((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) / 6) * 11) + (((((int)blockIdx.x) + ((int)threadIdx.x)) % 6) * 2)) + rv0) - 1)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 1, 11), \"float32\"), pool_max: T.Buffer((19, 1, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(19):\n            pad_temp = T.allocate([13], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((13,), data=pad_temp, align=32)\n            for ax2_s in range(13):\n                data_1 = T.Buffer((209,), data=data.data)\n                pad_temp_1[ax2_s] = T.if_then_else(1 <= ax2_s and ax2_s < 12, data_1[ax0 * 11 + ax2_s - 1], T.float32(-3.4028234663852886e+38))\n            for ax2 in range(6):\n                pool_max_1 = T.Buffer((114,), data=pool_max.data)\n                pool_max_1[ax0 * 6 + ax2] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_1: T.int32 = ax0 * 6 + ax2\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 2 + rv0])", "op_args": [19, 1, 5, 11], "input_shape": "[[19, 1, 11]]", "output_shape": "[[19, 1, 6]]"}{"op_name": "shape", "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 11 : ((ax0 == 2) ? 1 : ((ax0 == 1) ? 5 : 14)));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 11 : ((((int)threadIdx.x) == 2) ? 1 : ((((int)threadIdx.x) == 1) ? 5 : 14)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 5, 1, 11), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 11, T.if_then_else(ax0 == 2, 1, T.if_then_else(ax0 == 1, 5, 14)))", "op_args": [14, 5, 1, 11], "input_shape": "[[14, 5, 1, 11]]", "output_shape": "[[4]]"}{"op_name": "pool1d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 17; ++ax0) {\n    float pad_temp[21];\n    for (int32_t ax1 = 0; ax1 < 16; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 21; ++ax2) {\n        pad_temp[ax2] = ((1 <= ax2) ? data[((((ax0 * 320) + (ax1 * 20)) + ax2) - 1)] : -3.402823e+38f);\n      }\n      for (int32_t ax2_1 = 0; ax2_1 < 10; ++ax2_1) {\n        pool_max[(((ax0 * 160) + (ax1 * 10)) + ax2_1)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          pool_max[(((ax0 * 160) + (ax1 * 10)) + ax2_1)] = max(pool_max[(((ax0 * 160) + (ax1 * 10)) + ax2_1)], pad_temp[((ax2_1 * 2) + rv0)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))], ((1 <= (((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10) * 2) + rv0)) ? data[((((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 2)) + rv0) - 1)] : -3.402823e+38f));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 16, 20), \"float32\"), pool_max: T.Buffer((17, 16, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(17):\n            pad_temp = T.allocate([21], \"float32\", \"global\")\n            for ax1 in range(16):\n                pad_temp_1 = T.Buffer((21,), data=pad_temp)\n                for ax2 in range(21):\n                    data_1 = T.Buffer((5440,), data=data.data)\n                    pad_temp_1[ax2] = T.if_then_else(1 <= ax2, data_1[ax0 * 320 + ax1 * 20 + ax2 - 1], T.float32(-3.4028234663852886e+38))\n                for ax2 in range(10):\n                    pool_max_1 = T.Buffer((2720,), data=pool_max.data)\n                    pool_max_1[ax0 * 160 + ax1 * 10 + ax2] = T.float32(-3.4028234663852886e+38)\n                    for rv0 in range(3):\n                        cse_var_1: T.int32 = ax0 * 160 + ax1 * 10 + ax2\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 2 + rv0])", "op_args": [17, 16, 10, 20], "input_shape": "[[17, 16, 20]]", "output_shape": "[[17, 16, 10]]"}{"op_name": "pool1d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 108; ++ax0_ax1_fused) {\n    float pad_temp[3];\n    for (int32_t ax2 = 0; ax2 < 5; ++ax2) {\n      for (int32_t ax1_ax2_fused_s = 0; ax1_ax2_fused_s < 3; ++ax1_ax2_fused_s) {\n        pad_temp[ax1_ax2_fused_s] = (((1 <= ((ax2 * 2) + ax1_ax2_fused_s)) && (((ax1_ax2_fused_s >> 1) + ax2) < 5)) ? data[((((ax0_ax1_fused * 9) + (ax2 * 2)) + ax1_ax2_fused_s) - 1)] : -3.402823e+38f);\n      }\n      pool_max[((ax0_ax1_fused * 5) + ax2)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n        pool_max[((ax0_ax1_fused * 5) + ax2)] = max(pool_max[((ax0_ax1_fused * 5) + ax2)], pad_temp[rv0]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    pool_max[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], (((1 <= (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 5) * 2) + rv0)) && (((rv0 >> 1) + (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 5)) < 5)) ? data[(((((((((int)blockIdx.x) * 12) + ((int)threadIdx.x)) / 5) * 9) + ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 5) * 2)) + rv0) - 1)] : -3.402823e+38f));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 9, 9), \"float32\"), pool_max: T.Buffer((12, 9, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(108):\n            pad_temp = T.allocate([3], \"float32\", \"global\")\n            for ax2 in range(5):\n                pad_temp_1 = T.Buffer((3,), data=pad_temp, align=8)\n                for ax1_ax2_fused_s in range(3):\n                    cse_var_1: T.int32 = ax2 * 2\n                    data_1 = T.Buffer((972,), data=data.data)\n                    pad_temp_1[ax1_ax2_fused_s] = T.if_then_else(1 <= cse_var_1 + ax1_ax2_fused_s and ax1_ax2_fused_s // 2 + ax2 < 5, data_1[ax0_ax1_fused * 9 + cse_var_1 + ax1_ax2_fused_s - 1], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((540,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused * 5 + ax2] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_2: T.int32 = ax0_ax1_fused * 5 + ax2\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0])", "op_args": [12, 9, 5, 9], "input_shape": "[[12, 9, 9]]", "output_shape": "[[12, 9, 5]]"}{"op_name": "shape", "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 3 : ((ax0 == 2) ? 2 : ((ax0 == 1) ? 3 : 9)));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 3 : ((((int)threadIdx.x) == 2) ? 2 : ((((int)threadIdx.x) == 1) ? 3 : 9)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 3, 2, 3), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 3, T.if_then_else(ax0 == 2, 2, T.if_then_else(ax0 == 1, 3, 9)))", "op_args": [9, 3, 2, 3], "input_shape": "[[9, 3, 2, 3]]", "output_shape": "[[4]]"}{"op_name": "pool1d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 17; ++ax0) {\n    float pad_temp[169];\n    for (int32_t ax1 = 0; ax1 < 13; ++ax1) {\n      for (int32_t ax2_s = 0; ax2_s < 13; ++ax2_s) {\n        pad_temp[((ax1 * 13) + ax2_s)] = ((1 <= ax2_s) ? data[((((ax0 * 156) + (ax1 * 12)) + ax2_s) - 1)] : -3.402823e+38f);\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 13; ++ax1_1) {\n      for (int32_t ax2 = 0; ax2 < 6; ++ax2) {\n        pool_max[(((ax0 * 78) + (ax1_1 * 6)) + ax2)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          pool_max[(((ax0 * 78) + (ax1_1 * 6)) + ax2)] = max(pool_max[(((ax0 * 78) + (ax1_1 * 6)) + ax2)], pad_temp[(((ax1_1 * 13) + (ax2 * 2)) + rv0)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(51) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    pool_max[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))], ((1 <= (((((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) % 6) * 2) + rv0)) ? data[((((((int)blockIdx.x) * 102) + (((int)threadIdx.x) * 2)) + rv0) - 1)] : -3.402823e+38f));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 13, 12), \"float32\"), pool_max: T.Buffer((17, 13, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(17):\n            pad_temp = T.allocate([169], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((169,), data=pad_temp)\n            for ax1, ax2_s in T.grid(13, 13):\n                data_1 = T.Buffer((2652,), data=data.data)\n                pad_temp_1[ax1 * 13 + ax2_s] = T.if_then_else(1 <= ax2_s, data_1[ax0 * 156 + ax1 * 12 + ax2_s - 1], T.float32(-3.4028234663852886e+38))\n            for ax1, ax2 in T.grid(13, 6):\n                pool_max_1 = T.Buffer((1326,), data=pool_max.data)\n                pool_max_1[ax0 * 78 + ax1 * 6 + ax2] = T.float32(-3.4028234663852886e+38)\n                for rv0 in range(3):\n                    cse_var_1: T.int32 = ax0 * 78 + ax1 * 6 + ax2\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax1 * 13 + ax2 * 2 + rv0])", "op_args": [17, 13, 6, 12], "input_shape": "[[17, 13, 12]]", "output_shape": "[[17, 13, 6]]"}{"op_name": "shape", "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 8 : ((ax0 == 2) ? 8 : ((ax0 == 1) ? 5 : 2)));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 8 : ((((int)threadIdx.x) == 2) ? 8 : ((((int)threadIdx.x) == 1) ? 5 : 2)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 5, 8, 8), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 8, T.if_then_else(ax0 == 2, 8, T.if_then_else(ax0 == 1, 5, 2)))", "op_args": [2, 5, 8, 8], "input_shape": "[[2, 5, 8, 8]]", "output_shape": "[[4]]"}{"op_name": "pool1d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 1568; ++ax0_ax1_fused_ax2_fused) {\n    float pad_temp[3];\n    for (int32_t ax1_ax2_fused_s = 0; ax1_ax2_fused_s < 3; ++ax1_ax2_fused_s) {\n      pad_temp[ax1_ax2_fused_s] = (((1 <= (((ax0_ax1_fused_ax2_fused % 7) * 2) + ax1_ax2_fused_s)) && (((ax1_ax2_fused_s >> 1) + (ax0_ax1_fused_ax2_fused % 7)) < 7)) ? data[(((((ax0_ax1_fused_ax2_fused / 7) * 13) + ((ax0_ax1_fused_ax2_fused % 7) * 2)) + ax1_ax2_fused_s) - 1)] : -3.402823e+38f);\n    }\n    pool_max[ax0_ax1_fused_ax2_fused] = -3.402823e+38f;\n    for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n      pool_max[ax0_ax1_fused_ax2_fused] = max(pool_max[ax0_ax1_fused_ax2_fused], pad_temp[rv0]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    pool_max[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))], (((1 <= (((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 7) * 2) + rv0)) && (((rv0 >> 1) + (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 7)) < 7)) ? data[(((((((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 7) * 13) + ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 7) * 2)) + rv0) - 1)] : -3.402823e+38f));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 16, 13), \"float32\"), pool_max: T.Buffer((14, 16, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(1568):\n            pad_temp = T.allocate([3], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((3,), data=pad_temp, align=8)\n            for ax1_ax2_fused_s in range(3):\n                cse_var_2: T.int32 = ax0_ax1_fused_ax2_fused % 7\n                cse_var_1: T.int32 = cse_var_2 * 2\n                data_1 = T.Buffer((2912,), data=data.data)\n                pad_temp_1[ax1_ax2_fused_s] = T.if_then_else(1 <= cse_var_1 + ax1_ax2_fused_s and ax1_ax2_fused_s // 2 + cse_var_2 < 7, data_1[ax0_ax1_fused_ax2_fused // 7 * 13 + cse_var_1 + ax1_ax2_fused_s - 1], T.float32(-3.4028234663852886e+38))\n            pool_max_1 = T.Buffer((1568,), data=pool_max.data)\n            pool_max_1[ax0_ax1_fused_ax2_fused] = T.float32(-3.4028234663852886e+38)\n            for rv0 in range(3):\n                pool_max_1[ax0_ax1_fused_ax2_fused] = T.max(pool_max_1[ax0_ax1_fused_ax2_fused], pad_temp_1[rv0])", "op_args": [14, 16, 2, 13], "input_shape": "[[14, 16, 13]]", "output_shape": "[[14, 16, 7]]"}{"op_name": "shape", "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 7 : ((ax0 == 2) ? 10 : ((ax0 == 1) ? 13 : 20)));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 7 : ((((int)threadIdx.x) == 2) ? 10 : ((((int)threadIdx.x) == 1) ? 13 : 20)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 13, 10, 7), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 7, T.if_then_else(ax0 == 2, 10, T.if_then_else(ax0 == 1, 13, 20)))", "op_args": [20, 13, 10, 7], "input_shape": "[[20, 13, 10, 7]]", "output_shape": "[[4]]"}{"op_name": "pool2d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 3; ++ax0) {\n    float pad_temp[935];\n    for (int32_t ax1 = 0; ax1 < 11; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 17; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 55; ++ax3) {\n          pad_temp[((ax2 * 55) + ax3)] = ((((1 <= ax2) && (ax2 < 16)) && (1 <= ax3)) ? data[(((((ax0 * 8910) + (ax1 * 810)) + (ax2 * 54)) + ax3) - 55)] : -3.402823e+38f);\n        }\n      }\n      for (int32_t ax2_1 = 0; ax2_1 < 8; ++ax2_1) {\n        for (int32_t ax3_1 = 0; ax3_1 < 27; ++ax3_1) {\n          pool_max[((((ax0 * 2376) + (ax1 * 216)) + (ax2_1 * 27)) + ax3_1)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              pool_max[((((ax0 * 2376) + (ax1 * 216)) + (ax2_1 * 27)) + ax3_1)] = max(pool_max[((((ax0 * 2376) + (ax1 * 216)) + (ax2_1 * 27)) + ax3_1)], pad_temp[((((ax2_1 * 110) + (rv0 * 55)) + (ax3_1 * 2)) + rv1)]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], ((((1 <= ((((((((int)blockIdx.x) % 9) * 8) + (((int)threadIdx.x) / 3)) / 9) * 2) + rv0)) && ((((((((int)blockIdx.x) % 9) * 8) + (((int)threadIdx.x) / 3)) / 9) + (rv0 >> 1)) < 8)) && (1 <= (((((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 27) * 2) + rv1))) ? data[(((((((((int)blockIdx.x) / 9) * 810) + (((((((int)blockIdx.x) % 9) * 8) + (((int)threadIdx.x) / 3)) / 9) * 108)) + (rv0 * 54)) + ((((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 27) * 2)) + rv1) - 55)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 11, 15, 54), \"float32\"), pool_max: T.Buffer((3, 11, 8, 27), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(3):\n            pad_temp = T.allocate([935], \"float32\", \"global\")\n            for ax1 in range(11):\n                pad_temp_1 = T.Buffer((935,), data=pad_temp)\n                for ax2, ax3 in T.grid(17, 55):\n                    data_1 = T.Buffer((26730,), data=data.data)\n                    pad_temp_1[ax2 * 55 + ax3] = T.if_then_else(1 <= ax2 and ax2 < 16 and 1 <= ax3, data_1[ax0 * 8910 + ax1 * 810 + ax2 * 54 + ax3 - 55], T.float32(-3.4028234663852886e+38))\n                for ax2, ax3 in T.grid(8, 27):\n                    pool_max_1 = T.Buffer((7128,), data=pool_max.data)\n                    pool_max_1[ax0 * 2376 + ax1 * 216 + ax2 * 27 + ax3] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1 in T.grid(3, 3):\n                        cse_var_1: T.int32 = ax0 * 2376 + ax1 * 216 + ax2 * 27 + ax3\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 110 + rv0 * 55 + ax3 * 2 + rv1])", "op_args": [3, 11, 15, 18], "input_shape": "[[3, 11, 15, 54]]", "output_shape": "[[3, 11, 8, 27]]"}{"op_name": "pool2d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 72; ++ax0_ax1_fused) {\n    float pad_temp[9];\n    for (int32_t ax2 = 0; ax2 < 3; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 17; ++ax3) {\n        for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n          for (int32_t ax3_s = 0; ax3_s < 3; ++ax3_s) {\n            pad_temp[((ax2_1 * 3) + ax3_s)] = ((((1 <= ((ax2 * 2) + ax2_1)) && (1 <= ((ax3 * 2) + ax3_s))) && (((ax3_s >> 1) + ax3) < 17)) ? data[((((((ax0_ax1_fused * 198) + (ax2 * 66)) + (ax2_1 * 33)) + (ax3 * 2)) + ax3_s) - 34)] : -3.402823e+38f);\n          }\n        }\n        pool_max[(((ax0_ax1_fused * 51) + (ax2 * 17)) + ax3)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n            pool_max[(((ax0_ax1_fused * 51) + (ax2 * 17)) + ax3)] = max(pool_max[(((ax0_ax1_fused * 51) + (ax2 * 17)) + ax3)], pad_temp[((rv0 * 3) + rv1)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], ((((1 <= ((((((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 51) / 17) * 2) + rv0)) && (1 <= (((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) % 17) * 2) + rv1))) && (((rv1 >> 1) + (((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) % 17)) < 17)) ? data[((((((((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) / 17) * 66) + (rv0 * 33)) + ((((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) % 17) * 2)) + rv1) - 34)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 4, 6, 33), \"float32\"), pool_max: T.Buffer((18, 4, 3, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(72):\n            pad_temp = T.allocate([9], \"float32\", \"global\")\n            for ax2, ax3 in T.grid(3, 17):\n                pad_temp_1 = T.Buffer((9,), data=pad_temp, align=32)\n                for ax2_1, ax3_s in T.grid(3, 3):\n                    cse_var_1: T.int32 = ax3 * 2\n                    data_1 = T.Buffer((14256,), data=data.data)\n                    pad_temp_1[ax2_1 * 3 + ax3_s] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and 1 <= cse_var_1 + ax3_s and ax3_s // 2 + ax3 < 17, data_1[ax0_ax1_fused * 198 + ax2 * 66 + ax2_1 * 33 + cse_var_1 + ax3_s - 34], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((3672,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused * 51 + ax2 * 17 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(3, 3):\n                    cse_var_2: T.int32 = ax0_ax1_fused * 51 + ax2 * 17 + ax3\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0 * 3 + rv1])", "op_args": [18, 4, 6, 11], "input_shape": "[[18, 4, 6, 33]]", "output_shape": "[[18, 4, 3, 17]]"}{"op_name": "shape", "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 14 : ((ax0 == 2) ? 15 : ((ax0 == 1) ? 7 : 9)));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 14 : ((((int)threadIdx.x) == 2) ? 15 : ((((int)threadIdx.x) == 1) ? 7 : 9)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 7, 15, 14), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 14, T.if_then_else(ax0 == 2, 15, T.if_then_else(ax0 == 1, 7, 9)))", "op_args": [9, 7, 15, 14], "input_shape": "[[9, 7, 15, 14]]", "output_shape": "[[4]]"}{"op_name": "shape", "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 8 : ((ax0 == 2) ? 5 : ((ax0 == 1) ? 10 : 3)));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 8 : ((((int)threadIdx.x) == 2) ? 5 : ((((int)threadIdx.x) == 1) ? 10 : 3)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 10, 5, 8), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 8, T.if_then_else(ax0 == 2, 5, T.if_then_else(ax0 == 1, 10, 3)))", "op_args": [3, 10, 5, 8], "input_shape": "[[3, 10, 5, 8]]", "output_shape": "[[4]]"}{"op_name": "pool2d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 100; ++ax0_ax1_fused) {\n    float pad_temp[9];\n    for (int32_t ax2 = 0; ax2 < 10; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 26; ++ax3) {\n        for (int32_t ax2_ax3_fused_s = 0; ax2_ax3_fused_s < 9; ++ax2_ax3_fused_s) {\n          pad_temp[ax2_ax3_fused_s] = (((((1 <= ((ax2 * 2) + (ax2_ax3_fused_s / 3))) && (((ax2_ax3_fused_s / 6) + ax2) < 10)) && (1 <= ((ax3 * 2) + (ax2_ax3_fused_s % 3)))) && ((((ax2_ax3_fused_s % 3) >> 1) + ax3) < 26)) ? data[((((((ax0_ax1_fused * 969) + (ax2 * 102)) + ((ax2_ax3_fused_s / 3) * 51)) + (ax3 * 2)) + (ax2_ax3_fused_s % 3)) - 52)] : -3.402823e+38f);\n        }\n        pool_max[(((ax0_ax1_fused * 260) + (ax2 * 26)) + ax3)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n            pool_max[(((ax0_ax1_fused * 260) + (ax2 * 26)) + ax3)] = max(pool_max[(((ax0_ax1_fused * 260) + (ax2 * 26)) + ax3)], pad_temp[((rv0 * 3) + rv1)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))], (((((1 <= ((((((((int)blockIdx.x) * 25) + (((int)threadIdx.x) >> 1)) % 130) / 13) * 2) + rv0)) && ((((((((int)blockIdx.x) * 25) + (((int)threadIdx.x) >> 1)) % 130) / 13) + (rv0 >> 1)) < 10)) && (1 <= (((((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 26) * 2) + rv1))) && (((rv1 >> 1) + (((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 26)) < 26)) ? data[(((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10)) / 26) * 969) + (((((((int)blockIdx.x) * 25) + (((int)threadIdx.x) >> 1)) % 130) / 13) * 102)) + (rv0 * 51)) + ((((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 26) * 2)) + rv1) - 52)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 20, 19, 51), \"float32\"), pool_max: T.Buffer((5, 20, 10, 26), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(100):\n            pad_temp = T.allocate([9], \"float32\", \"global\")\n            for ax2, ax3 in T.grid(10, 26):\n                pad_temp_1 = T.Buffer((9,), data=pad_temp, align=32)\n                for ax2_ax3_fused_s in range(9):\n                    cse_var_3: T.int32 = ax2_ax3_fused_s // 3\n                    cse_var_2: T.int32 = ax3 * 2\n                    cse_var_1: T.int32 = ax2_ax3_fused_s % 3\n                    data_1 = T.Buffer((96900,), data=data.data)\n                    pad_temp_1[ax2_ax3_fused_s] = T.if_then_else(1 <= ax2 * 2 + cse_var_3 and ax2_ax3_fused_s // 6 + ax2 < 10 and 1 <= cse_var_2 + cse_var_1 and cse_var_1 // 2 + ax3 < 26, data_1[ax0_ax1_fused * 969 + ax2 * 102 + cse_var_3 * 51 + cse_var_2 + cse_var_1 - 52], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((26000,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused * 260 + ax2 * 26 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(3, 3):\n                    cse_var_4: T.int32 = ax0_ax1_fused * 260 + ax2 * 26 + ax3\n                    pool_max_1[cse_var_4] = T.max(pool_max_1[cse_var_4], pad_temp_1[rv0 * 3 + rv1])", "op_args": [5, 20, 19, 17], "input_shape": "[[5, 20, 19, 51]]", "output_shape": "[[5, 20, 10, 26]]"}{"op_name": "shape", "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 11 : ((ax0 == 2) ? 14 : ((ax0 == 1) ? 10 : 12)));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 11 : ((((int)threadIdx.x) == 2) ? 14 : ((((int)threadIdx.x) == 1) ? 10 : 12)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 10, 14, 11), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 11, T.if_then_else(ax0 == 2, 14, T.if_then_else(ax0 == 1, 10, 12)))", "op_args": [12, 10, 14, 11], "input_shape": "[[12, 10, 14, 11]]", "output_shape": "[[4]]"}{"op_name": "pool2d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 14; ++ax0) {\n    float pad_temp[15];\n    for (int32_t ax1 = 0; ax1 < 17; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 9; ++ax2) {\n        for (int32_t ax1_ax2_fused_ax3_fused_s = 0; ax1_ax2_fused_ax3_fused_s < 15; ++ax1_ax2_fused_ax3_fused_s) {\n          pad_temp[ax1_ax2_fused_ax3_fused_s] = (((((1 <= ((ax2 * 2) + (ax1_ax2_fused_ax3_fused_s / 5))) && (((ax1_ax2_fused_ax3_fused_s / 10) + ax2) < 9)) && (1 <= (ax1_ax2_fused_ax3_fused_s % 5))) && ((ax1_ax2_fused_ax3_fused_s % 5) < 4)) ? data[((((((ax0 * 867) + (ax1 * 51)) + (ax2 * 6)) + ((ax1_ax2_fused_ax3_fused_s / 5) * 3)) + (ax1_ax2_fused_ax3_fused_s % 5)) - 4)] : -3.402823e+38f);\n        }\n        for (int32_t ax3 = 0; ax3 < 2; ++ax3) {\n          pool_max[((((ax0 * 306) + (ax1 * 18)) + (ax2 * 2)) + ax3)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              pool_max[((((ax0 * 306) + (ax1 * 18)) + (ax2 * 2)) + ax3)] = max(pool_max[((((ax0 * 306) + (ax1 * 18)) + (ax2 * 2)) + ax3)], pad_temp[(((rv0 * 5) + (ax3 * 2)) + rv1)]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))], (((((1 <= (((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) % 9) * 2) + rv0)) && (((rv0 >> 1) + (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) % 9)) < 9)) && (1 <= (((((int)threadIdx.x) & 1) * 2) + rv1))) && (((rv1 >> 1) + (((int)threadIdx.x) & 1)) < 2)) ? data[(((((((((((int)blockIdx.x) * 17) + (((int)threadIdx.x) >> 1)) / 9) * 51) + ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) % 9) * 6)) + (rv0 * 3)) + ((((int)threadIdx.x) & 1) * 2)) + rv1) - 4)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 17, 17, 3), \"float32\"), pool_max: T.Buffer((14, 17, 9, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(14):\n            pad_temp = T.allocate([15], \"float32\", \"global\")\n            for ax1, ax2 in T.grid(17, 9):\n                pad_temp_1 = T.Buffer((15,), data=pad_temp, align=32)\n                for ax1_ax2_fused_ax3_fused_s in range(15):\n                    cse_var_2: T.int32 = ax1_ax2_fused_ax3_fused_s // 5\n                    cse_var_1: T.int32 = ax1_ax2_fused_ax3_fused_s % 5\n                    data_1 = T.Buffer((12138,), data=data.data)\n                    pad_temp_1[ax1_ax2_fused_ax3_fused_s] = T.if_then_else(1 <= ax2 * 2 + cse_var_2 and ax1_ax2_fused_ax3_fused_s // 10 + ax2 < 9 and 1 <= cse_var_1 and cse_var_1 < 4, data_1[ax0 * 867 + ax1 * 51 + ax2 * 6 + cse_var_2 * 3 + cse_var_1 - 4], T.float32(-3.4028234663852886e+38))\n                for ax3 in range(2):\n                    pool_max_1 = T.Buffer((4284,), data=pool_max.data)\n                    pool_max_1[ax0 * 306 + ax1 * 18 + ax2 * 2 + ax3] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1 in T.grid(3, 3):\n                        cse_var_3: T.int32 = ax0 * 306 + ax1 * 18 + ax2 * 2 + ax3\n                        pool_max_1[cse_var_3] = T.max(pool_max_1[cse_var_3], pad_temp_1[rv0 * 5 + ax3 * 2 + rv1])", "op_args": [14, 17, 17, 1], "input_shape": "[[14, 17, 17, 3]]", "output_shape": "[[14, 17, 9, 2]]"}{"op_name": "pool2d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 11; ++ax0) {\n    float pad_temp[9];\n    for (int32_t ax1 = 0; ax1 < 5; ++ax1) {\n      for (int32_t ax3 = 0; ax3 < 30; ++ax3) {\n        for (int32_t ax2 = 0; ax2 < 3; ++ax2) {\n          for (int32_t ax3_s = 0; ax3_s < 3; ++ax3_s) {\n            pad_temp[((ax2 * 3) + ax3_s)] = (((1 <= ax2) && (1 <= ((ax3 * 2) + ax3_s))) ? data[((((((ax0 * 600) + (ax1 * 120)) + (ax2 * 60)) + (ax3 * 2)) + ax3_s) - 61)] : -3.402823e+38f);\n          }\n        }\n        pool_max[(((ax0 * 150) + (ax1 * 30)) + ax3)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n            pool_max[(((ax0 * 150) + (ax1 * 30)) + ax3)] = max(pool_max[(((ax0 * 150) + (ax1 * 30)) + ax3)], pad_temp[((rv0 * 3) + rv1)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(15) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))], (((1 <= rv0) && (1 <= ((((((int)blockIdx.x) & 1) * 30) + (((int)threadIdx.x) * 2)) + rv1))) ? data[(((((((((int)blockIdx.x) >> 1) * 120) + (rv0 * 60)) + ((((int)blockIdx.x) & 1) * 30)) + (((int)threadIdx.x) * 2)) + rv1) - 61)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 5, 2, 60), \"float32\"), pool_max: T.Buffer((11, 5, 1, 30), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(11):\n            pad_temp = T.allocate([9], \"float32\", \"global\")\n            for ax1, ax3 in T.grid(5, 30):\n                pad_temp_1 = T.Buffer((9,), data=pad_temp, align=32)\n                for ax2, ax3_s in T.grid(3, 3):\n                    cse_var_1: T.int32 = ax3 * 2\n                    data_1 = T.Buffer((6600,), data=data.data)\n                    pad_temp_1[ax2 * 3 + ax3_s] = T.if_then_else(1 <= ax2 and 1 <= cse_var_1 + ax3_s, data_1[ax0 * 600 + ax1 * 120 + ax2 * 60 + cse_var_1 + ax3_s - 61], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((1650,), data=pool_max.data)\n                pool_max_1[ax0 * 150 + ax1 * 30 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(3, 3):\n                    cse_var_2: T.int32 = ax0 * 150 + ax1 * 30 + ax3\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0 * 3 + rv1])", "op_args": [11, 5, 2, 20], "input_shape": "[[11, 5, 2, 60]]", "output_shape": "[[11, 5, 1, 30]]"}{"op_name": "shape", "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 19 : ((ax0 == 2) ? 4 : ((ax0 == 1) ? 16 : 5)));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 19 : ((((int)threadIdx.x) == 2) ? 4 : ((((int)threadIdx.x) == 1) ? 16 : 5)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 16, 4, 19), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 19, T.if_then_else(ax0 == 2, 4, T.if_then_else(ax0 == 1, 16, 5)))", "op_args": [5, 16, 4, 19], "input_shape": "[[5, 16, 4, 19]]", "output_shape": "[[4]]"}{"op_name": "pool2d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 11; ++ax0) {\n    float pad_temp[247];\n    for (int32_t ax1 = 0; ax1 < 3; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 19; ++ax2) {\n        for (int32_t ax3_s = 0; ax3_s < 13; ++ax3_s) {\n          pad_temp[((ax2 * 13) + ax3_s)] = (((1 <= ax2) && (1 <= ax3_s)) ? data[(((((ax0 * 648) + (ax1 * 216)) + (ax2 * 12)) + ax3_s) - 13)] : -3.402823e+38f);\n        }\n      }\n      for (int32_t ax2_1 = 0; ax2_1 < 9; ++ax2_1) {\n        for (int32_t ax3 = 0; ax3 < 6; ++ax3) {\n          pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)] = max(pool_max[((((ax0 * 162) + (ax1 * 54)) + (ax2_1 * 6)) + ax3)], pad_temp[((((ax2_1 * 26) + (rv0 * 13)) + (ax3 * 2)) + rv1)]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))], (((1 <= (((((int)blockIdx.x) % 9) * 2) + rv0)) && (1 <= ((((int)threadIdx.x) * 2) + rv1))) ? data[(((((((int)blockIdx.x) * 24) + (rv0 * 12)) + (((int)threadIdx.x) * 2)) + rv1) - 13)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 3, 18, 12), \"float32\"), pool_max: T.Buffer((11, 3, 9, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(11):\n            pad_temp = T.allocate([247], \"float32\", \"global\")\n            for ax1 in range(3):\n                pad_temp_1 = T.Buffer((247,), data=pad_temp)\n                for ax2, ax3_s in T.grid(19, 13):\n                    data_1 = T.Buffer((7128,), data=data.data)\n                    pad_temp_1[ax2 * 13 + ax3_s] = T.if_then_else(1 <= ax2 and 1 <= ax3_s, data_1[ax0 * 648 + ax1 * 216 + ax2 * 12 + ax3_s - 13], T.float32(-3.4028234663852886e+38))\n                for ax2, ax3 in T.grid(9, 6):\n                    pool_max_1 = T.Buffer((1782,), data=pool_max.data)\n                    pool_max_1[ax0 * 162 + ax1 * 54 + ax2 * 6 + ax3] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1 in T.grid(3, 3):\n                        cse_var_1: T.int32 = ax0 * 162 + ax1 * 54 + ax2 * 6 + ax3\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 26 + rv0 * 13 + ax3 * 2 + rv1])", "op_args": [11, 3, 18, 4], "input_shape": "[[11, 3, 18, 12]]", "output_shape": "[[11, 3, 9, 6]]"}{"op_name": "shape", "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 8 : ((ax0 == 2) ? 5 : ((ax0 == 1) ? 17 : 18)));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 8 : ((((int)threadIdx.x) == 2) ? 5 : ((((int)threadIdx.x) == 1) ? 17 : 18)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 17, 5, 8), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 8, T.if_then_else(ax0 == 2, 5, T.if_then_else(ax0 == 1, 17, 18)))", "op_args": [18, 17, 5, 8], "input_shape": "[[18, 17, 5, 8]]", "output_shape": "[[4]]"}{"op_name": "pool2d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 52; ++ax0_ax1_fused) {\n    float pad_temp[95];\n    for (int32_t ax2 = 0; ax2 < 5; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 19; ++ax3) {\n        pad_temp[((ax2 * 19) + ax3)] = ((((1 <= ax2) && (ax2 < 4)) && (1 <= ax3)) ? data[((((ax0_ax1_fused * 54) + (ax2 * 18)) + ax3) - 19)] : -3.402823e+38f);\n      }\n    }\n    for (int32_t ax2_1 = 0; ax2_1 < 2; ++ax2_1) {\n      for (int32_t ax3_1 = 0; ax3_1 < 9; ++ax3_1) {\n        pool_max[(((ax0_ax1_fused * 18) + (ax2_1 * 9)) + ax3_1)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n            pool_max[(((ax0_ax1_fused * 18) + (ax2_1 * 9)) + ax3_1)] = max(pool_max[(((ax0_ax1_fused * 18) + (ax2_1 * 9)) + ax3_1)], pad_temp[((((ax2_1 * 38) + (rv0 * 19)) + (ax3_1 * 2)) + rv1)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(39) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))], ((((1 <= ((((((((int)threadIdx.x) / 3) + ((int)blockIdx.x)) % 6) / 3) * 2) + rv0)) && ((((((((int)threadIdx.x) / 3) + ((int)blockIdx.x)) % 6) / 3) + (rv0 >> 1)) < 2)) && (1 <= (((((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) % 9) * 2) + rv1))) ? data[(((((((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) / 3)) / 6) * 54) + (((((((int)threadIdx.x) / 3) + ((int)blockIdx.x)) % 6) / 3) * 36)) + (rv0 * 18)) + ((((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) % 9) * 2)) + rv1) - 19)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 13, 3, 18), \"float32\"), pool_max: T.Buffer((4, 13, 2, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(52):\n            pad_temp = T.allocate([95], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((95,), data=pad_temp)\n            for ax2, ax3 in T.grid(5, 19):\n                data_1 = T.Buffer((2808,), data=data.data)\n                pad_temp_1[ax2 * 19 + ax3] = T.if_then_else(1 <= ax2 and ax2 < 4 and 1 <= ax3, data_1[ax0_ax1_fused * 54 + ax2 * 18 + ax3 - 19], T.float32(-3.4028234663852886e+38))\n            for ax2, ax3 in T.grid(2, 9):\n                pool_max_1 = T.Buffer((936,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused * 18 + ax2 * 9 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(3, 3):\n                    cse_var_1: T.int32 = ax0_ax1_fused * 18 + ax2 * 9 + ax3\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 38 + rv0 * 19 + ax3 * 2 + rv1])", "op_args": [4, 13, 3, 6], "input_shape": "[[4, 13, 3, 18]]", "output_shape": "[[4, 13, 2, 9]]"}{"op_name": "shape", "c_code": "void default_function_kernel(int32_t* T_shape) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 4; ++ax0) {\n    T_shape[ax0] = ((ax0 == 3) ? 2 : ((ax0 == 2) ? 18 : ((ax0 == 1) ? 13 : 9)));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(int* __restrict__ T_shape) {\n  T_shape[((int)threadIdx.x)] = ((((int)threadIdx.x) == 3) ? 2 : ((((int)threadIdx.x) == 2) ? 18 : ((((int)threadIdx.x) == 1) ? 13 : 9)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 13, 18, 2), \"float32\"), T_shape: T.Buffer((4,), \"int32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(4):\n            T_shape[ax0] = T.if_then_else(ax0 == 3, 2, T.if_then_else(ax0 == 2, 18, T.if_then_else(ax0 == 1, 13, 9)))", "op_args": [9, 13, 18, 2], "input_shape": "[[9, 13, 18, 2]]", "output_shape": "[[4]]"}{"op_name": "sigmoid", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 15390; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[i0_i1_fused_i2_fused_i3_fused]))));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(57) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 57) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 57) + ((int)threadIdx.x))]))));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 3, 15, 18), \"float32\"), compute: T.Buffer((19, 3, 15, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(15390):\n            compute_1 = T.Buffer((15390,), data=compute.data)\n            data_1 = T.Buffer((15390,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sigmoid(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [19, 3, 15, 18], "input_shape": "[[19, 3, 15, 18]]", "output_shape": "[[19, 3, 15, 18]]"}{"op_name": "pool2d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 16; ++ax0) {\n    float pad_temp[105];\n    for (int32_t ax1 = 0; ax1 < 3; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n        for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n          for (int32_t ax3 = 0; ax3 < 35; ++ax3) {\n            pad_temp[((ax2_1 * 35) + ax3)] = ((((1 <= ((ax2 * 2) + ax2_1)) && (1 <= ax3)) && (ax3 < 34)) ? data[((((((ax0 * 1386) + (ax1 * 462)) + (ax2 * 66)) + (ax2_1 * 33)) + ax3) - 34)] : -3.402823e+38f);\n          }\n        }\n        for (int32_t ax3_1 = 0; ax3_1 < 17; ++ax3_1) {\n          pool_max[((((ax0 * 357) + (ax1 * 119)) + (ax2 * 17)) + ax3_1)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              pool_max[((((ax0 * 357) + (ax1 * 119)) + (ax2 * 17)) + ax3_1)] = max(pool_max[((((ax0 * 357) + (ax1 * 119)) + (ax2 * 17)) + ax3_1)], pad_temp[(((rv0 * 35) + (ax3_1 * 2)) + rv1)]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))], ((((1 <= (((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 17)) % 7) * 2) + rv0)) && (1 <= (((((int)threadIdx.x) % 17) * 2) + rv1))) && (((rv1 >> 1) + (((int)threadIdx.x) % 17)) < 17)) ? data[((((((((int)blockIdx.x) * 132) + ((((int)threadIdx.x) / 17) * 66)) + (rv0 * 33)) + ((((int)threadIdx.x) % 17) * 2)) + rv1) - 34)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 3, 14, 33), \"float32\"), pool_max: T.Buffer((16, 3, 7, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(16):\n            pad_temp = T.allocate([105], \"float32\", \"global\")\n            for ax1, ax2 in T.grid(3, 7):\n                pad_temp_1 = T.Buffer((105,), data=pad_temp)\n                for ax2_1, ax3 in T.grid(3, 35):\n                    data_1 = T.Buffer((22176,), data=data.data)\n                    pad_temp_1[ax2_1 * 35 + ax3] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and 1 <= ax3 and ax3 < 34, data_1[ax0 * 1386 + ax1 * 462 + ax2 * 66 + ax2_1 * 33 + ax3 - 34], T.float32(-3.4028234663852886e+38))\n                for ax3 in range(17):\n                    pool_max_1 = T.Buffer((5712,), data=pool_max.data)\n                    pool_max_1[ax0 * 357 + ax1 * 119 + ax2 * 17 + ax3] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1 in T.grid(3, 3):\n                        cse_var_1: T.int32 = ax0 * 357 + ax1 * 119 + ax2 * 17 + ax3\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[rv0 * 35 + ax3 * 2 + rv1])", "op_args": [16, 3, 14, 11], "input_shape": "[[16, 3, 14, 33]]", "output_shape": "[[16, 3, 7, 17]]"}{"op_name": "sigmoid", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 16; ++i2) {\n        for (int32_t i3 = 0; i3 < 12; ++i3) {\n          compute[((((i0 * 384) + (i1 * 192)) + (i2 * 12)) + i3)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[((((i0 * 384) + (i1 * 192)) + (i2 * 12)) + i3)]))));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))]))));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 2, 16, 12), \"float32\"), compute: T.Buffer((11, 2, 16, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i2, i3 in T.grid(2, 16, 12):\n                cse_var_1: T.int32 = i0 * 384 + i1 * 192 + i2 * 12 + i3\n                compute_1 = T.Buffer((4224,), data=compute.data)\n                data_1 = T.Buffer((4224,), data=data.data)\n                compute_1[cse_var_1] = T.sigmoid(data_1[cse_var_1])", "op_args": [11, 2, 16, 12], "input_shape": "[[11, 2, 16, 12]]", "output_shape": "[[11, 2, 16, 12]]"}{"op_name": "sigmoid", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 8; ++i1) {\n    for (int32_t i2 = 0; i2 < 16; ++i2) {\n      for (int32_t i3 = 0; i3 < 5; ++i3) {\n        compute[(((i1 * 80) + (i2 * 5)) + i3)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[(((i1 * 80) + (i2 * 5)) + i3)]))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(5) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))]))));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 8, 16, 5), \"float32\"), compute: T.Buffer((1, 8, 16, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(8, 16, 5):\n            cse_var_1: T.int32 = i1 * 80 + i2 * 5 + i3\n            compute_1 = T.Buffer((640,), data=compute.data)\n            data_1 = T.Buffer((640,), data=data.data)\n            compute_1[cse_var_1] = T.sigmoid(data_1[cse_var_1])", "op_args": [1, 8, 16, 5], "input_shape": "[[1, 8, 16, 5]]", "output_shape": "[[1, 8, 16, 5]]"}{"op_name": "pool2d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 320; ++ax0_ax1_fused) {\n    float pad_temp[9];\n    for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 15; ++ax3) {\n        for (int32_t ax1_ax2_fused_ax3_fused_s = 0; ax1_ax2_fused_ax3_fused_s < 9; ++ax1_ax2_fused_ax3_fused_s) {\n          pad_temp[ax1_ax2_fused_ax3_fused_s] = ((((1 <= ((ax2 * 2) + (ax1_ax2_fused_ax3_fused_s / 3))) && (((ax1_ax2_fused_ax3_fused_s / 6) + ax2) < 8)) && (1 <= ((ax3 * 2) + (ax1_ax2_fused_ax3_fused_s % 3)))) ? data[((((((ax0_ax1_fused * 450) + (ax2 * 60)) + ((ax1_ax2_fused_ax3_fused_s / 3) * 30)) + (ax3 * 2)) + (ax1_ax2_fused_ax3_fused_s % 3)) - 31)] : -3.402823e+38f);\n        }\n        pool_max[(((ax0_ax1_fused * 120) + (ax2 * 15)) + ax3)] = -3.402823e+38f;\n        for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n          for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n            pool_max[(((ax0_ax1_fused * 120) + (ax2 * 15)) + ax3)] = max(pool_max[(((ax0_ax1_fused * 120) + (ax2 * 15)) + ax3)], pad_temp[((rv0 * 3) + rv1)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))], ((((1 <= ((((((((int)blockIdx.x) % 3) * 8) + (((int)threadIdx.x) / 5)) / 3) * 2) + rv0)) && ((((((((int)blockIdx.x) % 3) * 8) + (((int)threadIdx.x) / 5)) / 3) + (rv0 >> 1)) < 8)) && (1 <= (((((((int)blockIdx.x) * 10) + ((int)threadIdx.x)) % 15) * 2) + rv1))) ? data[(((((((((int)blockIdx.x) / 3) * 450) + (((((((int)blockIdx.x) % 3) * 8) + (((int)threadIdx.x) / 5)) / 3) * 60)) + (rv0 * 30)) + ((((((int)blockIdx.x) * 10) + ((int)threadIdx.x)) % 15) * 2)) + rv1) - 31)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 16, 15, 30), \"float32\"), pool_max: T.Buffer((20, 16, 8, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(320):\n            pad_temp = T.allocate([9], \"float32\", \"global\")\n            for ax2, ax3 in T.grid(8, 15):\n                pad_temp_1 = T.Buffer((9,), data=pad_temp, align=32)\n                for ax1_ax2_fused_ax3_fused_s in range(9):\n                    cse_var_3: T.int32 = ax1_ax2_fused_ax3_fused_s // 3\n                    cse_var_2: T.int32 = ax3 * 2\n                    cse_var_1: T.int32 = ax1_ax2_fused_ax3_fused_s % 3\n                    data_1 = T.Buffer((144000,), data=data.data)\n                    pad_temp_1[ax1_ax2_fused_ax3_fused_s] = T.if_then_else(1 <= ax2 * 2 + cse_var_3 and ax1_ax2_fused_ax3_fused_s // 6 + ax2 < 8 and 1 <= cse_var_2 + cse_var_1, data_1[ax0_ax1_fused * 450 + ax2 * 60 + cse_var_3 * 30 + cse_var_2 + cse_var_1 - 31], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((38400,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused * 120 + ax2 * 15 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(3, 3):\n                    cse_var_4: T.int32 = ax0_ax1_fused * 120 + ax2 * 15 + ax3\n                    pool_max_1[cse_var_4] = T.max(pool_max_1[cse_var_4], pad_temp_1[rv0 * 3 + rv1])", "op_args": [20, 16, 15, 10], "input_shape": "[[20, 16, 15, 30]]", "output_shape": "[[20, 16, 8, 15]]"}{"op_name": "sigmoid", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 7; ++i1) {\n    for (int32_t i2 = 0; i2 < 17; ++i2) {\n      for (int32_t i3 = 0; i3 < 4; ++i3) {\n        compute[(((i1 * 68) + (i2 * 4)) + i3)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[(((i1 * 68) + (i2 * 4)) + i3)]))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))]))));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 7, 17, 4), \"float32\"), compute: T.Buffer((1, 7, 17, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(7, 17, 4):\n            cse_var_1: T.int32 = i1 * 68 + i2 * 4 + i3\n            compute_1 = T.Buffer((476,), data=compute.data)\n            data_1 = T.Buffer((476,), data=data.data)\n            compute_1[cse_var_1] = T.sigmoid(data_1[cse_var_1])", "op_args": [1, 7, 17, 4], "input_shape": "[[1, 7, 17, 4]]", "output_shape": "[[1, 7, 17, 4]]"}{"op_name": "pool2d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 9; ++ax0) {\n    float pad_temp[9];\n    for (int32_t ax1 = 0; ax1 < 3; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 6; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n          for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n            for (int32_t ax3_s = 0; ax3_s < 3; ++ax3_s) {\n              pad_temp[((ax2_1 * 3) + ax3_s)] = ((((1 <= ((ax2 * 2) + ax2_1)) && (((ax2_1 >> 1) + ax2) < 6)) && (1 <= ((ax3 * 2) + ax3_s))) ? data[(((((((ax0 * 1188) + (ax1 * 396)) + (ax2 * 72)) + (ax2_1 * 36)) + (ax3 * 2)) + ax3_s) - 37)] : -3.402823e+38f);\n            }\n          }\n          pool_max[((((ax0 * 324) + (ax1 * 108)) + (ax2 * 18)) + ax3)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              pool_max[((((ax0 * 324) + (ax1 * 108)) + (ax2 * 18)) + ax3)] = max(pool_max[((((ax0 * 324) + (ax1 * 108)) + (ax2 * 18)) + ax3)], pad_temp[((rv0 * 3) + rv1)]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      pool_max[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))], ((((1 <= ((((((int)blockIdx.x) & 1) * 6) + ((((int)threadIdx.x) / 18) * 2)) + rv0)) && (((((((int)threadIdx.x) / 18) + (rv0 >> 1)) / 3) + (((int)blockIdx.x) & 1)) < 2)) && (1 <= (((((int)threadIdx.x) % 18) * 2) + rv1))) ? data[((((((((((int)blockIdx.x) >> 1) * 396) + ((((int)blockIdx.x) & 1) * 216)) + ((((int)threadIdx.x) / 18) * 72)) + (rv0 * 36)) + ((((int)threadIdx.x) % 18) * 2)) + rv1) - 37)] : -3.402823e+38f));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 3, 11, 36), \"float32\"), pool_max: T.Buffer((9, 3, 6, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(9):\n            pad_temp = T.allocate([9], \"float32\", \"global\")\n            for ax1, ax2, ax3 in T.grid(3, 6, 18):\n                pad_temp_1 = T.Buffer((9,), data=pad_temp, align=32)\n                for ax2_1, ax3_s in T.grid(3, 3):\n                    cse_var_1: T.int32 = ax3 * 2\n                    data_1 = T.Buffer((10692,), data=data.data)\n                    pad_temp_1[ax2_1 * 3 + ax3_s] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and ax2_1 // 2 + ax2 < 6 and 1 <= cse_var_1 + ax3_s, data_1[ax0 * 1188 + ax1 * 396 + ax2 * 72 + ax2_1 * 36 + cse_var_1 + ax3_s - 37], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((2916,), data=pool_max.data)\n                pool_max_1[ax0 * 324 + ax1 * 108 + ax2 * 18 + ax3] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1 in T.grid(3, 3):\n                    cse_var_2: T.int32 = ax0 * 324 + ax1 * 108 + ax2 * 18 + ax3\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0 * 3 + rv1])", "op_args": [9, 3, 11, 12], "input_shape": "[[9, 3, 11, 36]]", "output_shape": "[[9, 3, 6, 18]]"}{"op_name": "sigmoid", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i2 = 0; i2 < 19; ++i2) {\n      compute[((i0 * 19) + i2)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[((i0 * 19) + i2)]))));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(22) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 22) + ((int)threadIdx.x)) < 133) {\n    compute[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))]))));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 1, 19, 1), \"float32\"), compute: T.Buffer((7, 1, 19, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i2 in range(19):\n                cse_var_1: T.int32 = i0 * 19 + i2\n                compute_1 = T.Buffer((133,), data=compute.data)\n                data_1 = T.Buffer((133,), data=data.data)\n                compute_1[cse_var_1] = T.sigmoid(data_1[cse_var_1])", "op_args": [7, 1, 19, 1], "input_shape": "[[7, 1, 19, 1]]", "output_shape": "[[7, 1, 19, 1]]"}{"op_name": "pool3d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 104; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    float pad_temp[27];\n    for (int32_t ax4 = 0; ax4 < 8; ++ax4) {\n      for (int32_t ax2 = 0; ax2 < 3; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 3; ++ax3) {\n          for (int32_t ax4_s = 0; ax4_s < 3; ++ax4_s) {\n            pad_temp[(((ax2 * 9) + (ax3 * 3)) + ax4_s)] = (((((1 <= (((ax0_ax1_fused_ax2_fused_ax3_fused & 1) * 2) + ax2)) && (((ax2 >> 1) + (ax0_ax1_fused_ax2_fused_ax3_fused & 1)) < 2)) && (1 <= ax3)) && (1 <= ((ax4 * 2) + ax4_s))) ? data[((((((((ax0_ax1_fused_ax2_fused_ax3_fused >> 1) * 96) + ((ax0_ax1_fused_ax2_fused_ax3_fused & 1) * 64)) + (ax2 * 32)) + (ax3 * 16)) + (ax4 * 2)) + ax4_s) - 49)] : -3.402823e+38f);\n          }\n        }\n      }\n      pool_max[((ax0_ax1_fused_ax2_fused_ax3_fused * 8) + ax4)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n          for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n            pool_max[((ax0_ax1_fused_ax2_fused_ax3_fused * 8) + ax4)] = max(pool_max[((ax0_ax1_fused_ax2_fused_ax3_fused * 8) + ax4)], pad_temp[(((rv0 * 9) + (rv1 * 3)) + rv2)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], (((((1 <= ((((((int)threadIdx.x) & 15) >> 3) * 2) + rv0)) && ((((((int)threadIdx.x) & 15) >> 3) + (rv0 >> 1)) < 2)) && (1 <= rv1)) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[((((((((((int)blockIdx.x) * 192) + ((((int)threadIdx.x) >> 4) * 96)) + (((((int)threadIdx.x) & 15) >> 3) * 64)) + (rv0 * 32)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 49)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 4, 3, 2, 16), \"float32\"), pool_max: T.Buffer((13, 4, 2, 1, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(104):\n            pad_temp = T.allocate([27], \"float32\", \"global\")\n            for ax4 in range(8):\n                pad_temp_1 = T.Buffer((27,), data=pad_temp)\n                for ax2, ax3, ax4_s in T.grid(3, 3, 3):\n                    cse_var_2: T.int32 = ax0_ax1_fused_ax2_fused_ax3_fused % 2\n                    cse_var_1: T.int32 = ax4 * 2\n                    data_1 = T.Buffer((4992,), data=data.data)\n                    pad_temp_1[ax2 * 9 + ax3 * 3 + ax4_s] = T.if_then_else(1 <= cse_var_2 * 2 + ax2 and ax2 // 2 + cse_var_2 < 2 and 1 <= ax3 and 1 <= cse_var_1 + ax4_s, data_1[ax0_ax1_fused_ax2_fused_ax3_fused // 2 * 96 + cse_var_2 * 64 + ax2 * 32 + ax3 * 16 + cse_var_1 + ax4_s - 49], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((832,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                    cse_var_3: T.int32 = ax0_ax1_fused_ax2_fused_ax3_fused * 8 + ax4\n                    pool_max_1[cse_var_3] = T.max(pool_max_1[cse_var_3], pad_temp_1[rv0 * 9 + rv1 * 3 + rv2])", "op_args": [13, 4, 3, 2], "input_shape": "[[13, 4, 3, 2, 16]]", "output_shape": "[[13, 4, 2, 1, 8]]"}{"op_name": "sigmoid", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 154; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 20; ++i3) {\n        compute[(((i0_i1_fused * 280) + (i2 * 20)) + i3)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[(((i0_i1_fused * 280) + (i2 * 20)) + i3)]))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(55) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))]))));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 14, 14, 20), \"float32\"), compute: T.Buffer((11, 14, 14, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(154):\n            for i2, i3 in T.grid(14, 20):\n                cse_var_1: T.int32 = i0_i1_fused * 280 + i2 * 20 + i3\n                compute_1 = T.Buffer((43120,), data=compute.data)\n                data_1 = T.Buffer((43120,), data=data.data)\n                compute_1[cse_var_1] = T.sigmoid(data_1[cse_var_1])", "op_args": [11, 14, 14, 20], "input_shape": "[[11, 14, 14, 20]]", "output_shape": "[[11, 14, 14, 20]]"}{"op_name": "pool3d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 204; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    float pad_temp[153];\n    for (int32_t ax2 = 0; ax2 < 3; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 3; ++ax3) {\n        for (int32_t ax4 = 0; ax4 < 17; ++ax4) {\n          pad_temp[(((ax2 * 51) + (ax3 * 17)) + ax4)] = ((((((1 <= ax2) && (ax2 < 2)) && (1 <= (((ax0_ax1_fused_ax2_fused_ax3_fused & 1) * 2) + ax3))) && (((ax3 >> 1) + (ax0_ax1_fused_ax2_fused_ax3_fused & 1)) < 2)) && (1 <= ax4)) ? data[(((((((ax0_ax1_fused_ax2_fused_ax3_fused >> 1) * 48) + (ax2 * 48)) + ((ax0_ax1_fused_ax2_fused_ax3_fused & 1) * 32)) + (ax3 * 16)) + ax4) - 65)] : -3.402823e+38f);\n        }\n      }\n    }\n    for (int32_t ax4_1 = 0; ax4_1 < 8; ++ax4_1) {\n      pool_max[((ax0_ax1_fused_ax2_fused_ax3_fused * 8) + ax4_1)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n          for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n            pool_max[((ax0_ax1_fused_ax2_fused_ax3_fused * 8) + ax4_1)] = max(pool_max[((ax0_ax1_fused_ax2_fused_ax3_fused * 8) + ax4_1)], pad_temp[((((rv0 * 51) + (rv1 * 17)) + (ax4_1 * 2)) + rv2)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], ((((((1 <= rv0) && (rv0 < 2)) && (1 <= (((((((int)threadIdx.x) >> 3) + ((int)blockIdx.x)) & 1) * 2) + rv1))) && (((rv1 >> 1) + (((((int)threadIdx.x) >> 3) + ((int)blockIdx.x)) & 1)) < 2)) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[((((((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 3)) >> 1) * 48) + (rv0 * 48)) + ((((((int)threadIdx.x) >> 3) + ((int)blockIdx.x)) & 1) * 32)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 65)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 17, 1, 3, 16), \"float32\"), pool_max: T.Buffer((6, 17, 1, 2, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(204):\n            pad_temp = T.allocate([153], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((153,), data=pad_temp)\n            for ax2, ax3, ax4 in T.grid(3, 3, 17):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused_ax3_fused % 2\n                data_1 = T.Buffer((4896,), data=data.data)\n                pad_temp_1[ax2 * 51 + ax3 * 17 + ax4] = T.if_then_else(1 <= ax2 and ax2 < 2 and 1 <= cse_var_1 * 2 + ax3 and ax3 // 2 + cse_var_1 < 2 and 1 <= ax4, data_1[ax0_ax1_fused_ax2_fused_ax3_fused // 2 * 48 + ax2 * 48 + cse_var_1 * 32 + ax3 * 16 + ax4 - 65], T.float32(-3.4028234663852886e+38))\n            for ax4 in range(8):\n                pool_max_1 = T.Buffer((1632,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                    cse_var_2: T.int32 = ax0_ax1_fused_ax2_fused_ax3_fused * 8 + ax4\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0 * 51 + rv1 * 17 + ax4 * 2 + rv2])", "op_args": [6, 17, 1, 3], "input_shape": "[[6, 17, 1, 3, 16]]", "output_shape": "[[6, 17, 1, 2, 8]]"}{"op_name": "sigmoid", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 396; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[i0_i1_fused_i2_fused_i3_fused]))));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 12)) < 33) {\n    compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]))));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 2, 2, 9), \"float32\"), compute: T.Buffer((11, 2, 2, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(396):\n            compute_1 = T.Buffer((396,), data=compute.data)\n            data_1 = T.Buffer((396,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sigmoid(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [11, 2, 2, 9], "input_shape": "[[11, 2, 2, 9]]", "output_shape": "[[11, 2, 2, 9]]"}{"op_name": "pool3d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 10; ++ax0) {\n    float pad_temp[153];\n    for (int32_t ax1 = 0; ax1 < 8; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 8; ++ax2) {\n        for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n          for (int32_t ax3 = 0; ax3 < 3; ++ax3) {\n            for (int32_t ax4 = 0; ax4 < 17; ++ax4) {\n              pad_temp[(((ax2_1 * 51) + (ax3 * 17)) + ax4)] = (((((1 <= ((ax2 * 2) + ax2_1)) && (1 <= ax3)) && (ax3 < 2)) && (1 <= ax4)) ? data[(((((((ax0 * 2048) + (ax1 * 256)) + (ax2 * 32)) + (ax2_1 * 16)) + (ax3 * 16)) + ax4) - 33)] : -3.402823e+38f);\n            }\n          }\n        }\n        for (int32_t ax4_1 = 0; ax4_1 < 8; ++ax4_1) {\n          pool_max[((((ax0 * 512) + (ax1 * 64)) + (ax2 * 8)) + ax4_1)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n                pool_max[((((ax0 * 512) + (ax1 * 64)) + (ax2 * 8)) + ax4_1)] = max(pool_max[((((ax0 * 512) + (ax1 * 64)) + (ax2 * 8)) + ax4_1)], pad_temp[((((rv0 * 51) + (rv1 * 17)) + (ax4_1 * 2)) + rv2)]);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))], (((((1 <= ((((((int)blockIdx.x) & 3) * 4) + ((((int)threadIdx.x) >> 3) * 2)) + rv0)) && (1 <= rv1)) && (rv1 < 2)) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[(((((((((int)blockIdx.x) * 64) + ((((int)threadIdx.x) >> 3) * 32)) + (rv0 * 16)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 33)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 8, 16, 1, 16), \"float32\"), pool_max: T.Buffer((10, 8, 8, 1, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(10):\n            pad_temp = T.allocate([153], \"float32\", \"global\")\n            for ax1, ax2 in T.grid(8, 8):\n                pad_temp_1 = T.Buffer((153,), data=pad_temp)\n                for ax2_1, ax3, ax4 in T.grid(3, 3, 17):\n                    data_1 = T.Buffer((20480,), data=data.data)\n                    pad_temp_1[ax2_1 * 51 + ax3 * 17 + ax4] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and 1 <= ax3 and ax3 < 2 and 1 <= ax4, data_1[ax0 * 2048 + ax1 * 256 + ax2 * 32 + ax2_1 * 16 + ax3 * 16 + ax4 - 33], T.float32(-3.4028234663852886e+38))\n                for ax4 in range(8):\n                    pool_max_1 = T.Buffer((5120,), data=pool_max.data)\n                    pool_max_1[ax0 * 512 + ax1 * 64 + ax2 * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                        cse_var_1: T.int32 = ax0 * 512 + ax1 * 64 + ax2 * 8 + ax4\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[rv0 * 51 + rv1 * 17 + ax4 * 2 + rv2])", "op_args": [10, 8, 16, 1], "input_shape": "[[10, 8, 16, 1, 16]]", "output_shape": "[[10, 8, 8, 1, 8]]"}{"op_name": "sigmoid", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 130; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 2; ++i2) {\n      for (int32_t i3 = 0; i3 < 6; ++i3) {\n        compute[(((i0_i1_fused * 12) + (i2 * 6)) + i3)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[(((i0_i1_fused * 12) + (i2 * 6)) + i3)]))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))]))));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 13, 2, 6), \"float32\"), compute: T.Buffer((10, 13, 2, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(130):\n            for i2, i3 in T.grid(2, 6):\n                cse_var_1: T.int32 = i0_i1_fused * 12 + i2 * 6 + i3\n                compute_1 = T.Buffer((1560,), data=compute.data)\n                data_1 = T.Buffer((1560,), data=data.data)\n                compute_1[cse_var_1] = T.sigmoid(data_1[cse_var_1])", "op_args": [10, 13, 2, 6], "input_shape": "[[10, 13, 2, 6]]", "output_shape": "[[10, 13, 2, 6]]"}{"op_name": "sigmoid", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 5; ++i0) {\n    for (int32_t i1 = 0; i1 < 7; ++i1) {\n      for (int32_t i2 = 0; i2 < 8; ++i2) {\n        for (int32_t i3 = 0; i3 < 19; ++i3) {\n          compute[((((i0 * 1064) + (i1 * 152)) + (i2 * 19)) + i3)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[((((i0 * 1064) + (i1 * 152)) + (i2 * 19)) + i3)]))));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 665) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]))));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 7, 8, 19), \"float32\"), compute: T.Buffer((5, 7, 8, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(5):\n            for i1, i2, i3 in T.grid(7, 8, 19):\n                cse_var_1: T.int32 = i0 * 1064 + i1 * 152 + i2 * 19 + i3\n                compute_1 = T.Buffer((5320,), data=compute.data)\n                data_1 = T.Buffer((5320,), data=data.data)\n                compute_1[cse_var_1] = T.sigmoid(data_1[cse_var_1])", "op_args": [5, 7, 8, 19], "input_shape": "[[5, 7, 8, 19]]", "output_shape": "[[5, 7, 8, 19]]"}{"op_name": "pool3d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 57; ++ax0_ax1_fused) {\n    float pad_temp[153];\n    for (int32_t ax2 = 0; ax2 < 5; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 2; ++ax3) {\n        for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n          for (int32_t ax3_1 = 0; ax3_1 < 3; ++ax3_1) {\n            for (int32_t ax4 = 0; ax4 < 17; ++ax4) {\n              pad_temp[(((ax2_1 * 51) + (ax3_1 * 17)) + ax4)] = ((((1 <= ((ax2 * 2) + ax2_1)) && (1 <= ((ax3 * 2) + ax3_1))) && (1 <= ax4)) ? data[(((((((ax0_ax1_fused * 640) + (ax2 * 128)) + (ax2_1 * 64)) + (ax3 * 32)) + (ax3_1 * 16)) + ax4) - 81)] : -3.402823e+38f);\n            }\n          }\n        }\n        for (int32_t ax4_1 = 0; ax4_1 < 8; ++ax4_1) {\n          pool_max[((((ax0_ax1_fused * 80) + (ax2 * 16)) + (ax3 * 8)) + ax4_1)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n                pool_max[((((ax0_ax1_fused * 80) + (ax2 * 16)) + (ax3 * 8)) + ax4_1)] = max(pool_max[((((ax0_ax1_fused * 80) + (ax2 * 16)) + (ax3 * 8)) + ax4_1)], pad_temp[((((rv0 * 51) + (rv1 * 17)) + (ax4_1 * 2)) + rv2)]);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))], ((((1 <= ((((((int)blockIdx.x) % 10) >> 1) * 2) + rv0)) && (1 <= (((((int)blockIdx.x) & 1) * 2) + rv1))) && (1 <= ((((int)threadIdx.x) * 2) + rv2))) ? data[((((((((((int)blockIdx.x) >> 1) * 128) + (rv0 * 64)) + ((((int)blockIdx.x) & 1) * 32)) + (rv1 * 16)) + (((int)threadIdx.x) * 2)) + rv2) - 81)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 3, 10, 4, 16), \"float32\"), pool_max: T.Buffer((19, 3, 5, 2, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(57):\n            pad_temp = T.allocate([153], \"float32\", \"global\")\n            for ax2, ax3 in T.grid(5, 2):\n                pad_temp_1 = T.Buffer((153,), data=pad_temp)\n                for ax2_1, ax3_1, ax4 in T.grid(3, 3, 17):\n                    data_1 = T.Buffer((36480,), data=data.data)\n                    pad_temp_1[ax2_1 * 51 + ax3_1 * 17 + ax4] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and 1 <= ax3 * 2 + ax3_1 and 1 <= ax4, data_1[ax0_ax1_fused * 640 + ax2 * 128 + ax2_1 * 64 + ax3 * 32 + ax3_1 * 16 + ax4 - 81], T.float32(-3.4028234663852886e+38))\n                for ax4 in range(8):\n                    pool_max_1 = T.Buffer((4560,), data=pool_max.data)\n                    pool_max_1[ax0_ax1_fused * 80 + ax2 * 16 + ax3 * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                        cse_var_1: T.int32 = ax0_ax1_fused * 80 + ax2 * 16 + ax3 * 8 + ax4\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[rv0 * 51 + rv1 * 17 + ax4 * 2 + rv2])", "op_args": [19, 3, 10, 4], "input_shape": "[[19, 3, 10, 4, 16]]", "output_shape": "[[19, 3, 5, 2, 8]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 13; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 9; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 7; ++ax3) {\n        T_sign[(((ax0_ax1_fused * 63) + (ax2 * 7)) + ax3)] = ((0.000000e+00f < data[(((ax0_ax1_fused * 63) + (ax2 * 7)) + ax3)]) ? 1.000000e+00f : ((data[(((ax0_ax1_fused * 63) + (ax2 * 7)) + ax3)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(9) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 1, 9, 7), \"float32\"), T_sign: T.Buffer((13, 1, 9, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(13):\n            for ax2, ax3 in T.grid(9, 7):\n                cse_var_1: T.int32 = ax0_ax1_fused * 63 + ax2 * 7 + ax3\n                T_sign_1 = T.Buffer((819,), data=T_sign.data)\n                data_1 = T.Buffer((819,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [13, 1, 9, 7], "input_shape": "[[13, 1, 9, 7]]", "output_shape": "[[13, 1, 9, 7]]"}{"op_name": "pool3d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 5; ++ax0) {\n    float pad_temp[663];\n    for (int32_t ax1 = 0; ax1 < 6; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n        for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n          for (int32_t ax3 = 0; ax3 < 13; ++ax3) {\n            for (int32_t ax4_s = 0; ax4_s < 17; ++ax4_s) {\n              pad_temp[(((ax2_1 * 221) + (ax3 * 17)) + ax4_s)] = ((((((1 <= ((ax2 * 2) + ax2_1)) && (((ax2_1 >> 1) + ax2) < 4)) && (1 <= ax3)) && (ax3 < 12)) && (1 <= ax4_s)) ? data[(((((((ax0 * 7392) + (ax1 * 1232)) + (ax2 * 352)) + (ax2_1 * 176)) + (ax3 * 16)) + ax4_s) - 193)] : -3.402823e+38f);\n            }\n          }\n        }\n        for (int32_t ax3_1 = 0; ax3_1 < 6; ++ax3_1) {\n          for (int32_t ax4 = 0; ax4 < 8; ++ax4) {\n            pool_max[(((((ax0 * 1152) + (ax1 * 192)) + (ax2 * 48)) + (ax3_1 * 8)) + ax4)] = -3.402823e+38f;\n            for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n              for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n                for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n                  pool_max[(((((ax0 * 1152) + (ax1 * 192)) + (ax2 * 48)) + (ax3_1 * 8)) + ax4)] = max(pool_max[(((((ax0 * 1152) + (ax1 * 192)) + (ax2 * 48)) + (ax3_1 * 8)) + ax4)], pad_temp[(((((rv0 * 221) + (ax3_1 * 34)) + (rv1 * 17)) + (ax4 * 2)) + rv2)]);\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))], ((((((1 <= ((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) % 24) / 6) * 2) + rv0)) && ((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) % 24) / 6) + (rv0 >> 1)) < 4)) && (1 <= (((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) % 6) * 2) + rv1))) && (((rv1 >> 1) + (((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) % 6)) < 6)) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[(((((((((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) / 24) * 1232) + (((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) % 24) / 6) * 352)) + (rv0 * 176)) + ((((((int)blockIdx.x) * 5) + (((int)threadIdx.x) >> 3)) % 6) * 32)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 193)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 6, 7, 11, 16), \"float32\"), pool_max: T.Buffer((5, 6, 4, 6, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(5):\n            pad_temp = T.allocate([663], \"float32\", \"global\")\n            for ax1, ax2 in T.grid(6, 4):\n                pad_temp_1 = T.Buffer((663,), data=pad_temp)\n                for ax2_1, ax3, ax4_s in T.grid(3, 13, 17):\n                    data_1 = T.Buffer((36960,), data=data.data)\n                    pad_temp_1[ax2_1 * 221 + ax3 * 17 + ax4_s] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and ax2_1 // 2 + ax2 < 4 and 1 <= ax3 and ax3 < 12 and 1 <= ax4_s, data_1[ax0 * 7392 + ax1 * 1232 + ax2 * 352 + ax2_1 * 176 + ax3 * 16 + ax4_s - 193], T.float32(-3.4028234663852886e+38))\n                for ax3, ax4 in T.grid(6, 8):\n                    pool_max_1 = T.Buffer((5760,), data=pool_max.data)\n                    pool_max_1[ax0 * 1152 + ax1 * 192 + ax2 * 48 + ax3 * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                        cse_var_1: T.int32 = ax0 * 1152 + ax1 * 192 + ax2 * 48 + ax3 * 8 + ax4\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[rv0 * 221 + ax3 * 34 + rv1 * 17 + ax4 * 2 + rv2])", "op_args": [5, 6, 7, 11], "input_shape": "[[5, 6, 7, 11, 16]]", "output_shape": "[[5, 6, 4, 6, 8]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 36; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n        T_sign[(((ax0_ax1_fused * 126) + (ax2 * 18)) + ax3)] = ((0.000000e+00f < data[(((ax0_ax1_fused * 126) + (ax2 * 18)) + ax3)]) ? 1.000000e+00f : ((data[(((ax0_ax1_fused * 126) + (ax2 * 18)) + ax3)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 18, 7, 18), \"float32\"), T_sign: T.Buffer((2, 18, 7, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(36):\n            for ax2, ax3 in T.grid(7, 18):\n                cse_var_1: T.int32 = ax0_ax1_fused * 126 + ax2 * 18 + ax3\n                T_sign_1 = T.Buffer((4536,), data=T_sign.data)\n                data_1 = T.Buffer((4536,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [2, 18, 7, 18], "input_shape": "[[2, 18, 7, 18]]", "output_shape": "[[2, 18, 7, 18]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 8; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 6; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 5; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 2; ++ax3) {\n          T_sign[((((ax0 * 60) + (ax1 * 10)) + (ax2 * 2)) + ax3)] = ((0.000000e+00f < data[((((ax0 * 60) + (ax1 * 10)) + (ax2 * 2)) + ax3)]) ? 1.000000e+00f : ((data[((((ax0 * 60) + (ax1 * 10)) + (ax2 * 2)) + ax3)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 6, 5, 2), \"float32\"), T_sign: T.Buffer((8, 6, 5, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(8):\n            for ax1, ax2, ax3 in T.grid(6, 5, 2):\n                cse_var_1: T.int32 = ax0 * 60 + ax1 * 10 + ax2 * 2 + ax3\n                T_sign_1 = T.Buffer((480,), data=T_sign.data)\n                data_1 = T.Buffer((480,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [8, 6, 5, 2], "input_shape": "[[8, 6, 5, 2]]", "output_shape": "[[8, 6, 5, 2]]"}{"op_name": "pool3d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 170; ++ax0_ax1_fused) {\n    float pad_temp[27];\n    for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 4; ++ax3) {\n        for (int32_t ax4 = 0; ax4 < 8; ++ax4) {\n          for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n            for (int32_t ax3_1 = 0; ax3_1 < 3; ++ax3_1) {\n              for (int32_t ax4_s = 0; ax4_s < 3; ++ax4_s) {\n                pad_temp[(((ax2_1 * 9) + (ax3_1 * 3)) + ax4_s)] = (((((1 <= ((ax2 * 2) + ax2_1)) && (((ax2_1 >> 1) + ax2) < 4)) && (1 <= ((ax3 * 2) + ax3_1))) && (1 <= ((ax4 * 2) + ax4_s))) ? data[((((((((ax0_ax1_fused * 896) + (ax2 * 256)) + (ax2_1 * 128)) + (ax3 * 32)) + (ax3_1 * 16)) + (ax4 * 2)) + ax4_s) - 145)] : -3.402823e+38f);\n              }\n            }\n          }\n          pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n                pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)] = max(pool_max[((((ax0_ax1_fused * 128) + (ax2 * 32)) + (ax3 * 8)) + ax4)], pad_temp[(((rv0 * 9) + (rv1 * 3)) + rv2)]);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))], (((((1 <= ((((((int)blockIdx.x) & 1) * 4) + ((((int)threadIdx.x) >> 5) * 2)) + rv0)) && (((((((int)threadIdx.x) >> 5) + (rv0 >> 1)) >> 1) + (((int)blockIdx.x) & 1)) < 2)) && (1 <= ((((((int)threadIdx.x) & 31) >> 3) * 2) + rv1))) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[((((((((((((int)blockIdx.x) >> 1) * 896) + ((((int)blockIdx.x) & 1) * 512)) + ((((int)threadIdx.x) >> 5) * 256)) + (rv0 * 128)) + (((((int)threadIdx.x) & 31) >> 3) * 32)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 145)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 17, 7, 8, 16), \"float32\"), pool_max: T.Buffer((10, 17, 4, 4, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(170):\n            pad_temp = T.allocate([27], \"float32\", \"global\")\n            for ax2, ax3, ax4 in T.grid(4, 4, 8):\n                pad_temp_1 = T.Buffer((27,), data=pad_temp)\n                for ax2_1, ax3_1, ax4_s in T.grid(3, 3, 3):\n                    cse_var_1: T.int32 = ax4 * 2\n                    data_1 = T.Buffer((152320,), data=data.data)\n                    pad_temp_1[ax2_1 * 9 + ax3_1 * 3 + ax4_s] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and ax2_1 // 2 + ax2 < 4 and 1 <= ax3 * 2 + ax3_1 and 1 <= cse_var_1 + ax4_s, data_1[ax0_ax1_fused * 896 + ax2 * 256 + ax2_1 * 128 + ax3 * 32 + ax3_1 * 16 + cse_var_1 + ax4_s - 145], T.float32(-3.4028234663852886e+38))\n                pool_max_1 = T.Buffer((21760,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused * 128 + ax2 * 32 + ax3 * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                    cse_var_2: T.int32 = ax0_ax1_fused * 128 + ax2 * 32 + ax3 * 8 + ax4\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0 * 9 + rv1 * 3 + rv2])", "op_args": [10, 17, 7, 8], "input_shape": "[[10, 17, 7, 8, 16]]", "output_shape": "[[10, 17, 4, 4, 8]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 7; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 20; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 5; ++ax2) {\n        T_sign[(((ax0 * 100) + (ax1 * 5)) + ax2)] = ((0.000000e+00f < data[(((ax0 * 100) + (ax1 * 5)) + ax2)]) ? 1.000000e+00f : ((data[(((ax0 * 100) + (ax1 * 5)) + ax2)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 1)) < 350) {\n    T_sign[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 20, 5, 1), \"float32\"), T_sign: T.Buffer((7, 20, 5, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(7):\n            for ax1, ax2 in T.grid(20, 5):\n                cse_var_1: T.int32 = ax0 * 100 + ax1 * 5 + ax2\n                T_sign_1 = T.Buffer((700,), data=T_sign.data)\n                data_1 = T.Buffer((700,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [7, 20, 5, 1], "input_shape": "[[7, 20, 5, 1]]", "output_shape": "[[7, 20, 5, 1]]"}{"op_name": "pool3d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  float pad_temp[27];\n  for (int32_t ax1 = 0; ax1 < 13; ++ax1) {\n    for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 10; ++ax3) {\n        for (int32_t ax4 = 0; ax4 < 8; ++ax4) {\n          for (int32_t ax2_1 = 0; ax2_1 < 3; ++ax2_1) {\n            for (int32_t ax3_1 = 0; ax3_1 < 3; ++ax3_1) {\n              for (int32_t ax4_s = 0; ax4_s < 3; ++ax4_s) {\n                pad_temp[(((ax2_1 * 9) + (ax3_1 * 3)) + ax4_s)] = (((((1 <= ((ax2 * 2) + ax2_1)) && (((ax2_1 >> 1) + ax2) < 2)) && (1 <= ((ax3 * 2) + ax3_1))) && (1 <= ((ax4 * 2) + ax4_s))) ? data[((((((((ax1 * 960) + (ax2 * 640)) + (ax2_1 * 320)) + (ax3 * 32)) + (ax3_1 * 16)) + (ax4 * 2)) + ax4_s) - 337)] : -3.402823e+38f);\n              }\n            }\n          }\n          pool_max[((((ax1 * 160) + (ax2 * 80)) + (ax3 * 8)) + ax4)] = -3.402823e+38f;\n          for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n            for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n              for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n                pool_max[((((ax1 * 160) + (ax2 * 80)) + (ax3 * 8)) + ax4)] = max(pool_max[((((ax1 * 160) + (ax2 * 80)) + (ax3 * 8)) + ax4)], pad_temp[(((rv0 * 9) + (rv1 * 3)) + rv2)]);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))], (((((1 <= ((((((int)blockIdx.x) % 40) / 20) * 2) + rv0)) && ((((((int)blockIdx.x) % 40) / 20) + (rv0 >> 1)) < 2)) && (1 <= ((((((int)blockIdx.x) % 20) >> 1) * 2) + rv1))) && (1 <= ((((((int)blockIdx.x) & 1) * 8) + (((int)threadIdx.x) * 2)) + rv2))) ? data[((((((((((((int)blockIdx.x) / 40) * 960) + (((((int)blockIdx.x) % 40) / 20) * 640)) + (rv0 * 320)) + (((((int)blockIdx.x) % 20) >> 1) * 32)) + (rv1 * 16)) + ((((int)blockIdx.x) & 1) * 8)) + (((int)threadIdx.x) * 2)) + rv2) - 337)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 13, 3, 20, 16), \"float32\"), pool_max: T.Buffer((1, 13, 2, 10, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        pad_temp = T.allocate([27], \"float32\", \"global\")\n        for ax1, ax2, ax3, ax4 in T.grid(13, 2, 10, 8):\n            pad_temp_1 = T.Buffer((27,), data=pad_temp)\n            for ax2_1, ax3_1, ax4_s in T.grid(3, 3, 3):\n                cse_var_1: T.int32 = ax4 * 2\n                data_1 = T.Buffer((12480,), data=data.data)\n                pad_temp_1[ax2_1 * 9 + ax3_1 * 3 + ax4_s] = T.if_then_else(1 <= ax2 * 2 + ax2_1 and ax2_1 // 2 + ax2 < 2 and 1 <= ax3 * 2 + ax3_1 and 1 <= cse_var_1 + ax4_s, data_1[ax1 * 960 + ax2 * 640 + ax2_1 * 320 + ax3 * 32 + ax3_1 * 16 + cse_var_1 + ax4_s - 337], T.float32(-3.4028234663852886e+38))\n            pool_max_1 = T.Buffer((2080,), data=pool_max.data)\n            pool_max_1[ax1 * 160 + ax2 * 80 + ax3 * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n            for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                cse_var_2: T.int32 = ax1 * 160 + ax2 * 80 + ax3 * 8 + ax4\n                pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0 * 9 + rv1 * 3 + rv2])", "op_args": [1, 13, 3, 20], "input_shape": "[[1, 13, 3, 20, 16]]", "output_shape": "[[1, 13, 2, 10, 8]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 180; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n      T_sign[((ax0_ax1_fused * 4) + ax2)] = ((0.000000e+00f < data[((ax0_ax1_fused * 4) + ax2)]) ? 1.000000e+00f : ((data[((ax0_ax1_fused * 4) + ax2)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(10) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 12, 4, 1), \"float32\"), T_sign: T.Buffer((15, 12, 4, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(180):\n            for ax2 in range(4):\n                cse_var_1: T.int32 = ax0_ax1_fused * 4 + ax2\n                T_sign_1 = T.Buffer((720,), data=T_sign.data)\n                data_1 = T.Buffer((720,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [15, 12, 4, 1], "input_shape": "[[15, 12, 4, 1]]", "output_shape": "[[15, 12, 4, 1]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 1248; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_sign[ax0_ax1_fused_ax2_fused_ax3_fused] = ((0.000000e+00f < data[ax0_ax1_fused_ax2_fused_ax3_fused]) ? 1.000000e+00f : ((data[ax0_ax1_fused_ax2_fused_ax3_fused] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 2, 13, 3), \"float32\"), T_sign: T.Buffer((16, 2, 13, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(1248):\n            T_sign_1 = T.Buffer((1248,), data=T_sign.data)\n            data_1 = T.Buffer((1248,), data=data.data)\n            T_sign_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.if_then_else(T.float32(0) < data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(1), T.Select(data_1[ax0_ax1_fused_ax2_fused_ax3_fused] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [16, 2, 13, 3], "input_shape": "[[16, 2, 13, 3]]", "output_shape": "[[16, 2, 13, 3]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 112; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 2; ++ax3) {\n      T_sign[((ax0_ax1_fused_ax2_fused * 2) + ax3)] = ((0.000000e+00f < data[((ax0_ax1_fused_ax2_fused * 2) + ax3)]) ? 1.000000e+00f : ((data[((ax0_ax1_fused_ax2_fused * 2) + ax3)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 8, 2), \"float32\"), T_sign: T.Buffer((7, 2, 8, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(112):\n            for ax3 in range(2):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 2 + ax3\n                T_sign_1 = T.Buffer((224,), data=T_sign.data)\n                data_1 = T.Buffer((224,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [7, 2, 8, 2], "input_shape": "[[7, 2, 8, 2]]", "output_shape": "[[7, 2, 8, 2]]"}{"op_name": "pool3d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 14; ++ax0) {\n    float pad_temp[4845];\n    for (int32_t ax1 = 0; ax1 < 17; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 19; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 15; ++ax3) {\n          for (int32_t ax4 = 0; ax4 < 17; ++ax4) {\n            pad_temp[(((ax2 * 255) + (ax3 * 17)) + ax4)] = ((((((1 <= ax2) && (ax2 < 18)) && (1 <= ax3)) && (ax3 < 14)) && (1 <= ax4)) ? data[((((((ax0 * 60112) + (ax1 * 3536)) + (ax2 * 208)) + (ax3 * 16)) + ax4) - 225)] : -3.402823e+38f);\n          }\n        }\n      }\n      for (int32_t ax2_1 = 0; ax2_1 < 9; ++ax2_1) {\n        for (int32_t ax3_1 = 0; ax3_1 < 7; ++ax3_1) {\n          for (int32_t ax4_1 = 0; ax4_1 < 8; ++ax4_1) {\n            pool_max[(((((ax0 * 8568) + (ax1 * 504)) + (ax2_1 * 56)) + (ax3_1 * 8)) + ax4_1)] = -3.402823e+38f;\n            for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n              for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n                for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n                  pool_max[(((((ax0 * 8568) + (ax1 * 504)) + (ax2_1 * 56)) + (ax3_1 * 8)) + ax4_1)] = max(pool_max[(((((ax0 * 8568) + (ax1 * 504)) + (ax2_1 * 56)) + (ax3_1 * 8)) + ax4_1)], pad_temp[((((((ax2_1 * 510) + (rv0 * 255)) + (ax3_1 * 34)) + (rv1 * 17)) + (ax4_1 * 2)) + rv2)]);\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))], ((((((1 <= ((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) % 63) / 7) * 2) + rv0)) && ((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) % 63) / 7) + (rv0 >> 1)) < 9)) && (1 <= (((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) % 7) * 2) + rv1))) && (((rv1 >> 1) + (((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) % 7)) < 7)) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[(((((((((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 24)) / 21) * 3536) + (((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) % 63) / 7) * 416)) + (rv0 * 208)) + ((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) % 7) * 32)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 225)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 17, 17, 13, 16), \"float32\"), pool_max: T.Buffer((14, 17, 9, 7, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(14):\n            pad_temp = T.allocate([4845], \"float32\", \"global\")\n            for ax1 in range(17):\n                pad_temp_1 = T.Buffer((4845,), data=pad_temp)\n                for ax2, ax3, ax4 in T.grid(19, 15, 17):\n                    data_1 = T.Buffer((841568,), data=data.data)\n                    pad_temp_1[ax2 * 255 + ax3 * 17 + ax4] = T.if_then_else(1 <= ax2 and ax2 < 18 and 1 <= ax3 and ax3 < 14 and 1 <= ax4, data_1[ax0 * 60112 + ax1 * 3536 + ax2 * 208 + ax3 * 16 + ax4 - 225], T.float32(-3.4028234663852886e+38))\n                for ax2, ax3, ax4 in T.grid(9, 7, 8):\n                    pool_max_1 = T.Buffer((119952,), data=pool_max.data)\n                    pool_max_1[ax0 * 8568 + ax1 * 504 + ax2 * 56 + ax3 * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                    for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                        cse_var_1: T.int32 = ax0 * 8568 + ax1 * 504 + ax2 * 56 + ax3 * 8 + ax4\n                        pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax2 * 510 + rv0 * 255 + ax3 * 34 + rv1 * 17 + ax4 * 2 + rv2])", "op_args": [14, 17, 17, 13], "input_shape": "[[14, 17, 17, 13, 16]]", "output_shape": "[[14, 17, 9, 7, 8]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 39; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 5; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 2; ++ax3) {\n        T_sign[(((ax0_ax1_fused * 10) + (ax2 * 2)) + ax3)] = ((0.000000e+00f < data[(((ax0_ax1_fused * 10) + (ax2 * 2)) + ax3)]) ? 1.000000e+00f : ((data[(((ax0_ax1_fused * 10) + (ax2 * 2)) + ax3)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 6)) < 65) {\n    T_sign[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 13, 5, 2), \"float32\"), T_sign: T.Buffer((3, 13, 5, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(39):\n            for ax2, ax3 in T.grid(5, 2):\n                cse_var_1: T.int32 = ax0_ax1_fused * 10 + ax2 * 2 + ax3\n                T_sign_1 = T.Buffer((390,), data=T_sign.data)\n                data_1 = T.Buffer((390,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [3, 13, 5, 2], "input_shape": "[[3, 13, 5, 2]]", "output_shape": "[[3, 13, 5, 2]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 187; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 14; ++ax3) {\n      T_sign[((ax0_ax1_fused_ax2_fused * 14) + ax3)] = ((0.000000e+00f < data[((ax0_ax1_fused_ax2_fused * 14) + ax3)]) ? 1.000000e+00f : ((data[((ax0_ax1_fused_ax2_fused * 14) + ax3)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 17, 1, 14), \"float32\"), T_sign: T.Buffer((11, 17, 1, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(187):\n            for ax3 in range(14):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 14 + ax3\n                T_sign_1 = T.Buffer((2618,), data=T_sign.data)\n                data_1 = T.Buffer((2618,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [11, 17, 1, 14], "input_shape": "[[11, 17, 1, 14]]", "output_shape": "[[11, 17, 1, 14]]"}{"op_name": "pool3d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 1750; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    float pad_temp[153];\n    for (int32_t ax2 = 0; ax2 < 3; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 3; ++ax3) {\n        for (int32_t ax4 = 0; ax4 < 17; ++ax4) {\n          pad_temp[(((ax2 * 51) + (ax3 * 17)) + ax4)] = ((((1 <= ((((ax0_ax1_fused_ax2_fused_ax3_fused % 35) / 5) * 2) + ax2)) && (1 <= (((ax0_ax1_fused_ax2_fused_ax3_fused % 5) * 2) + ax3))) && (1 <= ax4)) ? data[(((((((ax0_ax1_fused_ax2_fused_ax3_fused / 5) * 320) + (ax2 * 160)) + ((ax0_ax1_fused_ax2_fused_ax3_fused % 5) * 32)) + (ax3 * 16)) + ax4) - 177)] : -3.402823e+38f);\n        }\n      }\n    }\n    for (int32_t ax4_1 = 0; ax4_1 < 8; ++ax4_1) {\n      pool_max[((ax0_ax1_fused_ax2_fused_ax3_fused * 8) + ax4_1)] = -3.402823e+38f;\n      for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n        for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n          for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n            pool_max[((ax0_ax1_fused_ax2_fused_ax3_fused * 8) + ax4_1)] = max(pool_max[((ax0_ax1_fused_ax2_fused_ax3_fused * 8) + ax4_1)], pad_temp[((((rv0 * 51) + (rv1 * 17)) + (ax4_1 * 2)) + rv2)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))], ((((1 <= ((((((int)blockIdx.x) % 14) >> 1) * 2) + rv0)) && (1 <= ((((((((int)blockIdx.x) & 1) * 5) + (((int)threadIdx.x) >> 2)) >> 1) * 2) + rv1))) && (1 <= (((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 2) + rv2))) ? data[((((((((((int)blockIdx.x) >> 1) * 320) + (rv0 * 160)) + (((((((int)blockIdx.x) & 1) * 5) + (((int)threadIdx.x) >> 2)) >> 1) * 32)) + (rv1 * 16)) + ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) & 7) * 2)) + rv2) - 177)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 10, 14, 10, 16), \"float32\"), pool_max: T.Buffer((5, 10, 7, 5, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(1750):\n            pad_temp = T.allocate([153], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((153,), data=pad_temp)\n            for ax2, ax3, ax4 in T.grid(3, 3, 17):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused_ax3_fused % 5\n                data_1 = T.Buffer((112000,), data=data.data)\n                pad_temp_1[ax2 * 51 + ax3 * 17 + ax4] = T.if_then_else(1 <= ax0_ax1_fused_ax2_fused_ax3_fused % 35 // 5 * 2 + ax2 and 1 <= cse_var_1 * 2 + ax3 and 1 <= ax4, data_1[ax0_ax1_fused_ax2_fused_ax3_fused // 5 * 320 + ax2 * 160 + cse_var_1 * 32 + ax3 * 16 + ax4 - 177], T.float32(-3.4028234663852886e+38))\n            for ax4 in range(8):\n                pool_max_1 = T.Buffer((14000,), data=pool_max.data)\n                pool_max_1[ax0_ax1_fused_ax2_fused_ax3_fused * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                    cse_var_2: T.int32 = ax0_ax1_fused_ax2_fused_ax3_fused * 8 + ax4\n                    pool_max_1[cse_var_2] = T.max(pool_max_1[cse_var_2], pad_temp_1[rv0 * 51 + rv1 * 17 + ax4 * 2 + rv2])", "op_args": [5, 10, 14, 10], "input_shape": "[[5, 10, 14, 10, 16]]", "output_shape": "[[5, 10, 7, 5, 8]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 70; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 13; ++ax2) {\n      T_sign[((ax0_ax1_fused * 13) + ax2)] = ((0.000000e+00f < data[((ax0_ax1_fused * 13) + ax2)]) ? 1.000000e+00f : ((data[((ax0_ax1_fused * 13) + ax2)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(10) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 14, 13, 1), \"float32\"), T_sign: T.Buffer((5, 14, 13, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(70):\n            for ax2 in range(13):\n                cse_var_1: T.int32 = ax0_ax1_fused * 13 + ax2\n                T_sign_1 = T.Buffer((910,), data=T_sign.data)\n                data_1 = T.Buffer((910,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [5, 14, 13, 1], "input_shape": "[[5, 14, 13, 1]]", "output_shape": "[[5, 14, 13, 1]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 14; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 4; ++ax2) {\n        T_sign[(((ax0 * 40) + (ax1 * 4)) + ax2)] = ((0.000000e+00f < data[(((ax0 * 40) + (ax1 * 4)) + ax2)]) ? 1.000000e+00f : ((data[(((ax0 * 40) + (ax1 * 4)) + ax2)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 10, 4, 1), \"float32\"), T_sign: T.Buffer((14, 10, 4, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(14):\n            for ax1, ax2 in T.grid(10, 4):\n                cse_var_1: T.int32 = ax0 * 40 + ax1 * 4 + ax2\n                T_sign_1 = T.Buffer((560,), data=T_sign.data)\n                data_1 = T.Buffer((560,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [14, 10, 4, 1], "input_shape": "[[14, 10, 4, 1]]", "output_shape": "[[14, 10, 4, 1]]"}{"op_name": "pool3d", "c_code": "void default_function_kernel(float* data, float* pool_max) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 7; ++ax0) {\n    float pad_temp[2550];\n    for (int32_t ax1 = 0; ax1 < 2; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 5; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 15; ++ax3) {\n          for (int32_t ax4 = 0; ax4 < 17; ++ax4) {\n            pad_temp[((((ax1 * 1275) + (ax2 * 255)) + (ax3 * 17)) + ax4)] = (((((1 <= ax2) && (ax2 < 4)) && (1 <= ax3)) && (1 <= ax4)) ? data[((((((ax0 * 1344) + (ax1 * 672)) + (ax2 * 224)) + (ax3 * 16)) + ax4) - 241)] : -3.402823e+38f);\n          }\n        }\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 2; ++ax1_1) {\n      for (int32_t ax2_1 = 0; ax2_1 < 2; ++ax2_1) {\n        for (int32_t ax3_1 = 0; ax3_1 < 7; ++ax3_1) {\n          for (int32_t ax4_1 = 0; ax4_1 < 8; ++ax4_1) {\n            pool_max[(((((ax0 * 224) + (ax1_1 * 112)) + (ax2_1 * 56)) + (ax3_1 * 8)) + ax4_1)] = -3.402823e+38f;\n            for (int32_t rv0 = 0; rv0 < 3; ++rv0) {\n              for (int32_t rv1 = 0; rv1 < 3; ++rv1) {\n                for (int32_t rv2 = 0; rv2 < 3; ++rv2) {\n                  pool_max[(((((ax0 * 224) + (ax1_1 * 112)) + (ax2_1 * 56)) + (ax3_1 * 8)) + ax4_1)] = max(pool_max[(((((ax0 * 224) + (ax1_1 * 112)) + (ax2_1 * 56)) + (ax3_1 * 8)) + ax4_1)], pad_temp[(((((((ax1_1 * 1275) + (ax2_1 * 510)) + (rv0 * 255)) + (ax3_1 * 34)) + (rv1 * 17)) + (ax4_1 * 2)) + rv2)]);\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ data, float* __restrict__ pool_max) {\n  pool_max[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int rv0 = 0; rv0 < 3; ++rv0) {\n    for (int rv1 = 0; rv1 < 3; ++rv1) {\n      for (int rv2 = 0; rv2 < 3; ++rv2) {\n        pool_max[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = max(pool_max[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))], (((((1 <= ((((((((int)blockIdx.x) % 7) * 2) + (((int)threadIdx.x) >> 3)) / 7) * 2) + rv0)) && ((((((((int)blockIdx.x) % 7) * 2) + (((int)threadIdx.x) >> 3)) / 7) + (rv0 >> 1)) < 2)) && (1 <= (((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) % 7) * 2) + rv1))) && (1 <= (((((int)threadIdx.x) & 7) * 2) + rv2))) ? data[(((((((((((int)blockIdx.x) / 7) * 672) + (((((((int)blockIdx.x) % 7) * 2) + (((int)threadIdx.x) >> 3)) / 7) * 448)) + (rv0 * 224)) + ((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) % 7) * 32)) + (rv1 * 16)) + ((((int)threadIdx.x) & 7) * 2)) + rv2) - 241)] : -3.402823e+38f));\n      }\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 3, 14, 16), \"float32\"), pool_max: T.Buffer((7, 2, 2, 7, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(7):\n            pad_temp = T.allocate([2550], \"float32\", \"global\")\n            pad_temp_1 = T.Buffer((2550,), data=pad_temp)\n            for ax1, ax2, ax3, ax4 in T.grid(2, 5, 15, 17):\n                data_1 = T.Buffer((9408,), data=data.data)\n                pad_temp_1[ax1 * 1275 + ax2 * 255 + ax3 * 17 + ax4] = T.if_then_else(1 <= ax2 and ax2 < 4 and 1 <= ax3 and 1 <= ax4, data_1[ax0 * 1344 + ax1 * 672 + ax2 * 224 + ax3 * 16 + ax4 - 241], T.float32(-3.4028234663852886e+38))\n            for ax1, ax2, ax3, ax4 in T.grid(2, 2, 7, 8):\n                pool_max_1 = T.Buffer((1568,), data=pool_max.data)\n                pool_max_1[ax0 * 224 + ax1 * 112 + ax2 * 56 + ax3 * 8 + ax4] = T.float32(-3.4028234663852886e+38)\n                for rv0, rv1, rv2 in T.grid(3, 3, 3):\n                    cse_var_1: T.int32 = ax0 * 224 + ax1 * 112 + ax2 * 56 + ax3 * 8 + ax4\n                    pool_max_1[cse_var_1] = T.max(pool_max_1[cse_var_1], pad_temp_1[ax1 * 1275 + ax2 * 510 + rv0 * 255 + ax3 * 34 + rv1 * 17 + ax4 * 2 + rv2])", "op_args": [7, 2, 3, 14], "input_shape": "[[7, 2, 3, 14, 16]]", "output_shape": "[[7, 2, 2, 7, 8]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 720; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n      T_sign[((ax0_ax1_fused_ax2_fused * 18) + ax3)] = ((0.000000e+00f < data[((ax0_ax1_fused_ax2_fused * 18) + ax3)]) ? 1.000000e+00f : ((data[((ax0_ax1_fused_ax2_fused * 18) + ax3)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 4, 10, 18), \"float32\"), T_sign: T.Buffer((18, 4, 10, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(720):\n            for ax3 in range(18):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 18 + ax3\n                T_sign_1 = T.Buffer((12960,), data=T_sign.data)\n                data_1 = T.Buffer((12960,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [18, 4, 10, 18], "input_shape": "[[18, 4, 10, 18]]", "output_shape": "[[18, 4, 10, 18]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 8; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 15; ++i2) {\n      for (int32_t i3 = 0; i3 < 12; ++i3) {\n        compute[(((i0_i1_fused * 180) + (i2 * 12)) + i3)] = max(data[(((i0_i1_fused * 180) + (i2 * 12)) + i3)], 0.000000e+00f);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 4, 15, 12), \"float32\"), compute: T.Buffer((2, 4, 15, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(8):\n            for i2, i3 in T.grid(15, 12):\n                cse_var_1: T.int32 = i0_i1_fused * 180 + i2 * 12 + i3\n                compute_1 = T.Buffer((1440,), data=compute.data)\n                data_1 = T.Buffer((1440,), data=data.data)\n                compute_1[cse_var_1] = T.max(data_1[cse_var_1], T.float32(0))", "op_args": [2, 4, 15, 12], "input_shape": "[[2, 4, 15, 12]]", "output_shape": "[[2, 4, 15, 12]]"}{"op_name": "sign", "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 48; ++ax0_ax1_fused) {\n    for (int32_t ax3 = 0; ax3 < 3; ++ax3) {\n      T_sign[((ax0_ax1_fused * 3) + ax3)] = ((0.000000e+00f < data[((ax0_ax1_fused * 3) + ax3)]) ? 1.000000e+00f : ((data[((ax0_ax1_fused * 3) + ax3)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 8, 1, 3), \"float32\"), T_sign: T.Buffer((6, 8, 1, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(48):\n            for ax3 in range(3):\n                cse_var_1: T.int32 = ax0_ax1_fused * 3 + ax3\n                T_sign_1 = T.Buffer((144,), data=T_sign.data)\n                data_1 = T.Buffer((144,), data=data.data)\n                T_sign_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], T.float32(1), T.Select(data_1[cse_var_1] < T.float32(0), T.float32(-1), T.float32(0)))", "op_args": [6, 8, 1, 3], "input_shape": "[[6, 8, 1, 3]]", "output_shape": "[[6, 8, 1, 3]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2835; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = max(data[i0_i1_fused_i2_fused_i3_fused], 0.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 9, 5, 9), \"float32\"), compute: T.Buffer((7, 9, 5, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2835):\n            compute_1 = T.Buffer((2835,), data=compute.data)\n            data_1 = T.Buffer((2835,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.max(data_1[i0_i1_fused_i2_fused_i3_fused], T.float32(0))", "op_args": [7, 9, 5, 9], "input_shape": "[[7, 9, 5, 9]]", "output_shape": "[[7, 9, 5, 9]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2400; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = max(data[i0_i1_fused_i2_fused_i3_fused], 0.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 15, 1, 10), \"float32\"), compute: T.Buffer((16, 15, 1, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2400):\n            compute_1 = T.Buffer((2400,), data=compute.data)\n            data_1 = T.Buffer((2400,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.max(data_1[i0_i1_fused_i2_fused_i3_fused], T.float32(0))", "op_args": [16, 15, 1, 10], "input_shape": "[[16, 15, 1, 10]]", "output_shape": "[[16, 15, 1, 10]]"}{"op_name": "sinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 7; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 1666) + (i1 * 238)) + (i2 * 17)) + i3)] = sinhf(data[((((i0 * 1666) + (i1 * 238)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = sinhf(data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 7, 14, 17), \"float32\"), compute: T.Buffer((13, 7, 14, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3 in T.grid(7, 14, 17):\n                cse_var_1: T.int32 = i0 * 1666 + i1 * 238 + i2 * 17 + i3\n                compute_1 = T.Buffer((21658,), data=compute.data)\n                data_1 = T.Buffer((21658,), data=data.data)\n                compute_1[cse_var_1] = T.sinh(data_1[cse_var_1])", "op_args": [13, 7, 14, 17], "input_shape": "[[13, 7, 14, 17]]", "output_shape": "[[13, 7, 14, 17]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1728; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = max(data[i0_i1_fused_i2_fused_i3_fused], 0.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 12, 3, 3), \"float32\"), compute: T.Buffer((16, 12, 3, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1728):\n            compute_1 = T.Buffer((1728,), data=compute.data)\n            data_1 = T.Buffer((1728,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.max(data_1[i0_i1_fused_i2_fused_i3_fused], T.float32(0))", "op_args": [16, 12, 3, 3], "input_shape": "[[16, 12, 3, 3]]", "output_shape": "[[16, 12, 3, 3]]"}{"op_name": "sinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1620; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 20; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 20) + i3)] = sinhf(data[((i0_i1_fused_i2_fused * 20) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = sinhf(data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 20, 9, 20), \"float32\"), compute: T.Buffer((9, 20, 9, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1620):\n            for i3 in range(20):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 20 + i3\n                compute_1 = T.Buffer((32400,), data=compute.data)\n                data_1 = T.Buffer((32400,), data=data.data)\n                compute_1[cse_var_1] = T.sinh(data_1[cse_var_1])", "op_args": [9, 20, 9, 20], "input_shape": "[[9, 20, 9, 20]]", "output_shape": "[[9, 20, 9, 20]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 14; ++i1) {\n      for (int32_t i2 = 0; i2 < 12; ++i2) {\n        for (int32_t i3 = 0; i3 < 9; ++i3) {\n          compute[((((i0 * 1512) + (i1 * 108)) + (i2 * 9)) + i3)] = max(data[((((i0 * 1512) + (i1 * 108)) + (i2 * 9)) + i3)], 0.000000e+00f);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 14, 12, 9), \"float32\"), compute: T.Buffer((4, 14, 12, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(14, 12, 9):\n                cse_var_1: T.int32 = i0 * 1512 + i1 * 108 + i2 * 9 + i3\n                compute_1 = T.Buffer((6048,), data=compute.data)\n                data_1 = T.Buffer((6048,), data=data.data)\n                compute_1[cse_var_1] = T.max(data_1[cse_var_1], T.float32(0))", "op_args": [4, 14, 12, 9], "input_shape": "[[4, 14, 12, 9]]", "output_shape": "[[4, 14, 12, 9]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 480; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = max(data[i0_i1_fused_i2_fused_i3_fused], 0.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 20, 4, 3), \"float32\"), compute: T.Buffer((2, 20, 4, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(480):\n            compute_1 = T.Buffer((480,), data=compute.data)\n            data_1 = T.Buffer((480,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.max(data_1[i0_i1_fused_i2_fused_i3_fused], T.float32(0))", "op_args": [2, 20, 4, 3], "input_shape": "[[2, 20, 4, 3]]", "output_shape": "[[2, 20, 4, 3]]"}{"op_name": "sinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 12240; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = sinhf(data[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 8, 15, 17), \"float32\"), compute: T.Buffer((6, 8, 15, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(12240):\n            compute_1 = T.Buffer((12240,), data=compute.data)\n            data_1 = T.Buffer((12240,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sinh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [6, 8, 15, 17], "input_shape": "[[6, 8, 15, 17]]", "output_shape": "[[6, 8, 15, 17]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 72; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 9; ++i2) {\n      for (int32_t i3 = 0; i3 < 2; ++i3) {\n        compute[(((i0_i1_fused * 18) + (i2 * 2)) + i3)] = max(data[(((i0_i1_fused * 18) + (i2 * 2)) + i3)], 0.000000e+00f);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(9) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 12, 9, 2), \"float32\"), compute: T.Buffer((6, 12, 9, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(72):\n            for i2, i3 in T.grid(9, 2):\n                cse_var_1: T.int32 = i0_i1_fused * 18 + i2 * 2 + i3\n                compute_1 = T.Buffer((1296,), data=compute.data)\n                data_1 = T.Buffer((1296,), data=data.data)\n                compute_1[cse_var_1] = T.max(data_1[cse_var_1], T.float32(0))", "op_args": [6, 12, 9, 2], "input_shape": "[[6, 12, 9, 2]]", "output_shape": "[[6, 12, 9, 2]]"}{"op_name": "sinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1872; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 20; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 20) + i3)] = sinhf(data[((i0_i1_fused_i2_fused * 20) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(39) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))] = sinhf(data[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 12, 13, 20), \"float32\"), compute: T.Buffer((12, 12, 13, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1872):\n            for i3 in range(20):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 20 + i3\n                compute_1 = T.Buffer((37440,), data=compute.data)\n                data_1 = T.Buffer((37440,), data=data.data)\n                compute_1[cse_var_1] = T.sinh(data_1[cse_var_1])", "op_args": [12, 12, 13, 20], "input_shape": "[[12, 12, 13, 20]]", "output_shape": "[[12, 12, 13, 20]]"}{"op_name": "sinh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 4389; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(11) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 11) + ((int)threadIdx.x))] = sinhf(data[((((int)blockIdx.x) * 11) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 19, 3, 7), \"float32\"), compute: T.Buffer((11, 19, 3, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(4389):\n            compute_1 = T.Buffer((4389,), data=compute.data)\n            data_1 = T.Buffer((4389,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sinh(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [11, 19, 3, 7], "input_shape": "[[11, 19, 3, 7]]", "output_shape": "[[11, 19, 3, 7]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 588; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 11; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 11) + i3)] = max(data[((i0_i1_fused_i2_fused * 11) + i3)], 0.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 2)) < 1617) {\n    compute[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))], 0.000000e+00f);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 7, 7, 11), \"float32\"), compute: T.Buffer((12, 7, 7, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(588):\n            for i3 in range(11):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 11 + i3\n                compute_1 = T.Buffer((6468,), data=compute.data)\n                data_1 = T.Buffer((6468,), data=data.data)\n                compute_1[cse_var_1] = T.max(data_1[cse_var_1], T.float32(0))", "op_args": [12, 7, 7, 11], "input_shape": "[[12, 7, 7, 11]]", "output_shape": "[[12, 7, 7, 11]]"}{"op_name": "sqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 20; ++i1) {\n      for (int32_t i2 = 0; i2 < 9; ++i2) {\n        compute[(((i0 * 180) + (i1 * 9)) + i2)] = sqrtf(data[(((i0 * 180) + (i1 * 9)) + i2)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = sqrtf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 20, 9, 1), \"float32\"), compute: T.Buffer((7, 20, 9, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i1, i2 in T.grid(20, 9):\n                cse_var_1: T.int32 = i0 * 180 + i1 * 9 + i2\n                compute_1 = T.Buffer((1260,), data=compute.data)\n                data_1 = T.Buffer((1260,), data=data.data)\n                compute_1[cse_var_1] = T.sqrt(data_1[cse_var_1])", "op_args": [7, 20, 9, 1], "input_shape": "[[7, 20, 9, 1]]", "output_shape": "[[7, 20, 9, 1]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 6930; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = max(data[i0_i1_fused_i2_fused_i3_fused], 0.000000e+00f);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 14, 3, 11), \"float32\"), compute: T.Buffer((15, 14, 3, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(6930):\n            compute_1 = T.Buffer((6930,), data=compute.data)\n            data_1 = T.Buffer((6930,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.max(data_1[i0_i1_fused_i2_fused_i3_fused], T.float32(0))", "op_args": [15, 14, 3, 11], "input_shape": "[[15, 14, 3, 11]]", "output_shape": "[[15, 14, 3, 11]]"}{"op_name": "sqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 27; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 11; ++i2) {\n      for (int32_t i3 = 0; i3 < 7; ++i3) {\n        compute[(((i0_i1_fused * 77) + (i2 * 7)) + i3)] = sqrtf(data[(((i0_i1_fused * 77) + (i2 * 7)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) < 2079) {\n    compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = sqrtf(data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 3, 11, 7), \"float32\"), compute: T.Buffer((9, 3, 11, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(27):\n            for i2, i3 in T.grid(11, 7):\n                cse_var_1: T.int32 = i0_i1_fused * 77 + i2 * 7 + i3\n                compute_1 = T.Buffer((2079,), data=compute.data)\n                data_1 = T.Buffer((2079,), data=data.data)\n                compute_1[cse_var_1] = T.sqrt(data_1[cse_var_1])", "op_args": [9, 3, 11, 7], "input_shape": "[[9, 3, 11, 7]]", "output_shape": "[[9, 3, 11, 7]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 7; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      for (int32_t i3 = 0; i3 < 15; ++i3) {\n        compute[(((i0_i1_fused * 45) + (i2 * 15)) + i3)] = max(data[(((i0_i1_fused * 45) + (i2 * 15)) + i3)], 0.000000e+00f);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(9) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 1, 3, 15), \"float32\"), compute: T.Buffer((7, 1, 3, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(7):\n            for i2, i3 in T.grid(3, 15):\n                cse_var_1: T.int32 = i0_i1_fused * 45 + i2 * 15 + i3\n                compute_1 = T.Buffer((315,), data=compute.data)\n                data_1 = T.Buffer((315,), data=data.data)\n                compute_1[cse_var_1] = T.max(data_1[cse_var_1], T.float32(0))", "op_args": [7, 1, 3, 15], "input_shape": "[[7, 1, 3, 15]]", "output_shape": "[[7, 1, 3, 15]]"}{"op_name": "sqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 56; ++i0_i1_fused) {\n    for (int32_t i3 = 0; i3 < 16; ++i3) {\n      compute[((i0_i1_fused * 16) + i3)] = sqrtf(data[((i0_i1_fused * 16) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = sqrtf(data[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 7, 1, 16), \"float32\"), compute: T.Buffer((8, 7, 1, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(56):\n            for i3 in range(16):\n                cse_var_1: T.int32 = i0_i1_fused * 16 + i3\n                compute_1 = T.Buffer((896,), data=compute.data)\n                data_1 = T.Buffer((896,), data=data.data)\n                compute_1[cse_var_1] = T.sqrt(data_1[cse_var_1])", "op_args": [8, 7, 1, 16], "input_shape": "[[8, 7, 1, 16]]", "output_shape": "[[8, 7, 1, 16]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 169; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 13; ++i2) {\n      for (int32_t i3 = 0; i3 < 17; ++i3) {\n        compute[(((i0_i1_fused * 221) + (i2 * 17)) + i3)] = max(data[(((i0_i1_fused * 221) + (i2 * 17)) + i3)], 0.000000e+00f);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 48) + ((int)threadIdx.x)) < 37349) {\n    compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))], 0.000000e+00f);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 13, 13, 17), \"float32\"), compute: T.Buffer((13, 13, 13, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(169):\n            for i2, i3 in T.grid(13, 17):\n                cse_var_1: T.int32 = i0_i1_fused * 221 + i2 * 17 + i3\n                compute_1 = T.Buffer((37349,), data=compute.data)\n                data_1 = T.Buffer((37349,), data=data.data)\n                compute_1[cse_var_1] = T.max(data_1[cse_var_1], T.float32(0))", "op_args": [13, 13, 13, 17], "input_shape": "[[13, 13, 13, 17]]", "output_shape": "[[13, 13, 13, 17]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 480; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 17; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 17) + i3)] = max(data[((i0_i1_fused_i2_fused * 17) + i3)], 0.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 16, 2, 17), \"float32\"), compute: T.Buffer((15, 16, 2, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(480):\n            for i3 in range(17):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 17 + i3\n                compute_1 = T.Buffer((8160,), data=compute.data)\n                data_1 = T.Buffer((8160,), data=data.data)\n                compute_1[cse_var_1] = T.max(data_1[cse_var_1], T.float32(0))", "op_args": [15, 16, 2, 17], "input_shape": "[[15, 16, 2, 17]]", "output_shape": "[[15, 16, 2, 17]]"}{"op_name": "relu", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 325; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 12; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 12) + i3)] = max(data[((i0_i1_fused_i2_fused * 12) + i3)], 0.000000e+00f);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 5, 13, 12), \"float32\"), compute: T.Buffer((5, 5, 13, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(325):\n            for i3 in range(12):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 12 + i3\n                compute_1 = T.Buffer((3900,), data=compute.data)\n                data_1 = T.Buffer((3900,), data=data.data)\n                compute_1[cse_var_1] = T.max(data_1[cse_var_1], T.float32(0))", "op_args": [5, 5, 13, 12], "input_shape": "[[5, 5, 13, 12]]", "output_shape": "[[5, 5, 13, 12]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  for (int32_t i_outer_outer_outer = 0; i_outer_outer_outer < 3; ++i_outer_outer_outer) {\n    for (int32_t j_outer_outer_outer = 0; j_outer_outer_outer < 4; ++j_outer_outer_outer) {\n      for (int32_t j_outer_outer_inner = 0; j_outer_outer_inner < 2; ++j_outer_outer_inner) {\n        for (int32_t i_outer_inner = 0; i_outer_inner < 5; ++i_outer_inner) {\n          for (int32_t j_outer_inner = 0; j_outer_inner < 2; ++j_outer_inner) {\n            for (int32_t b_inner = 0; b_inner < 2; ++b_inner) {\n              ScaleShift[((((((b_inner * 240) + (i_outer_outer_outer * 80)) + (i_outer_inner * 16)) + (j_outer_outer_outer * 4)) + (j_outer_outer_inner * 2)) + j_outer_inner)] = ((data[((((((b_inner * 240) + (i_outer_outer_outer * 80)) + (i_outer_inner * 16)) + (j_outer_outer_outer * 4)) + (j_outer_outer_inner * 2)) + j_outer_inner)] * Scale[0]) + Shift[0]);\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] * Scale[0]) + Shift[0]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 1, 15, 16), \"float32\"), Scale: T.Buffer((1,), \"float32\"), Shift: T.Buffer((1,), \"float32\"), ScaleShift: T.Buffer((2, 1, 15, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i_outer_outer_outer, j_outer_outer_outer, j_outer_outer_inner, i_outer_inner, j_outer_inner, b_inner in T.grid(3, 4, 2, 5, 2, 2):\n            cse_var_1: T.int32 = b_inner * 240 + i_outer_outer_outer * 80 + i_outer_inner * 16 + j_outer_outer_outer * 4 + j_outer_outer_inner * 2 + j_outer_inner\n            ScaleShift_1 = T.Buffer((480,), data=ScaleShift.data)\n            data_1 = T.Buffer((480,), data=data.data)\n            ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[0] + Shift[0]", "op_args": [2, 1, 15, 16], "input_shape": "[[2, 1, 15, 16], [1], [1]]", "output_shape": "[[2, 1, 15, 16]]"}{"op_name": "sqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 6; ++i0) {\n    for (int32_t i1 = 0; i1 < 13; ++i1) {\n      for (int32_t i2 = 0; i2 < 10; ++i2) {\n        for (int32_t i3 = 0; i3 < 6; ++i3) {\n          compute[((((i0 * 780) + (i1 * 60)) + (i2 * 6)) + i3)] = sqrtf(data[((((i0 * 780) + (i1 * 60)) + (i2 * 6)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(13) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))] = sqrtf(data[((((int)blockIdx.x) * 13) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 13, 10, 6), \"float32\"), compute: T.Buffer((6, 13, 10, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(6):\n            for i1, i2, i3 in T.grid(13, 10, 6):\n                cse_var_1: T.int32 = i0 * 780 + i1 * 60 + i2 * 6 + i3\n                compute_1 = T.Buffer((4680,), data=compute.data)\n                data_1 = T.Buffer((4680,), data=data.data)\n                compute_1[cse_var_1] = T.sqrt(data_1[cse_var_1])", "op_args": [6, 13, 10, 6], "input_shape": "[[6, 13, 10, 6]]", "output_shape": "[[6, 13, 10, 6]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused < 112; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused) {\n    for (int32_t c_inner = 0; c_inner < 11; ++c_inner) {\n      ScaleShift[(((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused / 56) * 616) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused & 1) * 308)) + (c_inner * 28)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused % 56) >> 1))] = ((data[(((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused / 56) * 616) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused & 1) * 308)) + (c_inner * 28)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused % 56) >> 1))] * Scale[c_inner]) + Shift[c_inner]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 7) * 11) + (((int)threadIdx.x) >> 2)) / 7)]) + Shift[((((((int)blockIdx.x) % 7) * 11) + (((int)threadIdx.x) >> 2)) / 7)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 11, 14, 2), \"float32\"), Scale: T.Buffer((11,), \"float32\"), Shift: T.Buffer((11,), \"float32\"), ScaleShift: T.Buffer((4, 11, 14, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused in T.parallel(112):\n            for c_inner in range(11):\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused // 56 * 616 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused % 2 * 308 + c_inner * 28 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused % 56 // 2\n                ScaleShift_1 = T.Buffer((1232,), data=ScaleShift.data)\n                data_1 = T.Buffer((1232,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[c_inner] + Shift[c_inner]", "op_args": [4, 11, 14, 2], "input_shape": "[[4, 11, 14, 2], [11], [11]]", "output_shape": "[[4, 11, 14, 2]]"}{"op_name": "sqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 480; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sqrtf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(3) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))] = sqrtf(data[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 20, 3, 4), \"float32\"), compute: T.Buffer((2, 20, 3, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(480):\n            compute_1 = T.Buffer((480,), data=compute.data)\n            data_1 = T.Buffer((480,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sqrt(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [2, 20, 3, 4], "input_shape": "[[2, 20, 3, 4]]", "output_shape": "[[2, 20, 3, 4]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused < 416; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused) {\n    for (int32_t j_outer_outer_inner = 0; j_outer_outer_inner < 2; ++j_outer_outer_inner) {\n      for (int32_t b_outer_inner = 0; b_outer_inner < 3; ++b_outer_inner) {\n        for (int32_t b_inner = 0; b_inner < 4; ++b_inner) {\n          ScaleShift[((((((b_outer_inner * 3328) + (b_inner * 832)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused / 208) * 416)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused & 7) * 52)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused % 208) >> 3) * 2)) + j_outer_outer_inner)] = ((data[((((((b_outer_inner * 3328) + (b_inner * 832)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused / 208) * 416)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused & 7) * 52)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused % 208) >> 3) * 2)) + j_outer_outer_inner)] * Scale[(((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused / 208) * 8) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused & 7))]) + Shift[(((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused / 208) * 8) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused & 7))]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 2)) % 208) / 13)]) + Shift[((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 2)) % 208) / 13)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 16, 13, 4), \"float32\"), Scale: T.Buffer((16,), \"float32\"), Shift: T.Buffer((16,), \"float32\"), ScaleShift: T.Buffer((12, 16, 13, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused in T.parallel(416):\n            for j_outer_outer_inner, b_outer_inner, b_inner in T.grid(2, 3, 4):\n                cse_var_4: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused // 208\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused % 8\n                cse_var_2: T.int32 = cse_var_4 * 8 + cse_var_3\n                cse_var_1: T.int32 = b_outer_inner * 3328 + b_inner * 832 + cse_var_4 * 416 + cse_var_3 * 52 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused % 208 // 8 * 2 + j_outer_outer_inner\n                ScaleShift_1 = T.Buffer((9984,), data=ScaleShift.data)\n                data_1 = T.Buffer((9984,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [12, 16, 13, 4], "input_shape": "[[12, 16, 13, 4], [16], [16]]", "output_shape": "[[12, 16, 13, 4]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused < 1152; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused) {\n    for (int32_t j_outer_inner = 0; j_outer_inner < 18; ++j_outer_inner) {\n      ScaleShift[((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 192) * 3456) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 48) >> 4) * 1152)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 192) / 96) * 576)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused & 15) >> 1) * 72)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 96) / 48) * 36)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused & 1) * 18)) + j_outer_inner)] = ((data[((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 192) * 3456) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 48) >> 4) * 1152)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 192) / 96) * 576)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused & 15) >> 1) * 72)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 96) / 48) * 36)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused & 1) * 18)) + j_outer_inner)] * Scale[((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 192) / 96) * 8) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused & 15) >> 1))]) + Shift[((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 192) / 96) * 8) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused & 15) >> 1))]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 18)) & 63) >> 2)]) + Shift[((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 18)) & 63) >> 2)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 16, 4, 18), \"float32\"), Scale: T.Buffer((16,), \"float32\"), Shift: T.Buffer((16,), \"float32\"), ScaleShift: T.Buffer((18, 16, 4, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused in T.parallel(1152):\n            for j_outer_inner in range(18):\n                cse_var_4: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 192 // 96\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 16 // 2\n                cse_var_2: T.int32 = cse_var_4 * 8 + cse_var_3\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused // 192 * 3456 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 48 // 16 * 1152 + cse_var_4 * 576 + cse_var_3 * 72 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 96 // 48 * 36 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 2 * 18 + j_outer_inner\n                ScaleShift_1 = T.Buffer((20736,), data=ScaleShift.data)\n                data_1 = T.Buffer((20736,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [18, 16, 4, 18], "input_shape": "[[18, 16, 4, 18], [16], [16]]", "output_shape": "[[18, 16, 4, 18]]"}{"op_name": "sqrt", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 9; ++i0) {\n    for (int32_t i1 = 0; i1 < 13; ++i1) {\n      for (int32_t i2 = 0; i2 < 5; ++i2) {\n        for (int32_t i3 = 0; i3 < 18; ++i3) {\n          compute[((((i0 * 1170) + (i1 * 90)) + (i2 * 18)) + i3)] = sqrtf(data[((((i0 * 1170) + (i1 * 90)) + (i2 * 18)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = sqrtf(data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 13, 5, 18), \"float32\"), compute: T.Buffer((9, 13, 5, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(9):\n            for i1, i2, i3 in T.grid(13, 5, 18):\n                cse_var_1: T.int32 = i0 * 1170 + i1 * 90 + i2 * 18 + i3\n                compute_1 = T.Buffer((10530,), data=compute.data)\n                data_1 = T.Buffer((10530,), data=data.data)\n                compute_1[cse_var_1] = T.sqrt(data_1[cse_var_1])", "op_args": [9, 13, 5, 18], "input_shape": "[[9, 13, 5, 18]]", "output_shape": "[[9, 13, 5, 18]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused < 5390; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused) {\n    for (int32_t i_inner = 0; i_inner < 2; ++i_inner) {\n      ScaleShift[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused / 2695) * 5390) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 77) * 70)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 2695) / 539) * 14)) + (i_inner * 7)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 539) / 77))] = ((data[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused / 2695) * 5390) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 77) * 70)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 2695) / 539) * 14)) + (i_inner * 7)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 539) / 77))] * Scale[(b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 11)]) + Shift[(b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 11)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] * Scale[((((int)blockIdx.x) % 22) >> 1)]) + Shift[((((int)blockIdx.x) % 22) >> 1)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 11, 10, 7), \"float32\"), Scale: T.Buffer((11,), \"float32\"), Shift: T.Buffer((11,), \"float32\"), ScaleShift: T.Buffer((14, 11, 10, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused in T.parallel(5390):\n            for i_inner in range(2):\n                cse_var_2: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 11\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused // 2695 * 5390 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 77 * 70 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 2695 // 539 * 14 + i_inner * 7 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_b_inner_fused_c_inner_fused % 539 // 77\n                ScaleShift_1 = T.Buffer((10780,), data=ScaleShift.data)\n                data_1 = T.Buffer((10780,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [14, 11, 10, 7], "input_shape": "[[14, 11, 10, 7], [11], [11]]", "output_shape": "[[14, 11, 10, 7]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused < 840; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused) {\n    for (int32_t j_outer_inner = 0; j_outer_inner < 4; ++j_outer_inner) {\n      for (int32_t b_inner = 0; b_inner < 2; ++b_inner) {\n        for (int32_t i_inner = 0; i_inner < 2; ++i_inner) {\n          ScaleShift[(((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused / 168) * 2688) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 28) / 14) * 1344)) + (b_inner * 672)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 14) * 48)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 168) / 56) * 16)) + (i_inner * 8)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 56) / 28) * 4)) + j_outer_inner)] = ((data[(((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused / 168) * 2688) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 28) / 14) * 1344)) + (b_inner * 672)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 14) * 48)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 168) / 56) * 16)) + (i_inner * 8)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 56) / 28) * 4)) + j_outer_inner)] * Scale[(b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 14)]) + Shift[(b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 14)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) % 42) / 3)]) + Shift[((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) % 42) / 3)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 14, 6, 8), \"float32\"), Scale: T.Buffer((14,), \"float32\"), Shift: T.Buffer((14,), \"float32\"), ScaleShift: T.Buffer((20, 14, 6, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused in T.parallel(840):\n            for j_outer_inner, b_inner, i_inner in T.grid(4, 2, 2):\n                cse_var_2: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 14\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused // 168 * 2688 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 28 // 14 * 1344 + b_inner * 672 + cse_var_2 * 48 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 168 // 56 * 16 + i_inner * 8 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused % 56 // 28 * 4 + j_outer_inner\n                ScaleShift_1 = T.Buffer((13440,), data=ScaleShift.data)\n                data_1 = T.Buffer((13440,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [20, 14, 6, 8], "input_shape": "[[20, 14, 6, 8], [14], [14]]", "output_shape": "[[20, 14, 6, 8]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused < 68; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused) {\n    for (int32_t i_outer_inner = 0; i_outer_inner < 11; ++i_outer_inner) {\n      for (int32_t j_outer_inner = 0; j_outer_inner < 2; ++j_outer_inner) {\n        for (int32_t c_inner = 0; c_inner < 4; ++c_inner) {\n          ScaleShift[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused >> 1) * 176) + (c_inner * 44)) + (i_outer_inner * 4)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused & 1) * 2)) + j_outer_inner)] = ((data[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused >> 1) * 176) + (c_inner * 44)) + (i_outer_inner * 4)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused & 1) * 2)) + j_outer_inner)] * Scale[((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused & 3) >> 1) * 4) + c_inner)]) + Shift[((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused & 3) >> 1) * 4) + c_inner)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] * Scale[(((int)blockIdx.x) & 7)]) + Shift[(((int)blockIdx.x) & 7)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 8, 11, 4), \"float32\"), Scale: T.Buffer((8,), \"float32\"), Shift: T.Buffer((8,), \"float32\"), ScaleShift: T.Buffer((17, 8, 11, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused in T.parallel(68):\n            for i_outer_inner, j_outer_inner, c_inner in T.grid(11, 2, 4):\n                cse_var_2: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused % 4 // 2 * 4 + c_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused // 2 * 176 + c_inner * 44 + i_outer_inner * 4 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused % 2 * 2 + j_outer_inner\n                ScaleShift_1 = T.Buffer((5984,), data=ScaleShift.data)\n                data_1 = T.Buffer((5984,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [17, 8, 11, 4], "input_shape": "[[17, 8, 11, 4], [8], [8]]", "output_shape": "[[17, 8, 11, 4]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused < 60; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused) {\n    for (int32_t c_outer_outer_inner = 0; c_outer_outer_inner < 2; ++c_outer_outer_inner) {\n      for (int32_t i_inner = 0; i_inner < 19; ++i_inner) {\n        ScaleShift[(((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 15) * 570) + (c_outer_outer_inner * 285)) + (i_inner * 15)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 15))] = ((data[(((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 15) * 570) + (c_outer_outer_inner * 285)) + (i_inner * 15)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 15))] * Scale[(((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 15) * 2) + c_outer_outer_inner)]) + Shift[(((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 15) * 2) + c_outer_outer_inner)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] * Scale[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 5)) / 57)]) + Shift[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 5)) / 57)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 8, 19, 15), \"float32\"), Scale: T.Buffer((8,), \"float32\"), Shift: T.Buffer((8,), \"float32\"), ScaleShift: T.Buffer((1, 8, 19, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused in T.parallel(60):\n            for c_outer_outer_inner, i_inner in T.grid(2, 19):\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused // 15\n                cse_var_2: T.int32 = cse_var_3 * 2 + c_outer_outer_inner\n                cse_var_1: T.int32 = cse_var_3 * 570 + c_outer_outer_inner * 285 + i_inner * 15 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 15\n                ScaleShift_1 = T.Buffer((2280,), data=ScaleShift.data)\n                data_1 = T.Buffer((2280,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [1, 8, 19, 15], "input_shape": "[[1, 8, 19, 15], [8], [8]]", "output_shape": "[[1, 8, 19, 15]]"}{"op_name": "tan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 990; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = tanf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(9) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 3, 15, 11), \"float32\"), compute: T.Buffer((2, 3, 15, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(990):\n            compute_1 = T.Buffer((990,), data=compute.data)\n            data_1 = T.Buffer((990,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.tan(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [2, 3, 15, 11], "input_shape": "[[2, 3, 15, 11]]", "output_shape": "[[2, 3, 15, 11]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused < 1235; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused) {\n    for (int32_t i_outer_outer_inner = 0; i_outer_outer_inner < 7; ++i_outer_outer_inner) {\n      for (int32_t i_outer_inner = 0; i_outer_inner < 2; ++i_outer_inner) {\n        ScaleShift[(((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 19) * 266) + (i_outer_outer_inner * 38)) + (i_outer_inner * 19)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 19))] = ((data[(((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 19) * 266) + (i_outer_outer_inner * 38)) + (i_outer_inner * 19)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 19))] * Scale[((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 95) / 19)]) + Shift[((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 95) / 19)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(26) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 26) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 1)) % 665) / 133)]) + Shift[((((((int)blockIdx.x) * 13) + (((int)threadIdx.x) >> 1)) % 665) / 133)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 5, 14, 19), \"float32\"), Scale: T.Buffer((5,), \"float32\"), Shift: T.Buffer((5,), \"float32\"), ScaleShift: T.Buffer((13, 5, 14, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused in T.parallel(1235):\n            for i_outer_outer_inner, i_outer_inner in T.grid(7, 2):\n                cse_var_2: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 95 // 19\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused // 19 * 266 + i_outer_outer_inner * 38 + i_outer_inner * 19 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 19\n                ScaleShift_1 = T.Buffer((17290,), data=ScaleShift.data)\n                data_1 = T.Buffer((17290,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [13, 5, 14, 19], "input_shape": "[[13, 5, 14, 19], [5], [5]]", "output_shape": "[[13, 5, 14, 19]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused < 1482; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused) {\n    for (int32_t b_inner = 0; b_inner < 5; ++b_inner) {\n      for (int32_t i_inner = 0; i_inner < 6; ++i_inner) {\n        ScaleShift[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 741) * 22230) + (b_inner * 4446)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 19) * 114)) + (i_inner * 19)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 19))] = ((data[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 741) * 22230) + (b_inner * 4446)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 19) * 114)) + (i_inner * 19)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 19))] * Scale[((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 57)]) + Shift[((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741) / 57)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 11115) {\n    ScaleShift[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) % 2223) / 171)]) + Shift[((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) % 2223) / 171)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 13, 18, 19), \"float32\"), Scale: T.Buffer((13,), \"float32\"), Shift: T.Buffer((13,), \"float32\"), ScaleShift: T.Buffer((10, 13, 18, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused in T.parallel(1482):\n            for b_inner, i_inner in T.grid(5, 6):\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 741\n                cse_var_2: T.int32 = cse_var_3 // 57\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused // 741 * 22230 + b_inner * 4446 + cse_var_3 // 19 * 114 + i_inner * 19 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 19\n                ScaleShift_1 = T.Buffer((44460,), data=ScaleShift.data)\n                data_1 = T.Buffer((44460,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [10, 13, 18, 19], "input_shape": "[[10, 13, 18, 19], [13], [13]]", "output_shape": "[[10, 13, 18, 19]]"}{"op_name": "tan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 152; ++i0_i1_fused) {\n    for (int32_t i3 = 0; i3 < 4; ++i3) {\n      compute[((i0_i1_fused * 4) + i3)] = tanf(data[((i0_i1_fused * 4) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 19, 1, 4), \"float32\"), compute: T.Buffer((8, 19, 1, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(152):\n            for i3 in range(4):\n                cse_var_1: T.int32 = i0_i1_fused * 4 + i3\n                compute_1 = T.Buffer((608,), data=compute.data)\n                data_1 = T.Buffer((608,), data=data.data)\n                compute_1[cse_var_1] = T.tan(data_1[cse_var_1])", "op_args": [8, 19, 1, 4], "input_shape": "[[8, 19, 1, 4]]", "output_shape": "[[8, 19, 1, 4]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused < 57; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused) {\n    for (int32_t c_outer_inner = 0; c_outer_inner < 5; ++c_outer_inner) {\n      for (int32_t i_outer_inner = 0; i_outer_inner < 20; ++i_outer_inner) {\n        for (int32_t b_inner = 0; b_inner < 5; ++b_inner) {\n          ScaleShift[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 19) * 9500) + (b_inner * 1900)) + (c_outer_inner * 380)) + (i_outer_inner * 19)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 19))] = ((data[((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 19) * 9500) + (b_inner * 1900)) + (c_outer_inner * 380)) + (i_outer_inner * 19)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 19))] * Scale[c_outer_inner]) + Shift[c_outer_inner]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20)) % 95) / 19)]) + Shift[((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20)) % 95) / 19)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 5, 20, 19), \"float32\"), Scale: T.Buffer((5,), \"float32\"), Shift: T.Buffer((5,), \"float32\"), ScaleShift: T.Buffer((15, 5, 20, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused in T.parallel(57):\n            for c_outer_inner, i_outer_inner, b_inner in T.grid(5, 20, 5):\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused // 19 * 9500 + b_inner * 1900 + c_outer_inner * 380 + i_outer_inner * 19 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 19\n                ScaleShift_1 = T.Buffer((28500,), data=ScaleShift.data)\n                data_1 = T.Buffer((28500,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[c_outer_inner] + Shift[c_outer_inner]", "op_args": [15, 5, 20, 19], "input_shape": "[[15, 5, 20, 19], [5], [5]]", "output_shape": "[[15, 5, 20, 19]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused < 2280; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused) {\n    for (int32_t i_inner = 0; i_inner < 5; ++i_inner) {\n      ScaleShift[((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused / 760) * 3800) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 380) / 190) * 1900)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 5) * 380)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 760) / 380) * 190)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 190) / 95) * 95)) + (i_inner * 19)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 95) / 5))] = ((data[((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused / 760) * 3800) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 380) / 190) * 1900)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 5) * 380)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 760) / 380) * 190)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 190) / 95) * 95)) + (i_inner * 19)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 95) / 5))] * Scale[((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 380) / 190) * 5) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 5))]) + Shift[((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 380) / 190) * 5) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 5))]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 76) * 5) + (((int)threadIdx.x) / 10)) / 38)]) + Shift[((((((int)blockIdx.x) % 76) * 5) + (((int)threadIdx.x) / 10)) / 38)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 10, 20, 19), \"float32\"), Scale: T.Buffer((10,), \"float32\"), Shift: T.Buffer((10,), \"float32\"), ScaleShift: T.Buffer((3, 10, 20, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused in T.parallel(2280):\n            for i_inner in range(5):\n                cse_var_4: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 5\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 380 // 190\n                cse_var_2: T.int32 = cse_var_3 * 5 + cse_var_4\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused // 760 * 3800 + cse_var_3 * 1900 + cse_var_4 * 380 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 760 // 380 * 190 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 190 // 95 * 95 + i_inner * 19 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused % 95 // 5\n                ScaleShift_1 = T.Buffer((11400,), data=ScaleShift.data)\n                data_1 = T.Buffer((11400,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [3, 10, 20, 19], "input_shape": "[[3, 10, 20, 19], [10], [10]]", "output_shape": "[[3, 10, 20, 19]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused < 120; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused) {\n    for (int32_t i_outer_outer_inner = 0; i_outer_outer_inner < 3; ++i_outer_outer_inner) {\n      for (int32_t b_outer_inner = 0; b_outer_inner < 13; ++b_outer_inner) {\n        for (int32_t c_inner = 0; c_inner < 3; ++c_inner) {\n          ScaleShift[((((((b_outer_inner * 1080) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 24) * 216)) + (c_inner * 72)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 24) >> 3) * 24)) + (i_outer_outer_inner * 8)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused & 7))] = ((data[((((((b_outer_inner * 1080) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 24) * 216)) + (c_inner * 72)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 24) >> 3) * 24)) + (i_outer_outer_inner * 8)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused & 7))] * Scale[(((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 24) * 3) + c_inner)]) + Shift[(((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 24) * 3) + c_inner)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 27) * 5) + (((int)threadIdx.x) >> 3)) / 9)]) + Shift[((((((int)blockIdx.x) % 27) * 5) + (((int)threadIdx.x) >> 3)) / 9)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 15, 9, 8), \"float32\"), Scale: T.Buffer((15,), \"float32\"), Shift: T.Buffer((15,), \"float32\"), ScaleShift: T.Buffer((13, 15, 9, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused in T.parallel(120):\n            for i_outer_outer_inner, b_outer_inner, c_inner in T.grid(3, 13, 3):\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused // 24\n                cse_var_2: T.int32 = cse_var_3 * 3 + c_inner\n                cse_var_1: T.int32 = b_outer_inner * 1080 + cse_var_3 * 216 + c_inner * 72 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 24 // 8 * 24 + i_outer_outer_inner * 8 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 8\n                ScaleShift_1 = T.Buffer((14040,), data=ScaleShift.data)\n                data_1 = T.Buffer((14040,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [13, 15, 9, 8], "input_shape": "[[13, 15, 9, 8], [15], [15]]", "output_shape": "[[13, 15, 9, 8]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused < 5544; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused) {\n    ScaleShift[(((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 154) / 14) * 504) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 308) * 28)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 7) * 4)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 308) / 154) * 2)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 14) / 7))] = ((data[(((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 154) / 14) * 504) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 308) * 28)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 7) * 4)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 308) / 154) * 2)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 14) / 7))] * Scale[(b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 616)]) + Shift[(b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused / 616)]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] * Scale[((((int)blockIdx.x) % 18) >> 1)]) + Shift[((((int)blockIdx.x) % 18) >> 1)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 9, 14, 4), \"float32\"), Scale: T.Buffer((9,), \"float32\"), Shift: T.Buffer((9,), \"float32\"), ScaleShift: T.Buffer((11, 9, 14, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused in T.parallel(5544):\n            cse_var_2: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused // 616\n            cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 154 // 14 * 504 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused // 308 * 28 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 7 * 4 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 308 // 154 * 2 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused % 14 // 7\n            ScaleShift_1 = T.Buffer((5544,), data=ScaleShift.data)\n            data_1 = T.Buffer((5544,), data=data.data)\n            ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [11, 9, 14, 4], "input_shape": "[[11, 9, 14, 4], [9], [9]]", "output_shape": "[[11, 9, 14, 4]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused < 900; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused) {\n    for (int32_t b_inner = 0; b_inner < 2; ++b_inner) {\n      for (int32_t i_inner = 0; i_inner < 4; ++i_inner) {\n        ScaleShift[((((((b_inner * 3600) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused / 180) * 720)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 90) / 6) * 48)) + (i_inner * 12)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 180) / 90) * 6)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 6))] = ((data[((((((b_inner * 3600) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused / 180) * 720)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 90) / 6) * 48)) + (i_inner * 12)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 180) / 90) * 6)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 6))] * Scale[(((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused / 180) * 3) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 90) / 30))]) + Shift[(((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused / 180) * 3) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 90) / 30))]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] * Scale[((((int)blockIdx.x) % 150) / 10)]) + Shift[((((int)blockIdx.x) % 150) / 10)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 15, 20, 12), \"float32\"), Scale: T.Buffer((15,), \"float32\"), Shift: T.Buffer((15,), \"float32\"), ScaleShift: T.Buffer((2, 15, 20, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused in T.parallel(900):\n            for b_inner, i_inner in T.grid(2, 4):\n                cse_var_4: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 90\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused // 180\n                cse_var_2: T.int32 = cse_var_3 * 3 + cse_var_4 // 30\n                cse_var_1: T.int32 = b_inner * 3600 + cse_var_3 * 720 + cse_var_4 // 6 * 48 + i_inner * 12 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 180 // 90 * 6 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_b_outer_inner_fused_c_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused % 6\n                ScaleShift_1 = T.Buffer((7200,), data=ScaleShift.data)\n                data_1 = T.Buffer((7200,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [2, 15, 20, 12], "input_shape": "[[2, 15, 20, 12], [15], [15]]", "output_shape": "[[2, 15, 20, 12]]"}{"op_name": "tan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 6; ++i1) {\n      for (int32_t i2 = 0; i2 < 2; ++i2) {\n        for (int32_t i3 = 0; i3 < 18; ++i3) {\n          compute[((((i0 * 216) + (i1 * 36)) + (i2 * 18)) + i3)] = tanf(data[((((i0 * 216) + (i1 * 36)) + (i2 * 18)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(22) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 6, 2, 18), \"float32\"), compute: T.Buffer((11, 6, 2, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i2, i3 in T.grid(6, 2, 18):\n                cse_var_1: T.int32 = i0 * 216 + i1 * 36 + i2 * 18 + i3\n                compute_1 = T.Buffer((2376,), data=compute.data)\n                data_1 = T.Buffer((2376,), data=data.data)\n                compute_1[cse_var_1] = T.tan(data_1[cse_var_1])", "op_args": [11, 6, 2, 18], "input_shape": "[[11, 6, 2, 18]]", "output_shape": "[[11, 6, 2, 18]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused < 900; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused) {\n    for (int32_t j_outer_inner = 0; j_outer_inner < 2; ++j_outer_inner) {\n      for (int32_t i_inner = 0; i_inner < 4; ++i_inner) {\n        ScaleShift[((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 300) * 2400) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 20) >> 1) * 240)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 300) / 100) * 80)) + (i_inner * 20)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 100) / 20) * 4)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused & 1) * 2)) + j_outer_inner)] = ((data[((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 300) * 2400) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 20) >> 1) * 240)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 300) / 100) * 80)) + (i_inner * 20)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 100) / 20) * 4)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused & 1) * 2)) + j_outer_inner)] * Scale[((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 20) >> 1)]) + Shift[((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 20) >> 1)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 6)) % 400) / 40)]) + Shift[((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 6)) % 400) / 40)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 10, 12, 20), \"float32\"), Scale: T.Buffer((10,), \"float32\"), Shift: T.Buffer((10,), \"float32\"), ScaleShift: T.Buffer((3, 10, 12, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused in T.parallel(900):\n            for j_outer_inner, i_inner in T.grid(2, 4):\n                cse_var_2: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 20 // 2\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused // 300 * 2400 + cse_var_2 * 240 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 300 // 100 * 80 + i_inner * 20 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 100 // 20 * 4 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 2 * 2 + j_outer_inner\n                ScaleShift_1 = T.Buffer((7200,), data=ScaleShift.data)\n                data_1 = T.Buffer((7200,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [3, 10, 12, 20], "input_shape": "[[3, 10, 12, 20], [10], [10]]", "output_shape": "[[3, 10, 12, 20]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused < 6650; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused) {\n    for (int32_t c_outer_inner = 0; c_outer_inner < 2; ++c_outer_inner) {\n      for (int32_t b_inner = 0; b_inner < 2; ++b_inner) {\n        ScaleShift[((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 665) / 133) * 5320) + (b_inner * 2660)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 1330) * 532)) + (c_outer_inner * 266)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 1330) / 665) * 133)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 133))] = ((data[((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 665) / 133) * 5320) + (b_inner * 2660)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 1330) * 532)) + (c_outer_inner * 266)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 1330) / 665) * 133)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 133))] * Scale[(((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 1330) * 2) + c_outer_inner)]) + Shift[(((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 1330) * 2) + c_outer_inner)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) < 3325) {\n    ScaleShift[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) * 24) + (((int)threadIdx.x) >> 1)) % 1330) / 133)]) + Shift[((((((int)blockIdx.x) * 24) + (((int)threadIdx.x) >> 1)) % 1330) / 133)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 10, 14, 19), \"float32\"), Scale: T.Buffer((10,), \"float32\"), Shift: T.Buffer((10,), \"float32\"), ScaleShift: T.Buffer((10, 10, 14, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused in T.parallel(6650):\n            for c_outer_inner, b_inner in T.grid(2, 2):\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused // 1330\n                cse_var_2: T.int32 = cse_var_3 * 2 + c_outer_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 665 // 133 * 5320 + b_inner * 2660 + cse_var_3 * 532 + c_outer_inner * 266 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 1330 // 665 * 133 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 133\n                ScaleShift_1 = T.Buffer((26600,), data=ScaleShift.data)\n                data_1 = T.Buffer((26600,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [10, 10, 14, 19], "input_shape": "[[10, 10, 14, 19], [10], [10]]", "output_shape": "[[10, 10, 14, 19]]"}{"op_name": "tan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 8; ++i2) {\n        for (int32_t i3 = 0; i3 < 20; ++i3) {\n          compute[((((i0 * 320) + (i1 * 160)) + (i2 * 20)) + i3)] = tanf(data[((((i0 * 320) + (i1 * 160)) + (i2 * 20)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 2, 8, 20), \"float32\"), compute: T.Buffer((15, 2, 8, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(15):\n            for i1, i2, i3 in T.grid(2, 8, 20):\n                cse_var_1: T.int32 = i0 * 320 + i1 * 160 + i2 * 20 + i3\n                compute_1 = T.Buffer((4800,), data=compute.data)\n                data_1 = T.Buffer((4800,), data=data.data)\n                compute_1[cse_var_1] = T.tan(data_1[cse_var_1])", "op_args": [15, 2, 8, 20], "input_shape": "[[15, 2, 8, 20]]", "output_shape": "[[15, 2, 8, 20]]"}{"op_name": "scale_shift_nchw", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused = 0; b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused < 819; ++b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused) {\n    for (int32_t b_outer_inner = 0; b_outer_inner < 2; ++b_outer_inner) {\n      for (int32_t c_outer_inner = 0; c_outer_inner < 3; ++c_outer_inner) {\n        for (int32_t i_outer_inner = 0; i_outer_inner < 3; ++i_outer_inner) {\n          for (int32_t i_inner = 0; i_inner < 2; ++i_inner) {\n            ScaleShift[((((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 273) / 39) * 4212) + (b_outer_inner * 2106)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 39) / 13) * 702)) + (c_outer_inner * 234)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 273) * 78)) + (i_outer_inner * 26)) + (i_inner * 13)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 13))] = ((data[((((((((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 273) / 39) * 4212) + (b_outer_inner * 2106)) + (((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 39) / 13) * 702)) + (c_outer_inner * 234)) + ((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 273) * 78)) + (i_outer_inner * 26)) + (i_inner * 13)) + (b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 13))] * Scale[((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 39) / 13) * 3) + c_outer_inner)]) + Shift[((((b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 39) / 13) * 3) + c_outer_inner)]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 39) * 3) + (((int)threadIdx.x) / 18)) / 13)]) + Shift[((((((int)blockIdx.x) % 39) * 3) + (((int)threadIdx.x) / 18)) / 13)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 9, 18, 13), \"float32\"), Scale: T.Buffer((9,), \"float32\"), Shift: T.Buffer((9,), \"float32\"), ScaleShift: T.Buffer((14, 9, 18, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused in T.parallel(819):\n            for b_outer_inner, c_outer_inner, i_outer_inner, i_inner in T.grid(2, 3, 3, 2):\n                cse_var_3: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 39 // 13\n                cse_var_2: T.int32 = cse_var_3 * 3 + c_outer_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 273 // 39 * 4212 + b_outer_inner * 2106 + cse_var_3 * 702 + c_outer_inner * 234 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused // 273 * 78 + i_outer_inner * 26 + i_inner * 13 + b_outer_outer_outer_c_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_b_outer_outer_inner_fused_c_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 13\n                ScaleShift_1 = T.Buffer((29484,), data=ScaleShift.data)\n                data_1 = T.Buffer((29484,), data=data.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale[cse_var_2] + Shift[cse_var_2]", "op_args": [14, 9, 18, 13], "input_shape": "[[14, 9, 18, 13], [9], [9]]", "output_shape": "[[14, 9, 18, 13]]"}{"op_name": "tan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 160; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 10; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 10) + i3)] = tanf(data[((i0_i1_fused_i2_fused * 10) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 2, 16, 10), \"float32\"), compute: T.Buffer((5, 2, 16, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(160):\n            for i3 in range(10):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 10 + i3\n                compute_1 = T.Buffer((1600,), data=compute.data)\n                data_1 = T.Buffer((1600,), data=data.data)\n                compute_1[cse_var_1] = T.tan(data_1[cse_var_1])", "op_args": [5, 2, 16, 10], "input_shape": "[[5, 2, 16, 10]]", "output_shape": "[[5, 2, 16, 10]]"}{"op_name": "prelu", "c_code": "void default_function_kernel(float* Scale, float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 14; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 15; ++i2) {\n      for (int32_t i3 = 0; i3 < 14; ++i3) {\n        compute[(((i0_i1_fused * 210) + (i2 * 14)) + i3)] = ((0.000000e+00f < data[(((i0_i1_fused * 210) + (i2 * 14)) + i3)]) ? data[(((i0_i1_fused * 210) + (i2 * 14)) + i3)] : (data[(((i0_i1_fused * 210) + (i2 * 14)) + i3)] * Scale[i3]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(49) default_function_kernel(float* __restrict__ Scale, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 49) + ((int)threadIdx.x))] * Scale[(((((int)blockIdx.x) * 7) + ((int)threadIdx.x)) % 14)]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 7, 15, 14), \"float32\"), Scale: T.Buffer((14,), \"float32\"), compute: T.Buffer((2, 7, 15, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(14):\n            for i2, i3 in T.grid(15, 14):\n                cse_var_1: T.int32 = i0_i1_fused * 210 + i2 * 14 + i3\n                compute_1 = T.Buffer((2940,), data=compute.data)\n                data_1 = T.Buffer((2940,), data=data.data)\n                compute_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], data_1[cse_var_1], data_1[cse_var_1] * Scale[i3])", "op_args": [2, 7, 15, 14], "input_shape": "[[2, 7, 15, 14], [14]]", "output_shape": "[[2, 7, 15, 14]]"}{"op_name": "tan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 6; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3 = 0; i3 < 20; ++i3) {\n          compute[((((i0 * 1320) + (i1 * 220)) + (i2 * 20)) + i3)] = tanf(data[((((i0 * 1320) + (i1 * 220)) + (i2 * 20)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(55) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 6, 11, 20), \"float32\"), compute: T.Buffer((13, 6, 11, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3 in T.grid(6, 11, 20):\n                cse_var_1: T.int32 = i0 * 1320 + i1 * 220 + i2 * 20 + i3\n                compute_1 = T.Buffer((17160,), data=compute.data)\n                data_1 = T.Buffer((17160,), data=data.data)\n                compute_1[cse_var_1] = T.tan(data_1[cse_var_1])", "op_args": [13, 6, 11, 20], "input_shape": "[[13, 6, 11, 20]]", "output_shape": "[[13, 6, 11, 20]]"}{"op_name": "tan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 15; ++i1) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 6; ++i3) {\n        compute[(((i1 * 84) + (i2 * 6)) + i3)] = tanf(data[(((i1 * 84) + (i2 * 6)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 30) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 15, 14, 6), \"float32\"), compute: T.Buffer((1, 15, 14, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(15, 14, 6):\n            cse_var_1: T.int32 = i1 * 84 + i2 * 6 + i3\n            compute_1 = T.Buffer((1260,), data=compute.data)\n            data_1 = T.Buffer((1260,), data=data.data)\n            compute_1[cse_var_1] = T.tan(data_1[cse_var_1])", "op_args": [1, 15, 14, 6], "input_shape": "[[1, 15, 14, 6]]", "output_shape": "[[1, 15, 14, 6]]"}{"op_name": "tan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 100; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 17; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 17) + i3)] = tanf(data[((i0_i1_fused_i2_fused * 17) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(25) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 25) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 25) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 2, 10, 17), \"float32\"), compute: T.Buffer((5, 2, 10, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(100):\n            for i3 in range(17):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 17 + i3\n                compute_1 = T.Buffer((1700,), data=compute.data)\n                data_1 = T.Buffer((1700,), data=data.data)\n                compute_1[cse_var_1] = T.tan(data_1[cse_var_1])", "op_args": [5, 2, 10, 17], "input_shape": "[[5, 2, 10, 17]]", "output_shape": "[[5, 2, 10, 17]]"}{"op_name": "prelu", "c_code": "void default_function_kernel(float* Scale, float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 46512; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused]) ? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * Scale[(i0_i1_fused_i2_fused_i3_fused % 19)]));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ Scale, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] * Scale[(((int)threadIdx.x) % 19)]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 17, 16, 19), \"float32\"), Scale: T.Buffer((19,), \"float32\"), compute: T.Buffer((9, 17, 16, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(46512):\n            compute_1 = T.Buffer((46512,), data=compute.data)\n            data_1 = T.Buffer((46512,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.if_then_else(T.float32(0) < data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused] * Scale[i0_i1_fused_i2_fused_i3_fused % 19])", "op_args": [9, 17, 16, 19], "input_shape": "[[9, 17, 16, 19], [19]]", "output_shape": "[[9, 17, 16, 19]]"}{"op_name": "tan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 33264; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = tanf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 11, 12, 18), \"float32\"), compute: T.Buffer((14, 11, 12, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(33264):\n            compute_1 = T.Buffer((33264,), data=compute.data)\n            data_1 = T.Buffer((33264,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.tan(data_1[i0_i1_fused_i2_fused_i3_fused])", "op_args": [14, 11, 12, 18], "input_shape": "[[14, 11, 12, 18]]", "output_shape": "[[14, 11, 12, 18]]"}{"op_name": "prelu", "c_code": "void default_function_kernel(float* Scale, float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 50; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 6; ++i3) {\n        compute[(((i0_i1_fused * 84) + (i2 * 6)) + i3)] = ((0.000000e+00f < data[(((i0_i1_fused * 84) + (i2 * 6)) + i3)]) ? data[(((i0_i1_fused * 84) + (i2 * 6)) + i3)] : (data[(((i0_i1_fused * 84) + (i2 * 6)) + i3)] * Scale[i3]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ Scale, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] * Scale[(((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 6)]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 5, 14, 6), \"float32\"), Scale: T.Buffer((6,), \"float32\"), compute: T.Buffer((10, 5, 14, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(50):\n            for i2, i3 in T.grid(14, 6):\n                cse_var_1: T.int32 = i0_i1_fused * 84 + i2 * 6 + i3\n                compute_1 = T.Buffer((4200,), data=compute.data)\n                data_1 = T.Buffer((4200,), data=data.data)\n                compute_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], data_1[cse_var_1], data_1[cse_var_1] * Scale[i3])", "op_args": [10, 5, 14, 6], "input_shape": "[[10, 5, 14, 6], [6]]", "output_shape": "[[10, 5, 14, 6]]"}{"op_name": "tan", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 513; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 12; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 12) + i3)] = tanf(data[((i0_i1_fused_i2_fused * 12) + i3)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(19) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 19) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 19) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 19, 3, 12), \"float32\"), compute: T.Buffer((9, 19, 3, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(513):\n            for i3 in range(12):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 12 + i3\n                compute_1 = T.Buffer((6156,), data=compute.data)\n                data_1 = T.Buffer((6156,), data=data.data)\n                compute_1[cse_var_1] = T.tan(data_1[cse_var_1])", "op_args": [9, 19, 3, 12], "input_shape": "[[9, 19, 3, 12]]", "output_shape": "[[9, 19, 3, 12]]"}{"op_name": "tanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 144; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 6; ++i2) {\n      for (int32_t i3 = 0; i3 < 17; ++i3) {\n        compute[(((i0_i1_fused * 102) + (i2 * 17)) + i3)] = tanhf(data[(((i0_i1_fused * 102) + (i2 * 17)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = tanhf(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 12, 6, 17), \"float32\"), compute: T.Buffer((12, 12, 6, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(144):\n            for i2, i3 in T.grid(6, 17):\n                cse_var_1: T.int32 = i0_i1_fused * 102 + i2 * 17 + i3\n                compute_1 = T.Buffer((14688,), data=compute.data)\n                data_1 = T.Buffer((14688,), data=data.data)\n                compute_1[cse_var_1] = T.tanh(data_1[cse_var_1])", "op_args": [12, 12, 6, 17], "input_shape": "[[12, 12, 6, 17]]", "output_shape": "[[12, 12, 6, 17]]"}{"op_name": "prelu", "c_code": "void default_function_kernel(float* Scale, float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 126; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 16; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 16) + i3)] = ((0.000000e+00f < data[((i0_i1_fused_i2_fused * 16) + i3)]) ? data[((i0_i1_fused_i2_fused * 16) + i3)] : (data[((i0_i1_fused_i2_fused * 16) + i3)] * Scale[i3]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ Scale, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] * Scale[(((((int)blockIdx.x) * 12) + ((int)threadIdx.x)) & 15)]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 14, 3, 16), \"float32\"), Scale: T.Buffer((16,), \"float32\"), compute: T.Buffer((3, 14, 3, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(126):\n            for i3 in range(16):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 16 + i3\n                compute_1 = T.Buffer((2016,), data=compute.data)\n                data_1 = T.Buffer((2016,), data=data.data)\n                compute_1[cse_var_1] = T.if_then_else(T.float32(0) < data_1[cse_var_1], data_1[cse_var_1], data_1[cse_var_1] * Scale[i3])", "op_args": [3, 14, 3, 16], "input_shape": "[[3, 14, 3, 16], [16]]", "output_shape": "[[3, 14, 3, 16]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused < 84; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused) {\n    for (int32_t b_outer_inner = 0; b_outer_inner < 17; ++b_outer_inner) {\n      for (int32_t i_outer_inner = 0; i_outer_inner < 4; ++i_outer_inner) {\n        for (int32_t j_outer_inner = 0; j_outer_inner < 2; ++j_outer_inner) {\n          ScaleShift[((((((b_outer_inner * 672) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused / 14) * 112)) + (i_outer_inner * 28)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 14) >> 1) * 4)) + (j_outer_inner * 2)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 1))] = ((data[((((((b_outer_inner * 672) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused / 14) * 112)) + (i_outer_inner * 28)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 14) >> 1) * 4)) + (j_outer_inner * 2)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 1))] * Scale[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused / 42) * 2) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 1))]) + Shift[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused / 42) * 2) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 1))]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(42) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) & 15) >> 3) * 2) + (((int)threadIdx.x) & 1))]) + Shift[((((((int)blockIdx.x) & 15) >> 3) * 2) + (((int)threadIdx.x) & 1))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 12, 14, 2), \"float32\"), Scale: T.Buffer((2, 2), \"float32\"), Shift: T.Buffer((2, 2), \"float32\"), ScaleShift: T.Buffer((17, 2, 12, 14, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused in T.parallel(84):\n            for b_outer_inner, i_outer_inner, j_outer_inner in T.grid(17, 4, 2):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 2\n                cse_var_2: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused // 42 * 2 + cse_var_3\n                cse_var_1: T.int32 = b_outer_inner * 672 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused // 14 * 112 + i_outer_inner * 28 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 14 // 2 * 4 + j_outer_inner * 2 + cse_var_3\n                ScaleShift_1 = T.Buffer((11424,), data=ScaleShift.data)\n                data_1 = T.Buffer((11424,), data=data.data)\n                Scale_1 = T.Buffer((4,), data=Scale.data)\n                Shift_1 = T.Buffer((4,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [17, 2, 12, 14], "input_shape": "[[17, 2, 12, 14, 2], [2, 2], [2, 2]]", "output_shape": "[[17, 2, 12, 14, 2]]"}{"op_name": "tanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 2; ++i0) {\n    for (int32_t i1 = 0; i1 < 6; ++i1) {\n      for (int32_t i2 = 0; i2 < 10; ++i2) {\n        for (int32_t i3 = 0; i3 < 11; ++i3) {\n          compute[((((i0 * 660) + (i1 * 110)) + (i2 * 11)) + i3)] = tanhf(data[((((i0 * 660) + (i1 * 110)) + (i2 * 11)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(11) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 11) + ((int)threadIdx.x))] = tanhf(data[((((int)blockIdx.x) * 11) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 6, 10, 11), \"float32\"), compute: T.Buffer((2, 6, 10, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(2):\n            for i1, i2, i3 in T.grid(6, 10, 11):\n                cse_var_1: T.int32 = i0 * 660 + i1 * 110 + i2 * 11 + i3\n                compute_1 = T.Buffer((1320,), data=compute.data)\n                data_1 = T.Buffer((1320,), data=data.data)\n                compute_1[cse_var_1] = T.tanh(data_1[cse_var_1])", "op_args": [2, 6, 10, 11], "input_shape": "[[2, 6, 10, 11]]", "output_shape": "[[2, 6, 10, 11]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused < 850; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused) {\n    for (int32_t j_outer_outer_inner = 0; j_outer_outer_inner < 10; ++j_outer_outer_inner) {\n      for (int32_t cc_inner = 0; cc_inner < 2; ++cc_inner) {\n        ScaleShift[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused / 50) * 1000) + (cc_inner * 500)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused % 50) / 5) * 50)) + (j_outer_outer_inner * 5)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused % 5))] = ((data[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused / 50) * 1000) + (cc_inner * 500)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused % 50) / 5) * 50)) + (j_outer_outer_inner * 5)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused % 5))] * Scale[((cc_inner * 5) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused % 5))]) + Shift[((cc_inner * 5) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused % 5))]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 50) / 25) * 5) + (((int)threadIdx.x) % 5))]) + Shift[((((((int)blockIdx.x) % 50) / 25) * 5) + (((int)threadIdx.x) % 5))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 5, 20, 5), \"float32\"), Scale: T.Buffer((2, 5), \"float32\"), Shift: T.Buffer((2, 5), \"float32\"), ScaleShift: T.Buffer((17, 2, 5, 20, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused in T.parallel(850):\n            for j_outer_outer_inner, cc_inner in T.grid(10, 2):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused % 5\n                cse_var_2: T.int32 = cc_inner * 5 + cse_var_3\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused // 50 * 1000 + cc_inner * 500 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused % 50 // 5 * 50 + j_outer_outer_inner * 5 + cse_var_3\n                ScaleShift_1 = T.Buffer((17000,), data=ScaleShift.data)\n                data_1 = T.Buffer((17000,), data=data.data)\n                Scale_1 = T.Buffer((10,), data=Scale.data)\n                Shift_1 = T.Buffer((10,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [17, 5, 5, 20], "input_shape": "[[17, 2, 5, 20, 5], [2, 5], [2, 5]]", "output_shape": "[[17, 2, 5, 20, 5]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused < 864; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused) {\n    for (int32_t b_inner = 0; b_inner < 4; ++b_inner) {\n      for (int32_t i_inner = 0; i_inner < 3; ++i_inner) {\n        for (int32_t j_inner = 0; j_inner < 5; ++j_inner) {\n          ScaleShift[((((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 24) / 6) * 12960) + (b_inner * 3240)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 6) * 540)) + (i_inner * 180)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 288) / 72) * 45)) + (j_inner * 9)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused / 288) * 3)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 72) / 24))] = ((data[((((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 24) / 6) * 12960) + (b_inner * 3240)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 6) * 540)) + (i_inner * 180)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 288) / 72) * 45)) + (j_inner * 9)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused / 288) * 3)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 72) / 24))] * Scale[(((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 6) / 3) * 9) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused / 288) * 3)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 72) / 24))]) + Shift[(((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 6) / 3) * 9) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused / 288) * 3)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 72) / 24))]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) % 810) / 405) * 9) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 9))]) + Shift[((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) % 810) / 405) * 9) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 9))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 2, 9, 20, 9), \"float32\"), Scale: T.Buffer((2, 9), \"float32\"), Shift: T.Buffer((2, 9), \"float32\"), ScaleShift: T.Buffer((16, 2, 9, 20, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused in T.parallel(864):\n            for b_inner, i_inner, j_inner in T.grid(4, 3, 5):\n                cse_var_5: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 6\n                cse_var_4: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused // 288 * 3\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 72 // 24\n                cse_var_2: T.int32 = cse_var_5 // 3 * 9 + cse_var_4 + cse_var_3\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 24 // 6 * 12960 + b_inner * 3240 + cse_var_5 * 540 + i_inner * 180 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 288 // 72 * 45 + j_inner * 9 + cse_var_4 + cse_var_3\n                ScaleShift_1 = T.Buffer((51840,), data=ScaleShift.data)\n                data_1 = T.Buffer((51840,), data=data.data)\n                Scale_1 = T.Buffer((18,), data=Scale.data)\n                Shift_1 = T.Buffer((18,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [16, 9, 9, 20], "input_shape": "[[16, 2, 9, 20, 9], [2, 9], [2, 9]]", "output_shape": "[[16, 2, 9, 20, 9]]"}{"op_name": "tanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 5; ++i0) {\n    for (int32_t i1 = 0; i1 < 12; ++i1) {\n      for (int32_t i2 = 0; i2 < 17; ++i2) {\n        for (int32_t i3 = 0; i3 < 19; ++i3) {\n          compute[((((i0 * 3876) + (i1 * 323)) + (i2 * 19)) + i3)] = tanhf(data[((((i0 * 3876) + (i1 * 323)) + (i2 * 19)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = tanhf(data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 12, 17, 19), \"float32\"), compute: T.Buffer((5, 12, 17, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(5):\n            for i1, i2, i3 in T.grid(12, 17, 19):\n                cse_var_1: T.int32 = i0 * 3876 + i1 * 323 + i2 * 19 + i3\n                compute_1 = T.Buffer((19380,), data=compute.data)\n                data_1 = T.Buffer((19380,), data=data.data)\n                compute_1[cse_var_1] = T.tanh(data_1[cse_var_1])", "op_args": [5, 12, 17, 19], "input_shape": "[[5, 12, 17, 19]]", "output_shape": "[[5, 12, 17, 19]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused < 1080; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused) {\n    for (int32_t cb_outer_outer_inner = 0; cb_outer_outer_inner < 5; ++cb_outer_outer_inner) {\n      for (int32_t j_inner = 0; j_inner < 7; ++j_inner) {\n        ScaleShift[((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 90) / 10) * 4200) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 180) * 700)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 10) * 70)) + (j_inner * 10)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 180) / 90) * 5)) + cb_outer_outer_inner)] = ((data[((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 90) / 10) * 4200) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 180) * 700)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 10) * 70)) + (j_inner * 10)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 180) / 90) * 5)) + cb_outer_outer_inner)] * Scale[((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 540) * 10) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 180) / 90) * 5)) + cb_outer_outer_inner)]) + Shift[((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 540) * 10) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 180) / 90) * 5)) + cb_outer_outer_inner)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) % 105) * 2) + (((int)threadIdx.x) / 20)) / 105) * 10) + (((int)threadIdx.x) % 10))]) + Shift[((((((((int)blockIdx.x) % 105) * 2) + (((int)threadIdx.x) / 20)) / 105) * 10) + (((int)threadIdx.x) % 10))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 2, 15, 14, 10), \"float32\"), Scale: T.Buffer((2, 10), \"float32\"), Shift: T.Buffer((2, 10), \"float32\"), ScaleShift: T.Buffer((9, 2, 15, 14, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused in T.parallel(1080):\n            for cb_outer_outer_inner, j_inner in T.grid(5, 7):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 180 // 90 * 5\n                cse_var_2: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused // 540 * 10 + cse_var_3 + cb_outer_outer_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 90 // 10 * 4200 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused // 180 * 700 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 10 * 70 + j_inner * 10 + cse_var_3 + cb_outer_outer_inner\n                ScaleShift_1 = T.Buffer((37800,), data=ScaleShift.data)\n                data_1 = T.Buffer((37800,), data=data.data)\n                Scale_1 = T.Buffer((20,), data=Scale.data)\n                Shift_1 = T.Buffer((20,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [9, 10, 15, 14], "input_shape": "[[9, 2, 15, 14, 10], [2, 10], [2, 10]]", "output_shape": "[[9, 2, 15, 14, 10]]"}{"op_name": "tanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 20; ++i1) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 13; ++i3) {\n        compute[(((i1 * 182) + (i2 * 13)) + i3)] = tanhf(data[(((i1 * 182) + (i2 * 13)) + i3)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = tanhf(data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 20, 14, 13), \"float32\"), compute: T.Buffer((1, 20, 14, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(20, 14, 13):\n            cse_var_1: T.int32 = i1 * 182 + i2 * 13 + i3\n            compute_1 = T.Buffer((3640,), data=compute.data)\n            data_1 = T.Buffer((3640,), data=data.data)\n            compute_1[cse_var_1] = T.tanh(data_1[cse_var_1])", "op_args": [1, 20, 14, 13], "input_shape": "[[1, 20, 14, 13]]", "output_shape": "[[1, 20, 14, 13]]"}{"op_name": "tanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 12; ++i0) {\n    for (int32_t i1 = 0; i1 < 4; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3 = 0; i3 < 2; ++i3) {\n          compute[((((i0 * 88) + (i1 * 22)) + (i2 * 2)) + i3)] = tanhf(data[((((i0 * 88) + (i1 * 22)) + (i2 * 2)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(22) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))] = tanhf(data[((((int)blockIdx.x) * 22) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 4, 11, 2), \"float32\"), compute: T.Buffer((12, 4, 11, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(12):\n            for i1, i2, i3 in T.grid(4, 11, 2):\n                cse_var_1: T.int32 = i0 * 88 + i1 * 22 + i2 * 2 + i3\n                compute_1 = T.Buffer((1056,), data=compute.data)\n                data_1 = T.Buffer((1056,), data=data.data)\n                compute_1[cse_var_1] = T.tanh(data_1[cse_var_1])", "op_args": [12, 4, 11, 2], "input_shape": "[[12, 4, 11, 2]]", "output_shape": "[[12, 4, 11, 2]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  for (int32_t j_outer_outer_outer = 0; j_outer_outer_outer < 2; ++j_outer_outer_outer) {\n    for (int32_t b_outer_inner = 0; b_outer_inner < 7; ++b_outer_inner) {\n      for (int32_t cc_inner = 0; cc_inner < 2; ++cc_inner) {\n        ScaleShift[(((b_outer_inner * 4) + (cc_inner * 2)) + j_outer_outer_outer)] = ((data[(((b_outer_inner * 4) + (cc_inner * 2)) + j_outer_outer_outer)] * Scale[cc_inner]) + Shift[cc_inner]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((int)threadIdx.x)] = ((data[((int)threadIdx.x)] * Scale[((((int)threadIdx.x) & 3) >> 1)]) + Shift[((((int)threadIdx.x) & 3) >> 1)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 1, 2, 1), \"float32\"), Scale: T.Buffer((2, 1), \"float32\"), Shift: T.Buffer((2, 1), \"float32\"), ScaleShift: T.Buffer((7, 2, 1, 2, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for j_outer_outer_outer, b_outer_inner, cc_inner in T.grid(2, 7, 2):\n            cse_var_1: T.int32 = b_outer_inner * 4 + cc_inner * 2 + j_outer_outer_outer\n            ScaleShift_1 = T.Buffer((28,), data=ScaleShift.data)\n            data_1 = T.Buffer((28,), data=data.data)\n            Scale_1 = T.Buffer((2,), data=Scale.data)\n            Shift_1 = T.Buffer((2,), data=Shift.data)\n            ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cc_inner] + Shift_1[cc_inner]", "op_args": [7, 1, 1, 2], "input_shape": "[[7, 2, 1, 2, 1], [2, 1], [2, 1]]", "output_shape": "[[7, 2, 1, 2, 1]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused < 2160; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused) {\n    for (int32_t j_outer_inner = 0; j_outer_inner < 7; ++j_outer_inner) {\n      ScaleShift[(((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 1080) * 7560) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 3) * 1890)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 1080) / 360) * 630)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 24) >> 2) * 105)) + (j_outer_inner * 15)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 360) / 24))] = ((data[(((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 1080) * 7560) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 3) * 1890)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 1080) / 360) * 630)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 24) >> 2) * 105)) + (j_outer_inner * 15)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 360) / 24))] * Scale[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 15) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 360) / 24))]) + Shift[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 15) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 360) / 24))]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) % 63) * 2) + (((int)threadIdx.x) / 30)) / 63) * 15) + (((int)threadIdx.x) % 15))]) + Shift[((((((((int)blockIdx.x) % 63) * 2) + (((int)threadIdx.x) / 30)) / 63) * 15) + (((int)threadIdx.x) % 15))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 2, 9, 14, 15), \"float32\"), Scale: T.Buffer((2, 15), \"float32\"), Shift: T.Buffer((2, 15), \"float32\"), ScaleShift: T.Buffer((4, 2, 9, 14, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused in T.parallel(2160):\n            for j_outer_inner in range(7):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 360 // 24\n                cse_var_2: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 2 * 15 + cse_var_3\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused // 1080 * 7560 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 4 * 1890 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 1080 // 360 * 630 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 24 // 4 * 105 + j_outer_inner * 15 + cse_var_3\n                ScaleShift_1 = T.Buffer((15120,), data=ScaleShift.data)\n                data_1 = T.Buffer((15120,), data=data.data)\n                Scale_1 = T.Buffer((30,), data=Scale.data)\n                Shift_1 = T.Buffer((30,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [4, 15, 9, 14], "input_shape": "[[4, 2, 9, 14, 15], [2, 15], [2, 15]]", "output_shape": "[[4, 2, 9, 14, 15]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused < 128; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused) {\n    for (int32_t cc_outer_inner = 0; cc_outer_inner < 2; ++cc_outer_inner) {\n      for (int32_t i_outer_inner = 0; i_outer_inner < 2; ++i_outer_inner) {\n        for (int32_t b_inner = 0; b_inner < 11; ++b_inner) {\n          for (int32_t i_inner = 0; i_inner < 2; ++i_inner) {\n            ScaleShift[((((((((b_inner * 1024) + (cc_outer_inner * 512)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 63) >> 5) * 256)) + (i_outer_inner * 128)) + (i_inner * 64)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 31) >> 3) * 16)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused >> 6) * 8)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 7))] = ((data[((((((((b_inner * 1024) + (cc_outer_inner * 512)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 63) >> 5) * 256)) + (i_outer_inner * 128)) + (i_inner * 64)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 31) >> 3) * 16)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused >> 6) * 8)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 7))] * Scale[(((cc_outer_inner * 16) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused >> 6) * 8)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 7))]) + Shift[(((cc_outer_inner * 16) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused >> 6) * 8)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused & 7))]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) & 15) >> 3) * 16) + (((int)threadIdx.x) & 15))]) + Shift[((((((int)blockIdx.x) & 15) >> 3) * 16) + (((int)threadIdx.x) & 15))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 2, 8, 4, 16), \"float32\"), Scale: T.Buffer((2, 16), \"float32\"), Shift: T.Buffer((2, 16), \"float32\"), ScaleShift: T.Buffer((11, 2, 8, 4, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused in T.parallel(128):\n            for cc_outer_inner, i_outer_inner, b_inner, i_inner in T.grid(2, 2, 11, 2):\n                cse_var_4: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 8\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused // 64 * 8\n                cse_var_2: T.int32 = cc_outer_inner * 16 + cse_var_3 + cse_var_4\n                cse_var_1: T.int32 = b_inner * 1024 + cc_outer_inner * 512 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 64 // 32 * 256 + i_outer_inner * 128 + i_inner * 64 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 32 // 8 * 16 + cse_var_3 + cse_var_4\n                ScaleShift_1 = T.Buffer((11264,), data=ScaleShift.data)\n                data_1 = T.Buffer((11264,), data=data.data)\n                Scale_1 = T.Buffer((32,), data=Scale.data)\n                Shift_1 = T.Buffer((32,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [11, 16, 8, 4], "input_shape": "[[11, 2, 8, 4, 16], [2, 16], [2, 16]]", "output_shape": "[[11, 2, 8, 4, 16]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused < 144; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused) {\n    for (int32_t cc_outer_inner = 0; cc_outer_inner < 2; ++cc_outer_inner) {\n      for (int32_t b_inner = 0; b_inner < 5; ++b_inner) {\n        ScaleShift[((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 12) / 6) * 720) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused & 1) * 360)) + (b_inner * 72)) + (cc_outer_inner * 36)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 6) >> 1) * 12)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused / 12))] = ((data[((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 12) / 6) * 720) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused & 1) * 360)) + (b_inner * 72)) + (cc_outer_inner * 36)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 6) >> 1) * 12)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused / 12))] * Scale[cc_outer_inner]) + Shift[cc_outer_inner]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 9) * 2) + (((int)threadIdx.x) >> 2)) / 9)]) + Shift[((((((int)blockIdx.x) % 9) * 2) + (((int)threadIdx.x) >> 2)) / 9)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 2, 3, 12, 1), \"float32\"), Scale: T.Buffer((2, 1), \"float32\"), Shift: T.Buffer((2, 1), \"float32\"), ScaleShift: T.Buffer((20, 2, 3, 12, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused in T.parallel(144):\n            for cc_outer_inner, b_inner in T.grid(2, 5):\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 12 // 6 * 720 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 2 * 360 + b_inner * 72 + cc_outer_inner * 36 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 6 // 2 * 12 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused // 12\n                ScaleShift_1 = T.Buffer((1440,), data=ScaleShift.data)\n                data_1 = T.Buffer((1440,), data=data.data)\n                Scale_1 = T.Buffer((2,), data=Scale.data)\n                Shift_1 = T.Buffer((2,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cc_outer_inner] + Shift_1[cc_outer_inner]", "op_args": [20, 1, 3, 12], "input_shape": "[[20, 2, 3, 12, 1], [2, 1], [2, 1]]", "output_shape": "[[20, 2, 3, 12, 1]]"}{"op_name": "tanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 19; ++i1) {\n      for (int32_t i2 = 0; i2 < 20; ++i2) {\n        for (int32_t i3 = 0; i3 < 19; ++i3) {\n          compute[((((i0 * 7220) + (i1 * 380)) + (i2 * 19)) + i3)] = tanhf(data[((((i0 * 7220) + (i1 * 380)) + (i2 * 19)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(55) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))] = tanhf(data[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 19, 20, 19), \"float32\"), compute: T.Buffer((11, 19, 20, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i2, i3 in T.grid(19, 20, 19):\n                cse_var_1: T.int32 = i0 * 7220 + i1 * 380 + i2 * 19 + i3\n                compute_1 = T.Buffer((79420,), data=compute.data)\n                data_1 = T.Buffer((79420,), data=data.data)\n                compute_1[cse_var_1] = T.tanh(data_1[cse_var_1])", "op_args": [11, 19, 20, 19], "input_shape": "[[11, 19, 20, 19]]", "output_shape": "[[11, 19, 20, 19]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused < 196; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused) {\n    for (int32_t cb_outer_inner = 0; cb_outer_inner < 7; ++cb_outer_inner) {\n      for (int32_t i_inner = 0; i_inner < 16; ++i_inner) {\n        ScaleShift[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 28) * 3136) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 1568)) + (i_inner * 98)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 28) >> 1) * 7)) + cb_outer_inner)] = ((data[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 28) * 3136) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 1568)) + (i_inner * 98)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 28) >> 1) * 7)) + cb_outer_inner)] * Scale[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 7) + cb_outer_inner)]) + Shift[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 7) + cb_outer_inner)]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) % 49) * 2) + (((int)threadIdx.x) >> 5)) / 49) * 7) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 7))]) + Shift[((((((((int)blockIdx.x) % 49) * 2) + (((int)threadIdx.x) >> 5)) / 49) * 7) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 7))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 16, 14, 7), \"float32\"), Scale: T.Buffer((2, 7), \"float32\"), Shift: T.Buffer((2, 7), \"float32\"), ScaleShift: T.Buffer((7, 2, 16, 14, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused in T.parallel(196):\n            for cb_outer_inner, i_inner in T.grid(7, 16):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 2\n                cse_var_2: T.int32 = cse_var_3 * 7 + cb_outer_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused // 28 * 3136 + cse_var_3 * 1568 + i_inner * 98 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 28 // 2 * 7 + cb_outer_inner\n                ScaleShift_1 = T.Buffer((21952,), data=ScaleShift.data)\n                data_1 = T.Buffer((21952,), data=data.data)\n                Scale_1 = T.Buffer((14,), data=Scale.data)\n                Shift_1 = T.Buffer((14,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [7, 7, 16, 14], "input_shape": "[[7, 2, 16, 14, 7], [2, 7], [2, 7]]", "output_shape": "[[7, 2, 16, 14, 7]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused < 3213; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused) {\n    for (int32_t cc_inner = 0; cc_inner < 2; ++cc_inner) {\n      for (int32_t i_inner = 0; i_inner < 2; ++i_inner) {\n        ScaleShift[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused / 357) * 1428) + (cc_inner * 714)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 7) * 102)) + (i_inner * 51)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 357) / 7))] = ((data[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused / 357) * 1428) + (cc_inner * 714)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 7) * 102)) + (i_inner * 51)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 357) / 7))] * Scale[((cc_inner * 3) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 21) / 7))]) + Shift[((cc_inner * 3) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 21) / 7))]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) % 51) * 2) + (((int)threadIdx.x) / 14)) / 51) * 3) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 3))]) + Shift[((((((((int)blockIdx.x) % 51) * 2) + (((int)threadIdx.x) / 14)) / 51) * 3) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 3))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 2, 14, 17, 3), \"float32\"), Scale: T.Buffer((2, 3), \"float32\"), Shift: T.Buffer((2, 3), \"float32\"), ScaleShift: T.Buffer((9, 2, 14, 17, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused in T.parallel(3213):\n            for cc_inner, i_inner in T.grid(2, 2):\n                cse_var_2: T.int32 = cc_inner * 3 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 21 // 7\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused // 357 * 1428 + cc_inner * 714 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 7 * 102 + i_inner * 51 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused % 357 // 7\n                ScaleShift_1 = T.Buffer((12852,), data=ScaleShift.data)\n                data_1 = T.Buffer((12852,), data=data.data)\n                Scale_1 = T.Buffer((6,), data=Scale.data)\n                Shift_1 = T.Buffer((6,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [9, 3, 14, 17], "input_shape": "[[9, 2, 14, 17, 3], [2, 3], [2, 3]]", "output_shape": "[[9, 2, 14, 17, 3]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused < 576; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused) {\n    for (int32_t b_outer_inner = 0; b_outer_inner < 2; ++b_outer_inner) {\n      for (int32_t j_outer_inner = 0; j_outer_inner < 2; ++j_outer_inner) {\n        for (int32_t cb_outer_inner = 0; cb_outer_inner < 5; ++cb_outer_inner) {\n          ScaleShift[(((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 144) / 24) * 1920) + (b_outer_inner * 960)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 24) / 3) * 120)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused / 144) * 30)) + (j_outer_inner * 15)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 3) * 5)) + cb_outer_inner)] = ((data[(((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 144) / 24) * 1920) + (b_outer_inner * 960)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 24) / 3) * 120)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused / 144) * 30)) + (j_outer_inner * 15)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 3) * 5)) + cb_outer_inner)] * Scale[(((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 24) / 12) * 15) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 3) * 5)) + cb_outer_inner)]) + Shift[(((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 24) / 12) * 15) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 3) * 5)) + cb_outer_inner)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 30) / 15) * 15) + (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 15))]) + Shift[((((((int)blockIdx.x) % 30) / 15) * 15) + (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 15))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 2, 4, 8, 15), \"float32\"), Scale: T.Buffer((2, 15), \"float32\"), Shift: T.Buffer((2, 15), \"float32\"), ScaleShift: T.Buffer((12, 2, 4, 8, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused in T.parallel(576):\n            for b_outer_inner, j_outer_inner, cb_outer_inner in T.grid(2, 2, 5):\n                cse_var_4: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 24\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 3 * 5\n                cse_var_2: T.int32 = cse_var_4 // 12 * 15 + cse_var_3 + cb_outer_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 144 // 24 * 1920 + b_outer_inner * 960 + cse_var_4 // 3 * 120 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused // 144 * 30 + j_outer_inner * 15 + cse_var_3 + cb_outer_inner\n                ScaleShift_1 = T.Buffer((11520,), data=ScaleShift.data)\n                data_1 = T.Buffer((11520,), data=data.data)\n                Scale_1 = T.Buffer((30,), data=Scale.data)\n                Shift_1 = T.Buffer((30,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [12, 15, 4, 8], "input_shape": "[[12, 2, 4, 8, 15], [2, 15], [2, 15]]", "output_shape": "[[12, 2, 4, 8, 15]]"}{"op_name": "tanh", "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 10; ++i1) {\n      for (int32_t i2 = 0; i2 < 2; ++i2) {\n        for (int32_t i3 = 0; i3 < 2; ++i3) {\n          compute[((((i0 * 40) + (i1 * 4)) + (i2 * 2)) + i3)] = tanhf(data[((((i0 * 40) + (i1 * 4)) + (i2 * 2)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 3) + (((int)threadIdx.x) >> 1)) < 220) {\n    compute[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = tanhf(data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 10, 2, 2), \"float32\"), compute: T.Buffer((11, 10, 2, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i2, i3 in T.grid(10, 2, 2):\n                cse_var_1: T.int32 = i0 * 40 + i1 * 4 + i2 * 2 + i3\n                compute_1 = T.Buffer((440,), data=compute.data)\n                data_1 = T.Buffer((440,), data=data.data)\n                compute_1[cse_var_1] = T.tanh(data_1[cse_var_1])", "op_args": [11, 10, 2, 2], "input_shape": "[[11, 10, 2, 2]]", "output_shape": "[[11, 10, 2, 2]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused < 624; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused) {\n    for (int32_t cc_outer_inner = 0; cc_outer_inner < 2; ++cc_outer_inner) {\n      for (int32_t i_outer_inner = 0; i_outer_inner < 4; ++i_outer_inner) {\n        ScaleShift[((((((cc_outer_inner * 2496) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 24) >> 3) * 832)) + (i_outer_inner * 208)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 312) * 104)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused & 7) * 13)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 312) / 24))] = ((data[((((((cc_outer_inner * 2496) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 24) >> 3) * 832)) + (i_outer_inner * 208)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 312) * 104)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused & 7) * 13)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 312) / 24))] * Scale[((cc_outer_inner * 13) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 312) / 24))]) + Shift[((cc_outer_inner * 13) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 312) / 24))]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(52) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] * Scale[(((((int)blockIdx.x) / 48) * 13) + (((int)threadIdx.x) % 13))]) + Shift[(((((int)blockIdx.x) / 48) * 13) + (((int)threadIdx.x) % 13))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 2, 12, 16, 13), \"float32\"), Scale: T.Buffer((2, 13), \"float32\"), Shift: T.Buffer((2, 13), \"float32\"), ScaleShift: T.Buffer((1, 2, 12, 16, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused in T.parallel(624):\n            for cc_outer_inner, i_outer_inner in T.grid(2, 4):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 312 // 24\n                cse_var_2: T.int32 = cc_outer_inner * 13 + cse_var_3\n                cse_var_1: T.int32 = cc_outer_inner * 2496 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 24 // 8 * 832 + i_outer_inner * 208 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused // 312 * 104 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 8 * 13 + cse_var_3\n                ScaleShift_1 = T.Buffer((4992,), data=ScaleShift.data)\n                data_1 = T.Buffer((4992,), data=data.data)\n                Scale_1 = T.Buffer((26,), data=Scale.data)\n                Shift_1 = T.Buffer((26,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [1, 13, 12, 16], "input_shape": "[[1, 2, 12, 16, 13], [2, 13], [2, 13]]", "output_shape": "[[1, 2, 12, 16, 13]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused < 800; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused) {\n    for (int32_t cb_outer_inner = 0; cb_outer_inner < 2; ++cb_outer_inner) {\n      ScaleShift[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 160) * 320) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 15) >> 3) * 160)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 160) >> 4) * 16)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 7) * 2)) + cb_outer_inner)] = ((data[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 160) * 320) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 15) >> 3) * 160)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 160) >> 4) * 16)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 7) * 2)) + cb_outer_inner)] * Scale[(((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 15) >> 3) * 4) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 2)) + cb_outer_inner)]) + Shift[(((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 15) >> 3) * 4) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 2)) + cb_outer_inner)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 10) / 5) * 4) + (((int)threadIdx.x) & 3))]) + Shift[((((((int)blockIdx.x) % 10) / 5) * 4) + (((int)threadIdx.x) & 3))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 2, 2, 20, 4), \"float32\"), Scale: T.Buffer((2, 4), \"float32\"), Shift: T.Buffer((2, 4), \"float32\"), ScaleShift: T.Buffer((5, 2, 2, 20, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused in T.parallel(800):\n            for cb_outer_inner in range(2):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 16 // 8\n                cse_var_2: T.int32 = cse_var_3 * 4 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 2 * 2 + cb_outer_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused // 160 * 320 + cse_var_3 * 160 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 160 // 16 * 16 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 8 * 2 + cb_outer_inner\n                ScaleShift_1 = T.Buffer((1600,), data=ScaleShift.data)\n                data_1 = T.Buffer((1600,), data=data.data)\n                Scale_1 = T.Buffer((8,), data=Scale.data)\n                Shift_1 = T.Buffer((8,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [5, 4, 2, 20], "input_shape": "[[5, 2, 2, 20, 4], [2, 4], [2, 4]]", "output_shape": "[[5, 2, 2, 20, 4]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused < 988; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused) {\n    for (int32_t i_inner = 0; i_inner < 5; ++i_inner) {\n      ScaleShift[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 13) * 380) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 26) / 13) * 190)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 494) * 95)) + (i_inner * 19)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 494) / 26))] = ((data[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 13) * 380) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 26) / 13) * 190)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 494) * 95)) + (i_inner * 19)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 494) / 26))] * Scale[((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 26) / 13)]) + Shift[((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 26) / 13)]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 19) * 2) + (((int)threadIdx.x) / 10)) / 19)]) + Shift[((((((int)blockIdx.x) % 19) * 2) + (((int)threadIdx.x) / 10)) / 19)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 2, 10, 19, 1), \"float32\"), Scale: T.Buffer((2, 1), \"float32\"), Shift: T.Buffer((2, 1), \"float32\"), ScaleShift: T.Buffer((13, 2, 10, 19, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused in T.parallel(988):\n            for i_inner in range(5):\n                cse_var_2: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 26 // 13\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 13 * 380 + cse_var_2 * 190 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused // 494 * 95 + i_inner * 19 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 494 // 26\n                ScaleShift_1 = T.Buffer((4940,), data=ScaleShift.data)\n                data_1 = T.Buffer((4940,), data=data.data)\n                Scale_1 = T.Buffer((2,), data=Scale.data)\n                Shift_1 = T.Buffer((2,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [13, 1, 10, 19], "input_shape": "[[13, 2, 10, 19, 1], [2, 1], [2, 1]]", "output_shape": "[[13, 2, 10, 19, 1]]"}{"op_name": "matmul", "c_code": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  for (int32_t ax1_outer_inner_init = 0; ax1_outer_inner_init < 8; ++ax1_outer_inner_init) {\n    for (int32_t ax0_inner_init = 0; ax0_inner_init < 8; ++ax0_inner_init) {\n      T_matmul[((ax0_inner_init * 8) + ax1_outer_inner_init)] = 0.000000e+00f;\n    }\n  }\n  for (int32_t k_outer = 0; k_outer < 17; ++k_outer) {\n    for (int32_t ax1_outer_inner = 0; ax1_outer_inner < 8; ++ax1_outer_inner) {\n      for (int32_t ax0_inner = 0; ax0_inner < 8; ++ax0_inner) {\n        T_matmul[((ax0_inner * 8) + ax1_outer_inner)] = (T_matmul[((ax0_inner * 8) + ax1_outer_inner)] + (left_matrix[((ax0_inner * 17) + k_outer)] * right_matrix[((k_outer * 8) + ax1_outer_inner)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ T_matmul, float* __restrict__ left_matrix, float* __restrict__ right_matrix) {\n  float T_matmul_local[8];\n  __shared__ float left_matrix_shared[68];\n  __shared__ float right_matrix_shared[136];\n  for (int ax1_c_outer_inner_init = 0; ax1_c_outer_inner_init < 2; ++ax1_c_outer_inner_init) {\n    for (int ax0_c_inner_init = 0; ax0_c_inner_init < 2; ++ax0_c_inner_init) {\n      for (int ax1_c_inner_init = 0; ax1_c_inner_init < 2; ++ax1_c_inner_init) {\n        T_matmul_local[(((ax0_c_inner_init * 4) + (ax1_c_outer_inner_init * 2)) + ax1_c_inner_init)] = 0.000000e+00f;\n      }\n    }\n  }\n  for (int ax0_ax1_fused_outer_outer = 0; ax0_ax1_fused_outer_outer < 17; ++ax0_ax1_fused_outer_outer) {\n    left_matrix_shared[((ax0_ax1_fused_outer_outer * 4) + ((int)threadIdx.x))] = left_matrix[(((((int)blockIdx.x) * 68) + (ax0_ax1_fused_outer_outer * 4)) + ((int)threadIdx.x))];\n  }\n  for (int ax0_ax1_fused_outer_outer_1 = 0; ax0_ax1_fused_outer_outer_1 < 17; ++ax0_ax1_fused_outer_outer_1) {\n    *(float2*)(right_matrix_shared + ((ax0_ax1_fused_outer_outer_1 * 8) + (((int)threadIdx.x) * 2))) = *(float2*)(right_matrix + ((ax0_ax1_fused_outer_outer_1 * 8) + (((int)threadIdx.x) * 2)));\n  }\n  __syncthreads();\n  for (int ax1_c_outer_inner = 0; ax1_c_outer_inner < 2; ++ax1_c_outer_inner) {\n    for (int k_inner = 0; k_inner < 17; ++k_inner) {\n      for (int ax0_c_inner = 0; ax0_c_inner < 2; ++ax0_c_inner) {\n        for (int ax1_c_inner = 0; ax1_c_inner < 2; ++ax1_c_inner) {\n          T_matmul_local[(((ax0_c_inner * 4) + (ax1_c_outer_inner * 2)) + ax1_c_inner)] = (T_matmul_local[(((ax0_c_inner * 4) + (ax1_c_outer_inner * 2)) + ax1_c_inner)] + (left_matrix_shared[((((((int)threadIdx.x) >> 1) * 34) + (ax0_c_inner * 17)) + k_inner)] * right_matrix_shared[((((k_inner * 8) + ((((int)threadIdx.x) & 1) * 4)) + (ax1_c_outer_inner * 2)) + ax1_c_inner)]));\n        }\n      }\n    }\n  }\n  for (int ax0_inner = 0; ax0_inner < 2; ++ax0_inner) {\n    for (int ax1_inner = 0; ax1_inner < 4; ++ax1_inner) {\n      T_matmul[(((((((int)blockIdx.x) * 32) + ((((int)threadIdx.x) >> 1) * 16)) + (ax0_inner * 8)) + ((((int)threadIdx.x) & 1) * 4)) + ax1_inner)] = T_matmul_local[((ax0_inner * 4) + ax1_inner)];\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(left_matrix: T.Buffer((8, 17), \"float32\"), right_matrix: T.Buffer((17, 8), \"float32\"), T_matmul: T.Buffer((8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_matmul_1 = T.Buffer((64,), data=T_matmul.data)\n        for ax1_outer_inner_init, ax0_inner_init in T.grid(8, 8):\n            T_matmul_1[ax0_inner_init * 8 + ax1_outer_inner_init] = T.float32(0)\n        for k_outer, ax1_outer_inner, ax0_inner in T.grid(17, 8, 8):\n            cse_var_1: T.int32 = ax0_inner * 8 + ax1_outer_inner\n            left_matrix_1 = T.Buffer((136,), data=left_matrix.data)\n            right_matrix_1 = T.Buffer((136,), data=right_matrix.data)\n            T_matmul_1[cse_var_1] = T_matmul_1[cse_var_1] + left_matrix_1[ax0_inner * 17 + k_outer] * right_matrix_1[k_outer * 8 + ax1_outer_inner]", "op_args": [10, 13, 8, 17], "input_shape": "[[8, 17], [17, 8]]", "output_shape": "[[8, 8]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused < 340; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused) {\n    for (int32_t cb_outer_outer_inner = 0; cb_outer_outer_inner < 11; ++cb_outer_outer_inner) {\n      for (int32_t cc_outer_inner = 0; cc_outer_inner < 2; ++cc_outer_inner) {\n        for (int32_t i_outer_inner = 0; i_outer_inner < 7; ++i_outer_inner) {\n          ScaleShift[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 20) * 3080) + (cc_outer_inner * 1540)) + (i_outer_inner * 220)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 20) * 11)) + cb_outer_outer_inner)] = ((data[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused / 20) * 3080) + (cc_outer_inner * 1540)) + (i_outer_inner * 220)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 20) * 11)) + cb_outer_outer_inner)] * Scale[((cc_outer_inner * 11) + cb_outer_outer_inner)]) + Shift[((cc_outer_inner * 11) + cb_outer_outer_inner)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) % 55) * 2) + (((int)threadIdx.x) / 28)) / 55) * 11) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 11))]) + Shift[((((((((int)blockIdx.x) % 55) * 2) + (((int)threadIdx.x) / 28)) / 55) * 11) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 11))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 7, 20, 11), \"float32\"), Scale: T.Buffer((2, 11), \"float32\"), Shift: T.Buffer((2, 11), \"float32\"), ScaleShift: T.Buffer((17, 2, 7, 20, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused in T.parallel(340):\n            for cb_outer_outer_inner, cc_outer_inner, i_outer_inner in T.grid(11, 2, 7):\n                cse_var_2: T.int32 = cc_outer_inner * 11 + cb_outer_outer_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused // 20 * 3080 + cc_outer_inner * 1540 + i_outer_inner * 220 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused % 20 * 11 + cb_outer_outer_inner\n                ScaleShift_1 = T.Buffer((52360,), data=ScaleShift.data)\n                data_1 = T.Buffer((52360,), data=data.data)\n                Scale_1 = T.Buffer((22,), data=Scale.data)\n                Shift_1 = T.Buffer((22,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [17, 11, 7, 20], "input_shape": "[[17, 2, 7, 20, 11], [2, 11], [2, 11]]", "output_shape": "[[17, 2, 7, 20, 11]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused < 1440; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused) {\n    for (int32_t cb_outer_inner = 0; cb_outer_inner < 2; ++cb_outer_inner) {\n      for (int32_t b_inner = 0; b_inner < 2; ++b_inner) {\n        for (int32_t j_inner = 0; j_inner < 3; ++j_inner) {\n          ScaleShift[(((((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 90) / 30) * 5760) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 3) * 1920)) + (b_inner * 960)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused / 360) * 240)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 30) / 15) * 120)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 360) / 90) * 30)) + (j_inner * 10)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 15) / 3) * 2)) + cb_outer_inner)] = ((data[(((((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 90) / 30) * 5760) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 3) * 1920)) + (b_inner * 960)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused / 360) * 240)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 30) / 15) * 120)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 360) / 90) * 30)) + (j_inner * 10)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 15) / 3) * 2)) + cb_outer_inner)] * Scale[((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused / 720) * 10) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 15) / 3) * 2)) + cb_outer_inner)]) + Shift[((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused / 720) * 10) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 15) / 3) * 2)) + cb_outer_inner)]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) * 9) + (((int)threadIdx.x) / 6)) % 160) / 80) * 10) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10))]) + Shift[((((((((int)blockIdx.x) * 9) + (((int)threadIdx.x) / 6)) % 160) / 80) * 10) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 10))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 2, 4, 12, 10), \"float32\"), Scale: T.Buffer((2, 10), \"float32\"), Shift: T.Buffer((2, 10), \"float32\"), ScaleShift: T.Buffer((18, 2, 4, 12, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused in T.parallel(1440):\n            for cb_outer_inner, b_inner, j_inner in T.grid(2, 2, 3):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 15 // 3 * 2\n                cse_var_2: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused // 720 * 10 + cse_var_3 + cb_outer_inner\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 90 // 30 * 5760 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 3 * 1920 + b_inner * 960 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused // 360 * 240 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 30 // 15 * 120 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 360 // 90 * 30 + j_inner * 10 + cse_var_3 + cb_outer_inner\n                ScaleShift_1 = T.Buffer((17280,), data=ScaleShift.data)\n                data_1 = T.Buffer((17280,), data=data.data)\n                Scale_1 = T.Buffer((20,), data=Scale.data)\n                Shift_1 = T.Buffer((20,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [18, 10, 4, 12], "input_shape": "[[18, 2, 4, 12, 10], [2, 10], [2, 10]]", "output_shape": "[[18, 2, 4, 12, 10]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused < 5184; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused) {\n    for (int32_t j_inner = 0; j_inner < 9; ++j_inner) {\n      ScaleShift[(((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 12) * 3888) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 1296) / 216) * 648)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 108) / 36) * 216)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused / 2592) * 108)) + (j_inner * 12)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 2592) / 1296) * 6)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 216) / 108) * 3)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 36) / 12))] = ((data[(((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 12) * 3888) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 1296) / 216) * 648)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 108) / 36) * 216)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused / 2592) * 108)) + (j_inner * 12)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 2592) / 1296) * 6)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 216) / 108) * 3)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 36) / 12))] * Scale[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 1296) / 648) * 12) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 2592) / 1296) * 6)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 216) / 108) * 3)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 36) / 12))]) + Shift[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 1296) / 648) * 12) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 2592) / 1296) * 6)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 216) / 108) * 3)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 36) / 12))]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) % 486) / 243) * 12) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 12))]) + Shift[((((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) % 486) / 243) * 12) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 12))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 2, 9, 18, 12), \"float32\"), Scale: T.Buffer((2, 12), \"float32\"), Shift: T.Buffer((2, 12), \"float32\"), ScaleShift: T.Buffer((12, 2, 9, 18, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused in T.parallel(5184):\n            for j_inner in range(9):\n                cse_var_6: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 1296\n                cse_var_5: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 36 // 12\n                cse_var_4: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 2592 // 1296 * 6\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 216 // 108 * 3\n                cse_var_2: T.int32 = cse_var_6 // 648 * 12 + cse_var_4 + cse_var_3 + cse_var_5\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 12 * 3888 + cse_var_6 // 216 * 648 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused % 108 // 36 * 216 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused_i_outer_inner_fused_j_outer_inner_fused_cb_outer_inner_fused_b_inner_fused // 2592 * 108 + j_inner * 12 + cse_var_4 + cse_var_3 + cse_var_5\n                ScaleShift_1 = T.Buffer((46656,), data=ScaleShift.data)\n                data_1 = T.Buffer((46656,), data=data.data)\n                Scale_1 = T.Buffer((24,), data=Scale.data)\n                Shift_1 = T.Buffer((24,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [12, 12, 9, 18], "input_shape": "[[12, 2, 9, 18, 12], [2, 12], [2, 12]]", "output_shape": "[[12, 2, 9, 18, 12]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused < 80; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused) {\n    for (int32_t cc_outer_inner = 0; cc_outer_inner < 2; ++cc_outer_inner) {\n      for (int32_t b_inner = 0; b_inner < 7; ++b_inner) {\n        for (int32_t i_inner = 0; i_inner < 19; ++i_inner) {\n          for (int32_t j_inner = 0; j_inner < 3; ++j_inner) {\n            ScaleShift[(((((((b_inner * 9120) + (cc_outer_inner * 4560)) + (i_inner * 240)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 40) * 120)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused & 1) * 60)) + (j_inner * 20)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 40) >> 1))] = ((data[(((((((b_inner * 9120) + (cc_outer_inner * 4560)) + (i_inner * 240)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused / 40) * 120)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused & 1) * 60)) + (j_inner * 20)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 40) >> 1))] * Scale[((cc_outer_inner * 20) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 40) >> 1))]) + Shift[((cc_outer_inner * 20) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 40) >> 1))]);\n          }\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 152) / 76) * 20) + (((int)threadIdx.x) % 20))]) + Shift[((((((int)blockIdx.x) % 152) / 76) * 20) + (((int)threadIdx.x) % 20))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 19, 12, 20), \"float32\"), Scale: T.Buffer((2, 20), \"float32\"), Shift: T.Buffer((2, 20), \"float32\"), ScaleShift: T.Buffer((7, 2, 19, 12, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused in T.parallel(80):\n            for cc_outer_inner, b_inner, i_inner, j_inner in T.grid(2, 7, 19, 3):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 40 // 2\n                cse_var_2: T.int32 = cc_outer_inner * 20 + cse_var_3\n                cse_var_1: T.int32 = b_inner * 9120 + cc_outer_inner * 4560 + i_inner * 240 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused // 40 * 120 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused % 2 * 60 + j_inner * 20 + cse_var_3\n                ScaleShift_1 = T.Buffer((63840,), data=ScaleShift.data)\n                data_1 = T.Buffer((63840,), data=data.data)\n                Scale_1 = T.Buffer((40,), data=Scale.data)\n                Shift_1 = T.Buffer((40,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [7, 20, 19, 12], "input_shape": "[[7, 2, 19, 12, 20], [2, 20], [2, 20]]", "output_shape": "[[7, 2, 19, 12, 20]]"}{"op_name": "matmul", "c_code": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  T_matmul[0] = 0.000000e+00f;\n  for (int32_t k = 0; k < 8; ++k) {\n    T_matmul[0] = (T_matmul[0] + (left_matrix[k] * right_matrix[k]));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ T_matmul, float* __restrict__ left_matrix, float* __restrict__ right_matrix) {\n  T_matmul[0] = 0.000000e+00f;\n  for (int k = 0; k < 8; ++k) {\n    T_matmul[0] = (T_matmul[0] + (left_matrix[k] * right_matrix[k]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(left_matrix: T.Buffer((1, 8), \"float32\"), right_matrix: T.Buffer((8, 1), \"float32\"), T_matmul: T.Buffer((1, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_matmul_1 = T.Buffer((1,), data=T_matmul.data)\n        T_matmul_1[0] = T.float32(0)\n        for k in range(8):\n            left_matrix_1 = T.Buffer((8,), data=left_matrix.data)\n            right_matrix_1 = T.Buffer((8,), data=right_matrix.data)\n            T_matmul_1[0] = T_matmul_1[0] + left_matrix_1[k] * right_matrix_1[k]", "op_args": [14, 20, 1, 8], "input_shape": "[[1, 8], [8, 1]]", "output_shape": "[[1, 1]]"}{"op_name": "matmul", "c_code": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  for (int32_t ax1_outer_inner_init = 0; ax1_outer_inner_init < 8; ++ax1_outer_inner_init) {\n    for (int32_t ax0_inner_init = 0; ax0_inner_init < 8; ++ax0_inner_init) {\n      T_matmul[((ax0_inner_init * 8) + ax1_outer_inner_init)] = 0.000000e+00f;\n    }\n  }\n  for (int32_t ax1_outer_inner = 0; ax1_outer_inner < 8; ++ax1_outer_inner) {\n    for (int32_t k_inner = 0; k_inner < 9; ++k_inner) {\n      for (int32_t ax0_inner = 0; ax0_inner < 8; ++ax0_inner) {\n        T_matmul[((ax0_inner * 8) + ax1_outer_inner)] = (T_matmul[((ax0_inner * 8) + ax1_outer_inner)] + (left_matrix[((ax0_inner * 9) + k_inner)] * right_matrix[((k_inner * 8) + ax1_outer_inner)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ T_matmul, float* __restrict__ left_matrix, float* __restrict__ right_matrix) {\n  float T_matmul_local[16];\n  __shared__ float left_matrix_shared[72];\n  __shared__ float right_matrix_shared[36];\n  for (int ax0_c_outer_inner_init = 0; ax0_c_outer_inner_init < 2; ++ax0_c_outer_inner_init) {\n    for (int ax1_c_outer_inner_init = 0; ax1_c_outer_inner_init < 2; ++ax1_c_outer_inner_init) {\n      for (int ax1_c_inner_init = 0; ax1_c_inner_init < 2; ++ax1_c_inner_init) {\n        T_matmul_local[(((ax0_c_outer_inner_init * 4) + (ax1_c_outer_inner_init * 2)) + ax1_c_inner_init)] = 0.000000e+00f;\n        T_matmul_local[((((ax0_c_outer_inner_init * 4) + (ax1_c_outer_inner_init * 2)) + ax1_c_inner_init) + 8)] = 0.000000e+00f;\n      }\n    }\n  }\n  for (int ax0_ax1_fused_outer_outer = 0; ax0_ax1_fused_outer_outer < 12; ++ax0_ax1_fused_outer_outer) {\n    *(float3*)(left_matrix_shared + ((ax0_ax1_fused_outer_outer * 6) + (((int)threadIdx.x) * 3))) = *(float3*)(left_matrix + ((ax0_ax1_fused_outer_outer * 6) + (((int)threadIdx.x) * 3)));\n  }\n  for (int ax0_ax1_fused_outer_outer_1 = 0; ax0_ax1_fused_outer_outer_1 < 18; ++ax0_ax1_fused_outer_outer_1) {\n    right_matrix_shared[((ax0_ax1_fused_outer_outer_1 * 2) + ((int)threadIdx.x))] = right_matrix[(((((ax0_ax1_fused_outer_outer_1 >> 1) * 8) + (((int)blockIdx.x) * 4)) + ((ax0_ax1_fused_outer_outer_1 & 1) * 2)) + ((int)threadIdx.x))];\n  }\n  __syncthreads();\n  for (int k_outer_inner = 0; k_outer_inner < 9; ++k_outer_inner) {\n    for (int ax0_c_outer_inner = 0; ax0_c_outer_inner < 2; ++ax0_c_outer_inner) {\n      for (int ax1_c_outer_inner = 0; ax1_c_outer_inner < 2; ++ax1_c_outer_inner) {\n        for (int ax1_c_inner = 0; ax1_c_inner < 2; ++ax1_c_inner) {\n          T_matmul_local[(((ax0_c_outer_inner * 4) + (ax1_c_outer_inner * 2)) + ax1_c_inner)] = (T_matmul_local[(((ax0_c_outer_inner * 4) + (ax1_c_outer_inner * 2)) + ax1_c_inner)] + (left_matrix_shared[(((((int)threadIdx.x) * 18) + (ax0_c_outer_inner * 9)) + k_outer_inner)] * right_matrix_shared[(((k_outer_inner * 4) + (ax1_c_outer_inner * 2)) + ax1_c_inner)]));\n          T_matmul_local[((((ax0_c_outer_inner * 4) + (ax1_c_outer_inner * 2)) + ax1_c_inner) + 8)] = (T_matmul_local[((((ax0_c_outer_inner * 4) + (ax1_c_outer_inner * 2)) + ax1_c_inner) + 8)] + (left_matrix_shared[((((((int)threadIdx.x) * 18) + (ax0_c_outer_inner * 9)) + k_outer_inner) + 36)] * right_matrix_shared[(((k_outer_inner * 4) + (ax1_c_outer_inner * 2)) + ax1_c_inner)]));\n        }\n      }\n    }\n  }\n  for (int ax0_inner = 0; ax0_inner < 2; ++ax0_inner) {\n    for (int ax1_inner = 0; ax1_inner < 4; ++ax1_inner) {\n      T_matmul[((((((int)threadIdx.x) * 16) + (ax0_inner * 8)) + (((int)blockIdx.x) * 4)) + ax1_inner)] = T_matmul_local[((ax0_inner * 4) + ax1_inner)];\n      T_matmul[(((((((int)threadIdx.x) * 16) + (ax0_inner * 8)) + (((int)blockIdx.x) * 4)) + ax1_inner) + 32)] = T_matmul_local[(((ax0_inner * 4) + ax1_inner) + 8)];\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(left_matrix: T.Buffer((8, 9), \"float32\"), right_matrix: T.Buffer((9, 8), \"float32\"), T_matmul: T.Buffer((8, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_matmul_1 = T.Buffer((64,), data=T_matmul.data)\n        for ax1_outer_inner_init, ax0_inner_init in T.grid(8, 8):\n            T_matmul_1[ax0_inner_init * 8 + ax1_outer_inner_init] = T.float32(0)\n        for ax1_outer_inner, k_inner, ax0_inner in T.grid(8, 9, 8):\n            cse_var_1: T.int32 = ax0_inner * 8 + ax1_outer_inner\n            left_matrix_1 = T.Buffer((72,), data=left_matrix.data)\n            right_matrix_1 = T.Buffer((72,), data=right_matrix.data)\n            T_matmul_1[cse_var_1] = T_matmul_1[cse_var_1] + left_matrix_1[ax0_inner * 9 + k_inner] * right_matrix_1[k_inner * 8 + ax1_outer_inner]", "op_args": [5, 6, 8, 9], "input_shape": "[[8, 9], [9, 8]]", "output_shape": "[[8, 8]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused < 10260; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused) {\n    for (int32_t cc_inner = 0; cc_inner < 2; ++cc_inner) {\n      for (int32_t i_inner = 0; i_inner < 3; ++i_inner) {\n        for (int32_t j_inner = 0; j_inner < 3; ++j_inner) {\n          ScaleShift[((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 15) * 12312) + (cc_inner * 6156)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 1710) / 285) * 1026)) + (i_inner * 342)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused / 1710) * 57)) + (j_inner * 19)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 285) / 15))] = ((data[((((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 15) * 12312) + (cc_inner * 6156)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 1710) / 285) * 1026)) + (i_inner * 342)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused / 1710) * 57)) + (j_inner * 19)) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 285) / 15))] * Scale[((cc_inner * 19) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 285) / 15))]) + Shift[((cc_inner * 19) + ((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 285) / 15))]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) % 228) / 114) * 19) + (((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) % 19))]) + Shift[((((((int)blockIdx.x) % 228) / 114) * 19) + (((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) % 19))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 2, 18, 18, 19), \"float32\"), Scale: T.Buffer((2, 19), \"float32\"), Shift: T.Buffer((2, 19), \"float32\"), ScaleShift: T.Buffer((15, 2, 18, 18, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused in T.parallel(10260):\n            for cc_inner, i_inner, j_inner in T.grid(2, 3, 3):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 285 // 15\n                cse_var_2: T.int32 = cc_inner * 19 + cse_var_3\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 15 * 12312 + cc_inner * 6156 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused % 1710 // 285 * 1026 + i_inner * 342 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused // 1710 * 57 + j_inner * 19 + cse_var_3\n                ScaleShift_1 = T.Buffer((184680,), data=ScaleShift.data)\n                data_1 = T.Buffer((184680,), data=data.data)\n                Scale_1 = T.Buffer((38,), data=Scale.data)\n                Shift_1 = T.Buffer((38,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [15, 19, 18, 18], "input_shape": "[[15, 2, 18, 18, 19], [2, 19], [2, 19]]", "output_shape": "[[15, 2, 18, 18, 19]]"}{"op_name": "matmul", "c_code": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  for (int32_t ax1_outer_outer_outer = 0; ax1_outer_outer_outer < 2; ++ax1_outer_outer_outer) {\n    for (int32_t ax0_inner_init = 0; ax0_inner_init < 2; ++ax0_inner_init) {\n      T_matmul[((ax0_inner_init * 2) + ax1_outer_outer_outer)] = 0.000000e+00f;\n    }\n    for (int32_t k_inner = 0; k_inner < 2; ++k_inner) {\n      for (int32_t ax0_inner = 0; ax0_inner < 2; ++ax0_inner) {\n        T_matmul[((ax0_inner * 2) + ax1_outer_outer_outer)] = (T_matmul[((ax0_inner * 2) + ax1_outer_outer_outer)] + (left_matrix[((ax0_inner * 2) + k_inner)] * right_matrix[((k_inner * 2) + ax1_outer_outer_outer)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ T_matmul, float* __restrict__ left_matrix, float* __restrict__ right_matrix) {\n  float T_matmul_local[2];\n  __shared__ float left_matrix_shared[4];\n  __shared__ float right_matrix_shared[4];\n  T_matmul_local[0] = 0.000000e+00f;\n  T_matmul_local[1] = 0.000000e+00f;\n  for (int ax0_ax1_fused_outer_outer = 0; ax0_ax1_fused_outer_outer < 2; ++ax0_ax1_fused_outer_outer) {\n    left_matrix_shared[((ax0_ax1_fused_outer_outer * 2) + ((int)threadIdx.x))] = left_matrix[((ax0_ax1_fused_outer_outer * 2) + ((int)threadIdx.x))];\n  }\n  for (int ax0_ax1_fused_outer_outer_1 = 0; ax0_ax1_fused_outer_outer_1 < 2; ++ax0_ax1_fused_outer_outer_1) {\n    right_matrix_shared[((ax0_ax1_fused_outer_outer_1 * 2) + ((int)threadIdx.x))] = right_matrix[((ax0_ax1_fused_outer_outer_1 * 2) + ((int)threadIdx.x))];\n  }\n  __syncthreads();\n  for (int k_inner = 0; k_inner < 2; ++k_inner) {\n    T_matmul_local[0] = (T_matmul_local[0] + (left_matrix_shared[((((int)threadIdx.x) * 2) + k_inner)] * right_matrix_shared[(k_inner * 2)]));\n    T_matmul_local[1] = (T_matmul_local[1] + (left_matrix_shared[((((int)threadIdx.x) * 2) + k_inner)] * right_matrix_shared[((k_inner * 2) + 1)]));\n  }\n  T_matmul[(((int)threadIdx.x) * 2)] = T_matmul_local[0];\n  T_matmul[((((int)threadIdx.x) * 2) + 1)] = T_matmul_local[1];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(left_matrix: T.Buffer((2, 2), \"float32\"), right_matrix: T.Buffer((2, 2), \"float32\"), T_matmul: T.Buffer((2, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax1_outer_outer_outer in range(2):\n            T_matmul_1 = T.Buffer((4,), data=T_matmul.data)\n            for ax0_inner_init in range(2):\n                T_matmul_1[ax0_inner_init * 2 + ax1_outer_outer_outer] = T.float32(0)\n            for k_inner, ax0_inner in T.grid(2, 2):\n                cse_var_2: T.int32 = ax0_inner * 2\n                cse_var_1: T.int32 = cse_var_2 + ax1_outer_outer_outer\n                left_matrix_1 = T.Buffer((4,), data=left_matrix.data)\n                right_matrix_1 = T.Buffer((4,), data=right_matrix.data)\n                T_matmul_1[cse_var_1] = T_matmul_1[cse_var_1] + left_matrix_1[cse_var_2 + k_inner] * right_matrix_1[k_inner * 2 + ax1_outer_outer_outer]", "op_args": [7, 2, 2, 2], "input_shape": "[[2, 2], [2, 2]]", "output_shape": "[[2, 2]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused < 3060; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused) {\n    for (int32_t i_outer_inner = 0; i_outer_inner < 2; ++i_outer_inner) {\n      for (int32_t j_inner = 0; j_inner < 2; ++j_inner) {\n        ScaleShift[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 34) * 360) + (i_outer_inner * 180)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 204) / 34) * 30)) + (j_inner * 15)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 204))] = ((data[((((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 34) * 360) + (i_outer_inner * 180)) + (((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 204) / 34) * 30)) + (j_inner * 15)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 204))] * Scale[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 15) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 204))]) + Shift[(((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused & 1) * 15) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused / 204))]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] * Scale[((((((int)blockIdx.x) & 15) >> 3) * 15) + (((int)threadIdx.x) % 15))]) + Shift[((((((int)blockIdx.x) & 15) >> 3) * 15) + (((int)threadIdx.x) % 15))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 2, 12, 15), \"float32\"), Scale: T.Buffer((2, 15), \"float32\"), Shift: T.Buffer((2, 15), \"float32\"), ScaleShift: T.Buffer((17, 2, 2, 12, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused in T.parallel(3060):\n            for i_outer_inner, j_inner in T.grid(2, 2):\n                cse_var_3: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused // 204\n                cse_var_2: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 2 * 15 + cse_var_3\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 34 * 360 + i_outer_inner * 180 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused_b_outer_inner_fused_cc_outer_inner_fused % 204 // 34 * 30 + j_inner * 15 + cse_var_3\n                ScaleShift_1 = T.Buffer((12240,), data=ScaleShift.data)\n                data_1 = T.Buffer((12240,), data=data.data)\n                Scale_1 = T.Buffer((30,), data=Scale.data)\n                Shift_1 = T.Buffer((30,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [17, 15, 2, 12], "input_shape": "[[17, 2, 2, 12, 15], [2, 15], [2, 15]]", "output_shape": "[[17, 2, 2, 12, 15]]"}{"op_name": "matmul", "c_code": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  for (int32_t ax1_outer_inner_init = 0; ax1_outer_inner_init < 11; ++ax1_outer_inner_init) {\n    for (int32_t ax0_inner_init = 0; ax0_inner_init < 11; ++ax0_inner_init) {\n      T_matmul[((ax0_inner_init * 11) + ax1_outer_inner_init)] = 0.000000e+00f;\n    }\n  }\n  for (int32_t ax1_outer_inner = 0; ax1_outer_inner < 11; ++ax1_outer_inner) {\n    for (int32_t k_inner = 0; k_inner < 2; ++k_inner) {\n      for (int32_t ax0_inner = 0; ax0_inner < 11; ++ax0_inner) {\n        T_matmul[((ax0_inner * 11) + ax1_outer_inner)] = (T_matmul[((ax0_inner * 11) + ax1_outer_inner)] + (left_matrix[((ax0_inner * 2) + k_inner)] * right_matrix[((k_inner * 11) + ax1_outer_inner)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ T_matmul, float* __restrict__ left_matrix, float* __restrict__ right_matrix) {\n  float T_matmul_local[11];\n  __shared__ float left_matrix_shared[22];\n  __shared__ float right_matrix_shared[2];\n  T_matmul_local[0] = 0.000000e+00f;\n  T_matmul_local[1] = 0.000000e+00f;\n  T_matmul_local[2] = 0.000000e+00f;\n  T_matmul_local[3] = 0.000000e+00f;\n  T_matmul_local[4] = 0.000000e+00f;\n  T_matmul_local[5] = 0.000000e+00f;\n  T_matmul_local[6] = 0.000000e+00f;\n  T_matmul_local[7] = 0.000000e+00f;\n  T_matmul_local[8] = 0.000000e+00f;\n  T_matmul_local[9] = 0.000000e+00f;\n  T_matmul_local[10] = 0.000000e+00f;\n  for (int ax0_ax1_fused_outer_outer = 0; ax0_ax1_fused_outer_outer < 22; ++ax0_ax1_fused_outer_outer) {\n    left_matrix_shared[ax0_ax1_fused_outer_outer] = left_matrix[ax0_ax1_fused_outer_outer];\n  }\n  for (int ax0_ax1_fused_outer_outer_1 = 0; ax0_ax1_fused_outer_outer_1 < 2; ++ax0_ax1_fused_outer_outer_1) {\n    right_matrix_shared[ax0_ax1_fused_outer_outer_1] = right_matrix[((ax0_ax1_fused_outer_outer_1 * 11) + ((int)blockIdx.x))];\n  }\n  __syncthreads();\n  for (int k_outer_inner = 0; k_outer_inner < 2; ++k_outer_inner) {\n    T_matmul_local[0] = (T_matmul_local[0] + (left_matrix_shared[k_outer_inner] * right_matrix_shared[k_outer_inner]));\n    T_matmul_local[1] = (T_matmul_local[1] + (left_matrix_shared[(k_outer_inner + 2)] * right_matrix_shared[k_outer_inner]));\n    T_matmul_local[2] = (T_matmul_local[2] + (left_matrix_shared[(k_outer_inner + 4)] * right_matrix_shared[k_outer_inner]));\n    T_matmul_local[3] = (T_matmul_local[3] + (left_matrix_shared[(k_outer_inner + 6)] * right_matrix_shared[k_outer_inner]));\n    T_matmul_local[4] = (T_matmul_local[4] + (left_matrix_shared[(k_outer_inner + 8)] * right_matrix_shared[k_outer_inner]));\n    T_matmul_local[5] = (T_matmul_local[5] + (left_matrix_shared[(k_outer_inner + 10)] * right_matrix_shared[k_outer_inner]));\n    T_matmul_local[6] = (T_matmul_local[6] + (left_matrix_shared[(k_outer_inner + 12)] * right_matrix_shared[k_outer_inner]));\n    T_matmul_local[7] = (T_matmul_local[7] + (left_matrix_shared[(k_outer_inner + 14)] * right_matrix_shared[k_outer_inner]));\n    T_matmul_local[8] = (T_matmul_local[8] + (left_matrix_shared[(k_outer_inner + 16)] * right_matrix_shared[k_outer_inner]));\n    T_matmul_local[9] = (T_matmul_local[9] + (left_matrix_shared[(k_outer_inner + 18)] * right_matrix_shared[k_outer_inner]));\n    T_matmul_local[10] = (T_matmul_local[10] + (left_matrix_shared[(k_outer_inner + 20)] * right_matrix_shared[k_outer_inner]));\n  }\n  T_matmul[((int)blockIdx.x)] = T_matmul_local[0];\n  T_matmul[(((int)blockIdx.x) + 11)] = T_matmul_local[1];\n  T_matmul[(((int)blockIdx.x) + 22)] = T_matmul_local[2];\n  T_matmul[(((int)blockIdx.x) + 33)] = T_matmul_local[3];\n  T_matmul[(((int)blockIdx.x) + 44)] = T_matmul_local[4];\n  T_matmul[(((int)blockIdx.x) + 55)] = T_matmul_local[5];\n  T_matmul[(((int)blockIdx.x) + 66)] = T_matmul_local[6];\n  T_matmul[(((int)blockIdx.x) + 77)] = T_matmul_local[7];\n  T_matmul[(((int)blockIdx.x) + 88)] = T_matmul_local[8];\n  T_matmul[(((int)blockIdx.x) + 99)] = T_matmul_local[9];\n  T_matmul[(((int)blockIdx.x) + 110)] = T_matmul_local[10];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(left_matrix: T.Buffer((11, 2), \"float32\"), right_matrix: T.Buffer((2, 11), \"float32\"), T_matmul: T.Buffer((11, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_matmul_1 = T.Buffer((121,), data=T_matmul.data)\n        for ax1_outer_inner_init, ax0_inner_init in T.grid(11, 11):\n            T_matmul_1[ax0_inner_init * 11 + ax1_outer_inner_init] = T.float32(0)\n        for ax1_outer_inner, k_inner, ax0_inner in T.grid(11, 2, 11):\n            cse_var_1: T.int32 = ax0_inner * 11 + ax1_outer_inner\n            left_matrix_1 = T.Buffer((22,), data=left_matrix.data)\n            right_matrix_1 = T.Buffer((22,), data=right_matrix.data)\n            T_matmul_1[cse_var_1] = T_matmul_1[cse_var_1] + left_matrix_1[ax0_inner * 2 + k_inner] * right_matrix_1[k_inner * 11 + ax1_outer_inner]", "op_args": [5, 15, 11, 2], "input_shape": "[[11, 2], [2, 11]]", "output_shape": "[[11, 11]]"}{"op_name": "scale_shift_nchwc", "c_code": "void default_function_kernel(float* Scale, float* ScaleShift, float* Shift, float* data) {\n  #pragma omp parallel for\n  for (int32_t b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused = 0; b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused < 3168; ++b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused) {\n    for (int32_t b_outer_inner = 0; b_outer_inner < 3; ++b_outer_inner) {\n      for (int32_t cc_outer_inner = 0; cc_outer_inner < 2; ++cc_outer_inner) {\n        ScaleShift[(((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused / 1584) * 9504) + (b_outer_inner * 3168)) + (cc_outer_inner * 1584)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 1584))] = ((data[(((((b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused / 1584) * 9504) + (b_outer_inner * 3168)) + (cc_outer_inner * 1584)) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 1584))] * Scale[((cc_outer_inner * 11) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 11))]) + Shift[((cc_outer_inner * 11) + (b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 11))]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ Scale, float* __restrict__ ScaleShift, float* __restrict__ Shift, float* __restrict__ data) {\n  ScaleShift[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * Scale[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) % 198) / 99) * 11) + (((((int)blockIdx.x) * 9) + ((int)threadIdx.x)) % 11))]) + Shift[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) % 198) / 99) * 11) + (((((int)blockIdx.x) * 9) + ((int)threadIdx.x)) % 11))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 2, 12, 12, 11), \"float32\"), Scale: T.Buffer((2, 11), \"float32\"), Shift: T.Buffer((2, 11), \"float32\"), ScaleShift: T.Buffer((6, 2, 12, 12, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused in T.parallel(3168):\n            for b_outer_inner, cc_outer_inner in T.grid(3, 2):\n                cse_var_2: T.int32 = cc_outer_inner * 11 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 11\n                cse_var_1: T.int32 = b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused // 1584 * 9504 + b_outer_inner * 3168 + cc_outer_inner * 1584 + b_outer_outer_outer_cc_outer_outer_outer_fused_i_outer_outer_outer_fused_j_outer_outer_outer_fused_cb_outer_outer_outer_fused_b_outer_outer_inner_fused_cc_outer_outer_inner_fused_i_outer_outer_inner_fused_j_outer_outer_inner_fused_cb_outer_outer_inner_fused % 1584\n                ScaleShift_1 = T.Buffer((19008,), data=ScaleShift.data)\n                data_1 = T.Buffer((19008,), data=data.data)\n                Scale_1 = T.Buffer((22,), data=Scale.data)\n                Shift_1 = T.Buffer((22,), data=Shift.data)\n                ScaleShift_1[cse_var_1] = data_1[cse_var_1] * Scale_1[cse_var_2] + Shift_1[cse_var_2]", "op_args": [6, 11, 12, 12], "input_shape": "[[6, 2, 12, 12, 11], [2, 11], [2, 11]]", "output_shape": "[[6, 2, 12, 12, 11]]"}{"op_name": "matmul", "c_code": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  for (int32_t ax1_outer_inner_init = 0; ax1_outer_inner_init < 14; ++ax1_outer_inner_init) {\n    for (int32_t ax0_inner_init = 0; ax0_inner_init < 14; ++ax0_inner_init) {\n      T_matmul[((ax0_inner_init * 14) + ax1_outer_inner_init)] = 0.000000e+00f;\n    }\n  }\n  for (int32_t k_outer = 0; k_outer < 2; ++k_outer) {\n    for (int32_t ax1_outer_inner = 0; ax1_outer_inner < 14; ++ax1_outer_inner) {\n      for (int32_t k_inner = 0; k_inner < 8; ++k_inner) {\n        for (int32_t ax0_inner = 0; ax0_inner < 14; ++ax0_inner) {\n          T_matmul[((ax0_inner * 14) + ax1_outer_inner)] = (T_matmul[((ax0_inner * 14) + ax1_outer_inner)] + (left_matrix[(((ax0_inner * 16) + (k_outer * 8)) + k_inner)] * right_matrix[(((k_outer * 112) + (k_inner * 14)) + ax1_outer_inner)]));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ T_matmul, float* __restrict__ left_matrix, float* __restrict__ right_matrix) {\n  float T_matmul_local[4];\n  __shared__ float left_matrix_shared[16];\n  __shared__ float right_matrix_shared[112];\n  for (int ax1_c_outer_inner_init = 0; ax1_c_outer_inner_init < 2; ++ax1_c_outer_inner_init) {\n    for (int ax0_c_inner_init = 0; ax0_c_inner_init < 2; ++ax0_c_inner_init) {\n      T_matmul_local[((ax0_c_inner_init * 2) + ax1_c_outer_inner_init)] = 0.000000e+00f;\n    }\n  }\n  for (int k_outer_outer = 0; k_outer_outer < 2; ++k_outer_outer) {\n    __syncthreads();\n    for (int ax0_ax1_fused_outer_outer = 0; ax0_ax1_fused_outer_outer < 3; ++ax0_ax1_fused_outer_outer) {\n      if (((ax0_ax1_fused_outer_outer * 7) + ((int)threadIdx.x)) < 16) {\n        left_matrix_shared[((ax0_ax1_fused_outer_outer * 7) + ((int)threadIdx.x))] = left_matrix[((((((int)blockIdx.x) * 32) + ((((ax0_ax1_fused_outer_outer * 7) + ((int)threadIdx.x)) >> 3) * 16)) + (k_outer_outer * 8)) + (((ax0_ax1_fused_outer_outer * 7) + ((int)threadIdx.x)) & 7))];\n      }\n    }\n    for (int ax0_ax1_fused_outer_outer_1 = 0; ax0_ax1_fused_outer_outer_1 < 16; ++ax0_ax1_fused_outer_outer_1) {\n      right_matrix_shared[((ax0_ax1_fused_outer_outer_1 * 7) + ((int)threadIdx.x))] = right_matrix[(((k_outer_outer * 112) + (ax0_ax1_fused_outer_outer_1 * 7)) + ((int)threadIdx.x))];\n    }\n    __syncthreads();\n    for (int k_outer_inner = 0; k_outer_inner < 8; ++k_outer_inner) {\n      for (int ax1_c_outer_inner = 0; ax1_c_outer_inner < 2; ++ax1_c_outer_inner) {\n        for (int ax0_c_inner = 0; ax0_c_inner < 2; ++ax0_c_inner) {\n          T_matmul_local[((ax0_c_inner * 2) + ax1_c_outer_inner)] = (T_matmul_local[((ax0_c_inner * 2) + ax1_c_outer_inner)] + (left_matrix_shared[((ax0_c_inner * 8) + k_outer_inner)] * right_matrix_shared[(((k_outer_inner * 14) + (((int)threadIdx.x) * 2)) + ax1_c_outer_inner)]));\n        }\n      }\n    }\n  }\n  for (int ax0_inner = 0; ax0_inner < 2; ++ax0_inner) {\n    for (int ax1_inner = 0; ax1_inner < 2; ++ax1_inner) {\n      T_matmul[((((((int)blockIdx.x) * 28) + (ax0_inner * 14)) + (((int)threadIdx.x) * 2)) + ax1_inner)] = T_matmul_local[((ax0_inner * 2) + ax1_inner)];\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(left_matrix: T.Buffer((14, 16), \"float32\"), right_matrix: T.Buffer((16, 14), \"float32\"), T_matmul: T.Buffer((14, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_matmul_1 = T.Buffer((196,), data=T_matmul.data)\n        for ax1_outer_inner_init, ax0_inner_init in T.grid(14, 14):\n            T_matmul_1[ax0_inner_init * 14 + ax1_outer_inner_init] = T.float32(0)\n        for k_outer, ax1_outer_inner, k_inner, ax0_inner in T.grid(2, 14, 8, 14):\n            cse_var_1: T.int32 = ax0_inner * 14 + ax1_outer_inner\n            left_matrix_1 = T.Buffer((224,), data=left_matrix.data)\n            right_matrix_1 = T.Buffer((224,), data=right_matrix.data)\n            T_matmul_1[cse_var_1] = T_matmul_1[cse_var_1] + left_matrix_1[ax0_inner * 16 + k_outer * 8 + k_inner] * right_matrix_1[k_outer * 112 + k_inner * 14 + ax1_outer_inner]", "op_args": [17, 19, 14, 16], "input_shape": "[[14, 16], [16, 14]]", "output_shape": "[[14, 14]]"}{"op_name": "matmul", "c_code": "void default_function_kernel(float* T_matmul, float* left_matrix, float* right_matrix) {\n  for (int32_t ax0_outer_inner_init = 0; ax0_outer_inner_init < 2; ++ax0_outer_inner_init) {\n    for (int32_t ax1_outer_inner_init = 0; ax1_outer_inner_init < 4; ++ax1_outer_inner_init) {\n      for (int32_t ax0_inner_init = 0; ax0_inner_init < 2; ++ax0_inner_init) {\n        T_matmul[(((ax0_outer_inner_init * 8) + (ax0_inner_init * 4)) + ax1_outer_inner_init)] = 0.000000e+00f;\n      }\n    }\n  }\n  for (int32_t k_outer = 0; k_outer < 9; ++k_outer) {\n    for (int32_t ax0_outer_inner = 0; ax0_outer_inner < 2; ++ax0_outer_inner) {\n      for (int32_t ax1_outer_inner = 0; ax1_outer_inner < 4; ++ax1_outer_inner) {\n        for (int32_t ax0_inner = 0; ax0_inner < 2; ++ax0_inner) {\n          T_matmul[(((ax0_outer_inner * 8) + (ax0_inner * 4)) + ax1_outer_inner)] = (T_matmul[(((ax0_outer_inner * 8) + (ax0_inner * 4)) + ax1_outer_inner)] + (left_matrix[(((ax0_outer_inner * 18) + (ax0_inner * 9)) + k_outer)] * right_matrix[((k_outer * 4) + ax1_outer_inner)]));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ T_matmul, float* __restrict__ left_matrix, float* __restrict__ right_matrix) {\n  float T_matmul_local[4];\n  __shared__ float left_matrix_shared[36];\n  __shared__ float right_matrix_shared[36];\n  T_matmul_local[0] = 0.000000e+00f;\n  T_matmul_local[1] = 0.000000e+00f;\n  T_matmul_local[2] = 0.000000e+00f;\n  T_matmul_local[3] = 0.000000e+00f;\n  for (int ax0_ax1_fused_outer_outer = 0; ax0_ax1_fused_outer_outer < 3; ++ax0_ax1_fused_outer_outer) {\n    *(float3*)(left_matrix_shared + ((ax0_ax1_fused_outer_outer * 12) + (((int)threadIdx.x) * 3))) = *(float3*)(left_matrix + ((ax0_ax1_fused_outer_outer * 12) + (((int)threadIdx.x) * 3)));\n  }\n  for (int ax0_ax1_fused_outer_outer_1 = 0; ax0_ax1_fused_outer_outer_1 < 9; ++ax0_ax1_fused_outer_outer_1) {\n    right_matrix_shared[((ax0_ax1_fused_outer_outer_1 * 4) + ((int)threadIdx.x))] = right_matrix[((ax0_ax1_fused_outer_outer_1 * 4) + ((int)threadIdx.x))];\n  }\n  __syncthreads();\n  for (int k_outer_inner = 0; k_outer_inner < 9; ++k_outer_inner) {\n    T_matmul_local[0] = (T_matmul_local[0] + (left_matrix_shared[k_outer_inner] * right_matrix_shared[((k_outer_inner * 4) + ((int)threadIdx.x))]));\n    T_matmul_local[1] = (T_matmul_local[1] + (left_matrix_shared[(k_outer_inner + 9)] * right_matrix_shared[((k_outer_inner * 4) + ((int)threadIdx.x))]));\n    T_matmul_local[2] = (T_matmul_local[2] + (left_matrix_shared[(k_outer_inner + 18)] * right_matrix_shared[((k_outer_inner * 4) + ((int)threadIdx.x))]));\n    T_matmul_local[3] = (T_matmul_local[3] + (left_matrix_shared[(k_outer_inner + 27)] * right_matrix_shared[((k_outer_inner * 4) + ((int)threadIdx.x))]));\n  }\n  T_matmul[((int)threadIdx.x)] = T_matmul_local[0];\n  T_matmul[(((int)threadIdx.x) + 4)] = T_matmul_local[1];\n  T_matmul[(((int)threadIdx.x) + 8)] = T_matmul_local[2];\n  T_matmul[(((int)threadIdx.x) + 12)] = T_matmul_local[3];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(left_matrix: T.Buffer((4, 9), \"float32\"), right_matrix: T.Buffer((9, 4), \"float32\"), T_matmul: T.Buffer((4, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        T_matmul_1 = T.Buffer((16,), data=T_matmul.data)\n        for ax0_outer_inner_init, ax1_outer_inner_init, ax0_inner_init in T.grid(2, 4, 2):\n            T_matmul_1[ax0_outer_inner_init * 8 + ax0_inner_init * 4 + ax1_outer_inner_init] = T.float32(0)\n        for k_outer, ax0_outer_inner, ax1_outer_inner, ax0_inner in T.grid(9, 2, 4, 2):\n            cse_var_1: T.int32 = ax0_outer_inner * 8 + ax0_inner * 4 + ax1_outer_inner\n            left_matrix_1 = T.Buffer((36,), data=left_matrix.data)\n            right_matrix_1 = T.Buffer((36,), data=right_matrix.data)\n            T_matmul_1[cse_var_1] = T_matmul_1[cse_var_1] + left_matrix_1[ax0_outer_inner * 18 + ax0_inner * 9 + k_outer] * right_matrix_1[k_outer * 4 + ax1_outer_inner]", "op_args": [11, 2, 4, 9], "input_shape": "[[4, 9], [9, 4]]", "output_shape": "[[4, 4]]"}{"op_name": "softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 12; ++i0_i1_fused) {\n    float T_softmax_exp[10];\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i2 = 0; i2 < 5; ++i2) {\n      for (int32_t i3 = 0; i3 < 10; ++i3) {\n        for (int32_t i3_1 = 0; i3_1 < 10; ++i3_1) {\n          T_softmax_maxelem[0] = -3.402823e+38f;\n          for (int32_t k = 0; k < 10; ++k) {\n            T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[(((i0_i1_fused * 50) + (i2 * 10)) + k)]);\n          }\n          T_softmax_exp[i3_1] = expf((data[(((i0_i1_fused * 50) + (i2 * 10)) + i3_1)] - T_softmax_maxelem[0]));\n        }\n        T_softmax_expsum[0] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 10; ++k_1) {\n          T_softmax_expsum[0] = (T_softmax_expsum[0] + T_softmax_exp[k_1]);\n        }\n        T_softmax_norm[(((i0_i1_fused * 50) + (i2 * 10)) + i3)] = (T_softmax_exp[i3] / T_softmax_expsum[0]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((int)blockIdx.x)] = 0.000000e+00f;\n  for (int k = 0; k < 10; ++k) {\n    T_softmax_expsum[((int)blockIdx.x)] = (T_softmax_expsum[((int)blockIdx.x)] + __expf((data[((((int)blockIdx.x) * 10) + k)] - T_softmax_maxelem[((int)blockIdx.x)])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 75) {\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (__expf((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)])) / T_softmax_expsum[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 5)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 15) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 10; ++k) {\n    if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 15) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 320) + (((int)threadIdx.x) * 10)) + k)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 1, 5, 10), \"float32\"), T_softmax_norm: T.Buffer((12, 1, 5, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(12):\n            T_softmax_exp = T.allocate([10], \"float32\", \"global\")\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i2, i3 in T.grid(5, 10):\n                T_softmax_exp_1 = T.Buffer((10,), data=T_softmax_exp, align=32)\n                for i3_1 in range(10):\n                    T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                    T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                    data_1 = T.Buffer((600,), data=data.data)\n                    for k in range(10):\n                        T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0_i1_fused * 50 + i2 * 10 + k])\n                    T_softmax_exp_1[i3_1] = T.exp(data_1[i0_i1_fused * 50 + i2 * 10 + i3_1] - T_softmax_maxelem_1[0])\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(10):\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T_softmax_exp_1[k]\n                T_softmax_norm_1 = T.Buffer((600,), data=T_softmax_norm.data)\n                T_softmax_norm_1[i0_i1_fused * 50 + i2 * 10 + i3] = T_softmax_exp_1[i3] / T_softmax_expsum_1[0]", "op_args": [12, 1, 5, 10], "input_shape": "[[12, 1, 5, 10]]", "output_shape": "[[12, 1, 5, 10]]"}{"op_name": "combination_op", "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 650; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 3; ++ax3) {\n      T_add[((ax0_ax1_fused_ax2_fused * 3) + ax3)] = (sqrtf(data[((ax0_ax1_fused_ax2_fused * 3) + ax3)]) + cosf(data_1[((ax0_ax1_fused_ax2_fused * 3) + ax3)]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(39) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))] = (sqrtf(data[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))]) + __cosf(data_1[((((int)blockIdx.x) * 39) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 5, 10, 3), \"float32\"), data_1: T.Buffer((13, 5, 10, 3), \"float32\"), T_add: T.Buffer((13, 5, 10, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(650):\n            for ax3 in range(3):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 3 + ax3\n                T_add_1 = T.Buffer((1950,), data=T_add.data)\n                data_2 = T.Buffer((1950,), data=data.data)\n                data_3 = T.Buffer((1950,), data=data_1.data)\n                T_add_1[cse_var_1] = T.sqrt(data_2[cse_var_1]) + T.cos(data_3[cse_var_1])", "op_args": [13, 5, 10, 3], "input_shape": "[[13, 5, 10, 3], [13, 5, 10, 3]]", "output_shape": "[[13, 5, 10, 3]]"}{"op_name": "combination_op", "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 392; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n      T_add[((ax0_ax1_fused_ax2_fused * 16) + ax3)] = (sqrtf(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)]) + cosf(data_1[((ax0_ax1_fused_ax2_fused * 16) + ax3)]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (sqrtf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]) + __cosf(data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 4, 7, 16), \"float32\"), data_1: T.Buffer((14, 4, 7, 16), \"float32\"), T_add: T.Buffer((14, 4, 7, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(392):\n            for ax3 in range(16):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 16 + ax3\n                T_add_1 = T.Buffer((6272,), data=T_add.data)\n                data_2 = T.Buffer((6272,), data=data.data)\n                data_3 = T.Buffer((6272,), data=data_1.data)\n                T_add_1[cse_var_1] = T.sqrt(data_2[cse_var_1]) + T.cos(data_3[cse_var_1])", "op_args": [14, 4, 7, 16], "input_shape": "[[14, 4, 7, 16], [14, 4, 7, 16]]", "output_shape": "[[14, 4, 7, 16]]"}{"op_name": "softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 52; ++i0_i1_fused) {\n    float T_softmax_exp[128];\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i2 = 0; i2 < 16; ++i2) {\n      for (int32_t i3 = 0; i3 < 8; ++i3) {\n        T_softmax_maxelem[0] = -3.402823e+38f;\n        for (int32_t k = 0; k < 8; ++k) {\n          T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[(((i0_i1_fused * 128) + (i2 * 8)) + k)]);\n        }\n        T_softmax_exp[((i2 * 8) + i3)] = expf((data[(((i0_i1_fused * 128) + (i2 * 8)) + i3)] - T_softmax_maxelem[0]));\n      }\n    }\n    for (int32_t i2_1 = 0; i2_1 < 16; ++i2_1) {\n      for (int32_t i3_1 = 0; i3_1 < 8; ++i3_1) {\n        T_softmax_expsum[0] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 8; ++k_1) {\n          T_softmax_expsum[0] = (T_softmax_expsum[0] + T_softmax_exp[((i2_1 * 8) + k_1)]);\n        }\n        T_softmax_norm[(((i0_i1_fused * 128) + (i2_1 * 8)) + i3_1)] = (T_softmax_exp[((i2_1 * 8) + i3_1)] / T_softmax_expsum[0]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (__expf((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))])) / T_softmax_expsum[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3))]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 8; ++k) {\n    T_softmax_expsum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) * 8)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 8; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 128) + (((int)threadIdx.x) * 8)) + k)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 4, 16, 8), \"float32\"), T_softmax_norm: T.Buffer((13, 4, 16, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(52):\n            T_softmax_exp = T.allocate([128], \"float32\", \"global\")\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            T_softmax_exp_1 = T.Buffer((128,), data=T_softmax_exp)\n            for i2, i3 in T.grid(16, 8):\n                cse_var_1: T.int32 = i2 * 8\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((6656,), data=data.data)\n                for k in range(8):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0_i1_fused * 128 + cse_var_1 + k])\n                T_softmax_exp_1[cse_var_1 + i3] = T.exp(data_1[i0_i1_fused * 128 + cse_var_1 + i3] - T_softmax_maxelem_1[0])\n            for i2, i3 in T.grid(16, 8):\n                cse_var_2: T.int32 = i2 * 8\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(8):\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T_softmax_exp_1[cse_var_2 + k]\n                T_softmax_norm_1 = T.Buffer((6656,), data=T_softmax_norm.data)\n                T_softmax_norm_1[i0_i1_fused * 128 + cse_var_2 + i3] = T_softmax_exp_1[cse_var_2 + i3] / T_softmax_expsum_1[0]", "op_args": [13, 4, 16, 8], "input_shape": "[[13, 4, 16, 8]]", "output_shape": "[[13, 4, 16, 8]]"}{"op_name": "softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 2400; ++i0_i1_fused_i2_fused) {\n    float T_softmax_exp[16];\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i3 = 0; i3 < 16; ++i3) {\n      T_softmax_maxelem[0] = -3.402823e+38f;\n      for (int32_t k = 0; k < 16; ++k) {\n        T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[((i0_i1_fused_i2_fused * 16) + k)]);\n      }\n      T_softmax_exp[i3] = expf((data[((i0_i1_fused_i2_fused * 16) + i3)] - T_softmax_maxelem[0]));\n    }\n    for (int32_t i3_1 = 0; i3_1 < 16; ++i3_1) {\n      T_softmax_expsum[0] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 16; ++k_1) {\n        T_softmax_expsum[0] = (T_softmax_expsum[0] + T_softmax_exp[k_1]);\n      }\n      T_softmax_norm[((i0_i1_fused_i2_fused * 16) + i3_1)] = (T_softmax_exp[i3_1] / T_softmax_expsum[0]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 16; ++k) {\n    T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 128) + (((int)threadIdx.x) * 16)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  T_softmax_norm[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (__expf((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))])) / T_softmax_expsum[((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4))]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 16; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 512) + (((int)threadIdx.x) * 16)) + k)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 20, 12, 16), \"float32\"), T_softmax_norm: T.Buffer((10, 20, 12, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(2400):\n            T_softmax_exp = T.allocate([16], \"float32\", \"global\")\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            T_softmax_exp_1 = T.Buffer((16,), data=T_softmax_exp)\n            for i3 in range(16):\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((38400,), data=data.data)\n                for k in range(16):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0_i1_fused_i2_fused * 16 + k])\n                T_softmax_exp_1[i3] = T.exp(data_1[i0_i1_fused_i2_fused * 16 + i3] - T_softmax_maxelem_1[0])\n            for i3 in range(16):\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(16):\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T_softmax_exp_1[k]\n                T_softmax_norm_1 = T.Buffer((38400,), data=T_softmax_norm.data)\n                T_softmax_norm_1[i0_i1_fused_i2_fused * 16 + i3] = T_softmax_exp_1[i3] / T_softmax_expsum_1[0]", "op_args": [10, 20, 12, 16], "input_shape": "[[10, 20, 12, 16]]", "output_shape": "[[10, 20, 12, 16]]"}{"op_name": "combination_op", "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 15; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 8; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 3; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 3; ++ax3) {\n          T_add[((((ax0 * 72) + (ax1 * 9)) + (ax2 * 3)) + ax3)] = (sqrtf(data[((((ax0 * 72) + (ax1 * 9)) + (ax2 * 3)) + ax3)]) + cosf(data_1[((((ax0 * 72) + (ax1 * 9)) + (ax2 * 3)) + ax3)]));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(5) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))] = (sqrtf(data[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))]) + __cosf(data_1[((((int)blockIdx.x) * 5) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 8, 3, 3), \"float32\"), data_1: T.Buffer((15, 8, 3, 3), \"float32\"), T_add: T.Buffer((15, 8, 3, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(15):\n            for ax1, ax2, ax3 in T.grid(8, 3, 3):\n                cse_var_1: T.int32 = ax0 * 72 + ax1 * 9 + ax2 * 3 + ax3\n                T_add_1 = T.Buffer((1080,), data=T_add.data)\n                data_2 = T.Buffer((1080,), data=data.data)\n                data_3 = T.Buffer((1080,), data=data_1.data)\n                T_add_1[cse_var_1] = T.sqrt(data_2[cse_var_1]) + T.cos(data_3[cse_var_1])", "op_args": [15, 8, 3, 3], "input_shape": "[[15, 8, 3, 3], [15, 8, 3, 3]]", "output_shape": "[[15, 8, 3, 3]]"}{"op_name": "combination_op", "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 507; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 5; ++ax3) {\n      T_add[((ax0_ax1_fused_ax2_fused * 5) + ax3)] = (sqrtf(data[((ax0_ax1_fused_ax2_fused * 5) + ax3)]) + cosf(data_1[((ax0_ax1_fused_ax2_fused * 5) + ax3)]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 2535) {\n    T_add[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (sqrtf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]) + __cosf(data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 3, 13, 5), \"float32\"), data_1: T.Buffer((13, 3, 13, 5), \"float32\"), T_add: T.Buffer((13, 3, 13, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(507):\n            for ax3 in range(5):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 5 + ax3\n                T_add_1 = T.Buffer((2535,), data=T_add.data)\n                data_2 = T.Buffer((2535,), data=data.data)\n                data_3 = T.Buffer((2535,), data=data_1.data)\n                T_add_1[cse_var_1] = T.sqrt(data_2[cse_var_1]) + T.cos(data_3[cse_var_1])", "op_args": [13, 3, 13, 5], "input_shape": "[[13, 3, 13, 5], [13, 3, 13, 5]]", "output_shape": "[[13, 3, 13, 5]]"}{"op_name": "softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 6; ++i0) {\n    float T_softmax_exp[546];\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i1 = 0; i1 < 14; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 13; ++i3) {\n          T_softmax_maxelem[0] = -3.402823e+38f;\n          for (int32_t k = 0; k < 13; ++k) {\n            T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[((((i0 * 546) + (i1 * 39)) + (i2 * 13)) + k)]);\n          }\n          T_softmax_exp[(((i1 * 39) + (i2 * 13)) + i3)] = expf((data[((((i0 * 546) + (i1 * 39)) + (i2 * 13)) + i3)] - T_softmax_maxelem[0]));\n        }\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 14; ++i1_1) {\n      for (int32_t i2_1 = 0; i2_1 < 3; ++i2_1) {\n        for (int32_t i3_1 = 0; i3_1 < 13; ++i3_1) {\n          T_softmax_expsum[0] = 0.000000e+00f;\n          for (int32_t k_1 = 0; k_1 < 13; ++k_1) {\n            T_softmax_expsum[0] = (T_softmax_expsum[0] + T_softmax_exp[(((i1_1 * 39) + (i2_1 * 13)) + k_1)]);\n          }\n          T_softmax_norm[((((i0 * 546) + (i1_1 * 39)) + (i2_1 * 13)) + i3_1)] = (T_softmax_exp[(((i1_1 * 39) + (i2_1 * 13)) + i3_1)] / T_softmax_expsum[0]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 2)) < 63) {\n    T_softmax_expsum[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 13; ++k) {\n    if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 2)) < 63) {\n      T_softmax_expsum[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] + __expf((data[(((((int)blockIdx.x) * 208) + (((int)threadIdx.x) * 13)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 2)) < 63) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 13; ++k) {\n    if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 2)) < 63) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 208) + (((int)threadIdx.x) * 13)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) < 819) {\n    T_softmax_norm[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (__expf((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) / 13)])) / T_softmax_expsum[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) / 13)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 14, 3, 13), \"float32\"), T_softmax_norm: T.Buffer((6, 14, 3, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(6):\n            T_softmax_exp = T.allocate([546], \"float32\", \"global\")\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            T_softmax_exp_1 = T.Buffer((546,), data=T_softmax_exp)\n            for i1, i2, i3 in T.grid(14, 3, 13):\n                cse_var_2: T.int32 = i1 * 39\n                cse_var_1: T.int32 = i2 * 13\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((3276,), data=data.data)\n                for k in range(13):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0 * 546 + cse_var_2 + cse_var_1 + k])\n                T_softmax_exp_1[cse_var_2 + cse_var_1 + i3] = T.exp(data_1[i0 * 546 + cse_var_2 + cse_var_1 + i3] - T_softmax_maxelem_1[0])\n            for i1, i2, i3 in T.grid(14, 3, 13):\n                cse_var_4: T.int32 = i1 * 39\n                cse_var_3: T.int32 = i2 * 13\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(13):\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T_softmax_exp_1[cse_var_4 + cse_var_3 + k]\n                T_softmax_norm_1 = T.Buffer((3276,), data=T_softmax_norm.data)\n                T_softmax_norm_1[i0 * 546 + cse_var_4 + cse_var_3 + i3] = T_softmax_exp_1[cse_var_4 + cse_var_3 + i3] / T_softmax_expsum_1[0]", "op_args": [6, 14, 3, 13], "input_shape": "[[6, 14, 3, 13]]", "output_shape": "[[6, 14, 3, 13]]"}{"op_name": "softmax", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    float T_softmax_maxelem[4];\n    float T_softmax_expsum[4];\n    for (int32_t i1 = 0; i1 < 4; ++i1) {\n      for (int32_t i2 = 0; i2 < 4; ++i2) {\n        T_softmax_maxelem[i2] = -3.402823e+38f;\n        T_softmax_maxelem[i2] = max(T_softmax_maxelem[i2], data[(((i0 * 16) + (i1 * 4)) + i2)]);\n      }\n      for (int32_t i2_1 = 0; i2_1 < 4; ++i2_1) {\n        T_softmax_maxelem[i2_1] = expf((data[(((i0 * 16) + (i1 * 4)) + i2_1)] - T_softmax_maxelem[i2_1]));\n      }\n      for (int32_t i2_2 = 0; i2_2 < 4; ++i2_2) {\n        T_softmax_expsum[i2_2] = 0.000000e+00f;\n        T_softmax_expsum[i2_2] = (T_softmax_expsum[i2_2] + T_softmax_maxelem[i2_2]);\n      }\n      for (int32_t i2_3 = 0; i2_3 < 4; ++i2_3) {\n        T_softmax_norm[(((i0 * 16) + (i1 * 4)) + i2_3)] = (T_softmax_maxelem[i2_3] / T_softmax_expsum[i2_3]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 17) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 17) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) < 17) {\n    T_softmax_norm[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (__expf((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))])) / T_softmax_expsum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = 0.000000e+00f;\n  T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] + __expf((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))])));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 4, 4, 1), \"float32\"), T_softmax_norm: T.Buffer((17, 4, 4, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(17):\n            T_softmax_maxelem = T.allocate([4], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([4], \"float32\", \"global\")\n            for i1 in range(4):\n                T_softmax_maxelem_1 = T.Buffer((4,), data=T_softmax_maxelem, align=16)\n                data_1 = T.Buffer((272,), data=data.data)\n                for i2 in range(4):\n                    T_softmax_maxelem_1[i2] = T.float32(-3.4028234663852886e+38)\n                    T_softmax_maxelem_1[i2] = T.max(T_softmax_maxelem_1[i2], data_1[i0 * 16 + i1 * 4 + i2])\n                T_softmax_maxelem_2 = T.Buffer((4,), data=T_softmax_maxelem, align=16)\n                for i2 in range(4):\n                    T_softmax_maxelem_2[i2] = T.exp(data_1[i0 * 16 + i1 * 4 + i2] - T_softmax_maxelem_1[i2])\n                T_softmax_expsum_1 = T.Buffer((4,), data=T_softmax_expsum, align=16)\n                for i2 in range(4):\n                    T_softmax_expsum_1[i2] = T.float32(0)\n                    T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T_softmax_maxelem_2[i2]\n                for i2 in range(4):\n                    T_softmax_norm_1 = T.Buffer((272,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[i0 * 16 + i1 * 4 + i2] = T_softmax_maxelem_2[i2] / T_softmax_expsum_1[i2]", "op_args": [17, 4, 4, 1], "input_shape": "[[17, 4, 4, 1]]", "output_shape": "[[17, 4, 4, 1]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    for (int32_t i1 = 0; i1 < 15; ++i1) {\n      for (int32_t i2 = 0; i2 < 13; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 3315) + (i1 * 221)) + (i2 * 17)) + i3)] = sqrtf((data[((((i0 * 3315) + (i1 * 221)) + (i2 * 17)) + i3)] + data_1[((((i0 * 3315) + (i1 * 221)) + (i2 * 17)) + i3)]));\n        }\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 270; ++i0_i1_fused) {\n    for (int32_t i2_1 = 0; i2_1 < 13; ++i2_1) {\n      for (int32_t i3_1 = 0; i3_1 < 17; ++i3_1) {\n        compute_1[(((i0_i1_fused * 221) + (i2_1 * 17)) + i3_1)] = cosf((data[(((i0_i1_fused * 221) + (i2_1 * 17)) + i3_1)] + data_1[(((i0_i1_fused * 221) + (i2_1 * 17)) + i3_1)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 6)) < 9945) {\n    compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) < 29835) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 15, 13, 17), \"float32\"), data_1: T.Buffer((18, 15, 13, 17), \"float32\"), compute: T.Buffer((18, 15, 13, 17), \"float32\"), compute_1: T.Buffer((18, 15, 13, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((59670,), data=data.data)\n        data_3 = T.Buffer((59670,), data=data_1.data)\n        for i0 in T.parallel(18):\n            for i1, i2, i3 in T.grid(15, 13, 17):\n                cse_var_1: T.int32 = i0 * 3315 + i1 * 221 + i2 * 17 + i3\n                compute_2 = T.Buffer((59670,), data=compute.data)\n                compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i0_i1_fused in T.parallel(270):\n            for i2, i3 in T.grid(13, 17):\n                cse_var_2: T.int32 = i0_i1_fused * 221 + i2 * 17 + i3\n                compute_2 = T.Buffer((59670,), data=compute_1.data)\n                compute_2[cse_var_2] = T.cos(data_2[cse_var_2] + data_3[cse_var_2])", "op_args": [18, 15, 13, 17], "input_shape": "[[18, 15, 13, 17], [18, 15, 13, 17], [18, 15, 13, 17]]", "output_shape": "[[18, 15, 13, 17]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 8415; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sqrtf((data[i0_i1_fused_i2_fused_i3_fused] + data_1[i0_i1_fused_i2_fused_i3_fused]));\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 55; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 9; ++i2) {\n      for (int32_t i3 = 0; i3 < 17; ++i3) {\n        compute_1[(((i0_i1_fused * 153) + (i2 * 17)) + i3)] = cosf((data[(((i0_i1_fused * 153) + (i2 * 17)) + i3)] + data_1[(((i0_i1_fused * 153) + (i2 * 17)) + i3)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(9) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 8415) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 5, 9, 17), \"float32\"), data_1: T.Buffer((11, 5, 9, 17), \"float32\"), compute: T.Buffer((11, 5, 9, 17), \"float32\"), compute_1: T.Buffer((11, 5, 9, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((8415,), data=data.data)\n        data_3 = T.Buffer((8415,), data=data_1.data)\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(8415):\n            compute_2 = T.Buffer((8415,), data=compute.data)\n            compute_2[i0_i1_fused_i2_fused_i3_fused] = T.sqrt(data_2[i0_i1_fused_i2_fused_i3_fused] + data_3[i0_i1_fused_i2_fused_i3_fused])\n        for i0_i1_fused in T.parallel(55):\n            for i2, i3 in T.grid(9, 17):\n                cse_var_1: T.int32 = i0_i1_fused * 153 + i2 * 17 + i3\n                compute_2 = T.Buffer((8415,), data=compute_1.data)\n                compute_2[cse_var_1] = T.cos(data_2[cse_var_1] + data_3[cse_var_1])", "op_args": [11, 5, 9, 17], "input_shape": "[[11, 5, 9, 17], [11, 5, 9, 17], [11, 5, 9, 17]]", "output_shape": "[[11, 5, 9, 17]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i2 = 0; i2 < 18; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 2448) + (i1 * 306)) + (i2 * 17)) + i3)] = sqrtf((data[((((i0 * 2448) + (i1 * 306)) + (i2 * 17)) + i3)] + data_1[((((i0 * 2448) + (i1 * 306)) + (i2 * 17)) + i3)]));\n        }\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 26928; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute_1[i0_i1_fused_i2_fused_i3_fused] = cosf((data[i0_i1_fused_i2_fused_i3_fused] + data_1[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 1683) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 8, 18, 17), \"float32\"), data_1: T.Buffer((11, 8, 18, 17), \"float32\"), compute: T.Buffer((11, 8, 18, 17), \"float32\"), compute_1: T.Buffer((11, 8, 18, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((26928,), data=data.data)\n        data_3 = T.Buffer((26928,), data=data_1.data)\n        for i0 in T.parallel(11):\n            for i1, i2, i3 in T.grid(8, 18, 17):\n                cse_var_1: T.int32 = i0 * 2448 + i1 * 306 + i2 * 17 + i3\n                compute_2 = T.Buffer((26928,), data=compute.data)\n                compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(26928):\n            compute_2 = T.Buffer((26928,), data=compute_1.data)\n            compute_2[i0_i1_fused_i2_fused_i3_fused] = T.cos(data_2[i0_i1_fused_i2_fused_i3_fused] + data_3[i0_i1_fused_i2_fused_i3_fused])", "op_args": [11, 8, 18, 17], "input_shape": "[[11, 8, 18, 17], [11, 8, 18, 17], [11, 8, 18, 17]]", "output_shape": "[[11, 8, 18, 17]]"}{"op_name": "softmax_common", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    float T_softmax_maxelem[168];\n    float T_softmax_expsum[14];\n    for (int32_t i1 = 0; i1 < 12; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        T_softmax_maxelem[((i1 * 14) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 3; ++k) {\n          T_softmax_maxelem[((i1 * 14) + i2)] = max(T_softmax_maxelem[((i1 * 14) + i2)], data[((((i0 * 504) + (i1 * 42)) + (i2 * 3)) + k)]);\n        }\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 12; ++i1_1) {\n      for (int32_t i2_1 = 0; i2_1 < 14; ++i2_1) {\n        T_softmax_expsum[i2_1] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 3; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[i2_1] = (T_softmax_expsum[i2_1] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 504) + (i1_1 * 42)) + (i2_1 * 3)) + k_1)] - T_softmax_maxelem[((i1_1 * 14) + i2_1)])));\n        }\n      }\n      for (int32_t i2_2 = 0; i2_2 < 14; ++i2_2) {\n        for (int32_t i3_s = 0; i3_s < 3; ++i3_s) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 504) + (i1_1 * 42)) + (i2_2 * 3)) + i3_s)] - T_softmax_maxelem[((i1_1 * 14) + i2_2)])) / T_softmax_expsum[i2_2]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 189) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 3; ++k) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 189) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 96) + (((int)threadIdx.x) * 3)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 567) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 3)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(4) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 3; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 12) + (((int)threadIdx.x) * 3)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))])));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 12, 14, 3), \"float32\"), T_softmax_norm: T.Buffer((18, 12, 14, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(18):\n            T_softmax_maxelem = T.allocate([168], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([14], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((168,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((9072,), data=data.data)\n            for i1, i2 in T.grid(12, 14):\n                T_softmax_maxelem_1[i1 * 14 + i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(3):\n                    cse_var_1: T.int32 = i1 * 14 + i2\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 504 + i1 * 42 + i2 * 3 + k])\n            for i1 in range(12):\n                T_softmax_expsum_1 = T.Buffer((14,), data=T_softmax_expsum, align=32)\n                for i2 in range(14):\n                    T_softmax_expsum_1[i2] = T.float32(0)\n                    for k in range(3):\n                        cse_var_3: T.int32 = i1 * 14 + i2\n                        cse_var_2: T.int32 = i0 * 504 + i1 * 42 + i2 * 3 + k\n                        T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3])\n                for i2, i3_s in T.grid(14, 3):\n                    cse_var_5: T.int32 = i1 * 14 + i2\n                    cse_var_4: T.int32 = i0 * 504 + i1 * 42 + i2 * 3 + i3_s\n                    T_softmax_norm_1 = T.Buffer((9072,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_4] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5]) / T_softmax_expsum_1[i2]", "op_args": [18, 12, 14, 3], "input_shape": "[[18, 12, 14, 3]]", "output_shape": "[[18, 12, 14, 3]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 80; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 7; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 7) + i3)] = sqrtf((data[((i0_i1_fused_i2_fused * 7) + i3)] + data_1[((i0_i1_fused_i2_fused * 7) + i3)]));\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 20; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3_1 = 0; i3_1 < 7; ++i3_1) {\n        compute_1[(((i0_i1_fused * 28) + (i2 * 7)) + i3_1)] = cosf((data[(((i0_i1_fused * 28) + (i2 * 7)) + i3_1)] + data_1[(((i0_i1_fused * 28) + (i2 * 7)) + i3_1)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 35) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 1, 4, 7), \"float32\"), data_1: T.Buffer((20, 1, 4, 7), \"float32\"), compute: T.Buffer((20, 1, 4, 7), \"float32\"), compute_1: T.Buffer((20, 1, 4, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((560,), data=data.data)\n        data_3 = T.Buffer((560,), data=data_1.data)\n        for i0_i1_fused_i2_fused in T.parallel(80):\n            for i3 in range(7):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 7 + i3\n                compute_2 = T.Buffer((560,), data=compute.data)\n                compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i0_i1_fused in T.parallel(20):\n            for i2, i3 in T.grid(4, 7):\n                cse_var_2: T.int32 = i0_i1_fused * 28 + i2 * 7 + i3\n                compute_2 = T.Buffer((560,), data=compute_1.data)\n                compute_2[cse_var_2] = T.cos(data_2[cse_var_2] + data_3[cse_var_2])", "op_args": [20, 1, 4, 7], "input_shape": "[[20, 1, 4, 7], [20, 1, 4, 7], [20, 1, 4, 7]]", "output_shape": "[[20, 1, 4, 7]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  for (int32_t i1 = 0; i1 < 10; ++i1) {\n    for (int32_t i3 = 0; i3 < 15; ++i3) {\n      compute[((i1 * 15) + i3)] = sqrtf((data[((i1 * 15) + i3)] + data_1[((i1 * 15) + i3)]));\n    }\n  }\n  for (int32_t i1_1 = 0; i1_1 < 10; ++i1_1) {\n    for (int32_t i3_1 = 0; i3_1 < 15; ++i3_1) {\n      compute_1[((i1_1 * 15) + i3_1)] = cosf((data[((i1_1 * 15) + i3_1)] + data_1[((i1_1 * 15) + i3_1)]));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(10) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 10) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 10, 1, 15), \"float32\"), data_1: T.Buffer((1, 10, 1, 15), \"float32\"), compute: T.Buffer((1, 10, 1, 15), \"float32\"), compute_1: T.Buffer((1, 10, 1, 15), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((150,), data=data.data)\n        data_3 = T.Buffer((150,), data=data_1.data)\n        for i1, i3 in T.grid(10, 15):\n            cse_var_1: T.int32 = i1 * 15 + i3\n            compute_2 = T.Buffer((150,), data=compute.data)\n            compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i1, i3 in T.grid(10, 15):\n            cse_var_2: T.int32 = i1 * 15 + i3\n            compute_2 = T.Buffer((150,), data=compute_1.data)\n            compute_2[cse_var_2] = T.cos(data_2[cse_var_2] + data_3[cse_var_2])", "op_args": [1, 10, 1, 15], "input_shape": "[[1, 10, 1, 15], [1, 10, 1, 15], [1, 10, 1, 15]]", "output_shape": "[[1, 10, 1, 15]]"}{"op_name": "softmax_common", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 3610; ++i0_i1_fused_i2_fused) {\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i3 = 0; i3 < 19; ++i3) {\n      T_softmax_maxelem[0] = -3.402823e+38f;\n      for (int32_t k = 0; k < 19; ++k) {\n        T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[((i0_i1_fused_i2_fused * 19) + k)]);\n      }\n      T_softmax_expsum[0] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 19; ++k_1) {\n          int32_t v_ = ((int32_t)(floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((i0_i1_fused_i2_fused * 19) + k_1)] - T_softmax_maxelem[0])));\n      }\n        int32_t v__1 = ((int32_t)(floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_norm[((i0_i1_fused_i2_fused * 19) + i3)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((i0_i1_fused_i2_fused * 19) + i3)] - T_softmax_maxelem[0])) / T_softmax_expsum[0]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 22) + (((int)threadIdx.x) >> 1)) < 1805) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 19; ++k) {\n    if (((((int)blockIdx.x) * 22) + (((int)threadIdx.x) >> 1)) < 1805) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 836) + (((int)threadIdx.x) * 19)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 19; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 38) + (((int)threadIdx.x) * 19)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 34295) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 19)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 10, 19, 19), \"float32\"), T_softmax_norm: T.Buffer((19, 10, 19, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(3610):\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i3 in range(19):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 19 + i3\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((68590,), data=data.data)\n                for k in range(19):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0_i1_fused_i2_fused * 19 + k])\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(19):\n                    cse_var_2: T.int32 = i0_i1_fused_i2_fused * 19 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[0])\n                T_softmax_norm_1 = T.Buffer((68590,), data=T_softmax_norm.data)\n                T_softmax_norm_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[0]) / T_softmax_expsum_1[0]", "op_args": [19, 10, 19, 19], "input_shape": "[[19, 10, 19, 19]]", "output_shape": "[[19, 10, 19, 19]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 56; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 13; ++i2) {\n      for (int32_t i3 = 0; i3 < 5; ++i3) {\n        compute[(((i0_i1_fused * 65) + (i2 * 5)) + i3)] = sqrtf((data[(((i0_i1_fused * 65) + (i2 * 5)) + i3)] + data_1[(((i0_i1_fused * 65) + (i2 * 5)) + i3)]));\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3640; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute_1[i0_i1_fused_i2_fused_i3_fused] = cosf((data[i0_i1_fused_i2_fused_i3_fused] + data_1[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(52) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 52) + ((int)threadIdx.x))]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 455) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 7, 13, 5), \"float32\"), data_1: T.Buffer((8, 7, 13, 5), \"float32\"), compute: T.Buffer((8, 7, 13, 5), \"float32\"), compute_1: T.Buffer((8, 7, 13, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((3640,), data=data.data)\n        data_3 = T.Buffer((3640,), data=data_1.data)\n        for i0_i1_fused in T.parallel(56):\n            for i2, i3 in T.grid(13, 5):\n                cse_var_1: T.int32 = i0_i1_fused * 65 + i2 * 5 + i3\n                compute_2 = T.Buffer((3640,), data=compute.data)\n                compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3640):\n            compute_2 = T.Buffer((3640,), data=compute_1.data)\n            compute_2[i0_i1_fused_i2_fused_i3_fused] = T.cos(data_2[i0_i1_fused_i2_fused_i3_fused] + data_3[i0_i1_fused_i2_fused_i3_fused])", "op_args": [8, 7, 13, 5], "input_shape": "[[8, 7, 13, 5], [8, 7, 13, 5], [8, 7, 13, 5]]", "output_shape": "[[8, 7, 13, 5]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3420; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sqrtf((data[i0_i1_fused_i2_fused_i3_fused] + data_1[i0_i1_fused_i2_fused_i3_fused]));\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused_1 = 0; i0_i1_fused_i2_fused_i3_fused_1 < 3420; ++i0_i1_fused_i2_fused_i3_fused_1) {\n    compute_1[i0_i1_fused_i2_fused_i3_fused_1] = cosf((data[i0_i1_fused_i2_fused_i3_fused_1] + data_1[i0_i1_fused_i2_fused_i3_fused_1]));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 855) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 3, 19, 12), \"float32\"), data_1: T.Buffer((5, 3, 19, 12), \"float32\"), compute: T.Buffer((5, 3, 19, 12), \"float32\"), compute_1: T.Buffer((5, 3, 19, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((3420,), data=data.data)\n        data_3 = T.Buffer((3420,), data=data_1.data)\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3420):\n            compute_2 = T.Buffer((3420,), data=compute.data)\n            compute_2[i0_i1_fused_i2_fused_i3_fused] = T.sqrt(data_2[i0_i1_fused_i2_fused_i3_fused] + data_3[i0_i1_fused_i2_fused_i3_fused])\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3420):\n            compute_2 = T.Buffer((3420,), data=compute_1.data)\n            compute_2[i0_i1_fused_i2_fused_i3_fused] = T.cos(data_2[i0_i1_fused_i2_fused_i3_fused] + data_3[i0_i1_fused_i2_fused_i3_fused])", "op_args": [5, 3, 19, 12], "input_shape": "[[5, 3, 19, 12], [5, 3, 19, 12], [5, 3, 19, 12]]", "output_shape": "[[5, 3, 19, 12]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  for (int32_t i1 = 0; i1 < 14; ++i1) {\n    for (int32_t i2 = 0; i2 < 6; ++i2) {\n      for (int32_t i3 = 0; i3 < 10; ++i3) {\n        compute[(((i1 * 60) + (i2 * 10)) + i3)] = sqrtf((data[(((i1 * 60) + (i2 * 10)) + i3)] + data_1[(((i1 * 60) + (i2 * 10)) + i3)]));\n      }\n    }\n  }\n  for (int32_t i1_1 = 0; i1_1 < 14; ++i1_1) {\n    for (int32_t i2_1 = 0; i2_1 < 6; ++i2_1) {\n      for (int32_t i3_1 = 0; i3_1 < 10; ++i3_1) {\n        compute_1[(((i1_1 * 60) + (i2_1 * 10)) + i3_1)] = cosf((data[(((i1_1 * 60) + (i2_1 * 10)) + i3_1)] + data_1[(((i1_1 * 60) + (i2_1 * 10)) + i3_1)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 105) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(21) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 14, 6, 10), \"float32\"), data_1: T.Buffer((1, 14, 6, 10), \"float32\"), compute: T.Buffer((1, 14, 6, 10), \"float32\"), compute_1: T.Buffer((1, 14, 6, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((840,), data=data.data)\n        data_3 = T.Buffer((840,), data=data_1.data)\n        for i1, i2, i3 in T.grid(14, 6, 10):\n            cse_var_1: T.int32 = i1 * 60 + i2 * 10 + i3\n            compute_2 = T.Buffer((840,), data=compute.data)\n            compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i1, i2, i3 in T.grid(14, 6, 10):\n            cse_var_2: T.int32 = i1 * 60 + i2 * 10 + i3\n            compute_2 = T.Buffer((840,), data=compute_1.data)\n            compute_2[cse_var_2] = T.cos(data_2[cse_var_2] + data_3[cse_var_2])", "op_args": [1, 14, 6, 10], "input_shape": "[[1, 14, 6, 10], [1, 14, 6, 10], [1, 14, 6, 10]]", "output_shape": "[[1, 14, 6, 10]]"}{"op_name": "softmax_common", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 288; ++i0_i1_fused_i2_fused) {\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i3 = 0; i3 < 7; ++i3) {\n      T_softmax_maxelem[0] = -3.402823e+38f;\n      for (int32_t k = 0; k < 7; ++k) {\n        T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[((i0_i1_fused_i2_fused * 7) + k)]);\n      }\n      T_softmax_expsum[0] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 7; ++k_1) {\n          int32_t v_ = ((int32_t)(floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((i0_i1_fused_i2_fused * 7) + k_1)] - T_softmax_maxelem[0])));\n      }\n        int32_t v__1 = ((int32_t)(floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_norm[((i0_i1_fused_i2_fused * 7) + i3)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((i0_i1_fused_i2_fused * 7) + i3)] - T_softmax_maxelem[0])) / T_softmax_expsum[0]);\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 7; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 112) + (((int)threadIdx.x) * 7)) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 7; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 224) + (((int)threadIdx.x) * 7)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(14) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 14) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))])) / T_softmax_expsum[((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 16, 9, 7), \"float32\"), T_softmax_norm: T.Buffer((2, 16, 9, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(288):\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i3 in range(7):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 7 + i3\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((2016,), data=data.data)\n                for k in range(7):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0_i1_fused_i2_fused * 7 + k])\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(7):\n                    cse_var_2: T.int32 = i0_i1_fused_i2_fused * 7 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[0])\n                T_softmax_norm_1 = T.Buffer((2016,), data=T_softmax_norm.data)\n                T_softmax_norm_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[0]) / T_softmax_expsum_1[0]", "op_args": [2, 16, 9, 7], "input_shape": "[[2, 16, 9, 7]]", "output_shape": "[[2, 16, 9, 7]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1260; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 18; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 18) + i3)] = sqrtf((data[((i0_i1_fused_i2_fused * 18) + i3)] + data_1[((i0_i1_fused_i2_fused * 18) + i3)]));\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 252; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 5; ++i2) {\n      for (int32_t i3_1 = 0; i3_1 < 18; ++i3_1) {\n        compute_1[(((i0_i1_fused * 90) + (i2 * 18)) + i3_1)] = cosf((data[(((i0_i1_fused * 90) + (i2 * 18)) + i3_1)] + data_1[(((i0_i1_fused * 90) + (i2 * 18)) + i3_1)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 2835) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) < 2835) {\n    compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 18, 5, 18), \"float32\"), data_1: T.Buffer((14, 18, 5, 18), \"float32\"), compute: T.Buffer((14, 18, 5, 18), \"float32\"), compute_1: T.Buffer((14, 18, 5, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((22680,), data=data.data)\n        data_3 = T.Buffer((22680,), data=data_1.data)\n        for i0_i1_fused_i2_fused in T.parallel(1260):\n            for i3 in range(18):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 18 + i3\n                compute_2 = T.Buffer((22680,), data=compute.data)\n                compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i0_i1_fused in T.parallel(252):\n            for i2, i3 in T.grid(5, 18):\n                cse_var_2: T.int32 = i0_i1_fused * 90 + i2 * 18 + i3\n                compute_2 = T.Buffer((22680,), data=compute_1.data)\n                compute_2[cse_var_2] = T.cos(data_2[cse_var_2] + data_3[cse_var_2])", "op_args": [14, 18, 5, 18], "input_shape": "[[14, 18, 5, 18], [14, 18, 5, 18], [14, 18, 5, 18]]", "output_shape": "[[14, 18, 5, 18]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 20; ++i1) {\n      for (int32_t i2 = 0; i2 < 2; ++i2) {\n        compute[(((i0 * 40) + (i1 * 2)) + i2)] = sqrtf((data[(((i0 * 40) + (i1 * 2)) + i2)] + data_1[(((i0 * 40) + (i1 * 2)) + i2)]));\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 440; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute_1[i0_i1_fused_i2_fused_i3_fused] = cosf((data[i0_i1_fused_i2_fused_i3_fused] + data_1[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 55) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) < 55) {\n    compute[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 20, 2, 1), \"float32\"), data_1: T.Buffer((11, 20, 2, 1), \"float32\"), compute: T.Buffer((11, 20, 2, 1), \"float32\"), compute_1: T.Buffer((11, 20, 2, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((440,), data=data.data)\n        data_3 = T.Buffer((440,), data=data_1.data)\n        for i0 in T.parallel(11):\n            for i1, i2 in T.grid(20, 2):\n                cse_var_1: T.int32 = i0 * 40 + i1 * 2 + i2\n                compute_2 = T.Buffer((440,), data=compute.data)\n                compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(440):\n            compute_2 = T.Buffer((440,), data=compute_1.data)\n            compute_2[i0_i1_fused_i2_fused_i3_fused] = T.cos(data_2[i0_i1_fused_i2_fused_i3_fused] + data_3[i0_i1_fused_i2_fused_i3_fused])", "op_args": [11, 20, 2, 1], "input_shape": "[[11, 20, 2, 1], [11, 20, 2, 1], [11, 20, 2, 1]]", "output_shape": "[[11, 20, 2, 1]]"}{"op_name": "softmax_common", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 2; ++i0_i1_fused) {\n    float T_softmax_maxelem[18];\n    float T_softmax_expsum[1];\n    for (int32_t i2 = 0; i2 < 18; ++i2) {\n      T_softmax_maxelem[i2] = -3.402823e+38f;\n      for (int32_t k = 0; k < 4; ++k) {\n        T_softmax_maxelem[i2] = max(T_softmax_maxelem[i2], data[(((i0_i1_fused * 72) + (i2 * 4)) + k)]);\n      }\n    }\n    for (int32_t i2_1 = 0; i2_1 < 18; ++i2_1) {\n      T_softmax_expsum[0] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 4; ++k_1) {\n          int32_t v_ = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 72) + (i2_1 * 4)) + k_1)] - T_softmax_maxelem[i2_1])));\n      }\n      for (int32_t i3_s = 0; i3_s < 4; ++i3_s) {\n          int32_t v__1 = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_norm[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 72) + (i2_1 * 4)) + i3_s)] - T_softmax_maxelem[i2_1])) / T_softmax_expsum[0]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 4; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 4)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(4) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] - T_softmax_maxelem[((int)blockIdx.x)])) / T_softmax_expsum[((int)blockIdx.x)]);\n}\n\nextern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 2)) < 9) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 4; ++k) {\n    if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 2)) < 9) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 64) + (((int)threadIdx.x) * 4)) + k)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 1, 18, 4), \"float32\"), T_softmax_norm: T.Buffer((2, 1, 18, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(2):\n            T_softmax_maxelem = T.allocate([18], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((18,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((144,), data=data.data)\n            for i2 in range(18):\n                T_softmax_maxelem_1[i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(4):\n                    T_softmax_maxelem_1[i2] = T.max(T_softmax_maxelem_1[i2], data_1[i0_i1_fused * 72 + i2 * 4 + k])\n            for i2 in range(18):\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(4):\n                    cse_var_1: T.int32 = i0_i1_fused * 72 + i2 * 4 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[i2])\n                for i3_s in range(4):\n                    cse_var_2: T.int32 = i0_i1_fused * 72 + i2 * 4 + i3_s\n                    T_softmax_norm_1 = T.Buffer((144,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_2] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[i2]) / T_softmax_expsum_1[0]", "op_args": [2, 1, 18, 4], "input_shape": "[[2, 1, 18, 4]]", "output_shape": "[[2, 1, 18, 4]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 17; ++i1) {\n      for (int32_t i2 = 0; i2 < 12; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 3468) + (i1 * 204)) + (i2 * 17)) + i3)] = sqrtf((data[((((i0 * 3468) + (i1 * 204)) + (i2 * 17)) + i3)] + data_1[((((i0 * 3468) + (i1 * 204)) + (i2 * 17)) + i3)]));\n        }\n      }\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 68; ++i0_i1_fused) {\n    for (int32_t i2_1 = 0; i2_1 < 12; ++i2_1) {\n      for (int32_t i3_1 = 0; i3_1 < 17; ++i3_1) {\n        compute_1[(((i0_i1_fused * 204) + (i2_1 * 17)) + i3_1)] = cosf((data[(((i0_i1_fused * 204) + (i2_1 * 17)) + i3_1)] + data_1[(((i0_i1_fused * 204) + (i2_1 * 17)) + i3_1)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]));\n}\n\nextern \"C\" __global__ void __launch_bounds__(6) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 6) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 17, 12, 17), \"float32\"), data_1: T.Buffer((4, 17, 12, 17), \"float32\"), compute: T.Buffer((4, 17, 12, 17), \"float32\"), compute_1: T.Buffer((4, 17, 12, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((13872,), data=data.data)\n        data_3 = T.Buffer((13872,), data=data_1.data)\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(17, 12, 17):\n                cse_var_1: T.int32 = i0 * 3468 + i1 * 204 + i2 * 17 + i3\n                compute_2 = T.Buffer((13872,), data=compute.data)\n                compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i0_i1_fused in T.parallel(68):\n            for i2, i3 in T.grid(12, 17):\n                cse_var_2: T.int32 = i0_i1_fused * 204 + i2 * 17 + i3\n                compute_2 = T.Buffer((13872,), data=compute_1.data)\n                compute_2[cse_var_2] = T.cos(data_2[cse_var_2] + data_3[cse_var_2])", "op_args": [4, 17, 12, 17], "input_shape": "[[4, 17, 12, 17], [4, 17, 12, 17], [4, 17, 12, 17]]", "output_shape": "[[4, 17, 12, 17]]"}{"op_name": "multi_out_op", "c_code": "void default_function_kernel(float* compute, float* compute_1, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 660; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 7; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 7) + i3)] = sqrtf((data[((i0_i1_fused_i2_fused * 7) + i3)] + data_1[((i0_i1_fused_i2_fused * 7) + i3)]));\n    }\n  }\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 60; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 11; ++i2) {\n      for (int32_t i3_1 = 0; i3_1 < 7; ++i3_1) {\n        compute_1[(((i0_i1_fused * 77) + (i2 * 7)) + i3_1)] = cosf((data[(((i0_i1_fused * 77) + (i2 * 7)) + i3_1)] + data_1[(((i0_i1_fused * 77) + (i2 * 7)) + i3_1)]));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 1155) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = __cosf((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(55) default_function_kernel(float* __restrict__ compute, float* __restrict__ data, float* __restrict__ data_1) {\n  compute[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))] = sqrtf((data[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))]));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((10, 6, 11, 7), \"float32\"), data_1: T.Buffer((10, 6, 11, 7), \"float32\"), compute: T.Buffer((10, 6, 11, 7), \"float32\"), compute_1: T.Buffer((10, 6, 11, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        data_2 = T.Buffer((4620,), data=data.data)\n        data_3 = T.Buffer((4620,), data=data_1.data)\n        for i0_i1_fused_i2_fused in T.parallel(660):\n            for i3 in range(7):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 7 + i3\n                compute_2 = T.Buffer((4620,), data=compute.data)\n                compute_2[cse_var_1] = T.sqrt(data_2[cse_var_1] + data_3[cse_var_1])\n        for i0_i1_fused in T.parallel(60):\n            for i2, i3 in T.grid(11, 7):\n                cse_var_2: T.int32 = i0_i1_fused * 77 + i2 * 7 + i3\n                compute_2 = T.Buffer((4620,), data=compute_1.data)\n                compute_2[cse_var_2] = T.cos(data_2[cse_var_2] + data_3[cse_var_2])", "op_args": [10, 6, 11, 7], "input_shape": "[[10, 6, 11, 7], [10, 6, 11, 7], [10, 6, 11, 7]]", "output_shape": "[[10, 6, 11, 7]]"}{"op_name": "softmax_common", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 55; ++i0_i1_fused) {\n    float T_softmax_maxelem[7];\n    float T_softmax_expsum[1];\n    for (int32_t i2 = 0; i2 < 7; ++i2) {\n      T_softmax_maxelem[i2] = -3.402823e+38f;\n      for (int32_t k = 0; k < 6; ++k) {\n        T_softmax_maxelem[i2] = max(T_softmax_maxelem[i2], data[(((i0_i1_fused * 42) + (i2 * 6)) + k)]);\n      }\n    }\n    for (int32_t i2_1 = 0; i2_1 < 7; ++i2_1) {\n      for (int32_t i3 = 0; i3 < 6; ++i3) {\n        T_softmax_expsum[0] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 6; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 42) + (i2_1 * 6)) + k_1)] - T_softmax_maxelem[i2_1])));\n        }\n          int32_t v__1 = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_norm[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 42) + (i2_1 * 6)) + i3)] - T_softmax_maxelem[i2_1])) / T_softmax_expsum[0]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) < 1155) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + (((int)threadIdx.x) >> 1)) / 3)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) < 385) {\n    T_softmax_expsum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 6; ++k) {\n    if (((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) < 385) {\n        int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_softmax_expsum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 384) + (((int)threadIdx.x) * 6)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))])));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 385) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 6; ++k) {\n    if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 385) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 192) + (((int)threadIdx.x) * 6)) + k)]);\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((5, 11, 7, 6), \"float32\"), T_softmax_norm: T.Buffer((5, 11, 7, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(55):\n            T_softmax_maxelem = T.allocate([7], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((7,), data=T_softmax_maxelem, align=16)\n            data_1 = T.Buffer((2310,), data=data.data)\n            for i2 in range(7):\n                T_softmax_maxelem_1[i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(6):\n                    T_softmax_maxelem_1[i2] = T.max(T_softmax_maxelem_1[i2], data_1[i0_i1_fused * 42 + i2 * 6 + k])\n            for i2, i3 in T.grid(7, 6):\n                cse_var_1: T.int32 = i0_i1_fused * 42 + i2 * 6 + i3\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(6):\n                    cse_var_2: T.int32 = i0_i1_fused * 42 + i2 * 6 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[i2])\n                T_softmax_norm_1 = T.Buffer((2310,), data=T_softmax_norm.data)\n                T_softmax_norm_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[i2]) / T_softmax_expsum_1[0]", "op_args": [5, 11, 7, 6], "input_shape": "[[5, 11, 7, 6]]", "output_shape": "[[5, 11, 7, 6]]"}{"op_name": "softmax_common", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 76; ++i0_i1_fused) {\n    float T_softmax_maxelem[4];\n    float T_softmax_expsum[4];\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      T_softmax_maxelem[i2] = -3.402823e+38f;\n      for (int32_t k = 0; k < 9; ++k) {\n        T_softmax_maxelem[i2] = max(T_softmax_maxelem[i2], data[(((i0_i1_fused * 36) + (i2 * 9)) + k)]);\n      }\n    }\n    for (int32_t i2_1 = 0; i2_1 < 4; ++i2_1) {\n      T_softmax_expsum[i2_1] = 0.000000e+00f;\n      for (int32_t k_1 = 0; k_1 < 9; ++k_1) {\n          int32_t v_ = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_expsum[i2_1] = (T_softmax_expsum[i2_1] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 36) + (i2_1 * 9)) + k_1)] - T_softmax_maxelem[i2_1])));\n      }\n    }\n    for (int32_t i2_2 = 0; i2_2 < 4; ++i2_2) {\n      for (int32_t i3_s = 0; i3_s < 9; ++i3_s) {\n          int32_t v__1 = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_norm[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 36) + (i2_2 * 9)) + i3_s)] - T_softmax_maxelem[i2_2])) / T_softmax_expsum[i2_2]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 9; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 9; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 18) + (((int)threadIdx.x) * 9)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 171) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 9)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 19, 4, 9), \"float32\"), T_softmax_norm: T.Buffer((4, 19, 4, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(76):\n            T_softmax_maxelem = T.allocate([4], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([4], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((4,), data=T_softmax_maxelem, align=16)\n            data_1 = T.Buffer((2736,), data=data.data)\n            for i2 in range(4):\n                T_softmax_maxelem_1[i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(9):\n                    T_softmax_maxelem_1[i2] = T.max(T_softmax_maxelem_1[i2], data_1[i0_i1_fused * 36 + i2 * 9 + k])\n            T_softmax_expsum_1 = T.Buffer((4,), data=T_softmax_expsum, align=16)\n            for i2 in range(4):\n                T_softmax_expsum_1[i2] = T.float32(0)\n                for k in range(9):\n                    cse_var_1: T.int32 = i0_i1_fused * 36 + i2 * 9 + k\n                    T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[i2])\n            for i2, i3_s in T.grid(4, 9):\n                cse_var_2: T.int32 = i0_i1_fused * 36 + i2 * 9 + i3_s\n                T_softmax_norm_1 = T.Buffer((2736,), data=T_softmax_norm.data)\n                T_softmax_norm_1[cse_var_2] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[i2]) / T_softmax_expsum_1[i2]", "op_args": [4, 19, 4, 9], "input_shape": "[[4, 19, 4, 9]]", "output_shape": "[[4, 19, 4, 9]]"}{"op_name": "softmax_common", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 30; ++i0_i1_fused) {\n    float T_softmax_maxelem[8];\n    float T_softmax_expsum[1];\n    for (int32_t i2 = 0; i2 < 8; ++i2) {\n      T_softmax_maxelem[i2] = -3.402823e+38f;\n      for (int32_t k = 0; k < 11; ++k) {\n        T_softmax_maxelem[i2] = max(T_softmax_maxelem[i2], data[(((i0_i1_fused * 88) + (i2 * 11)) + k)]);\n      }\n    }\n    for (int32_t i2_1 = 0; i2_1 < 8; ++i2_1) {\n      for (int32_t i3 = 0; i3 < 11; ++i3) {\n        T_softmax_expsum[0] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 11; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 88) + (i2_1 * 11)) + k_1)] - T_softmax_maxelem[i2_1])));\n        }\n          int32_t v__1 = ((int32_t)(floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n        T_softmax_norm[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((i0_i1_fused * 88) + (i2_1 * 11)) + i3)] - T_softmax_maxelem[i2_1])) / T_softmax_expsum[0]);\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 11; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 176) + (((int)threadIdx.x) * 11)) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 165) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 11)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(24) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 11; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 264) + (((int)threadIdx.x) * 11)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))])));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 5, 8, 11), \"float32\"), T_softmax_norm: T.Buffer((6, 5, 8, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(30):\n            T_softmax_maxelem = T.allocate([8], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((8,), data=T_softmax_maxelem, align=32)\n            data_1 = T.Buffer((2640,), data=data.data)\n            for i2 in range(8):\n                T_softmax_maxelem_1[i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(11):\n                    T_softmax_maxelem_1[i2] = T.max(T_softmax_maxelem_1[i2], data_1[i0_i1_fused * 88 + i2 * 11 + k])\n            for i2, i3 in T.grid(8, 11):\n                cse_var_1: T.int32 = i0_i1_fused * 88 + i2 * 11 + i3\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(11):\n                    cse_var_2: T.int32 = i0_i1_fused * 88 + i2 * 11 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[i2])\n                T_softmax_norm_1 = T.Buffer((2640,), data=T_softmax_norm.data)\n                T_softmax_norm_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[i2], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[i2]) / T_softmax_expsum_1[0]", "op_args": [6, 5, 8, 11], "input_shape": "[[6, 5, 8, 11]]", "output_shape": "[[6, 5, 8, 11]]"}{"op_name": "softmax_common", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    float T_softmax_maxelem[270];\n    float T_softmax_expsum[15];\n    for (int32_t i1 = 0; i1 < 18; ++i1) {\n      for (int32_t i2 = 0; i2 < 15; ++i2) {\n        T_softmax_maxelem[((i1 * 15) + i2)] = -3.402823e+38f;\n        for (int32_t k = 0; k < 10; ++k) {\n          T_softmax_maxelem[((i1 * 15) + i2)] = max(T_softmax_maxelem[((i1 * 15) + i2)], data[((((i0 * 2700) + (i1 * 150)) + (i2 * 10)) + k)]);\n        }\n      }\n    }\n    for (int32_t i1_1 = 0; i1_1 < 18; ++i1_1) {\n      for (int32_t i2_1 = 0; i2_1 < 15; ++i2_1) {\n        T_softmax_expsum[i2_1] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 10; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[i2_1] = (T_softmax_expsum[i2_1] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 2700) + (i1_1 * 150)) + (i2_1 * 10)) + k_1)] - T_softmax_maxelem[((i1_1 * 15) + i2_1)])));\n        }\n      }\n      for (int32_t i2_2 = 0; i2_2 < 15; ++i2_2) {\n        for (int32_t i3_s = 0; i3_s < 10; ++i3_s) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 2700) + (i1_1 * 150)) + (i2_2 * 10)) + i3_s)] - T_softmax_maxelem[((i1_1 * 15) + i2_2)])) / T_softmax_expsum[i2_2]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 10; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 40) + (((int)threadIdx.x) * 10)) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(2) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 10; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 20) + (((int)threadIdx.x) * 10)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(50) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))])) / T_softmax_expsum[((((int)blockIdx.x) * 5) + (((int)threadIdx.x) / 10))]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 18, 15, 10), \"float32\"), T_softmax_norm: T.Buffer((4, 18, 15, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            T_softmax_maxelem = T.allocate([270], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([15], \"float32\", \"global\")\n            T_softmax_maxelem_1 = T.Buffer((270,), data=T_softmax_maxelem)\n            data_1 = T.Buffer((10800,), data=data.data)\n            for i1, i2 in T.grid(18, 15):\n                T_softmax_maxelem_1[i1 * 15 + i2] = T.float32(-3.4028234663852886e+38)\n                for k in range(10):\n                    cse_var_1: T.int32 = i1 * 15 + i2\n                    T_softmax_maxelem_1[cse_var_1] = T.max(T_softmax_maxelem_1[cse_var_1], data_1[i0 * 2700 + i1 * 150 + i2 * 10 + k])\n            for i1 in range(18):\n                T_softmax_expsum_1 = T.Buffer((15,), data=T_softmax_expsum, align=32)\n                for i2 in range(15):\n                    T_softmax_expsum_1[i2] = T.float32(0)\n                    for k in range(10):\n                        cse_var_3: T.int32 = i1 * 15 + i2\n                        cse_var_2: T.int32 = i0 * 2700 + i1 * 150 + i2 * 10 + k\n                        T_softmax_expsum_1[i2] = T_softmax_expsum_1[i2] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[cse_var_3])\n                for i2, i3_s in T.grid(15, 10):\n                    cse_var_5: T.int32 = i1 * 15 + i2\n                    cse_var_4: T.int32 = i0 * 2700 + i1 * 150 + i2 * 10 + i3_s\n                    T_softmax_norm_1 = T.Buffer((10800,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_4] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_4] - T_softmax_maxelem_1[cse_var_5]) / T_softmax_expsum_1[i2]", "op_args": [4, 18, 15, 10], "input_shape": "[[4, 18, 15, 10]]", "output_shape": "[[4, 18, 15, 10]]"}{"op_name": "softmax_common", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i1 = 0; i1 < 20; ++i1) {\n      for (int32_t i2 = 0; i2 < 15; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          T_softmax_maxelem[0] = -3.402823e+38f;\n          for (int32_t k = 0; k < 17; ++k) {\n            T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k)]);\n          }\n          T_softmax_expsum[0] = 0.000000e+00f;\n          for (int32_t k_1 = 0; k_1 < 17; ++k_1) {\n              int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n            T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + k_1)] - T_softmax_maxelem[0])));\n          }\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 5100) + (i1 * 255)) + (i2 * 17)) + i3)] - T_softmax_maxelem[0])) / T_softmax_expsum[0]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 17; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 68) + (((int)threadIdx.x) * 17)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 16575) {\n      int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 17)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 17; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 204) + (((int)threadIdx.x) * 17)) + k)]);\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 20, 15, 17), \"float32\"), T_softmax_norm: T.Buffer((13, 20, 15, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i1, i2, i3 in T.grid(20, 15, 17):\n                cse_var_1: T.int32 = i0 * 5100 + i1 * 255 + i2 * 17 + i3\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((66300,), data=data.data)\n                for k in range(17):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0 * 5100 + i1 * 255 + i2 * 17 + k])\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(17):\n                    cse_var_2: T.int32 = i0 * 5100 + i1 * 255 + i2 * 17 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[0])\n                T_softmax_norm_1 = T.Buffer((66300,), data=T_softmax_norm.data)\n                T_softmax_norm_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[0]) / T_softmax_expsum_1[0]", "op_args": [13, 20, 15, 17], "input_shape": "[[13, 20, 15, 17]]", "output_shape": "[[13, 20, 15, 17]]"}{"op_name": "softmax_common", "c_code": "void default_function_kernel(float* T_softmax_norm, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 9; ++i0) {\n    float T_softmax_maxelem[1];\n    float T_softmax_expsum[1];\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 16; ++i2) {\n        T_softmax_maxelem[0] = -3.402823e+38f;\n        for (int32_t k = 0; k < 5; ++k) {\n          T_softmax_maxelem[0] = max(T_softmax_maxelem[0], data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k)]);\n        }\n        T_softmax_expsum[0] = 0.000000e+00f;\n        for (int32_t k_1 = 0; k_1 < 5; ++k_1) {\n            int32_t v_ = ((int32_t)(floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_expsum[0] = (T_softmax_expsum[0] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + k_1)] - T_softmax_maxelem[0])));\n        }\n        for (int32_t i3 = 0; i3 < 5; ++i3) {\n            int32_t v__1 = ((int32_t)(floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_softmax_norm[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] = (max(((*(float *)(&(v__1))) * ((((((((((((((1.987569e-04f * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((i0 * 160) + (i1 * 80)) + (i2 * 5)) + i3)] - T_softmax_maxelem[0])) / T_softmax_expsum[0]);\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;\n  for (int k = 0; k < 5; ++k) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[(((((int)blockIdx.x) * 160) + (((int)threadIdx.x) * 5)) + k)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(48) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {\n  T_softmax_expsum[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k = 0; k < 5; ++k) {\n      int v_ = ((int)(floorf(((max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n    T_softmax_expsum[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] + max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[(((((int)blockIdx.x) * 240) + (((int)threadIdx.x) * 5)) + k)] - T_softmax_maxelem[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))])));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_softmax_norm[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]), 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), (data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] - T_softmax_maxelem[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)])) / T_softmax_expsum[(((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 5)]);\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 2, 16, 5), \"float32\"), T_softmax_norm: T.Buffer((9, 2, 16, 5), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(9):\n            T_softmax_maxelem = T.allocate([1], \"float32\", \"global\")\n            T_softmax_expsum = T.allocate([1], \"float32\", \"global\")\n            for i1, i2 in T.grid(2, 16):\n                T_softmax_maxelem_1 = T.Buffer((1,), data=T_softmax_maxelem, align=4)\n                T_softmax_maxelem_1[0] = T.float32(-3.4028234663852886e+38)\n                data_1 = T.Buffer((1440,), data=data.data)\n                for k in range(5):\n                    T_softmax_maxelem_1[0] = T.max(T_softmax_maxelem_1[0], data_1[i0 * 160 + i1 * 80 + i2 * 5 + k])\n                T_softmax_expsum_1 = T.Buffer((1,), data=T_softmax_expsum, align=4)\n                T_softmax_expsum_1[0] = T.float32(0)\n                for k in range(5):\n                    cse_var_1: T.int32 = i0 * 160 + i1 * 80 + i2 * 5 + k\n                    T_softmax_expsum_1[0] = T_softmax_expsum_1[0] + T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1] - T_softmax_maxelem_1[0])\n                for i3 in range(5):\n                    cse_var_2: T.int32 = i0 * 160 + i1 * 80 + i2 * 5 + i3\n                    T_softmax_norm_1 = T.Buffer((1440,), data=T_softmax_norm.data)\n                    T_softmax_norm_1[cse_var_2] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_2] - T_softmax_maxelem_1[0], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_2] - T_softmax_maxelem_1[0]) / T_softmax_expsum_1[0]", "op_args": [9, 2, 16, 5], "input_shape": "[[9, 2, 16, 5]]", "output_shape": "[[9, 2, 16, 5]]"}{"op_name": "space_to_depth", "c_code": "void default_function_kernel(float* data, float* space_to_depth) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 648; ++i0_i1_fused_i2_fused_i3_fused) {\n    space_to_depth[i0_i1_fused_i2_fused_i3_fused] = data[((((((i0_i1_fused_i2_fused_i3_fused / 36) * 36) + ((((i0_i1_fused_i2_fused_i3_fused % 36) / 3) % 3) * 12)) + ((((i0_i1_fused_i2_fused_i3_fused % 36) / 3) / 6) * 6)) + ((i0_i1_fused_i2_fused_i3_fused % 3) * 2)) + ((((i0_i1_fused_i2_fused_i3_fused % 36) / 3) % 6) / 3))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ data, float* __restrict__ space_to_depth) {\n  space_to_depth[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = data[((((((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 2)) / 9) * 36) + ((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 36) / 3) % 3) * 12)) + ((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 36) / 3) / 6) * 6)) + ((((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 3) * 2)) + ((((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 36) / 3) % 6) / 3))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 3, 2, 6), \"float32\"), space_to_depth: T.Buffer((18, 12, 1, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(648):\n            cse_var_1: T.int32 = i0_i1_fused_i2_fused_i3_fused % 36 // 3\n            space_to_depth_1 = T.Buffer((648,), data=space_to_depth.data)\n            data_1 = T.Buffer((648,), data=data.data)\n            space_to_depth_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 36 * 36 + T.truncmod(cse_var_1, 3) * 12 + T.Div(cse_var_1, 6) * 6 + i0_i1_fused_i2_fused_i3_fused % 3 * 2 + T.Div(T.truncmod(cse_var_1, 6), 3)]", "op_args": [18, 3, 1, 3], "input_shape": "[[18, 3, 2, 6]]", "output_shape": "[[18, 12, 1, 3]]"}{"op_name": "space_to_depth", "c_code": "void default_function_kernel(float* data, float* space_to_depth) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1584; ++i0_i1_fused_i2_fused_i3_fused) {\n    space_to_depth[i0_i1_fused_i2_fused_i3_fused] = data[((((((i0_i1_fused_i2_fused_i3_fused / 144) * 144) + ((((i0_i1_fused_i2_fused_i3_fused % 144) / 12) % 3) * 48)) + ((((i0_i1_fused_i2_fused_i3_fused % 144) / 12) / 6) * 24)) + ((i0_i1_fused_i2_fused_i3_fused % 12) * 2)) + ((((i0_i1_fused_i2_fused_i3_fused % 144) / 12) % 6) / 3))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(12) default_function_kernel(float* __restrict__ data, float* __restrict__ space_to_depth) {\n  space_to_depth[((((int)blockIdx.x) * 12) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) / 12) * 144) + (((((int)blockIdx.x) % 12) % 3) * 48)) + (((((int)blockIdx.x) % 12) / 6) * 24)) + (((int)threadIdx.x) * 2)) + (((((int)blockIdx.x) % 12) % 6) / 3))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 3, 2, 24), \"float32\"), space_to_depth: T.Buffer((11, 12, 1, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1584):\n            cse_var_1: T.int32 = i0_i1_fused_i2_fused_i3_fused % 144 // 12\n            space_to_depth_1 = T.Buffer((1584,), data=space_to_depth.data)\n            data_1 = T.Buffer((1584,), data=data.data)\n            space_to_depth_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 144 * 144 + T.truncmod(cse_var_1, 3) * 48 + T.Div(cse_var_1, 6) * 24 + i0_i1_fused_i2_fused_i3_fused % 12 * 2 + T.Div(T.truncmod(cse_var_1, 6), 3)]", "op_args": [11, 3, 1, 12], "input_shape": "[[11, 3, 2, 24]]", "output_shape": "[[11, 12, 1, 12]]"}{"op_name": "space_to_depth", "c_code": "void default_function_kernel(float* data, float* space_to_depth) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1568; ++i0_i1_fused_i2_fused_i3_fused) {\n    space_to_depth[i0_i1_fused_i2_fused_i3_fused] = data[(((((((i0_i1_fused_i2_fused_i3_fused / 224) * 224) + ((((i0_i1_fused_i2_fused_i3_fused % 224) / 28) % 2) * 112)) + (((i0_i1_fused_i2_fused_i3_fused % 28) / 7) * 28)) + ((((i0_i1_fused_i2_fused_i3_fused % 224) / 28) / 4) * 14)) + ((i0_i1_fused_i2_fused_i3_fused % 7) * 2)) + ((((i0_i1_fused_i2_fused_i3_fused % 224) / 28) % 4) / 2))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ data, float* __restrict__ space_to_depth) {\n  space_to_depth[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = data[(((((((((int)blockIdx.x) >> 3) * 224) + (((((int)blockIdx.x) & 7) % 2) * 112)) + ((((int)threadIdx.x) / 7) * 28)) + (((((int)blockIdx.x) & 7) / 4) * 14)) + ((((int)threadIdx.x) % 7) * 2)) + (((((int)blockIdx.x) & 7) % 4) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 2, 8, 14), \"float32\"), space_to_depth: T.Buffer((7, 8, 4, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1568):\n            cse_var_1: T.int32 = i0_i1_fused_i2_fused_i3_fused % 224 // 28\n            space_to_depth_1 = T.Buffer((1568,), data=space_to_depth.data)\n            data_1 = T.Buffer((1568,), data=data.data)\n            space_to_depth_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 224 * 224 + T.truncmod(cse_var_1, 2) * 112 + i0_i1_fused_i2_fused_i3_fused % 28 // 7 * 28 + T.Div(cse_var_1, 4) * 14 + i0_i1_fused_i2_fused_i3_fused % 7 * 2 + T.Div(T.truncmod(cse_var_1, 4), 2)]", "op_args": [7, 2, 4, 7], "input_shape": "[[7, 2, 8, 14]]", "output_shape": "[[7, 8, 4, 7]]"}{"op_name": "strided_slice", "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 105; ++ax0_ax1_fused_ax2_fused) {\n    T_strided_slice[ax0_ax1_fused_ax2_fused] = a[(((((ax0_ax1_fused_ax2_fused / 35) * 105) + (((ax0_ax1_fused_ax2_fused % 35) / 7) * 15)) + (ax0_ax1_fused_ax2_fused % 7)) + 138)];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  T_strided_slice[((int)blockIdx.x)] = a[(((((((int)blockIdx.x) / 35) * 105) + (((((int)blockIdx.x) % 35) / 7) * 15)) + (((int)blockIdx.x) % 7)) + 138)];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((20, 7, 15), \"float32\"), T_strided_slice: T.Buffer((3, 5, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(105):\n            T_strided_slice_1 = T.Buffer((105,), data=T_strided_slice.data)\n            a_1 = T.Buffer((2100,), data=a.data)\n            T_strided_slice_1[ax0_ax1_fused_ax2_fused] = a_1[ax0_ax1_fused_ax2_fused // 35 * 105 + ax0_ax1_fused_ax2_fused % 35 // 7 * 15 + ax0_ax1_fused_ax2_fused % 7 + 138]", "op_args": [7, 20, 7, 15], "input_shape": "[[20, 7, 15]]", "output_shape": "[[3, 5, 7]]"}{"op_name": "strided_slice", "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 15; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n      T_strided_slice[((ax0_ax1_fused * 7) + ax2)] = a[(((((ax0_ax1_fused / 5) * 200) + ((ax0_ax1_fused % 5) * 20)) + ax2) + 243)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  T_strided_slice[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = a[((((((int)blockIdx.x) * 200) + ((((int)threadIdx.x) / 7) * 20)) + (((int)threadIdx.x) % 7)) + 243)];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((6, 10, 20), \"float32\"), T_strided_slice: T.Buffer((3, 5, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(15):\n            for ax2 in range(7):\n                T_strided_slice_1 = T.Buffer((105,), data=T_strided_slice.data)\n                a_1 = T.Buffer((1200,), data=a.data)\n                T_strided_slice_1[ax0_ax1_fused * 7 + ax2] = a_1[ax0_ax1_fused // 5 * 200 + ax0_ax1_fused % 5 * 20 + ax2 + 243]", "op_args": [10, 6, 10, 20], "input_shape": "[[6, 10, 20]]", "output_shape": "[[3, 5, 7]]"}{"op_name": "strided_slice", "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 12; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n      T_strided_slice[((ax0_ax1_fused * 7) + ax2)] = a[(((((ax0_ax1_fused >> 2) * 90) + ((ax0_ax1_fused & 3) * 15)) + ax2) + 123)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(42) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  T_strided_slice[((((int)blockIdx.x) * 42) + ((int)threadIdx.x))] = a[(((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 14)) >> 1) * 90) + ((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 7)) & 3) * 15)) + (((int)threadIdx.x) % 7)) + 123)];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((20, 6, 15), \"float32\"), T_strided_slice: T.Buffer((3, 4, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(12):\n            for ax2 in range(7):\n                T_strided_slice_1 = T.Buffer((84,), data=T_strided_slice.data)\n                a_1 = T.Buffer((1800,), data=a.data)\n                T_strided_slice_1[ax0_ax1_fused * 7 + ax2] = a_1[ax0_ax1_fused // 4 * 90 + ax0_ax1_fused % 4 * 15 + ax2 + 123]", "op_args": [8, 20, 6, 15], "input_shape": "[[20, 6, 15]]", "output_shape": "[[3, 4, 7]]"}{"op_name": "strided_slice", "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 12; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n      T_strided_slice[((ax0_ax1_fused * 7) + ax2)] = a[(((((ax0_ax1_fused >> 2) * 102) + ((ax0_ax1_fused & 3) * 17)) + ax2) + 139)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(21) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  T_strided_slice[((((int)blockIdx.x) * 21) + ((int)threadIdx.x))] = a[(((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 7)) >> 2) * 102) + ((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 7)) & 3) * 17)) + (((int)threadIdx.x) % 7)) + 139)];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((11, 6, 17), \"float32\"), T_strided_slice: T.Buffer((3, 4, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(12):\n            for ax2 in range(7):\n                T_strided_slice_1 = T.Buffer((84,), data=T_strided_slice.data)\n                a_1 = T.Buffer((1122,), data=a.data)\n                T_strided_slice_1[ax0_ax1_fused * 7 + ax2] = a_1[ax0_ax1_fused // 4 * 102 + ax0_ax1_fused % 4 * 17 + ax2 + 139]", "op_args": [19, 11, 6, 17], "input_shape": "[[11, 6, 17]]", "output_shape": "[[3, 4, 7]]"}{"op_name": "strided_slice", "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 3; ++ax0) {\n    for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n      T_strided_slice[((ax0 * 7) + ax2)] = a[(((ax0 * 39) + ax2) + 68)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(21) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  T_strided_slice[((int)threadIdx.x)] = a[((((((int)threadIdx.x) / 7) * 39) + (((int)threadIdx.x) % 7)) + 68)];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((12, 3, 13), \"float32\"), T_strided_slice: T.Buffer((3, 1, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(3):\n            for ax2 in range(7):\n                T_strided_slice_1 = T.Buffer((21,), data=T_strided_slice.data)\n                a_1 = T.Buffer((468,), data=a.data)\n                T_strided_slice_1[ax0 * 7 + ax2] = a_1[ax0 * 39 + ax2 + 68]", "op_args": [10, 12, 3, 13], "input_shape": "[[12, 3, 13]]", "output_shape": "[[3, 1, 7]]"}{"op_name": "strided_slice", "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  for (int32_t ax1 = 0; ax1 < 5; ++ax1) {\n    for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n      T_strided_slice[((ax1 * 7) + ax2)] = a[(((ax1 * 15) + ax2) + 183)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  T_strided_slice[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = a[(((((int)blockIdx.x) * 15) + ((int)threadIdx.x)) + 183)];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((2, 10, 15), \"float32\"), T_strided_slice: T.Buffer((1, 5, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax1, ax2 in T.grid(5, 7):\n            T_strided_slice_1 = T.Buffer((35,), data=T_strided_slice.data)\n            a_1 = T.Buffer((300,), data=a.data)\n            T_strided_slice_1[ax1 * 7 + ax2] = a_1[ax1 * 15 + ax2 + 183]", "op_args": [1, 2, 10, 15], "input_shape": "[[2, 10, 15]]", "output_shape": "[[1, 5, 7]]"}{"op_name": "strided_slice", "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 21; ++ax0_ax1_fused_ax2_fused) {\n    T_strided_slice[ax0_ax1_fused_ax2_fused] = a[((((ax0_ax1_fused_ax2_fused / 7) * 45) + (ax0_ax1_fused_ax2_fused % 7)) + 78)];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(21) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  T_strided_slice[((int)threadIdx.x)] = a[((((((int)threadIdx.x) / 7) * 45) + (((int)threadIdx.x) % 7)) + 78)];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((4, 3, 15), \"float32\"), T_strided_slice: T.Buffer((3, 1, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(21):\n            T_strided_slice_1 = T.Buffer((21,), data=T_strided_slice.data)\n            a_1 = T.Buffer((180,), data=a.data)\n            T_strided_slice_1[ax0_ax1_fused_ax2_fused] = a_1[ax0_ax1_fused_ax2_fused // 7 * 45 + ax0_ax1_fused_ax2_fused % 7 + 78]", "op_args": [16, 4, 3, 15], "input_shape": "[[4, 3, 15]]", "output_shape": "[[3, 1, 7]]"}{"op_name": "strided_slice", "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 3; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 5; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n        T_strided_slice[(((ax0 * 35) + (ax1 * 7)) + ax2)] = a[((((ax0 * 168) + (ax1 * 12)) + ax2) + 195)];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 3)) < 35) {\n    T_strided_slice[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = a[(((((((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) / 35) * 168) + (((((((int)blockIdx.x) * 24) + ((int)threadIdx.x)) % 35) / 7) * 12)) + (((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) % 7)) + 195)];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((4, 14, 12), \"float32\"), T_strided_slice: T.Buffer((3, 5, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(3):\n            for ax1, ax2 in T.grid(5, 7):\n                T_strided_slice_1 = T.Buffer((105,), data=T_strided_slice.data)\n                a_1 = T.Buffer((672,), data=a.data)\n                T_strided_slice_1[ax0 * 35 + ax1 * 7 + ax2] = a_1[ax0 * 168 + ax1 * 12 + ax2 + 195]", "op_args": [7, 4, 14, 12], "input_shape": "[[4, 14, 12]]", "output_shape": "[[3, 5, 7]]"}{"op_name": "strided_slice", "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 15; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n      T_strided_slice[((ax0_ax1_fused * 2) + ax2)] = a[(((((ax0_ax1_fused / 5) * 40) + ((ax0_ax1_fused % 5) * 5)) + ax2) + 53)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(30) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  T_strided_slice[((int)threadIdx.x)] = a[(((((((int)threadIdx.x) / 10) * 40) + (((((int)threadIdx.x) % 10) >> 1) * 5)) + (((int)threadIdx.x) & 1)) + 53)];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((17, 8, 5), \"float32\"), T_strided_slice: T.Buffer((3, 5, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(15):\n            for ax2 in range(2):\n                T_strided_slice_1 = T.Buffer((30,), data=T_strided_slice.data)\n                a_1 = T.Buffer((680,), data=a.data)\n                T_strided_slice_1[ax0_ax1_fused * 2 + ax2] = a_1[ax0_ax1_fused // 5 * 40 + ax0_ax1_fused % 5 * 5 + ax2 + 53]", "op_args": [9, 17, 8, 5], "input_shape": "[[17, 8, 5]]", "output_shape": "[[3, 5, 2]]"}{"op_name": "strided_slice", "c_code": "void default_function_kernel(float* T_strided_slice, float* a) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 15; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n      T_strided_slice[((ax0_ax1_fused * 7) + ax2)] = a[(((((ax0_ax1_fused / 5) * 140) + ((ax0_ax1_fused % 5) * 10)) + ax2) + 163)];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_strided_slice, float* __restrict__ a) {\n  if (((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) < 105) {\n    T_strided_slice[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = a[(((((((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) / 35) * 140) + (((((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) % 35) / 7) * 10)) + (((((int)blockIdx.x) * 2) + ((int)threadIdx.x)) % 7)) + 163)];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(a: T.Buffer((11, 14, 10), \"float32\"), T_strided_slice: T.Buffer((3, 5, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(15):\n            for ax2 in range(7):\n                T_strided_slice_1 = T.Buffer((105,), data=T_strided_slice.data)\n                a_1 = T.Buffer((1540,), data=a.data)\n                T_strided_slice_1[ax0_ax1_fused * 7 + ax2] = a_1[ax0_ax1_fused // 5 * 140 + ax0_ax1_fused % 5 * 10 + ax2 + 163]", "op_args": [14, 11, 14, 10], "input_shape": "[[11, 14, 10]]", "output_shape": "[[3, 5, 7]]"}{"op_name": "unpack_NCHWc_to_nchw", "c_code": "void default_function_kernel(float* output_unpack, float* packed_out) {\n  #pragma omp parallel for\n  for (int32_t n_c_fused_h_fused_w_fused = 0; n_c_fused_h_fused_w_fused < 1400; ++n_c_fused_h_fused_w_fused) {\n    output_unpack[n_c_fused_h_fused_w_fused] = packed_out[((((n_c_fused_h_fused_w_fused / 200) * 200) + ((n_c_fused_h_fused_w_fused % 100) * 2)) + ((n_c_fused_h_fused_w_fused % 200) / 100))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ output_unpack, float* __restrict__ packed_out) {\n  if (((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) < 175) {\n    output_unpack[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = packed_out[((((((((int)blockIdx.x) * 6) + (((int)threadIdx.x) >> 3)) / 25) * 200) + ((((((int)blockIdx.x) * 48) + ((int)threadIdx.x)) % 100) * 2)) + ((((((int)blockIdx.x) * 12) + (((int)threadIdx.x) >> 2)) % 50) / 25))];\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(packed_out: T.Buffer((7, 1, 5, 20, 2), \"float32\"), output_unpack: T.Buffer((7, 2, 5, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for n_c_fused_h_fused_w_fused in T.parallel(1400):\n            output_unpack_1 = T.Buffer((1400,), data=output_unpack.data)\n            packed_out_1 = T.Buffer((1400,), data=packed_out.data)\n            output_unpack_1[n_c_fused_h_fused_w_fused] = packed_out_1[n_c_fused_h_fused_w_fused // 200 * 200 + n_c_fused_h_fused_w_fused % 100 * 2 + n_c_fused_h_fused_w_fused % 200 // 100]", "op_args": [7, 1, 5, 20], "input_shape": "[[7, 1, 5, 20, 2]]", "output_shape": "[[7, 2, 5, 20]]"}{"op_name": "unpack_NCHWc_to_nchw", "c_code": "void default_function_kernel(float* output_unpack, float* packed_out) {\n  for (int32_t c = 0; c < 4; ++c) {\n    for (int32_t w = 0; w < 13; ++w) {\n      output_unpack[((c * 13) + w)] = packed_out[((((c >> 1) * 26) + (w * 2)) + (c & 1))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ output_unpack, float* __restrict__ packed_out) {\n  output_unpack[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = packed_out[((((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 1)) / 13) * 26) + ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 13) * 2)) + ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 26) / 13))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(packed_out: T.Buffer((1, 2, 1, 13, 2), \"float32\"), output_unpack: T.Buffer((1, 4, 1, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for c, w in T.grid(4, 13):\n            output_unpack_1 = T.Buffer((52,), data=output_unpack.data)\n            packed_out_1 = T.Buffer((52,), data=packed_out.data)\n            output_unpack_1[c * 13 + w] = packed_out_1[c // 2 * 26 + w * 2 + c % 2]", "op_args": [1, 2, 1, 13], "input_shape": "[[1, 2, 1, 13, 2]]", "output_shape": "[[1, 4, 1, 13]]"}{"op_name": "unpack_NCHWc_to_nchw", "c_code": "void default_function_kernel(float* output_unpack, float* packed_out) {\n  #pragma omp parallel for\n  for (int32_t n_c_fused = 0; n_c_fused < 144; ++n_c_fused) {\n    for (int32_t w = 0; w < 10; ++w) {\n      output_unpack[((n_c_fused * 10) + w)] = packed_out[((((n_c_fused >> 1) * 20) + (w * 2)) + (n_c_fused & 1))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel(float* __restrict__ output_unpack, float* __restrict__ packed_out) {\n  output_unpack[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = packed_out[((((((int)blockIdx.x) * 40) + ((((int)threadIdx.x) / 20) * 20)) + ((((int)threadIdx.x) % 10) * 2)) + ((((int)threadIdx.x) % 20) / 10))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(packed_out: T.Buffer((8, 9, 1, 10, 2), \"float32\"), output_unpack: T.Buffer((8, 18, 1, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for n_c_fused in T.parallel(144):\n            for w in range(10):\n                output_unpack_1 = T.Buffer((1440,), data=output_unpack.data)\n                packed_out_1 = T.Buffer((1440,), data=packed_out.data)\n                output_unpack_1[n_c_fused * 10 + w] = packed_out_1[n_c_fused // 2 * 20 + w * 2 + n_c_fused % 2]", "op_args": [8, 9, 1, 10], "input_shape": "[[8, 9, 1, 10, 2]]", "output_shape": "[[8, 18, 1, 10]]"}{"op_name": "unpack_NCHWc_to_nchw", "c_code": "void default_function_kernel(float* output_unpack, float* packed_out) {\n  #pragma omp parallel for\n  for (int32_t n_c_fused_h_fused = 0; n_c_fused_h_fused < 504; ++n_c_fused_h_fused) {\n    for (int32_t w = 0; w < 8; ++w) {\n      output_unpack[((n_c_fused_h_fused * 8) + w)] = packed_out[(((((n_c_fused_h_fused / 24) * 192) + ((n_c_fused_h_fused % 12) * 16)) + (w * 2)) + ((n_c_fused_h_fused % 24) / 12))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ output_unpack, float* __restrict__ packed_out) {\n  output_unpack[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = packed_out[(((((((int)blockIdx.x) / 3) * 192) + ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) % 12) * 16)) + ((((int)threadIdx.x) & 7) * 2)) + ((((((int)blockIdx.x) % 3) * 2) + (((int)threadIdx.x) >> 5)) / 3))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(packed_out: T.Buffer((3, 7, 12, 8, 2), \"float32\"), output_unpack: T.Buffer((3, 14, 12, 8), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for n_c_fused_h_fused in T.parallel(504):\n            for w in range(8):\n                output_unpack_1 = T.Buffer((4032,), data=output_unpack.data)\n                packed_out_1 = T.Buffer((4032,), data=packed_out.data)\n                output_unpack_1[n_c_fused_h_fused * 8 + w] = packed_out_1[n_c_fused_h_fused // 24 * 192 + n_c_fused_h_fused % 12 * 16 + w * 2 + n_c_fused_h_fused % 24 // 12]", "op_args": [3, 7, 12, 8], "input_shape": "[[3, 7, 12, 8, 2]]", "output_shape": "[[3, 14, 12, 8]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 2508; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 24; ++i3) {\n      resize[((i0_i1_fused_i2_fused * 24) + i3)] = data[((((i0_i1_fused_i2_fused / 12) * 72) + (((i0_i1_fused_i2_fused % 12) / 2) * 12)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(57) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 57) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) * 19) + (((int)threadIdx.x) / 3)) / 96) * 72) + ((((((((int)blockIdx.x) * 19) + (((int)threadIdx.x) / 3)) % 96) >> 3) / 2) * 12)) + ((((((int)blockIdx.x) * 9) + ((int)threadIdx.x)) % 24) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 11, 6, 12), \"float32\"), resize: T.Buffer((19, 11, 12, 24), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(2508):\n            for i3 in range(24):\n                resize_1 = T.Buffer((60192,), data=resize.data)\n                data_1 = T.Buffer((15048,), data=data.data)\n                resize_1[i0_i1_fused_i2_fused * 24 + i3] = data_1[i0_i1_fused_i2_fused // 12 * 72 + T.Div(i0_i1_fused_i2_fused % 12, 2) * 12 + T.Div(i3, 2)]", "op_args": [19, 11, 3, 6], "input_shape": "[[19, 11, 6, 12]]", "output_shape": "[[19, 11, 12, 24]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 64800; ++i0_i1_fused_i2_fused_i3_fused) {\n    resize[i0_i1_fused_i2_fused_i3_fused] = data[((((i0_i1_fused_i2_fused_i3_fused / 3600) * 900) + ((((i0_i1_fused_i2_fused_i3_fused % 3600) / 60) / 2) * 30)) + ((i0_i1_fused_i2_fused_i3_fused % 60) / 2))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) / 60) * 900) + (((((int)blockIdx.x) % 60) / 2) * 30)) + (((int)threadIdx.x) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 1, 30, 30), \"float32\"), resize: T.Buffer((18, 1, 60, 60), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(64800):\n            resize_1 = T.Buffer((64800,), data=resize.data)\n            data_1 = T.Buffer((16200,), data=data.data)\n            resize_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 3600 * 900 + T.Div(i0_i1_fused_i2_fused_i3_fused % 3600 // 60, 2) * 30 + T.Div(i0_i1_fused_i2_fused_i3_fused % 60, 2)]", "op_args": [18, 1, 15, 15], "input_shape": "[[18, 1, 30, 30]]", "output_shape": "[[18, 1, 60, 60]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 285120; ++i0_i1_fused_i2_fused_i3_fused) {\n    resize[i0_i1_fused_i2_fused_i3_fused] = data[((((i0_i1_fused_i2_fused_i3_fused / 2640) * 660) + ((((i0_i1_fused_i2_fused_i3_fused % 2640) / 60) / 2) * 30)) + ((i0_i1_fused_i2_fused_i3_fused % 60) / 2))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) / 165) * 660) + ((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) % 660) / 15) / 2) * 30)) + ((((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 60) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 12, 22, 30), \"float32\"), resize: T.Buffer((9, 12, 44, 60), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(285120):\n            resize_1 = T.Buffer((285120,), data=resize.data)\n            data_1 = T.Buffer((71280,), data=data.data)\n            resize_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 2640 * 660 + T.Div(i0_i1_fused_i2_fused_i3_fused % 2640 // 60, 2) * 30 + T.Div(i0_i1_fused_i2_fused_i3_fused % 60, 2)]", "op_args": [9, 12, 11, 15], "input_shape": "[[9, 12, 22, 30]]", "output_shape": "[[9, 12, 44, 60]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 6656; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 44; ++i3) {\n      resize[((i0_i1_fused_i2_fused * 44) + i3)] = data[((((i0_i1_fused_i2_fused / 52) * 572) + (((i0_i1_fused_i2_fused % 52) / 2) * 22)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) / 143) * 572) + ((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) % 572) / 11) / 2) * 22)) + ((((((int)blockIdx.x) * 20) + ((int)threadIdx.x)) % 44) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 8, 26, 22), \"float32\"), resize: T.Buffer((16, 8, 52, 44), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(6656):\n            for i3 in range(44):\n                resize_1 = T.Buffer((292864,), data=resize.data)\n                data_1 = T.Buffer((73216,), data=data.data)\n                resize_1[i0_i1_fused_i2_fused * 44 + i3] = data_1[i0_i1_fused_i2_fused // 52 * 572 + T.Div(i0_i1_fused_i2_fused % 52, 2) * 22 + T.Div(i3, 2)]", "op_args": [16, 8, 13, 11], "input_shape": "[[16, 8, 26, 22]]", "output_shape": "[[16, 8, 52, 44]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 68; ++i2) {\n        for (int32_t i3 = 0; i3 < 64; ++i3) {\n          resize[((((i0 * 8704) + (i1 * 4352)) + (i2 * 64)) + i3)] = data[((((i0 * 2176) + (i1 * 1088)) + ((i2 / 2) * 32)) + (i3 / 2))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) / 68) * 1088) + (((((int)blockIdx.x) % 68) / 2) * 32)) + (((int)threadIdx.x) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 2, 34, 32), \"float32\"), resize: T.Buffer((13, 2, 68, 64), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3 in T.grid(2, 68, 64):\n                resize_1 = T.Buffer((113152,), data=resize.data)\n                data_1 = T.Buffer((28288,), data=data.data)\n                resize_1[i0 * 8704 + i1 * 4352 + i2 * 64 + i3] = data_1[i0 * 2176 + i1 * 1088 + T.Div(i2, 2) * 32 + T.Div(i3, 2)]", "op_args": [13, 2, 17, 16], "input_shape": "[[13, 2, 34, 32]]", "output_shape": "[[13, 2, 68, 64]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 9240; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 36; ++i3) {\n      resize[((i0_i1_fused_i2_fused * 36) + i3)] = data[((((i0_i1_fused_i2_fused / 56) * 504) + (((i0_i1_fused_i2_fused % 56) / 2) * 18)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 18)) / 112) * 504) + ((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 18)) % 112) >> 1) / 2) * 18)) + ((((((int)blockIdx.x) * 18) + ((int)threadIdx.x)) % 36) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 15, 28, 18), \"float32\"), resize: T.Buffer((11, 15, 56, 36), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(9240):\n            for i3 in range(36):\n                resize_1 = T.Buffer((332640,), data=resize.data)\n                data_1 = T.Buffer((83160,), data=data.data)\n                resize_1[i0_i1_fused_i2_fused * 36 + i3] = data_1[i0_i1_fused_i2_fused // 56 * 504 + T.Div(i0_i1_fused_i2_fused % 56, 2) * 18 + T.Div(i3, 2)]", "op_args": [11, 15, 14, 9], "input_shape": "[[11, 15, 28, 18]]", "output_shape": "[[11, 15, 56, 36]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 2; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 28; ++i2) {\n        for (int32_t i3 = 0; i3 < 56; ++i3) {\n          resize[((((i0 * 17248) + (i1 * 1568)) + (i2 * 56)) + i3)] = data[((((i0 * 4312) + (i1 * 392)) + ((i2 / 2) * 28)) + (i3 / 2))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(56) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 56) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) / 28) * 392) + (((((int)blockIdx.x) % 28) / 2) * 28)) + (((int)threadIdx.x) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 11, 14, 28), \"float32\"), resize: T.Buffer((2, 11, 28, 56), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(2):\n            for i1, i2, i3 in T.grid(11, 28, 56):\n                resize_1 = T.Buffer((34496,), data=resize.data)\n                data_1 = T.Buffer((8624,), data=data.data)\n                resize_1[i0 * 17248 + i1 * 1568 + i2 * 56 + i3] = data_1[i0 * 4312 + i1 * 392 + T.Div(i2, 2) * 28 + T.Div(i3, 2)]", "op_args": [2, 11, 7, 14], "input_shape": "[[2, 11, 14, 28]]", "output_shape": "[[2, 11, 28, 56]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1344; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 44; ++i3) {\n      resize[((i0_i1_fused_i2_fused * 44) + i3)] = data[((((i0_i1_fused_i2_fused / 28) * 308) + (((i0_i1_fused_i2_fused % 28) / 2) * 22)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) / 28) * 308) + (((((int)blockIdx.x) % 28) / 2) * 22)) + (((int)threadIdx.x) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 16, 14, 22), \"float32\"), resize: T.Buffer((3, 16, 28, 44), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1344):\n            for i3 in range(44):\n                resize_1 = T.Buffer((59136,), data=resize.data)\n                data_1 = T.Buffer((14784,), data=data.data)\n                resize_1[i0_i1_fused_i2_fused * 44 + i3] = data_1[i0_i1_fused_i2_fused // 28 * 308 + T.Div(i0_i1_fused_i2_fused % 28, 2) * 22 + T.Div(i3, 2)]", "op_args": [3, 16, 7, 11], "input_shape": "[[3, 16, 14, 22]]", "output_shape": "[[3, 16, 28, 44]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i2 = 0; i2 < 48; ++i2) {\n        for (int32_t i3 = 0; i3 < 36; ++i3) {\n          resize[((((i0 * 13824) + (i1 * 1728)) + (i2 * 36)) + i3)] = data[((((i0 * 3456) + (i1 * 432)) + ((i2 / 2) * 18)) + (i3 / 2))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) / 27) * 432) + ((((((((int)blockIdx.x) % 27) * 16) + (((int)threadIdx.x) >> 2)) / 9) / 2) * 18)) + ((((((int)blockIdx.x) * 28) + ((int)threadIdx.x)) % 36) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 8, 24, 18), \"float32\"), resize: T.Buffer((7, 8, 48, 36), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i1, i2, i3 in T.grid(8, 48, 36):\n                resize_1 = T.Buffer((96768,), data=resize.data)\n                data_1 = T.Buffer((24192,), data=data.data)\n                resize_1[i0 * 13824 + i1 * 1728 + i2 * 36 + i3] = data_1[i0 * 3456 + i1 * 432 + T.Div(i2, 2) * 18 + T.Div(i3, 2)]", "op_args": [7, 8, 12, 9], "input_shape": "[[7, 8, 24, 18]]", "output_shape": "[[7, 8, 48, 36]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 9; ++i0) {\n    for (int32_t i1 = 0; i1 < 3; ++i1) {\n      for (int32_t i2 = 0; i2 < 20; ++i2) {\n        for (int32_t i3 = 0; i3 < 60; ++i3) {\n          resize[((((i0 * 3600) + (i1 * 1200)) + (i2 * 60)) + i3)] = data[((((i0 * 900) + (i1 * 300)) + ((i2 / 2) * 30)) + (i3 / 2))];\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) / 24) * 300) + ((((((((int)blockIdx.x) % 24) * 5) + (((int)threadIdx.x) / 10)) / 6) / 2) * 30)) + ((((((int)blockIdx.x) * 50) + ((int)threadIdx.x)) % 60) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 3, 10, 30), \"float32\"), resize: T.Buffer((9, 3, 20, 60), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(9):\n            for i1, i2, i3 in T.grid(3, 20, 60):\n                resize_1 = T.Buffer((32400,), data=resize.data)\n                data_1 = T.Buffer((8100,), data=data.data)\n                resize_1[i0 * 3600 + i1 * 1200 + i2 * 60 + i3] = data_1[i0 * 900 + i1 * 300 + T.Div(i2, 2) * 30 + T.Div(i3, 2)]", "op_args": [9, 3, 5, 15], "input_shape": "[[9, 3, 10, 30]]", "output_shape": "[[9, 3, 20, 60]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 73216; ++i0_i1_fused_i2_fused_i3_fused) {\n    resize[i0_i1_fused_i2_fused_i3_fused] = data[((((i0_i1_fused_i2_fused_i3_fused >> 9) * 128) + ((((i0_i1_fused_i2_fused_i3_fused & 511) >> 5) / 2) * 16)) + ((i0_i1_fused_i2_fused_i3_fused & 31) / 2))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = data[((((int)blockIdx.x) * 16) + ((((int)threadIdx.x) & 31) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 11, 8, 16), \"float32\"), resize: T.Buffer((13, 11, 16, 32), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(73216):\n            resize_1 = T.Buffer((73216,), data=resize.data)\n            data_1 = T.Buffer((18304,), data=data.data)\n            resize_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 512 * 128 + T.Div(i0_i1_fused_i2_fused_i3_fused % 512 // 32, 2) * 16 + T.Div(i0_i1_fused_i2_fused_i3_fused % 32, 2)]", "op_args": [13, 11, 4, 8], "input_shape": "[[13, 11, 8, 16]]", "output_shape": "[[13, 11, 16, 32]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1080; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 80; ++i3) {\n      resize[((i0_i1_fused_i2_fused * 80) + i3)] = data[((((i0_i1_fused_i2_fused / 20) * 400) + (((i0_i1_fused_i2_fused % 20) / 2) * 40)) + (i3 / 2))];\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20)) / 80) * 400) + ((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20)) % 80) >> 2) / 2) * 40)) + ((((((int)blockIdx.x) * 60) + ((int)threadIdx.x)) % 80) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((6, 9, 10, 40), \"float32\"), resize: T.Buffer((6, 9, 20, 80), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1080):\n            for i3 in range(80):\n                resize_1 = T.Buffer((86400,), data=resize.data)\n                data_1 = T.Buffer((21600,), data=data.data)\n                resize_1[i0_i1_fused_i2_fused * 80 + i3] = data_1[i0_i1_fused_i2_fused // 20 * 400 + T.Div(i0_i1_fused_i2_fused % 20, 2) * 40 + T.Div(i3, 2)]", "op_args": [6, 9, 5, 20], "input_shape": "[[6, 9, 10, 40]]", "output_shape": "[[6, 9, 20, 80]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i2 = 0; i2 < 40; ++i2) {\n      for (int32_t i3 = 0; i3 < 36; ++i3) {\n        resize[(((i0 * 1440) + (i2 * 36)) + i3)] = data[(((i0 * 360) + ((i2 / 2) * 18)) + (i3 / 2))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) / 40) * 360) + (((((int)blockIdx.x) % 40) / 2) * 18)) + (((int)threadIdx.x) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 1, 20, 18), \"float32\"), resize: T.Buffer((11, 1, 40, 36), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i2, i3 in T.grid(40, 36):\n                resize_1 = T.Buffer((15840,), data=resize.data)\n                data_1 = T.Buffer((3960,), data=data.data)\n                resize_1[i0 * 1440 + i2 * 36 + i3] = data_1[i0 * 360 + T.Div(i2, 2) * 18 + T.Div(i3, 2)]", "op_args": [11, 1, 10, 9], "input_shape": "[[11, 1, 20, 18]]", "output_shape": "[[11, 1, 40, 36]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 38400; ++i0_i1_fused_i2_fused_i3_fused) {\n    resize[i0_i1_fused_i2_fused_i3_fused] = data[((((i0_i1_fused_i2_fused_i3_fused / 800) * 200) + ((((i0_i1_fused_i2_fused_i3_fused % 800) / 20) / 2) * 10)) + ((i0_i1_fused_i2_fused_i3_fused % 20) / 2))];\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = data[((((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20)) / 40) * 200) + (((((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20)) % 40) / 2) * 10)) + ((((int)threadIdx.x) % 20) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 3, 20, 10), \"float32\"), resize: T.Buffer((16, 3, 40, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(38400):\n            resize_1 = T.Buffer((38400,), data=resize.data)\n            data_1 = T.Buffer((9600,), data=data.data)\n            resize_1[i0_i1_fused_i2_fused_i3_fused] = data_1[i0_i1_fused_i2_fused_i3_fused // 800 * 200 + T.Div(i0_i1_fused_i2_fused_i3_fused % 800 // 20, 2) * 10 + T.Div(i0_i1_fused_i2_fused_i3_fused % 20, 2)]", "op_args": [16, 3, 10, 5], "input_shape": "[[16, 3, 20, 10]]", "output_shape": "[[16, 3, 40, 20]]"}{"op_name": "upsampling", "c_code": "void default_function_kernel(float* data, float* resize) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 60; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 36; ++i2) {\n      for (int32_t i3 = 0; i3 < 36; ++i3) {\n        resize[(((i0_i1_fused * 1296) + (i2 * 36)) + i3)] = data[(((i0_i1_fused * 324) + ((i2 / 2) * 18)) + (i3 / 2))];\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ data, float* __restrict__ resize) {\n  resize[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = data[((((((int)blockIdx.x) / 27) * 324) + ((((((((int)blockIdx.x) % 27) * 4) + (((int)threadIdx.x) / 12)) / 3) / 2) * 18)) + ((((((int)blockIdx.x) * 12) + ((int)threadIdx.x)) % 36) / 2))];\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 20, 18, 18), \"float32\"), resize: T.Buffer((3, 20, 36, 36), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(60):\n            for i2, i3 in T.grid(36, 36):\n                resize_1 = T.Buffer((77760,), data=resize.data)\n                data_1 = T.Buffer((19440,), data=data.data)\n                resize_1[i0_i1_fused * 1296 + i2 * 36 + i3] = data_1[i0_i1_fused * 324 + T.Div(i2, 2) * 18 + T.Div(i3, 2)]", "op_args": [3, 20, 9, 9], "input_shape": "[[3, 20, 18, 18]]", "output_shape": "[[3, 20, 36, 36]]"}{"op_name": "rms_norm", "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 624; ++ax0_ax1_fused_ax2_fused) {\n    float T_multiply_red[2];\n    for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n      T_multiply_red[ax2] = 0.000000e+00f;\n      for (int32_t k1 = 0; k1 < 16; ++k1) {\n        T_multiply_red[ax2] = (T_multiply_red[ax2] + (data[(((((ax0_ax1_fused_ax2_fused / 208) * 416) + (k1 * 26)) + ((ax0_ax1_fused_ax2_fused % 13) * 2)) + ax2)] * data[(((((ax0_ax1_fused_ax2_fused / 208) * 416) + (k1 * 26)) + ((ax0_ax1_fused_ax2_fused % 13) * 2)) + ax2)]));\n      }\n    }\n    for (int32_t ax3_s = 0; ax3_s < 2; ++ax3_s) {\n      T_cast[((ax0_ax1_fused_ax2_fused * 2) + ax3_s)] = ((data[((ax0_ax1_fused_ax2_fused * 2) + ax3_s)] * weight[((ax0_ax1_fused_ax2_fused % 208) / 13)]) * (1.000000e+00f / sqrtf(((T_multiply_red[ax3_s] * 6.250000e-02f) + 1.000000e-05f))));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  T_cast[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] * weight[((((((int)blockIdx.x) % 26) * 8) + (((int)threadIdx.x) >> 1)) / 13)]) * (1.000000e+00f / sqrtf(((T_multiply_red[((((((int)blockIdx.x) / 26) * 26) + ((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 1)) % 13) * 2)) + (((int)threadIdx.x) & 1))] * 6.250000e-02f) + 1.000000e-05f))));\n}\n\nextern \"C\" __global__ void default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  T_multiply_red[((int)blockIdx.x)] = 0.000000e+00f;\n  for (int k1 = 0; k1 < 16; ++k1) {\n    T_multiply_red[((int)blockIdx.x)] = (T_multiply_red[((int)blockIdx.x)] + (data[((((((int)blockIdx.x) / 26) * 416) + (k1 * 26)) + (((int)blockIdx.x) % 26))] * data[((((((int)blockIdx.x) / 26) * 416) + (k1 * 26)) + (((int)blockIdx.x) % 26))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 16, 13, 2), \"float32\"), weight: T.Buffer((2,), \"float32\"), T_cast: T.Buffer((3, 16, 13, 2), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(624):\n            T_multiply_red = T.allocate([2], \"float32\", \"global\")\n            T_multiply_red_1 = T.Buffer((2,), data=T_multiply_red, align=8)\n            data_1 = T.Buffer((1248,), data=data.data)\n            for ax2 in range(2):\n                T_multiply_red_1[ax2] = T.float32(0)\n                for k1 in range(16):\n                    cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused // 208 * 416 + k1 * 26 + ax0_ax1_fused_ax2_fused % 13 * 2 + ax2\n                    T_multiply_red_1[ax2] = T_multiply_red_1[ax2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax3_s in range(2):\n                cse_var_2: T.int32 = ax0_ax1_fused_ax2_fused * 2 + ax3_s\n                T_cast_1 = T.Buffer((1248,), data=T_cast.data)\n                T_cast_1[cse_var_2] = data_1[cse_var_2] * weight[ax0_ax1_fused_ax2_fused % 208 // 13] * T.rsqrt(T_multiply_red_1[ax3_s] * T.float32(0.0625) + T.float32(1.0000000000000001e-05))", "op_args": [3, 16, 13, 2], "input_shape": "[[3, 16, 13, 2], [2]]", "output_shape": "[[3, 16, 13, 2]]"}{"op_name": "rms_norm", "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 252; ++ax0_ax1_fused) {\n    float T_multiply_red[70];\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 7; ++ax2) {\n        T_multiply_red[((ax1 * 7) + ax2)] = 0.000000e+00f;\n        for (int32_t k1 = 0; k1 < 18; ++k1) {\n          T_multiply_red[((ax1 * 7) + ax2)] = (T_multiply_red[((ax1 * 7) + ax2)] + (data[(((((ax0_ax1_fused / 18) * 1260) + (k1 * 70)) + (ax1 * 7)) + ax2)] * data[(((((ax0_ax1_fused / 18) * 1260) + (k1 * 70)) + (ax1 * 7)) + ax2)]));\n        }\n      }\n    }\n    for (int32_t ax2_1 = 0; ax2_1 < 10; ++ax2_1) {\n      for (int32_t ax3_s = 0; ax3_s < 7; ++ax3_s) {\n        T_cast[(((ax0_ax1_fused * 70) + (ax2_1 * 7)) + ax3_s)] = ((data[(((ax0_ax1_fused * 70) + (ax2_1 * 7)) + ax3_s)] * weight[(ax0_ax1_fused % 18)]) * (1.000000e+00f / sqrtf(((T_multiply_red[((ax2_1 * 7) + ax3_s)] * 5.555556e-02f) + 1.000000e-05f))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(40) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  T_cast[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 40) + ((int)threadIdx.x))] * weight[((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) / 10)) % 126) / 7)]) * (1.000000e+00f / sqrtf(((T_multiply_red[(((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) / 20)) / 63) * 70) + (((((int)blockIdx.x) * 40) + ((int)threadIdx.x)) % 70))] * 5.555556e-02f) + 1.000000e-05f))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 245) {\n    T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k1 = 0; k1 < 18; ++k1) {\n    if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 2)) < 245) {\n      T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + (data[((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 35) * 1260) + (k1 * 70)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 70))] * data[((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 35) * 1260) + (k1 * 70)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 70))]));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 18, 10, 7), \"float32\"), weight: T.Buffer((7,), \"float32\"), T_cast: T.Buffer((14, 18, 10, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(252):\n            T_multiply_red = T.allocate([70], \"float32\", \"global\")\n            T_multiply_red_1 = T.Buffer((70,), data=T_multiply_red)\n            data_1 = T.Buffer((17640,), data=data.data)\n            for ax1, ax2 in T.grid(10, 7):\n                T_multiply_red_1[ax1 * 7 + ax2] = T.float32(0)\n                for k1 in range(18):\n                    cse_var_3: T.int32 = ax1 * 7\n                    cse_var_2: T.int32 = cse_var_3 + ax2\n                    cse_var_1: T.int32 = ax0_ax1_fused // 18 * 1260 + k1 * 70 + cse_var_3 + ax2\n                    T_multiply_red_1[cse_var_2] = T_multiply_red_1[cse_var_2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax2, ax3_s in T.grid(10, 7):\n                cse_var_5: T.int32 = ax2 * 7\n                cse_var_4: T.int32 = ax0_ax1_fused * 70 + cse_var_5 + ax3_s\n                T_cast_1 = T.Buffer((17640,), data=T_cast.data)\n                T_cast_1[cse_var_4] = data_1[cse_var_4] * weight[ax0_ax1_fused % 18] * T.rsqrt(T_multiply_red_1[cse_var_5 + ax3_s] * T.float32(0.055555555555555552) + T.float32(1.0000000000000001e-05))", "op_args": [14, 18, 10, 7], "input_shape": "[[14, 18, 10, 7], [7]]", "output_shape": "[[14, 18, 10, 7]]"}{"op_name": "rms_norm", "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 7; ++ax0) {\n    float T_multiply_red[1];\n    for (int32_t ax1 = 0; ax1 < 3; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 15; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 17; ++ax3) {\n          T_multiply_red[0] = 0.000000e+00f;\n          for (int32_t k1 = 0; k1 < 3; ++k1) {\n            T_multiply_red[0] = (T_multiply_red[0] + (data[((((ax0 * 765) + (k1 * 255)) + (ax2 * 17)) + ax3)] * data[((((ax0 * 765) + (k1 * 255)) + (ax2 * 17)) + ax3)]));\n          }\n          T_cast[((((ax0 * 765) + (ax1 * 255)) + (ax2 * 17)) + ax3)] = ((data[((((ax0 * 765) + (ax1 * 255)) + (ax2 * 17)) + ax3)] * weight[ax1]) * (1.000000e+00f / sqrtf(((T_multiply_red[0] * 3.333333e-01f) + 1.000000e-05f))));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  if (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) < 5355) {\n    T_cast[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * weight[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 765) / 255)]) * (1.000000e+00f / sqrtf(((T_multiply_red[(((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) / 765) * 255) + (((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) % 255))] * 3.333333e-01f) + 1.000000e-05f))));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 1785) {\n    T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k1 = 0; k1 < 3; ++k1) {\n    if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 1785) {\n      T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + (data[((((((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 255) * 765) + (k1 * 255)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 255))] * data[((((((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) / 255) * 765) + (k1 * 255)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 255))]));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 3, 15, 17), \"float32\"), weight: T.Buffer((17,), \"float32\"), T_cast: T.Buffer((7, 3, 15, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(7):\n            T_multiply_red = T.allocate([1], \"float32\", \"global\")\n            for ax1, ax2, ax3 in T.grid(3, 15, 17):\n                cse_var_1: T.int32 = ax0 * 765 + ax1 * 255 + ax2 * 17 + ax3\n                T_multiply_red_1 = T.Buffer((1,), data=T_multiply_red, align=4)\n                T_multiply_red_1[0] = T.float32(0)\n                data_1 = T.Buffer((5355,), data=data.data)\n                for k1 in range(3):\n                    cse_var_2: T.int32 = ax0 * 765 + k1 * 255 + ax2 * 17 + ax3\n                    T_multiply_red_1[0] = T_multiply_red_1[0] + data_1[cse_var_2] * data_1[cse_var_2]\n                T_cast_1 = T.Buffer((5355,), data=T_cast.data)\n                T_cast_1[cse_var_1] = data_1[cse_var_1] * weight[ax1] * T.rsqrt(T_multiply_red_1[0] * T.float32(0.33333333333333331) + T.float32(1.0000000000000001e-05))", "op_args": [7, 3, 15, 17], "input_shape": "[[7, 3, 15, 17], [17]]", "output_shape": "[[7, 3, 15, 17]]"}{"op_name": "rms_norm", "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 8; ++ax0) {\n    float T_multiply_red[168];\n    for (int32_t ax1 = 0; ax1 < 12; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 14; ++ax2) {\n        T_multiply_red[((ax1 * 14) + ax2)] = 0.000000e+00f;\n        for (int32_t k1 = 0; k1 < 10; ++k1) {\n          T_multiply_red[((ax1 * 14) + ax2)] = (T_multiply_red[((ax1 * 14) + ax2)] + (data[((((ax0 * 1680) + (k1 * 168)) + (ax1 * 14)) + ax2)] * data[((((ax0 * 1680) + (k1 * 168)) + (ax1 * 14)) + ax2)]));\n        }\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 10; ++ax1_1) {\n      for (int32_t ax2_1 = 0; ax2_1 < 12; ++ax2_1) {\n        for (int32_t ax3_s = 0; ax3_s < 14; ++ax3_s) {\n          T_cast[((((ax0 * 1680) + (ax1_1 * 168)) + (ax2_1 * 14)) + ax3_s)] = ((data[((((ax0 * 1680) + (ax1_1 * 168)) + (ax2_1 * 14)) + ax3_s)] * weight[ax1_1]) * (1.000000e+00f / sqrtf(((T_multiply_red[((ax2_1 * 14) + ax3_s)] * 1.000000e-01f) + 1.000000e-05f))));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(35) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  T_cast[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 35) + ((int)threadIdx.x))] * weight[((((((int)blockIdx.x) % 48) * 5) + (((int)threadIdx.x) / 7)) / 24)]) * (1.000000e+00f / sqrtf(((T_multiply_red[(((((int)blockIdx.x) / 48) * 168) + (((((int)blockIdx.x) * 35) + ((int)threadIdx.x)) % 168))] * 1.000000e-01f) + 1.000000e-05f))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k1 = 0; k1 < 10; ++k1) {\n    T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + (data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) / 21) * 1680) + (k1 * 168)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 168))] * data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) / 21) * 1680) + (k1 * 168)) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 168))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 10, 12, 14), \"float32\"), weight: T.Buffer((14,), \"float32\"), T_cast: T.Buffer((8, 10, 12, 14), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(8):\n            T_multiply_red = T.allocate([168], \"float32\", \"global\")\n            T_multiply_red_1 = T.Buffer((168,), data=T_multiply_red)\n            data_1 = T.Buffer((13440,), data=data.data)\n            for ax1, ax2 in T.grid(12, 14):\n                T_multiply_red_1[ax1 * 14 + ax2] = T.float32(0)\n                for k1 in range(10):\n                    cse_var_3: T.int32 = ax1 * 14\n                    cse_var_2: T.int32 = cse_var_3 + ax2\n                    cse_var_1: T.int32 = ax0 * 1680 + k1 * 168 + cse_var_3 + ax2\n                    T_multiply_red_1[cse_var_2] = T_multiply_red_1[cse_var_2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax1, ax2, ax3_s in T.grid(10, 12, 14):\n                cse_var_5: T.int32 = ax2 * 14\n                cse_var_4: T.int32 = ax0 * 1680 + ax1 * 168 + cse_var_5 + ax3_s\n                T_cast_1 = T.Buffer((13440,), data=T_cast.data)\n                T_cast_1[cse_var_4] = data_1[cse_var_4] * weight[ax1] * T.rsqrt(T_multiply_red_1[cse_var_5 + ax3_s] * T.float32(0.10000000000000001) + T.float32(1.0000000000000001e-05))", "op_args": [8, 10, 12, 14], "input_shape": "[[8, 10, 12, 14], [14]]", "output_shape": "[[8, 10, 12, 14]]"}{"op_name": "rms_norm", "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 4; ++ax0_ax1_fused) {\n    float T_multiply_red[36];\n    for (int32_t ax1 = 0; ax1 < 4; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 9; ++ax2) {\n        T_multiply_red[((ax1 * 9) + ax2)] = 0.000000e+00f;\n        for (int32_t k1 = 0; k1 < 2; ++k1) {\n          T_multiply_red[((ax1 * 9) + ax2)] = (T_multiply_red[((ax1 * 9) + ax2)] + (data[(((((ax0_ax1_fused >> 1) * 72) + (k1 * 36)) + (ax1 * 9)) + ax2)] * data[(((((ax0_ax1_fused >> 1) * 72) + (k1 * 36)) + (ax1 * 9)) + ax2)]));\n        }\n      }\n    }\n    for (int32_t ax2_1 = 0; ax2_1 < 4; ++ax2_1) {\n      for (int32_t ax3_s = 0; ax3_s < 9; ++ax3_s) {\n        T_cast[(((ax0_ax1_fused * 36) + (ax2_1 * 9)) + ax3_s)] = ((data[(((ax0_ax1_fused * 36) + (ax2_1 * 9)) + ax3_s)] * weight[(ax0_ax1_fused & 1)]) * (1.000000e+00f / sqrtf(((T_multiply_red[((ax2_1 * 9) + ax3_s)] * 5.000000e-01f) + 1.000000e-05f))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) < 9) {\n    T_cast[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * weight[((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 2)) % 18) / 9)]) * (1.000000e+00f / sqrtf(((T_multiply_red[((((((((int)blockIdx.x) * 8) + (((int)threadIdx.x) >> 3)) / 9) * 36) + (((((((int)blockIdx.x) * 28) + ((int)threadIdx.x)) % 36) / 9) * 9)) + ((((int)blockIdx.x) + ((int)threadIdx.x)) % 9))] * 5.000000e-01f) + 1.000000e-05f))));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) < 9) {\n    T_multiply_red[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k1 = 0; k1 < 2; ++k1) {\n    if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) < 9) {\n      T_multiply_red[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] + (data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 2)) / 9) * 72) + (k1 * 36)) + (((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) % 36))] * data[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 2)) / 9) * 72) + (k1 * 36)) + (((((int)blockIdx.x) * 16) + ((int)threadIdx.x)) % 36))]));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 2, 4, 9), \"float32\"), weight: T.Buffer((9,), \"float32\"), T_cast: T.Buffer((2, 2, 4, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(4):\n            T_multiply_red = T.allocate([36], \"float32\", \"global\")\n            T_multiply_red_1 = T.Buffer((36,), data=T_multiply_red)\n            data_1 = T.Buffer((144,), data=data.data)\n            for ax1, ax2 in T.grid(4, 9):\n                T_multiply_red_1[ax1 * 9 + ax2] = T.float32(0)\n                for k1 in range(2):\n                    cse_var_3: T.int32 = ax1 * 9\n                    cse_var_2: T.int32 = cse_var_3 + ax2\n                    cse_var_1: T.int32 = ax0_ax1_fused // 2 * 72 + k1 * 36 + cse_var_3 + ax2\n                    T_multiply_red_1[cse_var_2] = T_multiply_red_1[cse_var_2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax2, ax3_s in T.grid(4, 9):\n                cse_var_5: T.int32 = ax2 * 9\n                cse_var_4: T.int32 = ax0_ax1_fused * 36 + cse_var_5 + ax3_s\n                T_cast_1 = T.Buffer((144,), data=T_cast.data)\n                T_cast_1[cse_var_4] = data_1[cse_var_4] * weight[ax0_ax1_fused % 2] * T.rsqrt(T_multiply_red_1[cse_var_5 + ax3_s] * T.float32(0.5) + T.float32(1.0000000000000001e-05))", "op_args": [2, 2, 4, 9], "input_shape": "[[2, 2, 4, 9], [9]]", "output_shape": "[[2, 2, 4, 9]]"}{"op_name": "rms_norm", "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 8; ++ax0_ax1_fused_ax2_fused) {\n    float T_multiply_red[18];\n    for (int32_t ax2 = 0; ax2 < 18; ++ax2) {\n      T_multiply_red[ax2] = 0.000000e+00f;\n      for (int32_t k1 = 0; k1 < 2; ++k1) {\n        T_multiply_red[ax2] = (T_multiply_red[ax2] + (data[((((ax0_ax1_fused_ax2_fused >> 1) * 36) + (k1 * 18)) + ax2)] * data[((((ax0_ax1_fused_ax2_fused >> 1) * 36) + (k1 * 18)) + ax2)]));\n      }\n    }\n    for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n      T_cast[((ax0_ax1_fused_ax2_fused * 18) + ax3)] = ((data[((ax0_ax1_fused_ax2_fused * 18) + ax3)] * weight[(ax0_ax1_fused_ax2_fused & 1)]) * (1.000000e+00f / sqrtf(((T_multiply_red[ax3] * 5.000000e-01f) + 1.000000e-05f))));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(9) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  T_cast[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 9) + ((int)threadIdx.x))] * weight[((((int)blockIdx.x) & 3) >> 1)]) * (1.000000e+00f / sqrtf(((T_multiply_red[((((((int)blockIdx.x) >> 2) * 18) + ((((int)blockIdx.x) & 1) * 9)) + ((int)threadIdx.x))] * 5.000000e-01f) + 1.000000e-05f))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  T_multiply_red[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k1 = 0; k1 < 2; ++k1) {\n    T_multiply_red[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] + (data[((((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 1)) / 9) * 36) + (k1 * 18)) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 18))] * data[((((((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 1)) / 9) * 36) + (k1 * 18)) + (((((int)blockIdx.x) * 4) + ((int)threadIdx.x)) % 18))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 2, 1, 18), \"float32\"), weight: T.Buffer((18,), \"float32\"), T_cast: T.Buffer((4, 2, 1, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(8):\n            T_multiply_red = T.allocate([18], \"float32\", \"global\")\n            T_multiply_red_1 = T.Buffer((18,), data=T_multiply_red)\n            data_1 = T.Buffer((144,), data=data.data)\n            for ax2 in range(18):\n                T_multiply_red_1[ax2] = T.float32(0)\n                for k1 in range(2):\n                    cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused // 2 * 36 + k1 * 18 + ax2\n                    T_multiply_red_1[ax2] = T_multiply_red_1[ax2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax3 in range(18):\n                cse_var_2: T.int32 = ax0_ax1_fused_ax2_fused * 18 + ax3\n                T_cast_1 = T.Buffer((144,), data=T_cast.data)\n                T_cast_1[cse_var_2] = data_1[cse_var_2] * weight[ax0_ax1_fused_ax2_fused % 2] * T.rsqrt(T_multiply_red_1[ax3] * T.float32(0.5) + T.float32(1.0000000000000001e-05))", "op_args": [4, 2, 1, 18], "input_shape": "[[4, 2, 1, 18], [18]]", "output_shape": "[[4, 2, 1, 18]]"}{"op_name": "rms_norm", "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 156; ++ax0_ax1_fused_ax2_fused) {\n    float T_multiply_red[6];\n    for (int32_t ax2 = 0; ax2 < 6; ++ax2) {\n      T_multiply_red[ax2] = 0.000000e+00f;\n      T_multiply_red[ax2] = (T_multiply_red[ax2] + (data[((ax0_ax1_fused_ax2_fused * 6) + ax2)] * data[((ax0_ax1_fused_ax2_fused * 6) + ax2)]));\n    }\n    for (int32_t ax3_s = 0; ax3_s < 6; ++ax3_s) {\n      T_cast[((ax0_ax1_fused_ax2_fused * 6) + ax3_s)] = ((data[((ax0_ax1_fused_ax2_fused * 6) + ax3_s)] * weight[0]) * (1.000000e+00f / sqrtf((T_multiply_red[ax3_s] + 1.000000e-05f))));\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  T_cast[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] * weight[0]) * (1.000000e+00f / sqrtf((T_multiply_red[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] + 1.000000e-05f))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) < 117) {\n    T_multiply_red[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 3)) < 117) {\n    T_multiply_red[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] + (data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] * data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 1, 13, 6), \"float32\"), weight: T.Buffer((6,), \"float32\"), T_cast: T.Buffer((12, 1, 13, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(156):\n            T_multiply_red = T.allocate([6], \"float32\", \"global\")\n            T_multiply_red_1 = T.Buffer((6,), data=T_multiply_red, align=16)\n            data_1 = T.Buffer((936,), data=data.data)\n            for ax2 in range(6):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 6 + ax2\n                T_multiply_red_1[ax2] = T.float32(0)\n                T_multiply_red_1[ax2] = T_multiply_red_1[ax2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax3_s in range(6):\n                cse_var_2: T.int32 = ax0_ax1_fused_ax2_fused * 6 + ax3_s\n                T_cast_1 = T.Buffer((936,), data=T_cast.data)\n                T_cast_1[cse_var_2] = data_1[cse_var_2] * weight[0] * T.rsqrt(T_multiply_red_1[ax3_s] + T.float32(1.0000000000000001e-05))", "op_args": [12, 1, 13, 6], "input_shape": "[[12, 1, 13, 6], [6]]", "output_shape": "[[12, 1, 13, 6]]"}{"op_name": "rms_norm", "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 342; ++ax0_ax1_fused) {\n    float T_multiply_red[1];\n    for (int32_t ax2 = 0; ax2 < 3; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 13; ++ax3) {\n        T_multiply_red[0] = 0.000000e+00f;\n        for (int32_t k1 = 0; k1 < 18; ++k1) {\n          T_multiply_red[0] = (T_multiply_red[0] + (data[(((((ax0_ax1_fused / 18) * 702) + (k1 * 39)) + (ax2 * 13)) + ax3)] * data[(((((ax0_ax1_fused / 18) * 702) + (k1 * 39)) + (ax2 * 13)) + ax3)]));\n        }\n        T_cast[(((ax0_ax1_fused * 39) + (ax2 * 13)) + ax3)] = ((data[(((ax0_ax1_fused * 39) + (ax2 * 13)) + ax3)] * weight[(ax0_ax1_fused % 18)]) * (1.000000e+00f / sqrtf(((T_multiply_red[0] * 5.555556e-02f) + 1.000000e-05f))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 6669) {\n    T_cast[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] * weight[((((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 702) / 39)]) * (1.000000e+00f / sqrtf(((T_multiply_red[(((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 351) * 39) + (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) % 39))] * 5.555556e-02f) + 1.000000e-05f))));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 20) + ((int)threadIdx.x)) < 741) {\n    T_multiply_red[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k1 = 0; k1 < 18; ++k1) {\n    if (((((int)blockIdx.x) * 20) + ((int)threadIdx.x)) < 741) {\n      T_multiply_red[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] + (data[((((((((int)blockIdx.x) * 20) + ((int)threadIdx.x)) / 39) * 702) + (k1 * 39)) + (((((int)blockIdx.x) * 20) + ((int)threadIdx.x)) % 39))] * data[((((((((int)blockIdx.x) * 20) + ((int)threadIdx.x)) / 39) * 702) + (k1 * 39)) + (((((int)blockIdx.x) * 20) + ((int)threadIdx.x)) % 39))]));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((19, 18, 3, 13), \"float32\"), weight: T.Buffer((13,), \"float32\"), T_cast: T.Buffer((19, 18, 3, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(342):\n            T_multiply_red = T.allocate([1], \"float32\", \"global\")\n            for ax2, ax3 in T.grid(3, 13):\n                cse_var_1: T.int32 = ax0_ax1_fused * 39 + ax2 * 13 + ax3\n                T_multiply_red_1 = T.Buffer((1,), data=T_multiply_red, align=4)\n                T_multiply_red_1[0] = T.float32(0)\n                data_1 = T.Buffer((13338,), data=data.data)\n                for k1 in range(18):\n                    cse_var_2: T.int32 = ax0_ax1_fused // 18 * 702 + k1 * 39 + ax2 * 13 + ax3\n                    T_multiply_red_1[0] = T_multiply_red_1[0] + data_1[cse_var_2] * data_1[cse_var_2]\n                T_cast_1 = T.Buffer((13338,), data=T_cast.data)\n                T_cast_1[cse_var_1] = data_1[cse_var_1] * weight[ax0_ax1_fused % 18] * T.rsqrt(T_multiply_red_1[0] * T.float32(0.055555555555555552) + T.float32(1.0000000000000001e-05))", "op_args": [19, 18, 3, 13], "input_shape": "[[19, 18, 3, 13], [13]]", "output_shape": "[[19, 18, 3, 13]]"}{"op_name": "rms_norm", "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 15; ++ax0) {\n    float T_multiply_red[1];\n    for (int32_t ax1 = 0; ax1 < 5; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 18; ++ax2) {\n        T_multiply_red[0] = 0.000000e+00f;\n        for (int32_t k1 = 0; k1 < 5; ++k1) {\n          T_multiply_red[0] = (T_multiply_red[0] + (data[(((ax0 * 90) + (k1 * 18)) + ax2)] * data[(((ax0 * 90) + (k1 * 18)) + ax2)]));\n        }\n        T_cast[(((ax0 * 90) + (ax1 * 18)) + ax2)] = ((data[(((ax0 * 90) + (ax1 * 18)) + ax2)] * weight[ax1]) * (1.000000e+00f / sqrtf(((T_multiply_red[0] * 2.000000e-01f) + 1.000000e-05f))));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  if (((((int)blockIdx.x) * 14) + (((int)threadIdx.x) >> 1)) < 675) {\n    T_cast[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] * weight[((((((int)blockIdx.x) * 14) + (((int)threadIdx.x) >> 1)) % 45) / 9)]) * (1.000000e+00f / sqrtf(((T_multiply_red[(((((((int)blockIdx.x) * 14) + (((int)threadIdx.x) >> 1)) / 45) * 18) + (((((int)blockIdx.x) * 10) + ((int)threadIdx.x)) % 18))] * 2.000000e-01f) + 1.000000e-05f))));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 135) {\n    T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k1 = 0; k1 < 5; ++k1) {\n    if (((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) < 135) {\n      T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] + (data[((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 9) * 90) + (k1 * 18)) + (((((int)blockIdx.x) * 14) + ((int)threadIdx.x)) % 18))] * data[((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 1)) / 9) * 90) + (k1 * 18)) + (((((int)blockIdx.x) * 14) + ((int)threadIdx.x)) % 18))]));\n    }\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 5, 18, 1), \"float32\"), weight: T.Buffer((1,), \"float32\"), T_cast: T.Buffer((15, 5, 18, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(15):\n            T_multiply_red = T.allocate([1], \"float32\", \"global\")\n            for ax1, ax2 in T.grid(5, 18):\n                cse_var_1: T.int32 = ax0 * 90 + ax1 * 18 + ax2\n                T_multiply_red_1 = T.Buffer((1,), data=T_multiply_red, align=4)\n                T_multiply_red_1[0] = T.float32(0)\n                data_1 = T.Buffer((1350,), data=data.data)\n                for k1 in range(5):\n                    cse_var_2: T.int32 = ax0 * 90 + k1 * 18 + ax2\n                    T_multiply_red_1[0] = T_multiply_red_1[0] + data_1[cse_var_2] * data_1[cse_var_2]\n                T_cast_1 = T.Buffer((1350,), data=T_cast.data)\n                T_cast_1[cse_var_1] = data_1[cse_var_1] * weight[ax1] * T.rsqrt(T_multiply_red_1[0] * T.float32(0.20000000000000001) + T.float32(1.0000000000000001e-05))", "op_args": [15, 5, 18, 1], "input_shape": "[[15, 5, 18, 1], [1]]", "output_shape": "[[15, 5, 18, 1]]"}{"op_name": "rms_norm", "c_code": "void default_function_kernel(float* T_cast, float* data, float* weight) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 2; ++ax0) {\n    float T_multiply_red[320];\n    for (int32_t ax1 = 0; ax1 < 16; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 20; ++ax2) {\n        T_multiply_red[((ax1 * 20) + ax2)] = 0.000000e+00f;\n        for (int32_t k1 = 0; k1 < 5; ++k1) {\n          T_multiply_red[((ax1 * 20) + ax2)] = (T_multiply_red[((ax1 * 20) + ax2)] + (data[((((ax0 * 1600) + (k1 * 320)) + (ax1 * 20)) + ax2)] * data[((((ax0 * 1600) + (k1 * 320)) + (ax1 * 20)) + ax2)]));\n        }\n      }\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 5; ++ax1_1) {\n      for (int32_t ax2_1 = 0; ax2_1 < 16; ++ax2_1) {\n        for (int32_t ax3 = 0; ax3 < 20; ++ax3) {\n          T_cast[((((ax0 * 1600) + (ax1_1 * 320)) + (ax2_1 * 20)) + ax3)] = ((data[((((ax0 * 1600) + (ax1_1 * 320)) + (ax2_1 * 20)) + ax3)] * weight[ax1_1]) * (1.000000e+00f / sqrtf(((T_multiply_red[((ax2_1 * 20) + ax3)] * 2.000000e-01f) + 1.000000e-05f))));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel_1(float* __restrict__ T_cast, float* __restrict__ T_multiply_red, float* __restrict__ data, float* __restrict__ weight) {\n  T_cast[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] * weight[((((int)blockIdx.x) % 25) / 5)]) * (1.000000e+00f / sqrtf(((T_multiply_red[((((((int)blockIdx.x) / 25) * 320) + ((((int)blockIdx.x) % 5) * 64)) + ((int)threadIdx.x))] * 2.000000e-01f) + 1.000000e-05f))));\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ T_multiply_red, float* __restrict__ data) {\n  T_multiply_red[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = 0.000000e+00f;\n  for (int k1 = 0; k1 < 5; ++k1) {\n    T_multiply_red[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (T_multiply_red[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] + (data[(((((((int)blockIdx.x) / 5) * 1600) + (k1 * 320)) + ((((int)blockIdx.x) % 5) * 64)) + ((int)threadIdx.x))] * data[(((((((int)blockIdx.x) / 5) * 1600) + (k1 * 320)) + ((((int)blockIdx.x) % 5) * 64)) + ((int)threadIdx.x))]));\n  }\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((2, 5, 16, 20), \"float32\"), weight: T.Buffer((20,), \"float32\"), T_cast: T.Buffer((2, 5, 16, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(2):\n            T_multiply_red = T.allocate([320], \"float32\", \"global\")\n            T_multiply_red_1 = T.Buffer((320,), data=T_multiply_red)\n            data_1 = T.Buffer((3200,), data=data.data)\n            for ax1, ax2 in T.grid(16, 20):\n                T_multiply_red_1[ax1 * 20 + ax2] = T.float32(0)\n                for k1 in range(5):\n                    cse_var_3: T.int32 = ax1 * 20\n                    cse_var_2: T.int32 = cse_var_3 + ax2\n                    cse_var_1: T.int32 = ax0 * 1600 + k1 * 320 + cse_var_3 + ax2\n                    T_multiply_red_1[cse_var_2] = T_multiply_red_1[cse_var_2] + data_1[cse_var_1] * data_1[cse_var_1]\n            for ax1, ax2, ax3 in T.grid(5, 16, 20):\n                cse_var_5: T.int32 = ax2 * 20\n                cse_var_4: T.int32 = ax0 * 1600 + ax1 * 320 + cse_var_5 + ax3\n                T_cast_1 = T.Buffer((3200,), data=T_cast.data)\n                T_cast_1[cse_var_4] = data_1[cse_var_4] * weight[ax1] * T.rsqrt(T_multiply_red_1[cse_var_5 + ax3] * T.float32(0.20000000000000001) + T.float32(1.0000000000000001e-05))", "op_args": [2, 5, 16, 20], "input_shape": "[[2, 5, 16, 20], [20]]", "output_shape": "[[2, 5, 16, 20]]"}{"op_name": "batch_norm", "c_code": "void default_function_kernel(float* T_divide, float* data, float* moving_mean, float* moving_var) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 3; ++ax0) {\n    float T_reshape[11];\n    float T_reshape_1[1];\n    for (int32_t ax1 = 0; ax1 < 11; ++ax1) {\n      T_reshape[ax1] = moving_mean[ax1];\n    }\n    for (int32_t ax1_1 = 0; ax1_1 < 11; ++ax1_1) {\n      for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n          T_reshape_1[0] = moving_var[ax1_1];\n          T_divide[((((ax0 * 352) + (ax1_1 * 32)) + (ax2 * 16)) + ax3)] = ((data[((((ax0 * 352) + (ax1_1 * 32)) + (ax2 * 16)) + ax3)] - T_reshape[ax1_1]) / sqrtf((T_reshape_1[0] + 1.000000e-05f)));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(44) default_function_kernel(float* __restrict__ T_divide, float* __restrict__ data, float* __restrict__ moving_mean, float* __restrict__ moving_var) {\n  T_divide[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 44) + ((int)threadIdx.x))] - moving_mean[((((((int)blockIdx.x) & 7) * 11) + (((int)threadIdx.x) >> 2)) >> 3)]) / sqrtf((moving_var[((((((int)blockIdx.x) & 7) * 11) + (((int)threadIdx.x) >> 2)) >> 3)] + 1.000000e-05f)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 11, 2, 16), \"float32\"), gamma: T.Buffer((11,), \"float32\"), beta: T.Buffer((11,), \"float32\"), moving_mean: T.Buffer((11,), \"float32\"), moving_var: T.Buffer((11,), \"float32\"), T_divide: T.Buffer((3, 11, 2, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(3):\n            T_reshape = T.allocate([11], \"float32\", \"global\")\n            T_reshape_1 = T.allocate([1], \"float32\", \"global\")\n            T_reshape_2 = T.Buffer((11,), data=T_reshape, align=32)\n            for ax1 in range(11):\n                T_reshape_2[ax1] = moving_mean[ax1]\n            for ax1, ax2, ax3 in T.grid(11, 2, 16):\n                cse_var_1: T.int32 = ax0 * 352 + ax1 * 32 + ax2 * 16 + ax3\n                T_reshape_3 = T.Buffer((1,), data=T_reshape_1, align=4)\n                T_reshape_3[0] = moving_var[ax1]\n                T_divide_1 = T.Buffer((1056,), data=T_divide.data)\n                data_1 = T.Buffer((1056,), data=data.data)\n                T_divide_1[cse_var_1] = (data_1[cse_var_1] - T_reshape_2[ax1]) / T.sqrt(T_reshape_3[0] + T.float32(1.0000000000000001e-05))", "op_args": [3, 11, 2, 16], "input_shape": "[[3, 11, 2, 16], [11], [11], [11], [11]]", "output_shape": "[[3, 11, 2, 16]]"}{"op_name": "batch_norm", "c_code": "void default_function_kernel(float* T_divide, float* data, float* moving_mean, float* moving_var) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 12; ++ax0) {\n    float T_reshape[1];\n    float T_reshape_1[1];\n    for (int32_t ax1 = 0; ax1 < 18; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 11; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 20; ++ax3) {\n          T_reshape[0] = moving_mean[ax1];\n          T_reshape_1[0] = moving_var[ax1];\n          T_divide[((((ax0 * 3960) + (ax1 * 220)) + (ax2 * 20)) + ax3)] = ((data[((((ax0 * 3960) + (ax1 * 220)) + (ax2 * 20)) + ax3)] - T_reshape[0]) / sqrtf((T_reshape_1[0] + 1.000000e-05f)));\n        }\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(45) default_function_kernel(float* __restrict__ T_divide, float* __restrict__ data, float* __restrict__ moving_mean, float* __restrict__ moving_var) {\n  T_divide[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 45) + ((int)threadIdx.x))] - moving_mean[((((((int)blockIdx.x) % 88) * 9) + (((int)threadIdx.x) / 5)) / 44)]) / sqrtf((moving_var[((((((int)blockIdx.x) % 88) * 9) + (((int)threadIdx.x) / 5)) / 44)] + 1.000000e-05f)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((12, 18, 11, 20), \"float32\"), gamma: T.Buffer((18,), \"float32\"), beta: T.Buffer((18,), \"float32\"), moving_mean: T.Buffer((18,), \"float32\"), moving_var: T.Buffer((18,), \"float32\"), T_divide: T.Buffer((12, 18, 11, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(12):\n            T_reshape = T.allocate([1], \"float32\", \"global\")\n            T_reshape_1 = T.allocate([1], \"float32\", \"global\")\n            for ax1, ax2, ax3 in T.grid(18, 11, 20):\n                cse_var_1: T.int32 = ax0 * 3960 + ax1 * 220 + ax2 * 20 + ax3\n                T_reshape_2 = T.Buffer((1,), data=T_reshape, align=4)\n                T_reshape_2[0] = moving_mean[ax1]\n                T_reshape_3 = T.Buffer((1,), data=T_reshape_1, align=4)\n                T_reshape_3[0] = moving_var[ax1]\n                T_divide_1 = T.Buffer((47520,), data=T_divide.data)\n                data_1 = T.Buffer((47520,), data=data.data)\n                T_divide_1[cse_var_1] = (data_1[cse_var_1] - T_reshape_2[0]) / T.sqrt(T_reshape_3[0] + T.float32(1.0000000000000001e-05))", "op_args": [12, 18, 11, 20], "input_shape": "[[12, 18, 11, 20], [18], [18], [18], [18]]", "output_shape": "[[12, 18, 11, 20]]"}{"op_name": "batch_norm", "c_code": "void default_function_kernel(float* T_divide, float* data, float* moving_mean, float* moving_var) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 12; ++ax0_ax1_fused) {\n    float T_reshape[1];\n    float T_reshape_1[1];\n    T_reshape[0] = moving_var[(ax0_ax1_fused & 3)];\n    for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n      T_reshape_1[0] = moving_mean[(ax0_ax1_fused & 3)];\n      for (int32_t ax3 = 0; ax3 < 10; ++ax3) {\n        T_divide[(((ax0_ax1_fused * 20) + (ax2 * 10)) + ax3)] = ((data[(((ax0_ax1_fused * 20) + (ax2 * 10)) + ax3)] - T_reshape_1[0]) / sqrtf((T_reshape[0] + 1.000000e-05f)));\n      }\n    }\n  }\n}\n\n", "cuda_code": "extern \"C\" __global__ void __launch_bounds__(60) default_function_kernel(float* __restrict__ T_divide, float* __restrict__ data, float* __restrict__ moving_mean, float* __restrict__ moving_var) {\n  T_divide[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] = ((data[((((int)blockIdx.x) * 60) + ((int)threadIdx.x))] - moving_mean[(((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20)) & 3)]) / sqrtf((moving_var[(((((int)blockIdx.x) * 3) + (((int)threadIdx.x) / 20)) & 3)] + 1.000000e-05f)));\n}\n\n", "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 4, 2, 10), \"float32\"), gamma: T.Buffer((4,), \"float32\"), beta: T.Buffer((4,), \"float32\"), moving_mean: T.Buffer((4,), \"float32\"), moving_var: T.Buffer((4,), \"float32\"), T_divide: T.Buffer((3, 4, 2, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(12):\n            T_reshape = T.allocate([1], \"float32\", \"global\")\n            T_reshape_1 = T.allocate([1], \"float32\", \"global\")\n            T_reshape_2 = T.Buffer((1,), data=T_reshape, align=4)\n            T_reshape_2[0] = moving_var[ax0_ax1_fused % 4]\n            for ax2 in range(2):\n                T_reshape_3 = T.Buffer((1,), data=T_reshape_1, align=4)\n                T_reshape_3[0] = moving_mean[ax0_ax1_fused % 4]\n                for ax3 in range(10):\n                    cse_var_1: T.int32 = ax0_ax1_fused * 20 + ax2 * 10 + ax3\n                    T_divide_1 = T.Buffer((240,), data=T_divide.data)\n                    data_1 = T.Buffer((240,), data=data.data)\n                    T_divide_1[cse_var_1] = (data_1[cse_var_1] - T_reshape_3[0]) / T.sqrt(T_reshape_2[0] + T.float32(1.0000000000000001e-05))", "op_args": [3, 4, 2, 10], "input_shape": "[[3, 4, 2, 10], [4], [4], [4], [4]]", "output_shape": "[[3, 4, 2, 10]]"}